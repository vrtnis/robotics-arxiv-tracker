{"2024-10-17T00:00:00Z":{"Robotics":[{"id":"http://arxiv.org/abs/2410.13860v1","updated":"2024-10-17T17:59:55Z","published":"2024-10-17T17:59:55Z","title":"VLM-Grounder: A VLM Agent for Zero-Shot 3D Visual Grounding","summary":"  3D visual grounding is crucial for robots, requiring integration of natural\nlanguage and 3D scene understanding. Traditional methods depending on\nsupervised learning with 3D point clouds are limited by scarce datasets.\nRecently zero-shot methods leveraging LLMs have been proposed to address the\ndata issue. While effective, these methods only use object-centric information,\nlimiting their ability to handle complex queries. In this work, we present\nVLM-Grounder, a novel framework using vision-language models (VLMs) for\nzero-shot 3D visual grounding based solely on 2D images. VLM-Grounder\ndynamically stitches image sequences, employs a grounding and feedback scheme\nto find the target object, and uses a multi-view ensemble projection to\naccurately estimate 3D bounding boxes. Experiments on ScanRefer and Nr3D\ndatasets show VLM-Grounder outperforms previous zero-shot methods, achieving\n51.6% Acc@0.25 on ScanRefer and 48.0% Acc on Nr3D, without relying on 3D\ngeometry or object priors. Codes are available at\nhttps://github.com/OpenRobotLab/VLM-Grounder .\n","authors":["Runsen Xu","Zhiwei Huang","Tai Wang","Yilun Chen","Jiangmiao Pang","Dahua Lin"],"pdf_url":"https://arxiv.org/pdf/2410.13860v1.pdf","comment":"CoRL 2024 Camera Ready. 25 pages. A novel zero-shot 3D visual\n  grounding framework based solely on 2D images"},{"id":"http://arxiv.org/abs/2410.13851v1","updated":"2024-10-17T17:59:02Z","published":"2024-10-17T17:59:02Z","title":"Differentiable Robot Rendering","summary":"  Vision foundation models trained on massive amounts of visual data have shown\nunprecedented reasoning and planning skills in open-world settings. A key\nchallenge in applying them to robotic tasks is the modality gap between visual\ndata and action data. We introduce differentiable robot rendering, a method\nallowing the visual appearance of a robot body to be directly differentiable\nwith respect to its control parameters. Our model integrates a kinematics-aware\ndeformable model and Gaussians Splatting and is compatible with any robot form\nfactors and degrees of freedom. We demonstrate its capability and usage in\napplications including reconstruction of robot poses from images and\ncontrolling robots through vision language models. Quantitative and qualitative\nresults show that our differentiable rendering model provides effective\ngradients for robotic control directly from pixels, setting the foundation for\nthe future applications of vision foundation models in robotics.\n","authors":["Ruoshi Liu","Alper Canberk","Shuran Song","Carl Vondrick"],"pdf_url":"https://arxiv.org/pdf/2410.13851v1.pdf","comment":"Project Page: https://drrobot.cs.columbia.edu/"},{"id":"http://arxiv.org/abs/2410.13847v1","updated":"2024-10-17T17:58:35Z","published":"2024-10-17T17:58:35Z","title":"Adaptive Subsampling and Learned Model Improve Spatiotemporal Resolution\n  of Tactile Skin","summary":"  High-speed tactile arrays are essential for real-time robotic control in\nunstructured environments, but high pixel counts limit readout rates of most\nlarge tactile arrays to below 100Hz. We introduce ACTS - adaptive compressive\ntactile subsampling - a method that efficiently samples tactile matrices and\nreconstructs interactions using sparse recovery and a learned tactile\ndictionary. Tested on a 1024-pixel sensor array (32x32), ACTS increased frame\nrates by 18X compared to raster scanning, with minimal error. For the first\ntime in large-area tactile skin, we demonstrate rapid object classification\nwithin 20ms of contact, high-speed projectile detection, ricochet angle\nestimation, and deformation tracking through enhanced spatiotemporal\nresolution. Our method can be implemented in firmware, upgrading existing\nlow-cost, flexible, and robust tactile arrays into high-resolution systems for\nlarge-area spatiotemporal touch sensing.\n","authors":["Ariel Slepyan","Dian Li","Aidan Aug","Sriramana Sankar","Trac Tran","Nitish Thakor"],"pdf_url":"https://arxiv.org/pdf/2410.13847v1.pdf","comment":"40 pages, 8 main figures, 12 supplemental figures, Videos can be\n  accessed at https://tinyurl.com/TactileSubsampling"},{"id":"http://arxiv.org/abs/2410.13837v1","updated":"2024-10-17T17:55:05Z","published":"2024-10-17T17:55:05Z","title":"ORSO: Accelerating Reward Design via Online Reward Selection and Policy\n  Optimization","summary":"  Reward shaping is a critical component in reinforcement learning (RL),\nparticularly for complex tasks where sparse rewards can hinder learning. While\nshaping rewards have been introduced to provide additional guidance, selecting\neffective shaping functions remains challenging and computationally expensive.\nThis paper introduces Online Reward Selection and Policy Optimization (ORSO), a\nnovel approach that frames shaping reward selection as an online model\nselection problem. ORSO employs principled exploration strategies to\nautomatically identify promising shaping reward functions without human\nintervention, balancing exploration and exploitation with provable regret\nguarantees. We demonstrate ORSO's effectiveness across various continuous\ncontrol tasks using the Isaac Gym simulator. Compared to traditional methods\nthat fully evaluate each shaping reward function, ORSO significantly improves\nsample efficiency, reduces computational time, and consistently identifies\nhigh-quality reward functions that produce policies comparable to those\ngenerated by domain experts through hand-engineered rewards.\n","authors":["Chen Bo Calvin Zhang","Zhang-Wei Hong","Aldo Pacchiano","Pulkit Agrawal"],"pdf_url":"https://arxiv.org/pdf/2410.13837v1.pdf","comment":"preprint, 35 pages, 23 figures"},{"id":"http://arxiv.org/abs/2410.13827v1","updated":"2024-10-17T17:51:51Z","published":"2024-10-17T17:51:51Z","title":"Towards a Factor Graph-Based Method using Angular Rates for Full\n  Magnetometer Calibration and Gyroscope Bias Estimation","summary":"  MEMS Attitude Heading Reference Systems are widely employed to determine a\nsystem's attitude, but sensor measurement biases limit their accuracy. This\npaper introduces a novel factor graph-based method called MAgnetometer and\nGYroscope Calibration (MAGYC). MAGYC leverages three-axis angular rate\nmeasurements from an angular rate gyroscope to enhance calibration for batch\nand online applications. Our approach imposes less restrictive conditions for\ninstrument movements required for calibration, eliminates the need for\nknowledge of the local magnetic field or instrument attitude, and facilitates\nintegration into factor graph algorithms within Smoothing and Mapping\nframeworks. We evaluate the proposed methods through numerical simulations and\nin-field experimental assessments using a sensor installed on an underwater\nvehicle. Ultimately, our proposed methods reduced the underwater vehicle's\nheading error standard deviation from 6.21 to 0.57 degrees for a standard\nseafloor mapping survey.\n","authors":["Sebastián Rodríguez-Martínez","Giancarlo Troni"],"pdf_url":"https://arxiv.org/pdf/2410.13827v1.pdf","comment":"7 pages, 4 figures, submitted to 2024 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS)"},{"id":"http://arxiv.org/abs/2410.13817v1","updated":"2024-10-17T17:46:27Z","published":"2024-10-17T17:46:27Z","title":"Guided Reinforcement Learning for Robust Multi-Contact Loco-Manipulation","summary":"  Reinforcement learning (RL) often necessitates a meticulous Markov Decision\nProcess (MDP) design tailored to each task. This work aims to address this\nchallenge by proposing a systematic approach to behavior synthesis and control\nfor multi-contact loco-manipulation tasks, such as navigating spring-loaded\ndoors and manipulating heavy dishwashers. We define a task-independent MDP to\ntrain RL policies using only a single demonstration per task generated from a\nmodel-based trajectory optimizer. Our approach incorporates an adaptive phase\ndynamics formulation to robustly track the demonstrations while accommodating\ndynamic uncertainties and external disturbances. We compare our method against\nprior motion imitation RL works and show that the learned policies achieve\nhigher success rates across all considered tasks. These policies learn recovery\nmaneuvers that are not present in the demonstration, such as re-grasping\nobjects during execution or dealing with slippages. Finally, we successfully\ntransfer the policies to a real robot, demonstrating the practical viability of\nour approach.\n","authors":["Jean-Pierre Sleiman","Mayank Mittal","Marco Hutter"],"pdf_url":"https://arxiv.org/pdf/2410.13817v1.pdf","comment":"J. P. Sleiman and M. Mittal contributed equally. Accepted for CoRL\n  2024 (Oral). Project website:\n  https://leggedrobotics.github.io/guided-rl-locoma/"},{"id":"http://arxiv.org/abs/2410.13816v1","updated":"2024-10-17T17:46:26Z","published":"2024-10-17T17:46:26Z","title":"Steering Your Generalists: Improving Robotic Foundation Models via Value\n  Guidance","summary":"  Large, general-purpose robotic policies trained on diverse demonstration\ndatasets have been shown to be remarkably effective both for controlling a\nvariety of robots in a range of different scenes, and for acquiring broad\nrepertoires of manipulation skills. However, the data that such policies are\ntrained on is generally of mixed quality -- not only are human-collected\ndemonstrations unlikely to perform the task perfectly, but the larger the\ndataset is, the harder it is to curate only the highest quality examples. It\nalso remains unclear how optimal data from one embodiment is for training on\nanother embodiment. In this paper, we present a general and broadly applicable\napproach that enhances the performance of such generalist robot policies at\ndeployment time by re-ranking their actions according to a value function\nlearned via offline RL. This approach, which we call Value-Guided Policy\nSteering (V-GPS), is compatible with a wide range of different generalist\npolicies, without needing to fine-tune or even access the weights of the\npolicy. We show that the same value function can improve the performance of\nfive different state-of-the-art policies with different architectures, even\nthough they were trained on distinct datasets, attaining consistent performance\nimprovement on multiple robotic platforms across a total of 12 tasks. Code and\nvideos can be found at: https://nakamotoo.github.io/V-GPS\n","authors":["Mitsuhiko Nakamoto","Oier Mees","Aviral Kumar","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2410.13816v1.pdf","comment":"Conference on Robot Learning (CoRL) 2024. Project Page:\n  https://nakamotoo.github.io/V-GPS"},{"id":"http://arxiv.org/abs/2410.13756v1","updated":"2024-10-17T16:53:43Z","published":"2024-10-17T16:53:43Z","title":"CLIMB: Language-Guided Continual Learning for Task Planning with\n  Iterative Model Building","summary":"  Intelligent and reliable task planning is a core capability for generalized\nrobotics, requiring a descriptive domain representation that sufficiently\nmodels all object and state information for the scene. We present CLIMB, a\ncontinual learning framework for robot task planning that leverages foundation\nmodels and execution feedback to guide domain model construction. CLIMB can\nbuild a model from a natural language description, learn non-obvious predicates\nwhile solving tasks, and store that information for future problems. We\ndemonstrate the ability of CLIMB to improve performance in common planning\nenvironments compared to baseline methods. We also develop the BlocksWorld++\ndomain, a simulated environment with an easily usable real counterpart,\ntogether with a curriculum of tasks with progressing difficulty for evaluating\ncontinual learning. Additional details and demonstrations for this system can\nbe found at https://plan-with-climb.github.io/ .\n","authors":["Walker Byrnes","Miroslav Bogdanovic","Avi Balakirsky","Stephen Balakirsky","Animesh Garg"],"pdf_url":"https://arxiv.org/pdf/2410.13756v1.pdf","comment":"6 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.13755v1","updated":"2024-10-17T16:53:37Z","published":"2024-10-17T16:53:37Z","title":"Interacting humans and robots can improve sensory prediction by adapting\n  their viscoelasticity","summary":"  To manipulate objects or dance together, humans and robots exchange energy\nand haptic information. While the exchange of energy in human-robot interaction\nhas been extensively investigated, the underlying exchange of haptic\ninformation is not well understood. Here, we develop a computational model of\nthe mechanical and sensory interactions between agents that can tune their\nviscoelasticity while considering their sensory and motor noise. The resulting\nstochastic-optimal-information-and-effort (SOIE) controller predicts how the\nexchange of haptic information and the performance can be improved by adjusting\nviscoelasticity. This controller was first implemented on a robot-robot\nexperiment with a tracking task which showed its superior performance when\ncompared to either stiff or compliant control. Importantly, the optimal\ncontroller also predicts how connected humans alter their muscle activation to\nimprove haptic communication, with differentiated viscoelasticity adjustment to\ntheir own sensing noise and haptic perturbations. A human-robot experiment then\nillustrated the applicability of this optimal control strategy for robots,\nyielding improved tracking performance and effective haptic communication as\nthe robot adjusted its viscoelasticity according to its own and the user's\nnoise characteristics. The proposed SOIE controller may thus be used to improve\nhaptic communication and collaboration of humans and robots.\n","authors":["Xiaoxiao Cheng","Jonathan Eden","Bastien Berret","Atsushi Takagi","Etienne Burdet"],"pdf_url":"https://arxiv.org/pdf/2410.13755v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13691v1","updated":"2024-10-17T15:55:36Z","published":"2024-10-17T15:55:36Z","title":"Jailbreaking LLM-Controlled Robots","summary":"  The recent introduction of large language models (LLMs) has revolutionized\nthe field of robotics by enabling contextual reasoning and intuitive\nhuman-robot interaction in domains as varied as manipulation, locomotion, and\nself-driving vehicles. When viewed as a stand-alone technology, LLMs are known\nto be vulnerable to jailbreaking attacks, wherein malicious prompters elicit\nharmful text by bypassing LLM safety guardrails. To assess the risks of\ndeploying LLMs in robotics, in this paper, we introduce RoboPAIR, the first\nalgorithm designed to jailbreak LLM-controlled robots. Unlike existing, textual\nattacks on LLM chatbots, RoboPAIR elicits harmful physical actions from\nLLM-controlled robots, a phenomenon we experimentally demonstrate in three\nscenarios: (i) a white-box setting, wherein the attacker has full access to the\nNVIDIA Dolphins self-driving LLM, (ii) a gray-box setting, wherein the attacker\nhas partial access to a Clearpath Robotics Jackal UGV robot equipped with a\nGPT-4o planner, and (iii) a black-box setting, wherein the attacker has only\nquery access to the GPT-3.5-integrated Unitree Robotics Go2 robot dog. In each\nscenario and across three new datasets of harmful robotic actions, we\ndemonstrate that RoboPAIR, as well as several static baselines, finds\njailbreaks quickly and effectively, often achieving 100% attack success rates.\nOur results reveal, for the first time, that the risks of jailbroken LLMs\nextend far beyond text generation, given the distinct possibility that\njailbroken robots could cause physical damage in the real world. Indeed, our\nresults on the Unitree Go2 represent the first successful jailbreak of a\ndeployed commercial robotic system. Addressing this emerging vulnerability is\ncritical for ensuring the safe deployment of LLMs in robotics. Additional media\nis available at: https://robopair.org\n","authors":["Alexander Robey","Zachary Ravichandran","Vijay Kumar","Hamed Hassani","George J. Pappas"],"pdf_url":"https://arxiv.org/pdf/2410.13691v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.16312v3","updated":"2024-10-17T15:49:34Z","published":"2024-04-25T03:38:07Z","title":"3D Guidance Law for Flexible Target Enclosing with Inherent Safety","summary":"  In this paper, we address the problem of enclosing an arbitrarily moving\ntarget in three dimensions by a single pursuer while ensuring the pursuer's\nsafety by preventing collisions with the target. The proposed guidance strategy\nsteers the pursuer to a safe region of space surrounding and excluding the\ntarget, allowing it to maintain a certain distance from the latter while\noffering greater flexibility in positioning and converging to any orbit within\nthis safe zone. We leverage the concept of the Lyapunov Barrier Function as a\npowerful tool to constrain the distance between the pursuer and the target\nwithin asymmetric bounds, thereby ensuring the pursuer's safety within the\npredefined region. Further, we demonstrate the effectiveness of the proposed\nguidance law in managing arbitrarily maneuvering targets and other\nuncertainties (such as vehicle/autopilot dynamics and external disturbances) by\nenabling the pursuer to consistently achieve stable global enclosing behaviors\nby switching between stable enclosing trajectories within the safe region\nwhenever necessary, even in response to aggressive target maneuvers. To attest\nto the merits of our work, we conduct experimental tests with various plant\nmodels, including a high-fidelity quadrotor model within Software-in-the-loop\n(SITL) simulations, encompassing various challenging target maneuver scenarios\nand requiring only relative information for successful execution.\n","authors":["Praveen Kumar Ranjan","Abhinav Sinha","Yongcan Cao"],"pdf_url":"https://arxiv.org/pdf/2404.16312v3.pdf","comment":"Supplementary video at https://youtu.be/UU704o_966s"},{"id":"http://arxiv.org/abs/2408.13759v2","updated":"2024-10-17T15:21:05Z","published":"2024-08-25T08:04:20Z","title":"MASQ: Multi-Agent Reinforcement Learning for Single Quadruped Robot\n  Locomotion","summary":"  This paper proposes a novel method to improve locomotion learning for a\nsingle quadruped robot using multi-agent deep reinforcement learning (MARL).\nMany existing methods use single-agent reinforcement learning for an individual\nrobot or MARL for the cooperative task in multi-robot systems. Unlike existing\nmethods, this paper proposes using MARL for the locomotion learning of a single\nquadruped robot. We develop a learning structure called Multi-Agent\nReinforcement Learning for Single Quadruped Robot Locomotion (MASQ),\nconsidering each leg as an agent to explore the action space of the quadruped\nrobot, sharing a global critic, and learning collaboratively. Experimental\nresults indicate that MASQ not only speeds up learning convergence but also\nenhances robustness in real-world settings, suggesting that applying MASQ to\nsingle robots such as quadrupeds could surpass traditional single-robot\nreinforcement learning approaches. Our study provides insightful guidance on\nintegrating MARL with single-robot locomotion learning.\n","authors":["Qi Liu","Jingxiang Guo","Sixu Lin","Shuaikang Ma","Jinxuan Zhu","Yanjie Li"],"pdf_url":"https://arxiv.org/pdf/2408.13759v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13612v1","updated":"2024-10-17T14:46:37Z","published":"2024-10-17T14:46:37Z","title":"Automatic Navigation and Voice Cloning Technology Deployment on a\n  Humanoid Robot","summary":"  Mobile robots have shown immense potential and are expected to be widely used\nin the service industry. The importance of automatic navigation and voice\ncloning cannot be overstated as they enable functional robots to provide\nhigh-quality services. The objective of this work is to develop a control\nalgorithm for the automatic navigation of a humanoid mobile robot called Cruzr,\nwhich is a service robot manufactured by Ubtech. Initially, a virtual\nenvironment is constructed in the simulation software Gazebo using Simultaneous\nLocalization And Mapping (SLAM), and global path planning is carried out by\nmeans of local path tracking. The two-wheel differential chassis kinematics\nmodel is employed to ensure autonomous dynamic obstacle avoidance for the robot\nchassis. Furthermore, the mapping and trajectory generation algorithms\ndeveloped in the simulation environment are successfully implemented on the\nreal robot Cruzr. The performance of automatic navigation is compared between\nthe Dynamic Window Approach (DWA) and Model Predictive Control (MPC)\nalgorithms. Additionally, a mobile application for voice cloning is created\nbased on a Hidden Markov Model, and the proposed Chatbot is also tested and\ndeployed on Cruzr.\n","authors":["Dongkun Han","Boyuan Shao"],"pdf_url":"https://arxiv.org/pdf/2410.13612v1.pdf","comment":"7 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.13586v1","updated":"2024-10-17T14:21:32Z","published":"2024-10-17T14:21:32Z","title":"Preference Aligned Diffusion Planner for Quadrupedal Locomotion Control","summary":"  Diffusion models demonstrate superior performance in capturing complex\ndistributions from large-scale datasets, providing a promising solution for\nquadrupedal locomotion control. However, offline policy is sensitive to\nOut-of-Distribution (OOD) states due to the limited state coverage in the\ndatasets. In this work, we propose a two-stage learning framework combining\noffline learning and online preference alignment for legged locomotion control.\nThrough the offline stage, the diffusion planner learns the joint distribution\nof state-action sequences from expert datasets without using reward labels.\nSubsequently, we perform the online interaction in the simulation environment\nbased on the trained offline planer, which significantly addresses the OOD\nissues and improves the robustness. Specifically, we propose a novel weak\npreference labeling method without the ground-truth reward or human\npreferences. The proposed method exhibits superior stability and velocity\ntracking accuracy in pacing, trotting, and bounding gait under both slow- and\nhigh-speed scenarios and can perform zero-shot transfer to the real Unitree Go1\nrobots. The project website for this paper is at\nhttps://shangjaven.github.io/preference-aligned-diffusion-legged/.\n","authors":["Xinyi Yuan","Zhiwei Shang","Zifan Wang","Chenkai Wang","Zhao Shan","Zhenchao Qi","Meixin Zhu","Chenjia Bai","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2410.13586v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13573v1","updated":"2024-10-17T14:09:51Z","published":"2024-10-17T14:09:51Z","title":"SPF-EMPC Planner: A real-time multi-robot trajectory planner for complex\n  environments with uncertainties","summary":"  In practical applications, the unpredictable movement of obstacles and the\nimprecise state observation of robots introduce significant uncertainties for\nthe swarm of robots, especially in cluster environments. However, existing\nmethods are difficult to realize safe navigation, considering uncertainties,\ncomplex environmental structures, and robot swarms. This paper introduces an\nextended state model predictive control planner with a safe probability field\nto address the multi-robot navigation problem in complex, dynamic, and\nuncertain environments. Initially, the safe probability field offers an\ninnovative approach to model the uncertainty of external dynamic obstacles,\ncombining it with an unconstrained optimization method to generate safe\ntrajectories for multi-robot online. Subsequently, the extended state model\npredictive controller can accurately track these generated trajectories while\nconsidering the robots' inherent model constraints and state uncertainty, thus\nensuring the practical feasibility of the planned trajectories. Simulation\nexperiments show a success rate four times higher than that of state-of-the-art\nalgorithms. Physical experiments demonstrate the method's ability to operate in\nreal-time, enabling safe navigation for multi-robot in uncertain environments.\n","authors":["Peng Liu","Pengming Zhu","Zhiwen Zeng","Xuekai Qiu","Yu Wang","Huimin Lu"],"pdf_url":"https://arxiv.org/pdf/2410.13573v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13541v1","updated":"2024-10-17T13:32:13Z","published":"2024-10-17T13:32:13Z","title":"DualQuat-LOAM: LiDAR Odometry and Mapping parametrized on Dual\n  Quaternions","summary":"  This paper reports on a novel method for LiDAR odometry estimation, which\ncompletely parameterizes the system with dual quaternions. To accomplish this,\nthe features derived from the point cloud, including edges, surfaces, and\nStable Triangle Descriptor (STD), along with the optimization problem, are\nexpressed in the dual quaternion set. This approach enables the direct\ncombination of translation and orientation errors via dual quaternion\noperations, greatly enhancing pose estimation, as demonstrated in comparative\nexperiments against other state-of-the-art methods. Our approach reduced drift\nerror compared to other LiDAR-only-odometry methods, especially in scenarios\nwith sharp curves and aggressive movements with large angular displacement.\nDualQuat-LOAM is benchmarked against several public datasets. In the KITTI\ndataset it has a translation and rotation error of 0.79% and 0.0039{\\deg}/m,\nwith an average run time of 53 ms.\n","authors":["Edison P. Velasco-Sánchez","Luis F. Recalde","Guanrui Li","Francisco A. Candelas-Herias","Santiago T. Puente-Mendez","Fernando Torres-Medina"],"pdf_url":"https://arxiv.org/pdf/2410.13541v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13514v1","updated":"2024-10-17T13:02:06Z","published":"2024-10-17T13:02:06Z","title":"CERES: Critical-Event Reconstruction via Temporal Scene Graph Completion","summary":"  This paper proposes a method for on-demand scenario generation in simulation,\ngrounded on real-world data. Evaluating the behaviour of Autonomous Vehicles\n(AVs) in both safety-critical and regular scenarios is essential for assessing\ntheir robustness before real-world deployment. By integrating scenarios derived\nfrom real-world datasets into the simulation, we enhance the plausibility and\nvalidity of testing sets. This work introduces a novel approach that employs\ntemporal scene graphs to capture evolving spatiotemporal relationships among\nscene entities from a real-world dataset, enabling the generation of dynamic\nscenarios in simulation through Graph Neural Networks (GNNs). User-defined\naction and criticality conditioning are used to ensure flexible, tailored\nscenario creation. Our model significantly outperforms the benchmarks in\naccurately predicting links corresponding to the requested scenarios. We\nfurther evaluate the validity and compatibility of our generated scenarios in\nan off-the-shelf simulator.\n","authors":["Efimia Panagiotaki","Georgi Pramatarov","Lars Kunze","Daniele De Martini"],"pdf_url":"https://arxiv.org/pdf/2410.13514v1.pdf","comment":"7 pages, 8 figures"},{"id":"http://arxiv.org/abs/2410.13496v1","updated":"2024-10-17T12:43:14Z","published":"2024-10-17T12:43:14Z","title":"State Estimation Transformers for Agile Legged Locomotion","summary":"  We propose a state estimation method that can accurately predict the robot's\nprivileged states to push the limits of quadruped robots in executing advanced\nskills such as jumping in the wild. In particular, we present the State\nEstimation Transformers (SET), an architecture that casts the state estimation\nproblem as conditional sequence modeling. SET outputs the robot states that are\nhard to obtain directly in the real world, such as the body height and\nvelocities, by leveraging a causally masked Transformer. By conditioning an\nautoregressive model on the robot's past states, our SET model can predict\nthese privileged observations accurately even in highly dynamic locomotions. We\nevaluate our methods on three tasks -- running jumping, running backflipping,\nand running sideslipping -- on a low-cost quadruped robot, Cyberdog2. Results\nshow that SET can outperform other methods in estimation accuracy and\ntransferability in the simulation as well as success rates of jumping and\ntriggering a recovery controller in the real world, suggesting the superiority\nof such a Transformer-based explicit state estimator in highly dynamic\nlocomotion tasks.\n","authors":["Chen Yu","Yichu Yang","Tianlin Liu","Yangwei You","Mingliang Zhou","Diyun Xiang"],"pdf_url":"https://arxiv.org/pdf/2410.13496v1.pdf","comment":"Accepted by IROS 2024"},{"id":"http://arxiv.org/abs/2410.13490v1","updated":"2024-10-17T12:34:37Z","published":"2024-10-17T12:34:37Z","title":"Novelty-based Sample Reuse for Continuous Robotics Control","summary":"  In reinforcement learning, agents collect state information and rewards\nthrough environmental interactions, essential for policy refinement. This\nprocess is notably time-consuming, especially in complex robotic simulations\nand real-world applications. Traditional algorithms usually re-engage with the\nenvironment after processing a single batch of samples, thereby failing to\nfully capitalize on historical data. However, frequently observed states, with\nreliable value estimates, require minimal updates; in contrast, rare observed\nstates necessitate more intensive updates for achieving accurate value\nestimations. To address uneven sample utilization, we propose Novelty-guided\nSample Reuse (NSR). NSR provides extra updates for infrequent, novel states and\nskips additional updates for frequent states, maximizing sample use before\ninteracting with the environment again. Our experiments show that NSR improves\nthe convergence rate and success rate of algorithms without significantly\nincreasing time consumption. Our code is publicly available at\nhttps://github.com/ppksigs/NSR-DDPG-HER.\n","authors":["Ke Duan","Kai Yang","Houde Liu","Xueqian Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13490v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.16617v2","updated":"2024-10-17T12:11:45Z","published":"2024-07-23T16:27:24Z","title":"Motion Accuracy and Computational Effort in QP-based Robot Control","summary":"  Quadratic Programs (QPs) have become a mature technology for the control of\nrobots of all kinds, including humanoid robots. One aspect has been largely\noverlooked, however, which is the accuracy with which these QPs should be\nsolved. QP solvers aim at providing solutions accurate up to floating point\nprecision ($\\approx10^{-8}$). Considering physical quantities expressed in SI\nor similar units (meters, radians, etc.), such precision seems completely\nunrelated to both task requirements and hardware capacity. Typically, humanoid\nrobots never achieve, nor are capable of achieving sub-millimeter precision in\nmanipulation tasks. With this observation in mind, our objectives in this paper\nare two-fold: first examine how the QP solution accuracy impacts the resulting\nrobot motion accuracy, then evaluate how a reduced solution accuracy\nrequirement can be leveraged to reduce the corresponding computational effort.\nExperiments with a dynamic simulation of RHPS-1 humanoid robot indicate that\ncomputational effort can be divided by more than 27 while maintaining the\ndesired motion accuracy.\n","authors":["Sélim Chefchaouni","Mehdi Benallegue","Adrien Escande","Pierre-Brice Wieber"],"pdf_url":"https://arxiv.org/pdf/2407.16617v2.pdf","comment":"Submitted to 2024 IEEE-RAS International Conference on Humanoid\n  Robots (Humanoids)"},{"id":"http://arxiv.org/abs/2410.09747v2","updated":"2024-10-17T11:14:37Z","published":"2024-10-13T06:53:58Z","title":"t-READi: Transformer-Powered Robust and Efficient Multimodal Inference\n  for Autonomous Driving","summary":"  Given the wide adoption of multimodal sensors (e.g., camera, lidar, radar) by\nautonomous vehicles (AVs), deep analytics to fuse their outputs for a robust\nperception become imperative. However, existing fusion methods often make two\nassumptions rarely holding in practice: i) similar data distributions for all\ninputs and ii) constant availability for all sensors. Because, for example,\nlidars have various resolutions and failures of radars may occur, such\nvariability often results in significant performance degradation in fusion. To\nthis end, we present tREADi, an adaptive inference system that accommodates the\nvariability of multimodal sensory data and thus enables robust and efficient\nperception. t-READi identifies variation-sensitive yet structure-specific model\nparameters; it then adapts only these parameters while keeping the rest intact.\nt-READi also leverages a cross-modality contrastive learning method to\ncompensate for the loss from missing modalities. Both functions are implemented\nto maintain compatibility with existing multimodal deep fusion methods. The\nextensive experiments evidently demonstrate that compared with the status quo\napproaches, t-READi not only improves the average inference accuracy by more\nthan 6% but also reduces the inference latency by almost 15x with the cost of\nonly 5% extra memory overhead in the worst case under realistic data and modal\nvariations.\n","authors":["Pengfei Hu","Yuhang Qian","Tianyue Zheng","Ang Li","Zhe Chen","Yue Gao","Xiuzhen Cheng","Jun Luo"],"pdf_url":"https://arxiv.org/pdf/2410.09747v2.pdf","comment":"14 pages, 16 figures"},{"id":"http://arxiv.org/abs/2410.13418v1","updated":"2024-10-17T10:40:31Z","published":"2024-10-17T10:40:31Z","title":"Interactive Navigation with Adaptive Non-prehensile Mobile Manipulation","summary":"  This paper introduces a framework for interactive navigation through adaptive\nnon-prehensile mobile manipulation. A key challenge in this process is handling\nobjects with unknown dynamics, which are difficult to infer from visual\nobservation. To address this, we propose an adaptive dynamics model for common\nmovable indoor objects via learned SE(2) dynamics representations. This model\nis integrated into Model Predictive Path Integral (MPPI) control to guide the\nrobot's interactions. Additionally, the learned dynamics help inform\ndecision-making when navigating around objects that cannot be manipulated.Our\napproach is validated in both simulation and real-world scenarios,\ndemonstrating its ability to accurately represent object dynamics and\neffectively manipulate various objects. We further highlight its success in the\nNavigation Among Movable Objects (NAMO) task by deploying the proposed\nframework on a dynamically balancing mobile robot, Shmoobot. Project website:\nhttps://cmushmoobot.github.io/AdaptivePushing/.\n","authors":["Cunxi Dai","Xiaohan Liu","Koushil Sreenath","Zhongyu Li","Ralph Hollis"],"pdf_url":"https://arxiv.org/pdf/2410.13418v1.pdf","comment":"7 pages, 8 figures"},{"id":"http://arxiv.org/abs/2410.13412v1","updated":"2024-10-17T10:21:28Z","published":"2024-10-17T10:21:28Z","title":"RAMPA: Robotic Augmented Reality for Machine Programming and Automation","summary":"  As robotics continue to enter various sectors beyond traditional industrial\napplications, the need for intuitive robot training and interaction systems\nbecomes increasingly more important. This paper introduces Robotic Augmented\nReality for Machine Programming (RAMPA), a system that utilizes the\ncapabilities of state-of-the-art and commercially available AR headsets, e.g.,\nMeta Quest 3, to facilitate the application of Programming from Demonstration\n(PfD) approaches on industrial robotic arms, such as Universal Robots UR10. Our\napproach enables in-situ data recording, visualization, and fine-tuning of\nskill demonstrations directly within the user's physical environment. RAMPA\naddresses critical challenges of PfD, such as safety concerns, programming\nbarriers, and the inefficiency of collecting demonstrations on the actual\nhardware. The performance of our system is evaluated against the traditional\nmethod of kinesthetic control in teaching three different robotic manipulation\ntasks and analyzed with quantitative metrics, measuring task performance and\ncompletion time, trajectory smoothness, system usability, user experience, and\ntask load using standardized surveys. Our findings indicate a substantial\nadvancement in how robotic tasks are taught and refined, promising improvements\nin operational safety, efficiency, and user engagement in robotic programming.\n","authors":["Fatih Dogangun","Serdar Bahar","Yigit Yildirim","Bora Toprak Temir","Emre Ugur","Mustafa Doga Dogan"],"pdf_url":"https://arxiv.org/pdf/2410.13412v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2410.13407v1","updated":"2024-10-17T10:09:44Z","published":"2024-10-17T10:09:44Z","title":"BestMan: A Modular Mobile Manipulator Platform for Embodied AI with\n  Unified Simulation-Hardware APIs","summary":"  Embodied Artificial Intelligence (Embodied AI) emphasizes agents' ability to\nperceive, understand, and act in physical environments. Simulation platforms\nplay a crucial role in advancing this field by enabling the validation and\noptimization of algorithms. However, existing platforms face challenges such as\nmultilevel technical integration complexity, insufficient modularity, interface\nheterogeneity, and adaptation to diverse hardware. We present BestMan, a\nsimulation platform based on PyBullet, designed to address these issues.\nBestMan introduces an integrated multilevel skill chain for seamless\ncoordination across perception, planning, and control; a highly modular\narchitecture for flexible algorithm integration; unified interfaces for smooth\nsimulation-to-reality transfer; and a hardware-agnostic approach for adapting\nto various mobile manipulator configurations. These features collectively\nsimplify development and enhance platform expandability, making BestMan a\nvaluable tool for Embodied AI research.\n","authors":["Kui Yang","Nieqing Cao","Yan Ding","Chao Chen"],"pdf_url":"https://arxiv.org/pdf/2410.13407v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11989v2","updated":"2024-10-17T10:06:12Z","published":"2024-10-15T18:52:22Z","title":"Dynamic Open-Vocabulary 3D Scene Graphs for Long-term Language-Guided\n  Mobile Manipulation","summary":"  Enabling mobile robots to perform long-term tasks in dynamic real-world\nenvironments is a formidable challenge, especially when the environment changes\nfrequently due to human-robot interactions or the robot's own actions.\nTraditional methods typically assume static scenes, which limits their\napplicability in the continuously changing real world. To overcome these\nlimitations, we present DovSG, a novel mobile manipulation framework that\nleverages dynamic open-vocabulary 3D scene graphs and a language-guided task\nplanning module for long-term task execution. DovSG takes RGB-D sequences as\ninput and utilizes vision-language models (VLMs) for object detection to obtain\nhigh-level object semantic features. Based on the segmented objects, a\nstructured 3D scene graph is generated for low-level spatial relationships.\nFurthermore, an efficient mechanism for locally updating the scene graph,\nallows the robot to adjust parts of the graph dynamically during interactions\nwithout the need for full scene reconstruction. This mechanism is particularly\nvaluable in dynamic environments, enabling the robot to continually adapt to\nscene changes and effectively support the execution of long-term tasks. We\nvalidated our system in real-world environments with varying degrees of manual\nmodifications, demonstrating its effectiveness and superior performance in\nlong-term tasks. Our project page is available at:\nhttps://BJHYZJ.github.io/DoviSG.\n","authors":["Zhijie Yan","Shufei Li","Zuoxu Wang","Lixiu Wu","Han Wang","Jun Zhu","Lijiang Chen","Jihong Liu"],"pdf_url":"https://arxiv.org/pdf/2410.11989v2.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2403.15569v2","updated":"2024-10-17T09:58:52Z","published":"2024-03-22T18:47:54Z","title":"Music to Dance as Language Translation using Sequence Models","summary":"  Synthesising appropriate choreographies from music remains an open problem.\nWe introduce MDLT, a novel approach that frames the choreography generation\nproblem as a translation task. Our method leverages an existing data set to\nlearn to translate sequences of audio into corresponding dance poses. We\npresent two variants of MDLT: one utilising the Transformer architecture and\nthe other employing the Mamba architecture. We train our method on AIST++ and\nPhantomDance data sets to teach a robotic arm to dance, but our method can be\napplied to a full humanoid robot. Evaluation metrics, including Average Joint\nError and Fr\\'echet Inception Distance, consistently demonstrate that, when\ngiven a piece of music, MDLT excels at producing realistic and high-quality\nchoreography. The code can be found at github.com/meowatthemoon/MDLT.\n","authors":["André Correia","Luís A. Alexandre"],"pdf_url":"https://arxiv.org/pdf/2403.15569v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12345v2","updated":"2024-10-17T08:36:25Z","published":"2024-10-16T08:05:56Z","title":"A Data-driven Contact Estimation Method for Wheeled-Biped Robots","summary":"  Contact estimation is a key ability for limbed robots, where making and\nbreaking contacts has a direct impact on state estimation and balance control.\nExisting approaches typically rely on gate-cycle priors or designated contact\nsensors. We design a contact estimator that is suitable for the emerging\nwheeled-biped robot types that do not have these features. To this end, we\npropose a Bayes filter in which update steps are learned from real-robot torque\nmeasurements while prediction steps rely on inertial measurements. We evaluate\nthis approach in extensive real-robot and simulation experiments. Our method\nachieves better performance while being considerably more sample efficient than\na comparable deep-learning baseline.\n","authors":["Ü. Bora Gökbakan","Frederike Dümbgen","Stéphane Caron"],"pdf_url":"https://arxiv.org/pdf/2410.12345v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13322v1","updated":"2024-10-17T08:25:44Z","published":"2024-10-17T08:25:44Z","title":"Arc-Length-Based Warping for Robot Skill Synthesis from Multiple\n  Demonstrations","summary":"  In robotics, Learning from Demonstration (LfD) aims to transfer skills to\nrobots by using multiple demonstrations of the same task. These demonstrations\nare recorded and processed to extract a consistent skill representation. This\nprocess typically requires temporal alignment through techniques such as\nDynamic Time Warping (DTW). In this paper, we introduce a novel algorithm,\nnamed Spatial Sampling (SS), specifically designed for robot trajectories, that\nenables time-independent alignment of the trajectories by providing an\narc-length parametrization of the signals. This approach eliminates the need\nfor temporal alignment, enhancing the accuracy and robustness of skill\nrepresentation. Specifically, we show that large time shifts in the\ndemonstrated trajectories can introduce uncertainties in the synthesis of the\nfinal trajectory, which alignment in the arc-length domain can drastically\nreduce, in comparison with various state-of-the-art time-based signal alignment\nalgorithms. To this end, we built a custom publicly available dataset of robot\nrecordings to test real-world trajectories.\n","authors":["Giovanni Braglia","Davide Tebaldi","André Eugenio Lazzaretti","Luigi Biagiotti"],"pdf_url":"https://arxiv.org/pdf/2410.13322v1.pdf","comment":"8 pages, 8 figures"},{"id":"http://arxiv.org/abs/2410.13240v1","updated":"2024-10-17T05:47:45Z","published":"2024-10-17T05:47:45Z","title":"TRLO: An Efficient LiDAR Odometry with 3D Dynamic Object Tracking and\n  Removal","summary":"  Simultaneous state estimation and mapping is an essential capability for\nmobile robots working in dynamic urban environment. The majority of existing\nSLAM solutions heavily rely on a primarily static assumption. However, due to\nthe presence of moving vehicles and pedestrians, this assumption does not\nalways hold, leading to localization accuracy decreased and maps distorted. To\naddress this challenge, we propose TRLO, a dynamic LiDAR odometry that\nefficiently improves the accuracy of state estimation and generates a cleaner\npoint cloud map. To efficiently detect dynamic objects in the surrounding\nenvironment, a deep learning-based method is applied, generating detection\nbounding boxes. We then design a 3D multi-object tracker based on Unscented\nKalman Filter (UKF) and nearest neighbor (NN) strategy to reliably identify and\nremove dynamic objects. Subsequently, a fast two-stage iterative nearest point\nsolver is employed to solve the state estimation using cleaned static point\ncloud. Note that a novel hash-based keyframe database management is proposed\nfor fast access to search keyframes. Furthermore, all the detected object\nbounding boxes are leveraged to impose posture consistency constraint to\nfurther refine the final state estimation. Extensive evaluations and ablation\nstudies conducted on the KITTI and UrbanLoco datasets demonstrate that our\napproach not only achieves more accurate state estimation but also generates\ncleaner maps, compared with baselines.\n","authors":["Yanpeng Jia","Ting Wang","Xieyuanli Chen","Shiliang Shao"],"pdf_url":"https://arxiv.org/pdf/2410.13240v1.pdf","comment":"8pages, 5figures"},{"id":"http://arxiv.org/abs/2406.14558v2","updated":"2024-10-17T04:41:22Z","published":"2024-06-20T17:59:22Z","title":"CooHOI: Learning Cooperative Human-Object Interaction with Manipulated\n  Object Dynamics","summary":"  Recent years have seen significant advancements in humanoid control, largely\ndue to the availability of large-scale motion capture data and the application\nof reinforcement learning methodologies. However, many real-world tasks, such\nas moving large and heavy furniture, require multi-character collaboration.\nGiven the scarcity of data on multi-character collaboration and the efficiency\nchallenges associated with multi-agent learning, these tasks cannot be\nstraightforwardly addressed using training paradigms designed for single-agent\nscenarios. In this paper, we introduce Cooperative Human-Object Interaction\n(CooHOI), a novel framework that addresses multi-character objects transporting\nthrough a two-phase learning paradigm: individual skill acquisition and\nsubsequent transfer. Initially, a single agent learns to perform tasks using\nthe Adversarial Motion Priors (AMP) framework. Following this, the agent learns\nto collaborate with others by considering the shared dynamics of the\nmanipulated object during parallel training using Multi Agent Proximal Policy\nOptimization (MAPPO). When one agent interacts with the object, resulting in\nspecific object dynamics changes, the other agents learn to respond\nappropriately, thereby achieving implicit communication and coordination\nbetween teammates. Unlike previous approaches that relied on tracking-based\nmethods for multi-character HOI, CooHOI is inherently efficient, does not\ndepend on motion capture data of multi-character interactions, and can be\nseamlessly extended to include more participants and a wide range of object\ntypes.\n","authors":["Jiawei Gao","Ziqin Wang","Zeqi Xiao","Jingbo Wang","Tai Wang","Jinkun Cao","Xiaolin Hu","Si Liu","Jifeng Dai","Jiangmiao Pang"],"pdf_url":"https://arxiv.org/pdf/2406.14558v2.pdf","comment":"Project website: https://gao-jiawei.com/Research/CooHOI/. NeurIPS\n  2024 Spotlight"},{"id":"http://arxiv.org/abs/2404.03570v2","updated":"2024-10-17T04:17:15Z","published":"2024-04-04T16:30:20Z","title":"Embodied AI with Two Arms: Zero-shot Learning, Safety and Modularity","summary":"  We present an embodied AI system which receives open-ended natural language\ninstructions from a human, and controls two arms to collaboratively accomplish\npotentially long-horizon tasks over a large workspace. Our system is modular:\nit deploys state of the art Large Language Models for task\nplanning,Vision-Language models for semantic perception, and Point Cloud\ntransformers for grasping. With semantic and physical safety in mind, these\nmodules are interfaced with a real-time trajectory optimizer and a compliant\ntracking controller to enable human-robot proximity. We demonstrate performance\nfor the following tasks: bi-arm sorting, bottle opening, and trash disposal\ntasks. These are done zero-shot where the models used have not been trained\nwith any real world data from this bi-arm robot, scenes or workspace. Composing\nboth learning- and non-learning-based components in a modular fashion with\ninterpretable inputs and outputs allows the user to easily debug points of\nfailures and fragilities. One may also in-place swap modules to improve the\nrobustness of the overall platform, for instance with imitation-learned\npolicies. https://sites.google.com/corp/view/safe-robots\n","authors":["Jake Varley","Sumeet Singh","Deepali Jain","Krzysztof Choromanski","Andy Zeng","Somnath Basu Roy Chowdhury","Avinava Dubey","Vikas Sindhwani"],"pdf_url":"https://arxiv.org/pdf/2404.03570v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02912v3","updated":"2024-10-17T03:35:21Z","published":"2024-08-06T02:53:55Z","title":"KOI: Accelerating Online Imitation Learning via Hybrid Key-state\n  Guidance","summary":"  Online Imitation Learning struggles with the gap between extensive online\nexploration space and limited expert trajectories, hindering efficient\nexploration due to inaccurate reward estimation. Inspired by the findings from\ncognitive neuroscience, we hypothesize that an agent could estimate precise\ntask-aware reward for efficient online exploration, through decomposing the\ntarget task into the objectives of \"what to do\" and the mechanisms of \"how to\ndo\". In this work, we introduce the hybrid Key-state guided Online Imitation\n(KOI) learning method, which leverages the integration of semantic and motion\nkey states as guidance for reward estimation. Initially, we utilize\nvisual-language models to extract semantic key states from expert trajectory,\nindicating the objectives of \"what to do\". Within the intervals between\nsemantic key states, optical flow is employed to capture motion key states to\nunderstand the mechanisms of \"how to do\". By integrating a thorough grasp of\nhybrid key states, we refine the trajectory-matching reward computation,\naccelerating online imitation learning with task-aware exploration. We evaluate\nnot only the success rate of the tasks in the Meta-World and LIBERO\nenvironments, but also the trend of variance during online imitation learning,\nproving that our method is more sample efficient. We also conduct real-world\nrobotic manipulation experiments to validate the efficacy of our method,\ndemonstrating the practical applicability of our KOI method. Videos and code\nare available at https://gewu-lab.github.io/Keystate_Online_Imitation/.\n","authors":["Jingxian Lu","Wenke Xia","Dong Wang","Zhigang Wang","Bin Zhao","Di Hu","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2408.02912v3.pdf","comment":"Accepted by CoRL 2024"},{"id":"http://arxiv.org/abs/2410.13149v1","updated":"2024-10-17T02:08:34Z","published":"2024-10-17T02:08:34Z","title":"Power in Numbers: Primitive Algorithm for Swarm Robot Navigation in\n  Unknown Environments","summary":"  Recently, the navigation of mobile robots in unknown environments has become\na particularly significant research topic. Previous studies have primarily\nemployed real-time environmental mapping using cameras and LiDAR, along with\nself-localization and path generation based on those maps. Additionally, there\nis research on Sim-to-Real transfer, where robots acquire behaviors through\npre-trained reinforcement learning and apply these learned actions in\nreal-world navigation. However, strictly the observe action and modelling of\nunknown environments that change unpredictably over time with accuracy and\nprecision is an extremely complex endeavor. This study proposes a simple\nnavigation algorithm for traversing unknown environments by utilizes the number\nof swarm robots. The proposed algorithm assumes that the robot has only the\nsimple function of sensing the direction of the goal and the relative positions\nof the surrounding robots. The robots can navigate an unknown environment by\nsimply continuing towards the goal while bypassing surrounding robots. The\nmethod does not need to sense the environment, determine whether they or other\nrobots are stuck, or do the complicated inter-robot communication. We\nmathematically validate the proposed navigation algorithm, present numerical\nsimulations based on the potential field method, and conduct experimental\ndemonstrations using developed robots based on the sound fields for navigation.\n","authors":["Yusuke Tsunoda","Shoken Otsuka","Kazuki Ito","Runze Xiao","Keisuke Naniwa","Yuichiro Sueoka","Koichi Osuka"],"pdf_url":"https://arxiv.org/pdf/2410.13149v1.pdf","comment":"11 pages, 22 figures"},{"id":"http://arxiv.org/abs/2410.13126v1","updated":"2024-10-17T01:29:49Z","published":"2024-10-17T01:29:49Z","title":"ALOHA Unleashed: A Simple Recipe for Robot Dexterity","summary":"  Recent work has shown promising results for learning end-to-end robot\npolicies using imitation learning. In this work we address the question of how\nfar can we push imitation learning for challenging dexterous manipulation\ntasks. We show that a simple recipe of large scale data collection on the ALOHA\n2 platform, combined with expressive models such as Diffusion Policies, can be\neffective in learning challenging bimanual manipulation tasks involving\ndeformable objects and complex contact rich dynamics. We demonstrate our recipe\non 5 challenging real-world and 3 simulated tasks and demonstrate improved\nperformance over state-of-the-art baselines. The project website and videos can\nbe found at aloha-unleashed.github.io.\n","authors":["Tony Z. Zhao","Jonathan Tompson","Danny Driess","Pete Florence","Kamyar Ghasemipour","Chelsea Finn","Ayzaan Wahid"],"pdf_url":"https://arxiv.org/pdf/2410.13126v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13124v1","updated":"2024-10-17T01:27:25Z","published":"2024-10-17T01:27:25Z","title":"Just Add Force for Contact-Rich Robot Policies","summary":"  Robot trajectories used for learning end-to-end robot policies typically\ncontain end-effector and gripper position, workspace images, and language.\nPolicies learned from such trajectories are unsuitable for delicate grasping,\nwhich require tightly coupled and precise gripper force and gripper position.\nWe collect and make publically available 130 trajectories with force feedback\nof successful grasps on 30 unique objects. Our current-based method for sensing\nforce, albeit noisy, is gripper-agnostic and requires no additional hardware.\nWe train and evaluate two diffusion policies: one with (forceful) the collected\nforce feedback and one without (position-only). We find that forceful policies\nare superior to position-only policies for delicate grasping and are able to\ngeneralize to unseen delicate objects, while reducing grasp policy latency by\nnear 4x, relative to LLM-based methods. With our promising results on limited\ndata, we hope to signal to others to consider investing in collecting force and\nother such tactile information in new datasets, enabling more robust,\ncontact-rich manipulation in future robot foundation models. Our data, code,\nmodels, and videos are viewable at https://justaddforce.github.io/.\n","authors":["William Xie","Stefan Caldararu","Nikolaus Correll"],"pdf_url":"https://arxiv.org/pdf/2410.13124v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11229v2","updated":"2024-10-17T00:46:32Z","published":"2024-10-15T03:22:49Z","title":"Self-Supervised Learning For Robust Robotic Grasping In Dynamic\n  Environment","summary":"  Some of the threats in the dynamic environment include the unpredictability\nof the motion of objects and interferences to the robotic grasp. In such\nconditions the traditional supervised and reinforcement learning approaches are\nill suited because they rely on a large amount of labelled data and a\npredefined reward signal. More specifically in this paper we introduce an\nimportant and promising framework known as self supervised learning (SSL) whose\ngoal is to apply to the RGBD sensor and proprioceptive data from robot hands in\norder to allow robots to learn and improve their grasping strategies in real\ntime. The invariant SSL framework overcomes the deficiencies of the fixed\nlabelling by adapting the SSL system to changes in the objects behavior and\nimproving performance in dynamic situations. The above proposed method was\ntested through various simulations and real world trials, with the series\nobtaining enhanced grasp success rates of 15% over other existing methods,\nespecially under dynamic scenarios. Also, having tested for adaptation times,\nit was confirmed that the system could adapt faster, thus applicable for use in\nthe real world, such as in industrial automation and service robotics. In\nfuture work, the proposed approach will be expanded to more complex tasks, such\nas multi object manipulation and functions in the context of cluttered\nenvironments, in order to apply the proposed methodology to a broader range of\nrobotic tasks.\n","authors":["Ankit Shaw"],"pdf_url":"https://arxiv.org/pdf/2410.11229v2.pdf","comment":"This work is submitted to IEEE journals and conferences and copyright\n  may be transferred to IEEE"},{"id":"http://arxiv.org/abs/2410.14084v1","updated":"2024-10-17T23:26:55Z","published":"2024-10-17T23:26:55Z","title":"Self Supervised Deep Learning for Robot Grasping","summary":"  Learning Based Robot Grasping currently involves the use of labeled data.\nThis approach has two major disadvantages. Firstly, labeling data for grasp\npoints and angles is a strenuous process, so the dataset remains limited.\nSecondly, human labeling is prone to bias due to semantics.\n  In order to solve these problems we propose a simpler self-supervised robotic\nsetup, that will train a Convolutional Neural Network (CNN). The robot will\nlabel and collect the data during the training process. The idea is to make a\nrobot that is less costly, small and easily maintainable in a lab setup. The\nrobot will be trained on a large data set for several hundred hours and then\nthe trained Neural Network can be mapped onto a larger grasping robot.\n","authors":["Danyal Saqib","Wajahat Hussain"],"pdf_url":"https://arxiv.org/pdf/2410.14084v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14040v1","updated":"2024-10-17T21:30:29Z","published":"2024-10-17T21:30:29Z","title":"Latent Weight Diffusion: Generating Policies from Trajectories","summary":"  With the increasing availability of open-source robotic data, imitation\nlearning has emerged as a viable approach for both robot manipulation and\nlocomotion. Currently, large generalized policies are trained to predict\ncontrols or trajectories using diffusion models, which have the desirable\nproperty of learning multimodal action distributions. However, generalizability\ncomes with a cost - namely, larger model size and slower inference. Further,\nthere is a known trade-off between performance and action horizon for Diffusion\nPolicy (i.e., diffusing trajectories): fewer diffusion queries accumulate\ngreater trajectory tracking errors. Thus, it is common practice to run these\nmodels at high inference frequency, subject to robot computational constraints.\n  To address these limitations, we propose Latent Weight Diffusion (LWD), a\nmethod that uses diffusion to learn a distribution over policies for robotic\ntasks, rather than over trajectories. Our approach encodes demonstration\ntrajectories into a latent space and then decodes them into policies using a\nhypernetwork. We employ a diffusion denoising model within this latent space to\nlearn its distribution. We demonstrate that LWD can reconstruct the behaviors\nof the original policies that generated the trajectory dataset. LWD offers the\nbenefits of considerably smaller policy networks during inference and requires\nfewer diffusion model queries. When tested on the Metaworld MT10 benchmark, LWD\nachieves a higher success rate compared to a vanilla multi-task policy, while\nusing models up to ~18x smaller during inference. Additionally, since LWD\ngenerates closed-loop policies, we show that it outperforms Diffusion Policy in\nlong action horizon settings, with reduced diffusion queries during rollout.\n","authors":["Shashank Hegde","Gautam Salhotra","Gaurav S. Sukhatme"],"pdf_url":"https://arxiv.org/pdf/2410.14040v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10284v2","updated":"2024-10-17T21:22:23Z","published":"2024-10-14T08:36:06Z","title":"Trust or Bust: Ensuring Trustworthiness in Autonomous Weapon Systems","summary":"  The integration of Autonomous Weapon Systems (AWS) into military operations\npresents both significant opportunities and challenges. This paper explores the\nmultifaceted nature of trust in AWS, emphasising the necessity of establishing\nreliable and transparent systems to mitigate risks associated with bias,\noperational failures, and accountability. Despite advancements in Artificial\nIntelligence (AI), the trustworthiness of these systems, especially in\nhigh-stakes military applications, remains a critical issue. Through a\nsystematic review of existing literature, this research identifies gaps in the\nunderstanding of trust dynamics during the development and deployment phases of\nAWS. It advocates for a collaborative approach that includes technologists,\nethicists, and military strategists to address these ongoing challenges. The\nfindings underscore the importance of Human-Machine teaming and enhancing\nsystem intelligibility to ensure accountability and adherence to International\nHumanitarian Law. Ultimately, this paper aims to contribute to the ongoing\ndiscourse on the ethical implications of AWS and the imperative for trustworthy\nAI in defense contexts.\n","authors":["Kasper Cools","Clara Maathuis"],"pdf_url":"https://arxiv.org/pdf/2410.10284v2.pdf","comment":"Accepted as a workshop paper at MILCOM 2024, 8 pages"},{"id":"http://arxiv.org/abs/2410.14022v1","updated":"2024-10-17T20:49:45Z","published":"2024-10-17T20:49:45Z","title":"Vision-Language-Action Model and Diffusion Policy Switching Enables\n  Dexterous Control of an Anthropomorphic Hand","summary":"  To advance autonomous dexterous manipulation, we propose a hybrid control\nmethod that combines the relative advantages of a fine-tuned\nVision-Language-Action (VLA) model and diffusion models. The VLA model provides\nlanguage commanded high-level planning, which is highly generalizable, while\nthe diffusion model handles low-level interactions which offers the precision\nand robustness required for specific objects and environments. By incorporating\na switching signal into the training-data, we enable event based transitions\nbetween these two models for a pick-and-place task where the target object and\nplacement location is commanded through language. This approach is deployed on\nour anthropomorphic ADAPT Hand 2, a 13DoF robotic hand, which incorporates\ncompliance through series elastic actuation allowing for resilience for any\ninteractions: showing the first use of a multi-fingered hand controlled with a\nVLA model. We demonstrate this model switching approach results in a over 80\\%\nsuccess rate compared to under 40\\% when only using a VLA model, enabled by\naccurate near-object arm motion by the VLA model and a multi-modal grasping\nmotion with error recovery abilities from the diffusion model.\n","authors":["Cheng Pan","Kai Junge","Josie Hughes"],"pdf_url":"https://arxiv.org/pdf/2410.14022v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14005v1","updated":"2024-10-17T20:19:01Z","published":"2024-10-17T20:19:01Z","title":"Whisker-Inspired Tactile Sensing: A Sim2Real Approach for Precise\n  Underwater Contact Tracking","summary":"  Aquatic mammals, such as pinnipeds, utilize their whiskers to detect and\ndiscriminate objects and analyze water movements, inspiring the development of\nrobotic whiskers for sensing contacts, surfaces, and water flows. We present\nthe design and application of underwater whisker sensors based on Fiber Bragg\nGrating (FBG) technology. These passive whiskers are mounted along the\nrobot$'$s exterior to sense its surroundings through light, non-intrusive\ncontacts. For contact tracking, we employ a sim-to-real learning framework,\nwhich involves extensive data collection in simulation followed by a\nsim-to-real calibration process to transfer the model trained in simulation to\nthe real world. Experiments with whiskers immersed in water indicate that our\napproach can track contact points with an accuracy of $<2$ mm, without\nrequiring precise robot proprioception. We demonstrate that the approach also\ngeneralizes to unseen objects.\n","authors":["Hao Li","Chengyi Xing","Saad Khan","Miaoya Zhong","Mark R. Cutkosky"],"pdf_url":"https://arxiv.org/pdf/2410.14005v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.19578v3","updated":"2024-10-17T19:31:39Z","published":"2024-03-28T17:04:00Z","title":"Keypoint Action Tokens Enable In-Context Imitation Learning in Robotics","summary":"  We show that off-the-shelf text-based Transformers, with no additional\ntraining, can perform few-shot in-context visual imitation learning, mapping\nvisual observations to action sequences that emulate the demonstrator's\nbehaviour. We achieve this by transforming visual observations (inputs) and\ntrajectories of actions (outputs) into sequences of tokens that a\ntext-pretrained Transformer (GPT-4 Turbo) can ingest and generate, via a\nframework we call Keypoint Action Tokens (KAT). Despite being trained only on\nlanguage, we show that these Transformers excel at translating tokenised visual\nkeypoint observations into action trajectories, performing on par or better\nthan state-of-the-art imitation learning (diffusion policies) in the low-data\nregime on a suite of real-world, everyday tasks. Rather than operating in the\nlanguage domain as is typical, KAT leverages text-based Transformers to operate\nin the vision and action domains to learn general patterns in demonstration\ndata for highly efficient imitation learning, indicating promising new avenues\nfor repurposing natural language models for embodied tasks. Videos are\navailable at https://www.robot-learning.uk/keypoint-action-tokens.\n","authors":["Norman Di Palo","Edward Johns"],"pdf_url":"https://arxiv.org/pdf/2403.19578v3.pdf","comment":"Published at Robotics: Science and Systems (RSS) 2024"},{"id":"http://arxiv.org/abs/2410.13979v1","updated":"2024-10-17T19:14:43Z","published":"2024-10-17T19:14:43Z","title":"RecoveryChaining: Learning Local Recovery Policies for Robust\n  Manipulation","summary":"  Model-based planners and controllers are commonly used to solve complex\nmanipulation problems as they can efficiently optimize diverse objectives and\ngeneralize to long horizon tasks. However, they are limited by the fidelity of\ntheir model which oftentimes leads to failures during deployment. To enable a\nrobot to recover from such failures, we propose to use hierarchical\nreinforcement learning to learn a separate recovery policy. The recovery policy\nis triggered when a failure is detected based on sensory observations and seeks\nto take the robot to a state from which it can complete the task using the\nnominal model-based controllers. Our approach, called RecoveryChaining, uses a\nhybrid action space, where the model-based controllers are provided as\nadditional \\emph{nominal} options which allows the recovery policy to decide\nhow to recover, when to switch to a nominal controller and which controller to\nswitch to even with \\emph{sparse rewards}. We evaluate our approach in three\nmulti-step manipulation tasks with sparse rewards, where it learns\nsignificantly more robust recovery policies than those learned by baselines.\nFinally, we successfully transfer recovery policies learned in simulation to a\nphysical robot to demonstrate the feasibility of sim-to-real transfer with our\nmethod.\n","authors":["Shivam Vats","Devesh K. Jha","Maxim Likhachev","Oliver Kroemer","Diego Romeres"],"pdf_url":"https://arxiv.org/pdf/2410.13979v1.pdf","comment":"8 pages, 9 figures"},{"id":"http://arxiv.org/abs/2410.13973v1","updated":"2024-10-17T18:57:15Z","published":"2024-10-17T18:57:15Z","title":"MarineFormer: A Transformer-based Navigation Policy Model for Collision\n  Avoidance in Marine Environment","summary":"  In this work, we investigate the problem of Unmanned Surface Vehicle (USV)\nnavigation in a dense marine environment with a high-intensity current flow.\nThe complexities arising from static and dynamic obstacles and the disturbance\nforces caused by current flow render existing navigation protocols inadequate\nfor ensuring safety and avoiding collisions at sea. To learn a safe and\nefficient robot policy, we propose a novel methodology that leverages attention\nmechanisms to capture heterogeneous interactions of the agents with the static\nand moving obstacles and the flow disturbances from the environment in space\nand time. In particular, we refine a temporal function with MarineFormer, a\nTransformer navigation policy for spatially variable Marine environment,\ntrained end-to-end with reinforcement learning (RL). MarineFormer uses\nfoundational spatio-temporal graph attention with transformer architecture to\nprocess spatial attention and temporal sequences in an environment that\nsimulates a 2D turbulent marine condition. We propose architectural\nmodifications that improve the stability and learning speed of the recurrent\nmodels. The flow velocity estimation, which can be derived from flow\nsimulations or sensors, is incorporated into a model-free RL framework to\nprevent the robot from entering into high-intensity current flow regions\nincluding intense vortices, while potentially leveraging the flow to assist in\ntransportation. The investigated 2D marine environment encompasses flow\nsingularities, including vortices, sinks, and sources, representing fundamental\nplanar flow patterns associated with flood or maritime thunderstorms. Our\nproposed method is trained with a new reward model to deal with static and\ndynamic obstacles and disturbances from the current flow.\n","authors":["Ehsan Kazemi","Iman Soltani"],"pdf_url":"https://arxiv.org/pdf/2410.13973v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.12474v2","updated":"2024-10-17T18:45:57Z","published":"2024-04-18T19:11:34Z","title":"Learning a Stable, Safe, Distributed Feedback Controller for a\n  Heterogeneous Platoon of Autonomous Vehicles","summary":"  Platooning of autonomous vehicles has the potential to increase safety and\nfuel efficiency on highways. The goal of platooning is to have each vehicle\ndrive at a specified speed (set by the leader) while maintaining a safe\ndistance from its neighbors. Many prior works have analyzed various controllers\nfor platooning, most commonly linear feedback and distributed model predictive\ncontrollers. In this work, we introduce an algorithm for learning a stable,\nsafe, distributed controller for a heterogeneous platoon. Our algorithm relies\non recent developments in learning neural network stability certificates. We\ntrain a controller for autonomous platooning in simulation and evaluate its\nperformance on hardware with a platoon of four F1Tenth vehicles. We then\nperform further analysis in simulation with a platoon of 100 vehicles.\nExperimental results demonstrate the practicality of the algorithm and the\nlearned controller by comparing the performance of the neural network\ncontroller to linear feedback and distributed model predictive controllers.\n","authors":["Michael H. Shaham","Taskin Padir"],"pdf_url":"https://arxiv.org/pdf/2404.12474v2.pdf","comment":"Accepted to the International Symposium of Robotics Research (ISRR)\n  2024"},{"id":"http://arxiv.org/abs/2410.13957v1","updated":"2024-10-17T18:30:52Z","published":"2024-10-17T18:30:52Z","title":"Goal Inference from Open-Ended Dialog","summary":"  We present an online method for embodied agents to learn and accomplish\ndiverse user goals. While offline methods like RLHF can represent various goals\nbut require large datasets, our approach achieves similar flexibility with\nonline efficiency. We extract natural language goal representations from\nconversations with Large Language Models (LLMs). We prompt an LLM to role play\nas a human with different goals and use the corresponding likelihoods to run\nBayesian inference over potential goals. As a result, our method can represent\nuncertainty over complex goals based on unrestricted dialog. We evaluate our\nmethod in grocery shopping and home robot assistance domains using a text-based\ninterface and AI2Thor simulation respectively. Results show our method\noutperforms ablation baselines that lack either explicit goal representation or\nprobabilistic inference.\n","authors":["Rachel Ma","Jingyi Qu","Andreea Bobu","Dylan Hadfield-Menell"],"pdf_url":"https://arxiv.org/pdf/2410.13957v1.pdf","comment":"6 pages + 2 page (references and appendix)"},{"id":"http://arxiv.org/abs/2310.10931v2","updated":"2024-10-17T18:06:59Z","published":"2023-10-17T02:01:37Z","title":"Open-Structure: Structural Benchmark Dataset for SLAM Algorithms","summary":"  This paper presents Open-Structure, a novel benchmark dataset for evaluating\nvisual odometry and SLAM methods. Compared to existing public datasets that\nprimarily offer raw images, Open-Structure provides direct access to point and\nline measurements, correspondences, structural associations, and co-visibility\nfactor graphs, which can be fed to various stages of SLAM pipelines to mitigate\nthe impact of data preprocessing modules in ablation experiments. The dataset\ncomprises two distinct types of sequences from the perspective of scenarios.\nThe first type maintains reasonable observation and occlusion relationships, as\nthese critical elements are extracted from public image-based sequences using\nour dataset generator. In contrast, the second type consists of carefully\ndesigned simulation sequences that enhance dataset diversity by introducing a\nwide range of trajectories and observations. Furthermore, a baseline is\nproposed using our dataset to evaluate widely used modules, including camera\npose tracking, parametrization, and factor graph optimization, within SLAM\nsystems. By evaluating these state-of-the-art algorithms across different\nscenarios, we discern each module's strengths and weaknesses in the context of\ncamera tracking and optimization processes. The Open-Structure dataset and\nbaseline system are openly accessible on website:\n\\url{https://open-structure.github.io}, encouraging further research and\ndevelopment in the field of SLAM.\n","authors":["Yanyan Li","Zhao Guo","Ze Yang","Yanbiao Sun","Liang Zhao","Federico Tombari"],"pdf_url":"https://arxiv.org/pdf/2310.10931v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13412v1","updated":"2024-10-17T10:21:28Z","published":"2024-10-17T10:21:28Z","title":"RAMPA: Robotic Augmented Reality for Machine Programming and Automation","summary":"  As robotics continue to enter various sectors beyond traditional industrial\napplications, the need for intuitive robot training and interaction systems\nbecomes increasingly more important. This paper introduces Robotic Augmented\nReality for Machine Programming (RAMPA), a system that utilizes the\ncapabilities of state-of-the-art and commercially available AR headsets, e.g.,\nMeta Quest 3, to facilitate the application of Programming from Demonstration\n(PfD) approaches on industrial robotic arms, such as Universal Robots UR10. Our\napproach enables in-situ data recording, visualization, and fine-tuning of\nskill demonstrations directly within the user's physical environment. RAMPA\naddresses critical challenges of PfD, such as safety concerns, programming\nbarriers, and the inefficiency of collecting demonstrations on the actual\nhardware. The performance of our system is evaluated against the traditional\nmethod of kinesthetic control in teaching three different robotic manipulation\ntasks and analyzed with quantitative metrics, measuring task performance and\ncompletion time, trajectory smoothness, system usability, user experience, and\ntask load using standardized surveys. Our findings indicate a substantial\nadvancement in how robotic tasks are taught and refined, promising improvements\nin operational safety, efficiency, and user engagement in robotic programming.\n","authors":["Fatih Dogangun","Serdar Bahar","Yigit Yildirim","Bora Toprak Temir","Emre Ugur","Mustafa Doga Dogan"],"pdf_url":"https://arxiv.org/pdf/2410.13412v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2410.13863v1","updated":"2024-10-17T17:59:59Z","published":"2024-10-17T17:59:59Z","title":"Fluid: Scaling Autoregressive Text-to-image Generative Models with\n  Continuous Tokens","summary":"  Scaling up autoregressive models in vision has not proven as beneficial as in\nlarge language models. In this work, we investigate this scaling problem in the\ncontext of text-to-image generation, focusing on two critical factors: whether\nmodels use discrete or continuous tokens, and whether tokens are generated in a\nrandom or fixed raster order using BERT- or GPT-like transformer architectures.\nOur empirical results show that, while all models scale effectively in terms of\nvalidation loss, their evaluation performance -- measured by FID, GenEval\nscore, and visual quality -- follows different trends. Models based on\ncontinuous tokens achieve significantly better visual quality than those using\ndiscrete tokens. Furthermore, the generation order and attention mechanisms\nsignificantly affect the GenEval score: random-order models achieve notably\nbetter GenEval scores compared to raster-order models. Inspired by these\nfindings, we train Fluid, a random-order autoregressive model on continuous\ntokens. Fluid 10.5B model achieves a new state-of-the-art zero-shot FID of 6.16\non MS-COCO 30K, and 0.69 overall score on the GenEval benchmark. We hope our\nfindings and results will encourage future efforts to further bridge the\nscaling gap between vision and language models.\n","authors":["Lijie Fan","Tianhong Li","Siyang Qin","Yuanzhen Li","Chen Sun","Michael Rubinstein","Deqing Sun","Kaiming He","Yonglong Tian"],"pdf_url":"https://arxiv.org/pdf/2410.13863v1.pdf","comment":"Tech report"},{"id":"http://arxiv.org/abs/2410.13864v1","updated":"2024-10-17T17:59:59Z","published":"2024-10-17T17:59:59Z","title":"UniDrive: Towards Universal Driving Perception Across Camera\n  Configurations","summary":"  Vision-centric autonomous driving has demonstrated excellent performance with\neconomical sensors. As the fundamental step, 3D perception aims to infer 3D\ninformation from 2D images based on 3D-2D projection. This makes driving\nperception models susceptible to sensor configuration (e.g., camera intrinsics\nand extrinsics) variations. However, generalizing across camera configurations\nis important for deploying autonomous driving models on different car models.\nIn this paper, we present UniDrive, a novel framework for vision-centric\nautonomous driving to achieve universal perception across camera\nconfigurations. We deploy a set of unified virtual cameras and propose a\nground-aware projection method to effectively transform the original images\ninto these unified virtual views. We further propose a virtual configuration\noptimization method by minimizing the expected projection error between\noriginal cameras and virtual cameras. The proposed virtual camera projection\ncan be applied to existing 3D perception methods as a plug-and-play module to\nmitigate the challenges posed by camera parameter variability, resulting in\nmore adaptable and reliable driving perception models. To evaluate the\neffectiveness of our framework, we collect a dataset on Carla by driving the\nsame routes while only modifying the camera configurations. Experimental\nresults demonstrate that our method trained on one specific camera\nconfiguration can generalize to varying configurations with minor performance\ndegradation.\n","authors":["Ye Li","Wenzhao Zheng","Xiaonan Huang","Kurt Keutzer"],"pdf_url":"https://arxiv.org/pdf/2410.13864v1.pdf","comment":"Preprint; 14 pages, 5 figures, 2 tables; Code at\n  https://github.com/ywyeli/UniDrive"},{"id":"http://arxiv.org/abs/2410.13862v1","updated":"2024-10-17T17:59:58Z","published":"2024-10-17T17:59:58Z","title":"DepthSplat: Connecting Gaussian Splatting and Depth","summary":"  Gaussian splatting and single/multi-view depth estimation are typically\nstudied in isolation. In this paper, we present DepthSplat to connect Gaussian\nsplatting and depth estimation and study their interactions. More specifically,\nwe first contribute a robust multi-view depth model by leveraging pre-trained\nmonocular depth features, leading to high-quality feed-forward 3D Gaussian\nsplatting reconstructions. We also show that Gaussian splatting can serve as an\nunsupervised pre-training objective for learning powerful depth models from\nlarge-scale unlabelled datasets. We validate the synergy between Gaussian\nsplatting and depth estimation through extensive ablation and cross-task\ntransfer experiments. Our DepthSplat achieves state-of-the-art performance on\nScanNet, RealEstate10K and DL3DV datasets in terms of both depth estimation and\nnovel view synthesis, demonstrating the mutual benefits of connecting both\ntasks. Our code, models, and video results are available at\nhttps://haofeixu.github.io/depthsplat/.\n","authors":["Haofei Xu","Songyou Peng","Fangjinhua Wang","Hermann Blum","Daniel Barath","Andreas Geiger","Marc Pollefeys"],"pdf_url":"https://arxiv.org/pdf/2410.13862v1.pdf","comment":"Project page: https://haofeixu.github.io/depthsplat/"},{"id":"http://arxiv.org/abs/2410.13861v1","updated":"2024-10-17T17:59:57Z","published":"2024-10-17T17:59:57Z","title":"PUMA: Empowering Unified MLLM with Multi-granular Visual Generation","summary":"  Recent advancements in multimodal foundation models have yielded significant\nprogress in vision-language understanding. Initial attempts have also explored\nthe potential of multimodal large language models (MLLMs) for visual content\ngeneration. However, existing works have insufficiently addressed the varying\ngranularity demands of different image generation tasks within a unified MLLM\nparadigm - from the diversity required in text-to-image generation to the\nprecise controllability needed in image manipulation. In this work, we propose\nPUMA, emPowering Unified MLLM with Multi-grAnular visual generation. PUMA\nunifies multi-granular visual features as both inputs and outputs of MLLMs,\nelegantly addressing the different granularity requirements of various image\ngeneration tasks within a unified MLLM framework. Following multimodal\npretraining and task-specific instruction tuning, PUMA demonstrates proficiency\nin a wide range of multimodal tasks. This work represents a significant step\ntowards a truly unified MLLM capable of adapting to the granularity demands of\nvarious visual tasks. The code and model will be released in\nhttps://github.com/rongyaofang/PUMA.\n","authors":["Rongyao Fang","Chengqi Duan","Kun Wang","Hao Li","Hao Tian","Xingyu Zeng","Rui Zhao","Jifeng Dai","Hongsheng Li","Xihui Liu"],"pdf_url":"https://arxiv.org/pdf/2410.13861v1.pdf","comment":"Project page: https://rongyaofang.github.io/puma/"},{"id":"http://arxiv.org/abs/2410.13860v1","updated":"2024-10-17T17:59:55Z","published":"2024-10-17T17:59:55Z","title":"VLM-Grounder: A VLM Agent for Zero-Shot 3D Visual Grounding","summary":"  3D visual grounding is crucial for robots, requiring integration of natural\nlanguage and 3D scene understanding. Traditional methods depending on\nsupervised learning with 3D point clouds are limited by scarce datasets.\nRecently zero-shot methods leveraging LLMs have been proposed to address the\ndata issue. While effective, these methods only use object-centric information,\nlimiting their ability to handle complex queries. In this work, we present\nVLM-Grounder, a novel framework using vision-language models (VLMs) for\nzero-shot 3D visual grounding based solely on 2D images. VLM-Grounder\ndynamically stitches image sequences, employs a grounding and feedback scheme\nto find the target object, and uses a multi-view ensemble projection to\naccurately estimate 3D bounding boxes. Experiments on ScanRefer and Nr3D\ndatasets show VLM-Grounder outperforms previous zero-shot methods, achieving\n51.6% Acc@0.25 on ScanRefer and 48.0% Acc on Nr3D, without relying on 3D\ngeometry or object priors. Codes are available at\nhttps://github.com/OpenRobotLab/VLM-Grounder .\n","authors":["Runsen Xu","Zhiwei Huang","Tai Wang","Yilun Chen","Jiangmiao Pang","Dahua Lin"],"pdf_url":"https://arxiv.org/pdf/2410.13860v1.pdf","comment":"CoRL 2024 Camera Ready. 25 pages. A novel zero-shot 3D visual\n  grounding framework based solely on 2D images"},{"id":"http://arxiv.org/abs/2410.13859v1","updated":"2024-10-17T17:59:53Z","published":"2024-10-17T17:59:53Z","title":"$γ-$MoD: Exploring Mixture-of-Depth Adaptation for Multimodal Large\n  Language Models","summary":"  Despite the significant progress in multimodal large language models (MLLMs),\ntheir high computational cost remains a barrier to real-world deployment.\nInspired by the mixture of depths (MoDs) in natural language processing, we aim\nto address this limitation from the perspective of ``activated tokens''. Our\nkey insight is that if most tokens are redundant for the layer computation,\nthen can be skipped directly via the MoD layer. However, directly converting\nthe dense layers of MLLMs to MoD layers leads to substantial performance\ndegradation. To address this issue, we propose an innovative MoD adaptation\nstrategy for existing MLLMs called $\\gamma$-MoD. In $\\gamma$-MoD, a novel\nmetric is proposed to guide the deployment of MoDs in the MLLM, namely rank of\nattention maps (ARank). Through ARank, we can effectively identify which layer\nis redundant and should be replaced with the MoD layer. Based on ARank, we\nfurther propose two novel designs to maximize the computational sparsity of\nMLLM while maintaining its performance, namely shared vision-language router\nand masked routing learning. With these designs, more than 90% dense layers of\nthe MLLM can be effectively converted to the MoD ones. To validate our method,\nwe apply it to three popular MLLMs, and conduct extensive experiments on 9\nbenchmark datasets. Experimental results not only validate the significant\nefficiency benefit of $\\gamma$-MoD to existing MLLMs but also confirm its\ngeneralization ability on various MLLMs. For example, with a minor performance\ndrop, i.e., -1.5%, $\\gamma$-MoD can reduce the training and inference time of\nLLaVA-HR by 31.0% and 53.2%, respectively.\n","authors":["Yaxin Luo","Gen Luo","Jiayi Ji","Yiyi Zhou","Xiaoshuai Sun","Zhiqiang Shen","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2410.13859v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13854v1","updated":"2024-10-17T17:59:24Z","published":"2024-10-17T17:59:24Z","title":"Can MLLMs Understand the Deep Implication Behind Chinese Images?","summary":"  As the capabilities of Multimodal Large Language Models (MLLMs) continue to\nimprove, the need for higher-order capability evaluation of MLLMs is\nincreasing. However, there is a lack of work evaluating MLLM for higher-order\nperception and understanding of Chinese visual content. To fill the gap, we\nintroduce the **C**hinese **I**mage **I**mplication understanding\n**Bench**mark, **CII-Bench**, which aims to assess the higher-order perception\nand understanding capabilities of MLLMs for Chinese images. CII-Bench stands\nout in several ways compared to existing benchmarks. Firstly, to ensure the\nauthenticity of the Chinese context, images in CII-Bench are sourced from the\nChinese Internet and manually reviewed, with corresponding answers also\nmanually crafted. Additionally, CII-Bench incorporates images that represent\nChinese traditional culture, such as famous Chinese traditional paintings,\nwhich can deeply reflect the model's understanding of Chinese traditional\nculture. Through extensive experiments on CII-Bench across multiple MLLMs, we\nhave made significant findings. Initially, a substantial gap is observed\nbetween the performance of MLLMs and humans on CII-Bench. The highest accuracy\nof MLLMs attains 64.4%, where as human accuracy averages 78.2%, peaking at an\nimpressive 81.0%. Subsequently, MLLMs perform worse on Chinese traditional\nculture images, suggesting limitations in their ability to understand\nhigh-level semantics and lack a deep knowledge base of Chinese traditional\nculture. Finally, it is observed that most models exhibit enhanced accuracy\nwhen image emotion hints are incorporated into the prompts. We believe that\nCII-Bench will enable MLLMs to gain a better understanding of Chinese semantics\nand Chinese-specific images, advancing the journey towards expert artificial\ngeneral intelligence (AGI). Our project is publicly available at\nhttps://cii-bench.github.io/.\n","authors":["Chenhao Zhang","Xi Feng","Yuelin Bai","Xinrun Du","Jinchang Hou","Kaixin Deng","Guangzeng Han","Qinrui Li","Bingli Wang","Jiaheng Liu","Xingwei Qu","Yifei Zhang","Qixuan Zhao","Yiming Liang","Ziqiang Liu","Feiteng Fang","Min Yang","Wenhao Huang","Chenghua Lin","Ge Zhang","Shiwen Ni"],"pdf_url":"https://arxiv.org/pdf/2410.13854v1.pdf","comment":"32 pages,18 figures. Project Page: https://cii-bench.github.io/ Code:\n  https://github.com/MING_X/CII-Bench Dataset:\n  https://huggingface.co/datasets/m-a-p/CII-Bench"},{"id":"http://arxiv.org/abs/2410.13852v1","updated":"2024-10-17T17:59:03Z","published":"2024-10-17T17:59:03Z","title":"Retrospective Learning from Interactions","summary":"  Multi-turn interactions between large language models (LLMs) and users\nnaturally include implicit feedback signals. If an LLM responds in an\nunexpected way to an instruction, the user is likely to signal it by rephrasing\nthe request, expressing frustration, or pivoting to an alternative task. Such\nsignals are task-independent and occupy a relatively constrained subspace of\nlanguage, allowing the LLM to identify them even if it fails on the actual\ntask. This creates an avenue for continually learning from interactions without\nadditional annotations. We introduce ReSpect, a method to learn from such\nsignals in past interactions via retrospection. We deploy ReSpect in a new\nmultimodal interaction scenario, where humans instruct an LLM to solve an\nabstract reasoning task with a combinatorial solution space. Through thousands\nof interactions with humans, we show how ReSpect gradually improves task\ncompletion rate from 31% to 82%, all without any external annotation.\n","authors":["Zizhao Chen","Mustafa Omer Gul","Yiwei Chen","Gloria Geng","Anne Wu","Yoav Artzi"],"pdf_url":"https://arxiv.org/pdf/2410.13852v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13851v1","updated":"2024-10-17T17:59:02Z","published":"2024-10-17T17:59:02Z","title":"Differentiable Robot Rendering","summary":"  Vision foundation models trained on massive amounts of visual data have shown\nunprecedented reasoning and planning skills in open-world settings. A key\nchallenge in applying them to robotic tasks is the modality gap between visual\ndata and action data. We introduce differentiable robot rendering, a method\nallowing the visual appearance of a robot body to be directly differentiable\nwith respect to its control parameters. Our model integrates a kinematics-aware\ndeformable model and Gaussians Splatting and is compatible with any robot form\nfactors and degrees of freedom. We demonstrate its capability and usage in\napplications including reconstruction of robot poses from images and\ncontrolling robots through vision language models. Quantitative and qualitative\nresults show that our differentiable rendering model provides effective\ngradients for robotic control directly from pixels, setting the foundation for\nthe future applications of vision foundation models in robotics.\n","authors":["Ruoshi Liu","Alper Canberk","Shuran Song","Carl Vondrick"],"pdf_url":"https://arxiv.org/pdf/2410.13851v1.pdf","comment":"Project Page: https://drrobot.cs.columbia.edu/"},{"id":"http://arxiv.org/abs/2410.13848v1","updated":"2024-10-17T17:58:37Z","published":"2024-10-17T17:58:37Z","title":"Janus: Decoupling Visual Encoding for Unified Multimodal Understanding\n  and Generation","summary":"  In this paper, we introduce Janus, an autoregressive framework that unifies\nmultimodal understanding and generation. Prior research often relies on a\nsingle visual encoder for both tasks, such as Chameleon. However, due to the\ndiffering levels of information granularity required by multimodal\nunderstanding and generation, this approach can lead to suboptimal performance,\nparticularly in multimodal understanding. To address this issue, we decouple\nvisual encoding into separate pathways, while still leveraging a single,\nunified transformer architecture for processing. The decoupling not only\nalleviates the conflict between the visual encoder's roles in understanding and\ngeneration, but also enhances the framework's flexibility. For instance, both\nthe multimodal understanding and generation components can independently select\ntheir most suitable encoding methods. Experiments show that Janus surpasses\nprevious unified model and matches or exceeds the performance of task-specific\nmodels. The simplicity, high flexibility, and effectiveness of Janus make it a\nstrong candidate for next-generation unified multimodal models.\n","authors":["Chengyue Wu","Xiaokang Chen","Zhiyu Wu","Yiyang Ma","Xingchao Liu","Zizheng Pan","Wen Liu","Zhenda Xie","Xingkai Yu","Chong Ruan","Ping Luo"],"pdf_url":"https://arxiv.org/pdf/2410.13848v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2410.13842v1","updated":"2024-10-17T17:57:01Z","published":"2024-10-17T17:57:01Z","title":"D-FINE: Redefine Regression Task in DETRs as Fine-grained Distribution\n  Refinement","summary":"  We introduce D-FINE, a powerful real-time object detector that achieves\noutstanding localization precision by redefining the bounding box regression\ntask in DETR models. D-FINE comprises two key components: Fine-grained\nDistribution Refinement (FDR) and Global Optimal Localization Self-Distillation\n(GO-LSD). FDR transforms the regression process from predicting fixed\ncoordinates to iteratively refining probability distributions, providing a\nfine-grained intermediate representation that significantly enhances\nlocalization accuracy. GO-LSD is a bidirectional optimization strategy that\ntransfers localization knowledge from refined distributions to shallower layers\nthrough self-distillation, while also simplifying the residual prediction tasks\nfor deeper layers. Additionally, D-FINE incorporates lightweight optimizations\nin computationally intensive modules and operations, achieving a better balance\nbetween speed and accuracy. Specifically, D-FINE-L / X achieves 54.0% / 55.8%\nAP on the COCO dataset at 124 / 78 FPS on an NVIDIA T4 GPU. When pretrained on\nObjects365, D-FINE-L / X attains 57.1% / 59.3% AP, surpassing all existing\nreal-time detectors. Furthermore, our method significantly enhances the\nperformance of a wide range of DETR models by up to 5.3% AP with negligible\nextra parameters and training costs. Our code and pretrained models:\nhttps://github.com/Peterande/D-FINE.\n","authors":["Yansong Peng","Hebei Li","Peixi Wu","Yueyi Zhang","Xiaoyan Sun","Feng Wu"],"pdf_url":"https://arxiv.org/pdf/2410.13842v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13832v1","updated":"2024-10-17T17:53:24Z","published":"2024-10-17T17:53:24Z","title":"VidPanos: Generative Panoramic Videos from Casual Panning Videos","summary":"  Panoramic image stitching provides a unified, wide-angle view of a scene that\nextends beyond the camera's field of view. Stitching frames of a panning video\ninto a panoramic photograph is a well-understood problem for stationary scenes,\nbut when objects are moving, a still panorama cannot capture the scene. We\npresent a method for synthesizing a panoramic video from a casually-captured\npanning video, as if the original video were captured with a wide-angle camera.\nWe pose panorama synthesis as a space-time outpainting problem, where we aim to\ncreate a full panoramic video of the same length as the input video. Consistent\ncompletion of the space-time volume requires a powerful, realistic prior over\nvideo content and motion, for which we adapt generative video models. Existing\ngenerative models do not, however, immediately extend to panorama completion,\nas we show. We instead apply video generation as a component of our panorama\nsynthesis system, and demonstrate how to exploit the strengths of the models\nwhile minimizing their limitations. Our system can create video panoramas for a\nrange of in-the-wild scenes including people, vehicles, and flowing water, as\nwell as stationary background features.\n","authors":["Jingwei Ma","Erika Lu","Roni Paiss","Shiran Zada","Aleksander Holynski","Tali Dekel","Brian Curless","Michael Rubinstein","Forrester Cole"],"pdf_url":"https://arxiv.org/pdf/2410.13832v1.pdf","comment":"Project page at https://vidpanos.github.io/. To appear at SIGGRAPH\n  Asia 2024 (conference track)"},{"id":"http://arxiv.org/abs/2410.13830v1","updated":"2024-10-17T17:52:57Z","published":"2024-10-17T17:52:57Z","title":"DreamVideo-2: Zero-Shot Subject-Driven Video Customization with Precise\n  Motion Control","summary":"  Recent advances in customized video generation have enabled users to create\nvideos tailored to both specific subjects and motion trajectories. However,\nexisting methods often require complicated test-time fine-tuning and struggle\nwith balancing subject learning and motion control, limiting their real-world\napplications. In this paper, we present DreamVideo-2, a zero-shot video\ncustomization framework capable of generating videos with a specific subject\nand motion trajectory, guided by a single image and a bounding box sequence,\nrespectively, and without the need for test-time fine-tuning. Specifically, we\nintroduce reference attention, which leverages the model's inherent\ncapabilities for subject learning, and devise a mask-guided motion module to\nachieve precise motion control by fully utilizing the robust motion signal of\nbox masks derived from bounding boxes. While these two components achieve their\nintended functions, we empirically observe that motion control tends to\ndominate over subject learning. To address this, we propose two key designs: 1)\nthe masked reference attention, which integrates a blended latent mask modeling\nscheme into reference attention to enhance subject representations at the\ndesired positions, and 2) a reweighted diffusion loss, which differentiates the\ncontributions of regions inside and outside the bounding boxes to ensure a\nbalance between subject and motion control. Extensive experimental results on a\nnewly curated dataset demonstrate that DreamVideo-2 outperforms\nstate-of-the-art methods in both subject customization and motion control. The\ndataset, code, and models will be made publicly available.\n","authors":["Yujie Wei","Shiwei Zhang","Hangjie Yuan","Xiang Wang","Haonan Qiu","Rui Zhao","Yutong Feng","Feng Liu","Zhizhong Huang","Jiaxin Ye","Yingya Zhang","Hongming Shan"],"pdf_url":"https://arxiv.org/pdf/2410.13830v1.pdf","comment":"Project page: https://dreamvideo2.github.io/"},{"id":"http://arxiv.org/abs/2410.13826v1","updated":"2024-10-17T17:51:40Z","published":"2024-10-17T17:51:40Z","title":"Unearthing Skill-Level Insights for Understanding Trade-Offs of\n  Foundation Models","summary":"  With models getting stronger, evaluations have grown more complex, testing\nmultiple skills in one benchmark and even in the same instance at once.\nHowever, skill-wise performance is obscured when inspecting aggregate accuracy,\nunder-utilizing the rich signal modern benchmarks contain. We propose an\nautomatic approach to recover the underlying skills relevant for any evaluation\ninstance, by way of inspecting model-generated rationales. After validating the\nrelevance of rationale-parsed skills and inferring skills for $46$k instances\nover $12$ benchmarks, we observe many skills to be common across benchmarks,\nresulting in the curation of hundreds of skill-slices (i.e. sets of instances\ntesting a common skill). Inspecting accuracy over these slices yields novel\ninsights on model trade-offs: e.g., compared to GPT-4o and Claude 3.5 Sonnet,\non average, Gemini 1.5 Pro is $18\\%$ more accurate in \"computing molar mass\",\nbut $19\\%$ less accurate in \"applying constitutional law\", despite the overall\naccuracies of the three models differing by a mere $0.4\\%$. Furthermore, we\ndemonstrate the practical utility of our approach by showing that insights\nderived from skill slice analysis can generalize to held-out instances: when\nrouting each instance to the model strongest on the relevant skills, we see a\n$3\\%$ accuracy improvement over our $12$ dataset corpus. Our skill-slices and\nframework open a new avenue in model evaluation, leveraging skill-specific\nanalyses to unlock a more granular and actionable understanding of model\ncapabilities.\n","authors":["Mazda Moayeri","Vidhisha Balachandran","Varun Chandrasekaran","Safoora Yousefi","Thomas Fel","Soheil Feizi","Besmira Nushi","Neel Joshi","Vibhav Vineet"],"pdf_url":"https://arxiv.org/pdf/2410.13826v1.pdf","comment":"Code at: github.com/microsoft/skill-slice-insights"},{"id":"http://arxiv.org/abs/2410.13824v1","updated":"2024-10-17T17:48:54Z","published":"2024-10-17T17:48:54Z","title":"Harnessing Webpage UIs for Text-Rich Visual Understanding","summary":"  Text-rich visual understanding-the ability to process environments where\ndense textual content is integrated with visuals-is crucial for multimodal\nlarge language models (MLLMs) to interact effectively with structured\nenvironments. To enhance this capability, we propose synthesizing general\nmultimodal instructions from webpage UIs using text-based large language models\n(LLMs). Despite lacking direct visual input, text-based LLMs are able to\nprocess structured text representations from webpage accessibility trees. These\ninstructions are then paired with UI screenshots to train multimodal models. We\nintroduce MultiUI, a dataset containing 7.3 million samples from 1 million\nwebsites, covering diverse multimodal tasks and UI layouts. Models trained on\nMultiUI not only excel in web UI tasks-achieving up to a 48\\% improvement on\nVisualWebBench and a 19.1\\% boost in action accuracy on a web agent dataset\nMind2Web-but also generalize surprisingly well to non-web UI tasks and even to\nnon-UI domains, such as document understanding, OCR, and chart interpretation.\nThese results highlight the broad applicability of web UI data for advancing\ntext-rich visual understanding across various scenarios.\n","authors":["Junpeng Liu","Tianyue Ou","Yifan Song","Yuxiao Qu","Wai Lam","Chenyan Xiong","Wenhu Chen","Graham Neubig","Xiang Yue"],"pdf_url":"https://arxiv.org/pdf/2410.13824v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13823v1","updated":"2024-10-17T17:48:36Z","published":"2024-10-17T17:48:36Z","title":"Deep Generative Models Unveil Patterns in Medical Images Through\n  Vision-Language Conditioning","summary":"  Deep generative models have significantly advanced medical imaging analysis\nby enhancing dataset size and quality. Beyond mere data augmentation, our\nresearch in this paper highlights an additional, significant capacity of deep\ngenerative models: their ability to reveal and demonstrate patterns in medical\nimages. We employ a generative structure with hybrid conditions, combining\nclinical data and segmentation masks to guide the image synthesis process.\nFurthermore, we innovatively transformed the tabular clinical data into textual\ndescriptions. This approach simplifies the handling of missing values and also\nenables us to leverage large pre-trained vision-language models that\ninvestigate the relations between independent clinical entries and comprehend\ngeneral terms, such as gender and smoking status. Our approach differs from and\npresents a more challenging task than traditional medical report-guided\nsynthesis due to the less visual correlation of our clinical information with\nthe images. To overcome this, we introduce a text-visual embedding mechanism\nthat strengthens the conditions, ensuring the network effectively utilizes the\nprovided information. Our pipeline is generalizable to both GAN-based and\ndiffusion models. Experiments on chest CT, particularly focusing on the smoking\nstatus, demonstrated a consistent intensity shift in the lungs which is in\nagreement with clinical observations, indicating the effectiveness of our\nmethod in capturing and visualizing the impact of specific attributes on\nmedical image patterns. Our methods offer a new avenue for the early detection\nand precise visualization of complex clinical conditions with deep generative\nmodels. All codes are https://github.com/junzhin/DGM-VLC.\n","authors":["Xiaodan Xing","Junzhi Ning","Yang Nan","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2410.13823v1.pdf","comment":"Accepted by AIM-FM Workshop of NeurIPS2024"},{"id":"http://arxiv.org/abs/2410.13822v1","updated":"2024-10-17T17:48:17Z","published":"2024-10-17T17:48:17Z","title":"Multi-style conversion for semantic segmentation of lesions in fundus\n  images by adversarial attacks","summary":"  The diagnosis of diabetic retinopathy, which relies on fundus images, faces\nchallenges in achieving transparency and interpretability when using a global\nclassification approach. However, segmentation-based databases are\nsignificantly more expensive to acquire and combining them is often\nproblematic. This paper introduces a novel method, termed adversarial style\nconversion, to address the lack of standardization in annotation styles across\ndiverse databases. By training a single architecture on combined databases, the\nmodel spontaneously modifies its segmentation style depending on the input,\ndemonstrating the ability to convert among different labeling styles. The\nproposed methodology adds a linear probe to detect dataset origin based on\nencoder features and employs adversarial attacks to condition the model's\nsegmentation style. Results indicate significant qualitative and quantitative\nthrough dataset combination, offering avenues for improved model\ngeneralization, uncertainty estimation and continuous interpolation between\nannotation styles. Our approach enables training a segmentation model with\ndiverse databases while controlling and leveraging annotation styles for\nimproved retinopathy diagnosis.\n","authors":["Clément Playout","Renaud Duval","Marie Carole Boucher","Farida Cheriet"],"pdf_url":"https://arxiv.org/pdf/2410.13822v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2410.13807v1","updated":"2024-10-17T17:41:52Z","published":"2024-10-17T17:41:52Z","title":"ConsisSR: Delving Deep into Consistency in Diffusion-based Image\n  Super-Resolution","summary":"  Real-world image super-resolution (Real-ISR) aims at restoring high-quality\n(HQ) images from low-quality (LQ) inputs corrupted by unknown and complex\ndegradations. In particular, pretrained text-to-image (T2I) diffusion models\nprovide strong generative priors to reconstruct credible and intricate details.\nHowever, T2I generation focuses on semantic consistency while Real-ISR\nemphasizes pixel-level reconstruction, which hinders existing methods from\nfully exploiting diffusion priors. To address this challenge, we introduce\nConsisSR to handle both semantic and pixel-level consistency. Specifically,\ncompared to coarse-grained text prompts, we exploit the more powerful CLIP\nimage embedding and effectively leverage both modalities through our Hybrid\nPrompt Adapter (HPA) for semantic guidance. Secondly, we introduce Time-aware\nLatent Augmentation (TALA) to mitigate the inherent gap between T2I generation\nand Real-ISR consistency requirements. By randomly mixing LQ and HQ latent\ninputs, our model not only handle timestep-specific diffusion noise but also\nrefine the accumulated latent representations. Last but not least, our\nGAN-Embedding strategy employs the pretrained Real-ESRGAN model to refine the\ndiffusion start point. This accelerates the inference process to 10 steps while\npreserving sampling quality, in a training-free manner.Our method demonstrates\nstate-of-the-art performance among both full-scale and accelerated models. The\ncode will be made publicly available.\n","authors":["Junhao Gu","Peng-Tao Jiang","Hao Zhang","Mi Zhou","Jinwei Chen","Wenming Yang","Bo Li"],"pdf_url":"https://arxiv.org/pdf/2410.13807v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13790v1","updated":"2024-10-17T17:31:24Z","published":"2024-10-17T17:31:24Z","title":"MotionBank: A Large-scale Video Motion Benchmark with Disentangled\n  Rule-based Annotations","summary":"  In this paper, we tackle the problem of how to build and benchmark a large\nmotion model (LMM). The ultimate goal of LMM is to serve as a foundation model\nfor versatile motion-related tasks, e.g., human motion generation, with\ninterpretability and generalizability. Though advanced, recent LMM-related\nworks are still limited by small-scale motion data and costly text\ndescriptions. Besides, previous motion benchmarks primarily focus on pure body\nmovements, neglecting the ubiquitous motions in context, i.e., humans\ninteracting with humans, objects, and scenes. To address these limitations, we\nconsolidate large-scale video action datasets as knowledge banks to build\nMotionBank, which comprises 13 video action datasets, 1.24M motion sequences,\nand 132.9M frames of natural and diverse human motions. Different from\nlaboratory-captured motions, in-the-wild human-centric videos contain abundant\nmotions in context. To facilitate better motion text alignment, we also\nmeticulously devise a motion caption generation algorithm to automatically\nproduce rule-based, unbiased, and disentangled text descriptions via the\nkinematic characteristics for each motion. Extensive experiments show that our\nMotionBank is beneficial for general motion-related tasks of human motion\ngeneration, motion in-context generation, and motion understanding. Video\nmotions together with the rule-based text annotations could serve as an\nefficient alternative for larger LMMs. Our dataset, codes, and benchmark will\nbe publicly available at https://github.com/liangxuy/MotionBank.\n","authors":["Liang Xu","Shaoyang Hua","Zili Lin","Yifan Liu","Feipeng Ma","Yichao Yan","Xin Jin","Xiaokang Yang","Wenjun Zeng"],"pdf_url":"https://arxiv.org/pdf/2410.13790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13786v1","updated":"2024-10-17T17:22:59Z","published":"2024-10-17T17:22:59Z","title":"Emphasizing Semantic Consistency of Salient Posture for Speech-Driven\n  Gesture Generation","summary":"  Speech-driven gesture generation aims at synthesizing a gesture sequence\nsynchronized with the input speech signal. Previous methods leverage neural\nnetworks to directly map a compact audio representation to the gesture\nsequence, ignoring the semantic association of different modalities and failing\nto deal with salient gestures. In this paper, we propose a novel speech-driven\ngesture generation method by emphasizing the semantic consistency of salient\nposture. Specifically, we first learn a joint manifold space for the individual\nrepresentation of audio and body pose to exploit the inherent semantic\nassociation between two modalities, and propose to enforce semantic consistency\nvia a consistency loss. Furthermore, we emphasize the semantic consistency of\nsalient postures by introducing a weakly-supervised detector to identify\nsalient postures, and reweighting the consistency loss to focus more on\nlearning the correspondence between salient postures and the high-level\nsemantics of speech content. In addition, we propose to extract audio features\ndedicated to facial expression and body gesture separately, and design separate\nbranches for face and body gesture synthesis. Extensive experimental results\ndemonstrate the superiority of our method over the state-of-the-art approaches.\n","authors":["Fengqi Liu","Hexiang Wang","Jingyu Gong","Ran Yi","Qianyu Zhou","Xuequan Lu","Jiangbo Lu","Lizhuang Ma"],"pdf_url":"https://arxiv.org/pdf/2410.13786v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13569v1","updated":"2024-10-17T17:17:09Z","published":"2024-10-17T17:17:09Z","title":"Representing Model Weights with Language using Tree Experts","summary":"  The increasing availability of public models begs the question: can we train\nneural networks that use other networks as input? This paper learns to\nrepresent models within a joint space that embeds both model weights and\nlanguage. However, machine learning on model weights is challenging as model\nweights often exhibit significant variation unrelated to the models' semantic\nproperties (nuisance variation). We identify a key property of real-world\nmodels: most public models belong to a small set of Model Trees, where all\nmodels within a tree are fine-tuned from a common ancestor (e.g., a foundation\nmodel). Importantly, we find that within each tree there is less nuisance\nvariation between models. For example, while classifying models according to\ntheir training dataset generally requires complex architectures, in our case,\neven a linear classifier trained on a single layer is often effective. While\neffective, linear layers are computationally expensive as model weights are\nvery high dimensional. To address this, we introduce Probing Experts (ProbeX),\na theoretically motivated, lightweight probing method. Notably, ProbeX is the\nfirst probing method designed to learn from the weights of just a single model\nlayer. We also construct and release a dataset that simulates the structure of\npublic model repositories. Our results show that ProbeX can effectively map the\nweights of large models into a shared weight-language embedding space.\nFurthermore, we demonstrate the impressive generalization of our method,\nachieving zero-shot model classification and retrieval.\n","authors":["Eliahu Horwitz","Bar Cavia","Jonathan Kahana","Yedid Hoshen"],"pdf_url":"https://arxiv.org/pdf/2410.13569v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13760v1","updated":"2024-10-17T16:55:14Z","published":"2024-10-17T16:55:14Z","title":"Eyelid Fold Consistency in Facial Modeling","summary":"  Eyelid shape is integral to identity and likeness in human facial modeling.\nHuman eyelids are diverse in appearance with varied skin fold and epicanthal\nfold morphology between individuals. Existing parametric face models express\neyelid shape variation to an extent, but do not preserve sufficient likeness\nacross a diverse range of individuals. We propose a new definition of eyelid\nfold consistency and implement geometric processing techniques to model diverse\neyelid shapes in a unified topology. Using this method we reprocess data used\nto train a parametric face model and demonstrate significant improvements in\nface-related machine learning tasks.\n","authors":["Lohit Petikam","Charlie Hewitt","Fatemeh Saleh","Tadas Baltrušaitis"],"pdf_url":"https://arxiv.org/pdf/2410.13760v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.14015v2","updated":"2024-10-17T16:47:51Z","published":"2024-02-21T18:54:37Z","title":"Corrective Machine Unlearning","summary":"  Machine Learning models increasingly face data integrity challenges due to\nthe use of large-scale training datasets drawn from the Internet. We study what\nmodel developers can do if they detect that some data was manipulated or\nincorrect. Such manipulated data can cause adverse effects including\nvulnerability to backdoored samples, systemic biases, and reduced accuracy on\ncertain input domains. Realistically, all manipulated training samples cannot\nbe identified, and only a small, representative subset of the affected data can\nbe flagged.\n  We formalize Corrective Machine Unlearning as the problem of mitigating the\nimpact of data affected by unknown manipulations on a trained model, only\nhaving identified a subset of the corrupted data. We demonstrate that the\nproblem of corrective unlearning has significantly different requirements from\ntraditional privacy-oriented unlearning. We find most existing unlearning\nmethods, including retraining-from-scratch without the deletion set, require\nmost of the manipulated data to be identified for effective corrective\nunlearning. However, one approach, Selective Synaptic Dampening, achieves\nlimited success, unlearning adverse effects with just a small portion of the\nmanipulated samples in our setting, which shows encouraging signs for future\nprogress. We hope our work spurs research towards developing better methods for\ncorrective unlearning and offers practitioners a new strategy to handle data\nintegrity challenges arising from web-scale training. Code is available at\nhttps://github.com/drimpossible/corrective-unlearning-bench.\n","authors":["Shashwat Goel","Ameya Prabhu","Philip Torr","Ponnurangam Kumaraguru","Amartya Sanyal"],"pdf_url":"https://arxiv.org/pdf/2402.14015v2.pdf","comment":"Published in Transactions of Machine Learning Research (TMLR), 17\n  pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.13733v1","updated":"2024-10-17T16:36:38Z","published":"2024-10-17T16:36:38Z","title":"Improving Multi-modal Large Language Model through Boosting Vision\n  Capabilities","summary":"  We focus on improving the visual understanding capability for boosting the\nvision-language models. We propose \\textbf{Arcana}, a multiModal language\nmodel, which introduces two crucial techniques. First, we present Multimodal\nLoRA (MM-LoRA), a module designed to enhance the decoder. Unlike traditional\nlanguage-driven decoders, MM-LoRA consists of two parallel LoRAs -- one for\nvision and one for language -- each with its own parameters. This disentangled\nparameters design allows for more specialized learning in each modality and\nbetter integration of multimodal information. Second, we introduce the Query\nLadder adapter (QLadder) to improve the visual encoder. QLadder employs a\nlearnable ``\\textit{ladder}'' structure to deeply aggregates the intermediate\nrepresentations from the frozen pretrained visual encoder (e.g., CLIP image\nencoder). This enables the model to learn new and informative visual features,\nas well as remaining the powerful capabilities of the pretrained visual\nencoder. These techniques collectively enhance Arcana's visual perception\npower, enabling it to leverage improved visual information for more accurate\nand contextually relevant outputs across various multimodal scenarios.\nExtensive experiments and ablation studies demonstrate the effectiveness and\ngeneralization capability of our Arcana. The code and re-annotated data are\navailable at \\url{https://arcana-project-page.github.io}.\n","authors":["Yanpeng Sun","Huaxin Zhang","Qiang Chen","Xinyu Zhang","Nong Sang","Gang Zhang","Jingdong Wang","Zechao Li"],"pdf_url":"https://arxiv.org/pdf/2410.13733v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13726v1","updated":"2024-10-17T16:32:36Z","published":"2024-10-17T16:32:36Z","title":"DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework\n  for Talking Head Video Generation","summary":"  Talking head generation intends to produce vivid and realistic talking head\nvideos from a single portrait and speech audio clip. Although significant\nprogress has been made in diffusion-based talking head generation, almost all\nmethods rely on autoregressive strategies, which suffer from limited context\nutilization beyond the current generation step, error accumulation, and slower\ngeneration speed. To address these challenges, we present DAWN (Dynamic frame\nAvatar With Non-autoregressive diffusion), a framework that enables all-at-once\ngeneration of dynamic-length video sequences. Specifically, it consists of two\nmain components: (1) audio-driven holistic facial dynamics generation in the\nlatent motion space, and (2) audio-driven head pose and blink generation.\nExtensive experiments demonstrate that our method generates authentic and vivid\nvideos with precise lip motions, and natural pose/blink movements.\nAdditionally, with a high generation speed, DAWN possesses strong extrapolation\ncapabilities, ensuring the stable production of high-quality long videos. These\nresults highlight the considerable promise and potential impact of DAWN in the\nfield of talking head video generation. Furthermore, we hope that DAWN sparks\nfurther exploration of non-autoregressive approaches in diffusion models. Our\ncode will be publicly at https://github.com/Hanbo-Cheng/DAWN-pytorch.\n","authors":["Hanbo Cheng","Limin Lin","Chenyu Liu","Pengcheng Xia","Pengfei Hu","Jiefeng Ma","Jun Du","Jia Pan"],"pdf_url":"https://arxiv.org/pdf/2410.13726v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13720v1","updated":"2024-10-17T16:22:46Z","published":"2024-10-17T16:22:46Z","title":"Movie Gen: A Cast of Media Foundation Models","summary":"  We present Movie Gen, a cast of foundation models that generates\nhigh-quality, 1080p HD videos with different aspect ratios and synchronized\naudio. We also show additional capabilities such as precise instruction-based\nvideo editing and generation of personalized videos based on a user's image.\nOur models set a new state-of-the-art on multiple tasks: text-to-video\nsynthesis, video personalization, video editing, video-to-audio generation, and\ntext-to-audio generation. Our largest video generation model is a 30B parameter\ntransformer trained with a maximum context length of 73K video tokens,\ncorresponding to a generated video of 16 seconds at 16 frames-per-second. We\nshow multiple technical innovations and simplifications on the architecture,\nlatent spaces, training objectives and recipes, data curation, evaluation\nprotocols, parallelization techniques, and inference optimizations that allow\nus to reap the benefits of scaling pre-training data, model size, and training\ncompute for training large scale media generation models. We hope this paper\nhelps the research community to accelerate progress and innovation in media\ngeneration models. All videos from this paper are available at\nhttps://go.fb.me/MovieGenResearchVideos.\n","authors":["Adam Polyak","Amit Zohar","Andrew Brown","Andros Tjandra","Animesh Sinha","Ann Lee","Apoorv Vyas","Bowen Shi","Chih-Yao Ma","Ching-Yao Chuang","David Yan","Dhruv Choudhary","Dingkang Wang","Geet Sethi","Guan Pang","Haoyu Ma","Ishan Misra","Ji Hou","Jialiang Wang","Kiran Jagadeesh","Kunpeng Li","Luxin Zhang","Mannat Singh","Mary Williamson","Matt Le","Matthew Yu","Mitesh Kumar Singh","Peizhao Zhang","Peter Vajda","Quentin Duval","Rohit Girdhar","Roshan Sumbaly","Sai Saketh Rambhatla","Sam Tsai","Samaneh Azadi","Samyak Datta","Sanyuan Chen","Sean Bell","Sharadh Ramaswamy","Shelly Sheynin","Siddharth Bhattacharya","Simran Motwani","Tao Xu","Tianhe Li","Tingbo Hou","Wei-Ning Hsu","Xi Yin","Xiaoliang Dai","Yaniv Taigman","Yaqiao Luo","Yen-Cheng Liu","Yi-Chiao Wu","Yue Zhao","Yuval Kirstain","Zecheng He","Zijian He","Albert Pumarola","Ali Thabet","Artsiom Sanakoyeu","Arun Mallya","Baishan Guo","Boris Araya","Breena Kerr","Carleigh Wood","Ce Liu","Cen Peng","Dimitry Vengertsev","Edgar Schonfeld","Elliot Blanchard","Felix Juefei-Xu","Fraylie Nord","Jeff Liang","John Hoffman","Jonas Kohler","Kaolin Fire","Karthik Sivakumar","Lawrence Chen","Licheng Yu","Luya Gao","Markos Georgopoulos","Rashel Moritz","Sara K. Sampson","Shikai Li","Simone Parmeggiani","Steve Fine","Tara Fowler","Vladan Petrovic","Yuming Du"],"pdf_url":"https://arxiv.org/pdf/2410.13720v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12214v2","updated":"2024-10-17T16:16:33Z","published":"2024-10-16T04:19:28Z","title":"Order-aware Interactive Segmentation","summary":"  Interactive segmentation aims to accurately segment target objects with\nminimal user interactions. However, current methods often fail to accurately\nseparate target objects from the background, due to a limited understanding of\norder, the relative depth between objects in a scene. To address this issue, we\npropose OIS: order-aware interactive segmentation, where we explicitly encode\nthe relative depth between objects into order maps. We introduce a novel\norder-aware attention, where the order maps seamlessly guide the user\ninteractions (in the form of clicks) to attend to the image features. We\nfurther present an object-aware attention module to incorporate a strong\nobject-level understanding to better differentiate objects with similar order.\nOur approach allows both dense and sparse integration of user clicks, enhancing\nboth accuracy and efficiency as compared to prior works. Experimental results\ndemonstrate that OIS achieves state-of-the-art performance, improving mIoU\nafter one click by 7.61 on the HQSeg44K dataset and 1.32 on the DAVIS dataset\nas compared to the previous state-of-the-art SegNext, while also doubling\ninference speed compared to current leading methods. The project page is\nhttps://ukaukaaaa.github.io/projects/OIS/index.html\n","authors":["Bin Wang","Anwesa Choudhuri","Meng Zheng","Zhongpai Gao","Benjamin Planche","Andong Deng","Qin Liu","Terrence Chen","Ulas Bagci","Ziyan Wu"],"pdf_url":"https://arxiv.org/pdf/2410.12214v2.pdf","comment":"Interactive demo can be found in project page:\n  https://ukaukaaaa.github.io/projects/OIS/index.html"},{"id":"http://arxiv.org/abs/2410.11092v2","updated":"2024-10-17T16:13:49Z","published":"2024-10-14T21:10:56Z","title":"EchoApex: A General-Purpose Vision Foundation Model for Echocardiography","summary":"  Quantitative evaluation of echocardiography is essential for precise\nassessment of cardiac condition, monitoring disease progression, and guiding\ntreatment decisions. The diverse nature of echo images, including variations in\nprobe types, manufacturers, and pathologies, poses challenges for developing\nartificial intelligent models that can generalize across different clinical\npractice. We introduce EchoApex, the first general-purpose vision foundation\nmodel echocardiography with applications on a variety of clinical practice.\nLeveraging self-supervised learning, EchoApex is pretrained on over 20 million\necho images from 11 clinical centres. By incorporating task-specific decoders\nand adapter modules, we demonstrate the effectiveness of EchoApex on 4\ndifferent kind of clinical applications with 28 sub-tasks, including view\nclassification, interactive structure segmentation, left ventricle hypertrophy\ndetection and automated ejection fraction estimation from view sequences.\nCompared to state-of-the-art task-specific models, EchoApex attains improved\nperformance with a unified image encoding architecture, demonstrating the\nbenefits of model pretraining at scale with in-domain data. Furthermore,\nEchoApex illustrates the potential for developing a general-purpose vision\nfoundation model tailored specifically for echocardiography, capable of\naddressing a diverse range of clinical applications with high efficiency and\nefficacy.\n","authors":["Abdoul Aziz Amadou","Yue Zhang","Sebastien Piat","Paul Klein","Ingo Schmuecking","Tiziano Passerini","Puneet Sharma"],"pdf_url":"https://arxiv.org/pdf/2410.11092v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12040v5","updated":"2024-10-17T16:11:43Z","published":"2024-07-01T17:59:55Z","title":"Comprehensive Performance Evaluation of YOLO11, YOLOv10, YOLOv9 and\n  YOLOv8 on Detecting and Counting Fruitlet in Complex Orchard Environments","summary":"  This study extensively evaluated You Only Look Once (YOLO) object detection\nalgorithms across all configurations (total 22) of YOLOv8, YOLOv9, YOLOv10, and\nYOLO11 for green fruit detection in commercial orchards. The research also\nvalidated in-field fruitlet counting using an iPhone and machine vision sensors\nacross four apple varieties: Scifresh, Scilate, Honeycrisp and Cosmic Crisp.\nAmong the 22 configurations evaluated, YOLO11s and YOLOv9 gelan-base\noutperformed others with mAP@50 scores of 0.933 and 0.935 respectively. In\nterms of recall, YOLOv9 gelan-base achieved the highest value among YOLOv9\nconfigurations at 0.899, while YOLO11m led YOLO11 variants with 0.897. YOLO11n\nemerged as the fastest model, achieving fastest inference speed of only 2.4 ms,\nsignificantly outpacing the leading configurations of YOLOv10n, YOLOv9 gelan-s,\nand YOLOv8n, with speeds of 5.5, 11.5, and 4.1 ms, respectively. This\ncomparative evaluation highlights the strengths of YOLO11, YOLOv9, and YOLOv10,\noffering researchers essential insights to choose the best-suited model for\nfruitlet detection and possible automation in commercial orchards. For\nreal-time automation related work in relevant datasets, we recommend using\nYOLO11n due to its high detection and image processing speed. Keywords: YOLO11,\nYOLO11 Object Detection, YOLOv10, YOLOv9, YOLOv8, You Only Look Once, Fruitlet\nDetection, Greenfruit Detection, Green Apple Detection, Agricultural\nAutomation, Artificial Intelligence, Deep Learning, Machine Learning, Zero-shot\nDetection\n","authors":["Ranjan Sapkota","Zhichao Meng","Martin Churuvija","Xiaoqiang Du","Zenghong Ma","Manoj Karkee"],"pdf_url":"https://arxiv.org/pdf/2407.12040v5.pdf","comment":"15 figures, 2 tables"},{"id":"http://arxiv.org/abs/2406.10322v2","updated":"2024-10-17T16:06:18Z","published":"2024-06-14T17:41:55Z","title":"LieRE: Generalizing Rotary Position Encodings","summary":"  While Rotary Position Embeddings (RoPE) for large language models have become\nwidely adopted, their application for other modalities has been slower. Here,\nwe introduce Lie group Relative position Encodings (LieRE) that goes beyond\nRoPE in supporting n-dimensional inputs. We evaluate the performance of LieRE\non 2D and 3D image classification tasks and observe that LieRE leads to marked\nrelative improvements in performance (up to 9.7% for 2D and up to 25.5% for\n3D), training efficiency (3.5x reduction), data efficiency (30%) compared to\nthe baselines of DeiT III, RoPE-Mixed and Vision-Llama.\nhttps://github.com/Stanford-AIMI/LieRE\n","authors":["Sophie Ostmeier","Brian Axelrod","Michael E. Moseley","Akshay Chaudhari","Curtis Langlotz"],"pdf_url":"https://arxiv.org/pdf/2406.10322v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13694v1","updated":"2024-10-17T15:59:52Z","published":"2024-10-17T15:59:52Z","title":"Exploring the Design Space of Visual Context Representation in Video\n  MLLMs","summary":"  Video Multimodal Large Language Models (MLLMs) have shown remarkable\ncapability of understanding the video semantics on various downstream tasks.\nDespite the advancements, there is still a lack of systematic research on\nvisual context representation, which refers to the scheme to select frames from\na video and further select the tokens from a frame. In this paper, we explore\nthe design space for visual context representation, and aim to improve the\nperformance of video MLLMs by finding more effective representation schemes.\nFirstly, we formulate the task of visual context representation as a\nconstrained optimization problem, and model the language modeling loss as a\nfunction of the number of frames and the number of embeddings (or tokens) per\nframe, given the maximum visual context window size. Then, we explore the\nscaling effects in frame selection and token selection respectively, and fit\nthe corresponding function curve by conducting extensive empirical experiments.\nWe examine the effectiveness of typical selection strategies and present\nempirical findings to determine the two factors. Furthermore, we study the\njoint effect of frame selection and token selection, and derive the optimal\nformula for determining the two factors. We demonstrate that the derived\noptimal settings show alignment with the best-performed results of empirical\nexperiments. Our code and model are available at:\nhttps://github.com/RUCAIBox/Opt-Visor.\n","authors":["Yifan Du","Yuqi Huo","Kun Zhou","Zijia Zhao","Haoyu Lu","Han Huang","Wayne Xin Zhao","Bingning Wang","Weipeng Chen","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2410.13694v1.pdf","comment":"Long Video MLLM; work in progress"},{"id":"http://arxiv.org/abs/2410.12407v2","updated":"2024-10-17T15:59:34Z","published":"2024-10-16T09:42:29Z","title":"Beyond Coarse-Grained Matching in Video-Text Retrieval","summary":"  Video-text retrieval has seen significant advancements, yet the ability of\nmodels to discern subtle differences in captions still requires verification.\nIn this paper, we introduce a new approach for fine-grained evaluation. Our\napproach can be applied to existing datasets by automatically generating hard\nnegative test captions with subtle single-word variations across nouns, verbs,\nadjectives, adverbs, and prepositions. We perform comprehensive experiments\nusing four state-of-the-art models across two standard benchmarks (MSR-VTT and\nVATEX) and two specially curated datasets enriched with detailed descriptions\n(VLN-UVO and VLN-OOPS), resulting in a number of novel insights: 1) our\nanalyses show that the current evaluation benchmarks fall short in detecting a\nmodel's ability to perceive subtle single-word differences, 2) our fine-grained\nevaluation highlights the difficulty models face in distinguishing such subtle\nvariations. To enhance fine-grained understanding, we propose a new baseline\nthat can be easily combined with current methods. Experiments on our\nfine-grained evaluations demonstrate that this approach enhances a model's\nability to understand fine-grained differences.\n","authors":["Aozhu Chen","Hazel Doughty","Xirong Li","Cees G. M. Snoek"],"pdf_url":"https://arxiv.org/pdf/2410.12407v2.pdf","comment":"Accepted to ACCV 2024"},{"id":"http://arxiv.org/abs/2410.13685v1","updated":"2024-10-17T15:47:12Z","published":"2024-10-17T15:47:12Z","title":"Label-free prediction of fluorescence markers in bovine satellite cells\n  using deep learning","summary":"  Assessing the quality of bovine satellite cells (BSCs) is essential for the\ncultivated meat industry, which aims to address global food sustainability\nchallenges. This study aims to develop a label-free method for predicting\nfluorescence markers in isolated BSCs using deep learning. We employed a\nU-Net-based CNN model to predict multiple fluorescence signals from a single\nbright-field microscopy image of cell culture. Two key biomarkers, DAPI and\nPax7, were used to determine the abundance and quality of BSCs. The image\npre-processing pipeline included fluorescence denoising to improve prediction\nperformance and consistency. A total of 48 biological replicates were used,\nwith statistical performance metrics such as Pearson correlation coefficient\nand SSIM employed for model evaluation. The model exhibited better performance\nwith DAPI predictions due to uniform staining. Pax7 predictions were more\nvariable, reflecting biological heterogeneity. Enhanced visualization\ntechniques, including color mapping and image overlay, improved the\ninterpretability of the predictions by providing better contextual and\nperceptual information. The findings highlight the importance of data\npre-processing and demonstrate the potential of deep learning to advance\nnon-invasive, label-free assessment techniques in the cultivated meat industry,\npaving the way for reliable and actionable AI-driven evaluations.\n","authors":["Sania Sinha","Aarham Wasit","Won Seob Kim","Jongkyoo Kim","Jiyoon Yi"],"pdf_url":"https://arxiv.org/pdf/2410.13685v1.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2402.13251v3","updated":"2024-10-17T15:45:06Z","published":"2024-02-20T18:59:00Z","title":"FlashTex: Fast Relightable Mesh Texturing with LightControlNet","summary":"  Manually creating textures for 3D meshes is time-consuming, even for expert\nvisual content creators. We propose a fast approach for automatically texturing\nan input 3D mesh based on a user-provided text prompt. Importantly, our\napproach disentangles lighting from surface material/reflectance in the\nresulting texture so that the mesh can be properly relit and rendered in any\nlighting environment. We introduce LightControlNet, a new text-to-image model\nbased on the ControlNet architecture, which allows the specification of the\ndesired lighting as a conditioning image to the model. Our text-to-texture\npipeline then constructs the texture in two stages. The first stage produces a\nsparse set of visually consistent reference views of the mesh using\nLightControlNet. The second stage applies a texture optimization based on Score\nDistillation Sampling (SDS) that works with LightControlNet to increase the\ntexture quality while disentangling surface material from lighting. Our\nalgorithm is significantly faster than previous text-to-texture methods, while\nproducing high-quality and relightable textures.\n","authors":["Kangle Deng","Timothy Omernick","Alexander Weiss","Deva Ramanan","Jun-Yan Zhu","Tinghui Zhou","Maneesh Agrawala"],"pdf_url":"https://arxiv.org/pdf/2402.13251v3.pdf","comment":"Project page: https://flashtex.github.io/"},{"id":"http://arxiv.org/abs/2410.13675v1","updated":"2024-10-17T15:33:54Z","published":"2024-10-17T15:33:54Z","title":"Pose-Based Sign Language Appearance Transfer","summary":"  We introduce a method for transferring the signer's appearance in sign\nlanguage skeletal poses while preserving the sign content. Using estimated\nposes, we transfer the appearance of one signer to another, maintaining natural\nmovements and transitions. This approach improves pose-based rendering and sign\nstitching while obfuscating identity. Our experiments show that while the\nmethod reduces signer identification accuracy, it slightly harms sign\nrecognition performance, highlighting a tradeoff between privacy and utility.\nOur code is available at\n\\url{https://github.com/sign-language-processing/pose-anonymization}.\n","authors":["Amit Moryossef","Gerard Sant","Zifan Jiang"],"pdf_url":"https://arxiv.org/pdf/2410.13675v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13674v1","updated":"2024-10-17T15:33:35Z","published":"2024-10-17T15:33:35Z","title":"Diffusion Curriculum: Synthetic-to-Real Generative Curriculum Learning\n  via Image-Guided Diffusion","summary":"  Low-quality or scarce data has posed significant challenges for training deep\nneural networks in practice. While classical data augmentation cannot\ncontribute very different new data, diffusion models opens up a new door to\nbuild self-evolving AI by generating high-quality and diverse synthetic data\nthrough text-guided prompts. However, text-only guidance cannot control\nsynthetic images' proximity to the original images, resulting in\nout-of-distribution data detrimental to the model performance. To overcome the\nlimitation, we study image guidance to achieve a spectrum of interpolations\nbetween synthetic and real images. With stronger image guidance, the generated\nimages are similar to the training data but hard to learn. While with weaker\nimage guidance, the synthetic images will be easier for model but contribute to\na larger distribution gap with the original data. The generated full spectrum\nof data enables us to build a novel \"Diffusion Curriculum (DisCL)\". DisCL\nadjusts the image guidance level of image synthesis for each training stage: It\nidentifies and focuses on hard samples for the model and assesses the most\neffective guidance level of synthetic images to improve hard data learning. We\napply DisCL to two challenging tasks: long-tail (LT) classification and\nlearning from low-quality data. It focuses on lower-guidance images of\nhigh-quality to learn prototypical features as a warm-up of learning\nhigher-guidance images that might be weak on diversity or quality. Extensive\nexperiments showcase a gain of 2.7% and 2.1% in OOD and ID macro-accuracy when\napplying DisCL to iWildCam dataset. On ImageNet-LT, DisCL improves the base\nmodel's tail-class accuracy from 4.4% to 23.64% and leads to a 4.02%\nimprovement in all-class accuracy.\n","authors":["Yijun Liang","Shweta Bhardwaj","Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.13674v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16005v3","updated":"2024-10-17T15:28:15Z","published":"2024-05-25T02:02:08Z","title":"PTQ4DiT: Post-training Quantization for Diffusion Transformers","summary":"  The recent introduction of Diffusion Transformers (DiTs) has demonstrated\nexceptional capabilities in image generation by using a different backbone\narchitecture, departing from traditional U-Nets and embracing the scalable\nnature of transformers. Despite their advanced capabilities, the wide\ndeployment of DiTs, particularly for real-time applications, is currently\nhampered by considerable computational demands at the inference stage.\nPost-training Quantization (PTQ) has emerged as a fast and data-efficient\nsolution that can significantly reduce computation and memory footprint by\nusing low-bit weights and activations. However, its applicability to DiTs has\nnot yet been explored and faces non-trivial difficulties due to the unique\ndesign of DiTs. In this paper, we propose PTQ4DiT, a specifically designed PTQ\nmethod for DiTs. We discover two primary quantization challenges inherent in\nDiTs, notably the presence of salient channels with extreme magnitudes and the\ntemporal variability in distributions of salient activation over multiple\ntimesteps. To tackle these challenges, we propose Channel-wise Salience\nBalancing (CSB) and Spearmen's $\\rho$-guided Salience Calibration (SSC). CSB\nleverages the complementarity property of channel magnitudes to redistribute\nthe extremes, alleviating quantization errors for both activations and weights.\nSSC extends this approach by dynamically adjusting the balanced salience to\ncapture the temporal variations in activation. Additionally, to eliminate extra\ncomputational costs caused by PTQ4DiT during inference, we design an offline\nre-parameterization strategy for DiTs. Experiments demonstrate that our PTQ4DiT\nsuccessfully quantizes DiTs to 8-bit precision (W8A8) while preserving\ncomparable generation ability and further enables effective quantization to\n4-bit weight precision (W4A8) for the first time.\n","authors":["Junyi Wu","Haoxuan Wang","Yuzhang Shang","Mubarak Shah","Yan Yan"],"pdf_url":"https://arxiv.org/pdf/2405.16005v3.pdf","comment":"NeurIPS 2024. Code is available at\n  https://github.com/adreamwu/PTQ4DiT"},{"id":"http://arxiv.org/abs/2410.13666v1","updated":"2024-10-17T15:27:17Z","published":"2024-10-17T15:27:17Z","title":"VL-GLUE: A Suite of Fundamental yet Challenging Visuo-Linguistic\n  Reasoning Tasks","summary":"  Deriving inference from heterogeneous inputs (such as images, text, and\naudio) is an important skill for humans to perform day-to-day tasks. A similar\nability is desirable for the development of advanced Artificial Intelligence\n(AI) systems. While state-of-the-art models are rapidly closing the gap with\nhuman-level performance on diverse computer vision and NLP tasks separately,\nthey struggle to solve tasks that require joint reasoning over visual and\ntextual modalities. Inspired by GLUE (Wang et. al., 2018)- a multitask\nbenchmark for natural language understanding, we propose VL-GLUE in this paper.\nVL-GLUE consists of over 100k samples spanned across seven different tasks,\nwhich at their core require visuo-linguistic reasoning. Moreover, our benchmark\ncomprises of diverse image types (from synthetically rendered figures, and\nday-to-day scenes to charts and complex diagrams) and includes a broad variety\nof domain-specific text (from cooking, politics, and sports to high-school\ncurricula), demonstrating the need for multi-modal understanding in the\nreal-world. We show that this benchmark is quite challenging for existing\nlarge-scale vision-language models and encourage development of systems that\npossess robust visuo-linguistic reasoning capabilities.\n","authors":["Shailaja Keyur Sampat","Mutsumi Nakamura","Shankar Kailas","Kartik Aggarwal","Mandy Zhou","Yezhou Yang","Chitta Baral"],"pdf_url":"https://arxiv.org/pdf/2410.13666v1.pdf","comment":"18 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.13663v1","updated":"2024-10-17T15:25:13Z","published":"2024-10-17T15:25:13Z","title":"DiRecNetV2: A Transformer-Enhanced Network for Aerial Disaster\n  Recognition","summary":"  The integration of Unmanned Aerial Vehicles (UAVs) with artificial\nintelligence (AI) models for aerial imagery processing in disaster assessment,\nnecessitates models that demonstrate exceptional accuracy, computational\nefficiency, and real-time processing capabilities. Traditionally Convolutional\nNeural Networks (CNNs), demonstrate efficiency in local feature extraction but\nare limited by their potential for global context interpretation. On the other\nhand, Vision Transformers (ViTs) show promise for improved global context\ninterpretation through the use of attention mechanisms, although they still\nremain underinvestigated in UAV-based disaster response applications. Bridging\nthis research gap, we introduce DiRecNetV2, an improved hybrid model that\nutilizes convolutional and transformer layers. It merges the inductive biases\nof CNNs for robust feature extraction with the global context understanding of\nTransformers, maintaining a low computational load ideal for UAV applications.\nAdditionally, we introduce a new, compact multi-label dataset of disasters, to\nset an initial benchmark for future research, exploring how models trained on\nsingle-label data perform in a multi-label test set. The study assesses\nlightweight CNNs and ViTs on the AIDERSv2 dataset, based on the frames per\nsecond (FPS) for efficiency and the weighted F1 scores for classification\nperformance. DiRecNetV2 not only achieves a weighted F1 score of 0.964 on a\nsingle-label test set but also demonstrates adaptability, with a score of 0.614\non a complex multi-label test set, while functioning at 176.13 FPS on the\nNvidia Orin Jetson device.\n","authors":["Demetris Shianios","Panayiotis Kolios","Christos Kyrkou"],"pdf_url":"https://arxiv.org/pdf/2410.13663v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2410.13662v1","updated":"2024-10-17T15:22:57Z","published":"2024-10-17T15:22:57Z","title":"ActionCOMET: A Zero-shot Approach to Learn Image-specific Commonsense\n  Concepts about Actions","summary":"  Humans observe various actions being performed by other humans (physically or\nin videos/images) and can draw a wide range of inferences about it beyond what\nthey can visually perceive. Such inferences include determining the aspects of\nthe world that make action execution possible (e.g. liquid objects can undergo\npouring), predicting how the world will change as a result of the action (e.g.\npotatoes being golden and crispy after frying), high-level goals associated\nwith the action (e.g. beat the eggs to make an omelet) and reasoning about\nactions that possibly precede or follow the current action (e.g. crack eggs\nbefore whisking or draining pasta after boiling). Similar reasoning ability is\nhighly desirable in autonomous systems that would assist us in performing\neveryday tasks. To that end, we propose a multi-modal task to learn\naforementioned concepts about actions being performed in images. We develop a\ndataset consisting of 8.5k images and 59.3k inferences about actions grounded\nin those images, collected from an annotated cooking-video dataset. We propose\nActionCOMET, a zero-shot framework to discern knowledge present in language\nmodels specific to the provided visual input. We present baseline results of\nActionCOMET over the collected dataset and compare them with the performance of\nthe best existing VQA approaches.\n","authors":["Shailaja Keyur Sampat","Yezhou Yang","Chitta Baral"],"pdf_url":"https://arxiv.org/pdf/2410.13662v1.pdf","comment":"15 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:2004.10796 by other authors"},{"id":"http://arxiv.org/abs/2410.13651v1","updated":"2024-10-17T15:16:10Z","published":"2024-10-17T15:16:10Z","title":"Help Me Identify: Is an LLM+VQA System All We Need to Identify Visual\n  Concepts?","summary":"  An ability to learn about new objects from a small amount of visual data and\nproduce convincing linguistic justification about the presence/absence of\ncertain concepts (that collectively compose the object) in novel scenarios is\nan important characteristic of human cognition. This is possible due to\nabstraction of attributes/properties that an object is composed of e.g. an\nobject `bird' can be identified by the presence of a beak, feathers, legs,\nwings, etc. Inspired by this aspect of human reasoning, in this work, we\npresent a zero-shot framework for fine-grained visual concept learning by\nleveraging large language model and Visual Question Answering (VQA) system.\nSpecifically, we prompt GPT-3 to obtain a rich linguistic description of visual\nobjects in the dataset. We convert the obtained concept descriptions into a set\nof binary questions. We pose these questions along with the query image to a\nVQA system and aggregate the answers to determine the presence or absence of an\nobject in the test images. Our experiments demonstrate comparable performance\nwith existing zero-shot visual classification methods and few-shot concept\nlearning approaches, without substantial computational overhead, yet being\nfully explainable from the reasoning perspective.\n","authors":["Shailaja Keyur Sampat","Maitreya Patel","Yezhou Yang","Chitta Baral"],"pdf_url":"https://arxiv.org/pdf/2410.13651v1.pdf","comment":"14 pages, 7 figures"},{"id":"http://arxiv.org/abs/2407.03471v3","updated":"2024-10-17T15:12:44Z","published":"2024-07-03T19:36:33Z","title":"Learning Action and Reasoning-Centric Image Editing from Videos and\n  Simulations","summary":"  An image editing model should be able to perform diverse edits, ranging from\nobject replacement, changing attributes or style, to performing actions or\nmovement, which require many forms of reasoning. Current general\ninstruction-guided editing models have significant shortcomings with action and\nreasoning-centric edits. Object, attribute or stylistic changes can be learned\nfrom visually static datasets. On the other hand, high-quality data for action\nand reasoning-centric edits is scarce and has to come from entirely different\nsources that cover e.g. physical dynamics, temporality and spatial reasoning.\nTo this end, we meticulously curate the AURORA Dataset\n(Action-Reasoning-Object-Attribute), a collection of high-quality training\ndata, human-annotated and curated from videos and simulation engines. We focus\non a key aspect of quality training data: triplets (source image, prompt,\ntarget image) contain a single meaningful visual change described by the\nprompt, i.e., truly minimal changes between source and target images. To\ndemonstrate the value of our dataset, we evaluate an AURORA-finetuned model on\na new expert-curated benchmark (AURORA-Bench) covering 8 diverse editing tasks.\nOur model significantly outperforms previous editing models as judged by human\nraters. For automatic evaluations, we find important flaws in previous metrics\nand caution their use for semantically hard editing tasks. Instead, we propose\na new automatic metric that focuses on discriminative understanding. We hope\nthat our efforts : (1) curating a quality training dataset and an evaluation\nbenchmark, (2) developing critical evaluations, and (3) releasing a\nstate-of-the-art model, will fuel further progress on general image editing.\n","authors":["Benno Krojer","Dheeraj Vattikonda","Luis Lara","Varun Jampani","Eva Portelance","Christopher Pal","Siva Reddy"],"pdf_url":"https://arxiv.org/pdf/2407.03471v3.pdf","comment":"NeurIPS 2024 (Dataset & Benchmarks)"},{"id":"http://arxiv.org/abs/2410.09913v2","updated":"2024-10-17T15:08:08Z","published":"2024-10-13T16:40:48Z","title":"Stratified Domain Adaptation: A Progressive Self-Training Approach for\n  Scene Text Recognition","summary":"  Unsupervised domain adaptation (UDA) has become increasingly prevalent in\nscene text recognition (STR), especially where training and testing data reside\nin different domains. The efficacy of existing UDA approaches tends to degrade\nwhen there is a large gap between the source and target domains. To deal with\nthis problem, gradually shifting or progressively learning to shift from domain\nto domain is the key issue. In this paper, we introduce the Stratified Domain\nAdaptation (StrDA) approach, which examines the gradual escalation of the\ndomain gap for the learning process. The objective is to partition the training\ndata into subsets so that the progressively self-trained model can adapt to\ngradual changes. We stratify the training data by evaluating the proximity of\neach data sample to both the source and target domains. We propose a novel\nmethod for employing domain discriminators to estimate the out-of-distribution\nand domain discriminative levels of data samples. Extensive experiments on\nbenchmark scene-text datasets show that our approach significantly improves the\nperformance of baseline (source-trained) STR models.\n","authors":["Kha Nhat Le","Hoang-Tuan Nguyen","Hung Tien Tran","Thanh Duc Ngo"],"pdf_url":"https://arxiv.org/pdf/2410.09913v2.pdf","comment":"15 pages, 12 figures, 5 tables, include supplementary materials"},{"id":"http://arxiv.org/abs/2407.04952v2","updated":"2024-10-17T14:58:53Z","published":"2024-07-06T04:06:55Z","title":"Granular Privacy Control for Geolocation with Vision Language Models","summary":"  Vision Language Models (VLMs) are rapidly advancing in their capability to\nanswer information-seeking questions. As these models are widely deployed in\nconsumer applications, they could lead to new privacy risks due to emergent\nabilities to identify people in photos, geolocate images, etc. As we\ndemonstrate, somewhat surprisingly, current open-source and proprietary VLMs\nare very capable image geolocators, making widespread geolocation with VLMs an\nimmediate privacy risk, rather than merely a theoretical future concern. As a\nfirst step to address this challenge, we develop a new benchmark, GPTGeoChat,\nto test the ability of VLMs to moderate geolocation dialogues with users. We\ncollect a set of 1,000 image geolocation conversations between in-house\nannotators and GPT-4v, which are annotated with the granularity of location\ninformation revealed at each turn. Using this new dataset, we evaluate the\nability of various VLMs to moderate GPT-4v geolocation conversations by\ndetermining when too much location information has been revealed. We find that\ncustom fine-tuned models perform on par with prompted API-based models when\nidentifying leaked location information at the country or city level; however,\nfine-tuning on supervised data appears to be needed to accurately moderate\nfiner granularities, such as the name of a restaurant or building.\n","authors":["Ethan Mendes","Yang Chen","James Hays","Sauvik Das","Wei Xu","Alan Ritter"],"pdf_url":"https://arxiv.org/pdf/2407.04952v2.pdf","comment":"Accepted to EMNLP 2024 main conference"},{"id":"http://arxiv.org/abs/2410.13621v1","updated":"2024-10-17T14:55:09Z","published":"2024-10-17T14:55:09Z","title":"Enhanced Prompt-leveraged Weakly Supervised Cancer Segmentation based on\n  Segment Anything","summary":"  This work proposes a novel approach beyond supervised learning for effective\npathological image analysis, addressing the challenge of limited robust labeled\ndata. Pathological diagnosis of diseases like cancer has conventionally relied\non the evaluation of morphological features by physicians and pathologists.\nHowever, recent advancements in compute-aided diagnosis (CAD) systems are\ngaining significant attention as diagnostic support tools. Although the\nadvancement of deep learning has improved CAD significantly, segmentation\nmodels typically require large pixel-level annotated dataset, and such labeling\nis expensive. Existing studies not based on supervised approaches still\nstruggle with limited generalization, and no practical approach has emerged\nyet. To address this issue, we present a weakly supervised semantic\nsegmentation (WSSS) model by combining class activation map and Segment\nAnything Model (SAM)-based pseudo-labeling. For effective pretraining, we adopt\nthe SAM-a foundation model that is pretrained on large datasets and operates in\nzero-shot configurations using only coarse prompts. The proposed approach\ntransfer enhanced Attention Dropout Layer's knowledge to SAM, thereby\ngenerating pseudo-labels. To demonstrate the superiority of the proposed\nmethod, experimental studies are conducted on histopathological breast cancer\ndatasets. The proposed method outperformed other WSSS methods across three\ndatasets, demonstrating its efficiency by achieving this with only 12GB of GPU\nmemory during training. Our code is available at :\nhttps://github.com/QI-NemoSong/EPLC-SAM\n","authors":["Joonhyeon Song","Seohwan Yun","Seongho Yoon","Joohyeok Kim","Sangmin Lee"],"pdf_url":"https://arxiv.org/pdf/2410.13621v1.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.13618v1","updated":"2024-10-17T14:51:17Z","published":"2024-10-17T14:51:17Z","title":"LoLDU: Low-Rank Adaptation via Lower-Diag-Upper Decomposition for\n  Parameter-Efficient Fine-Tuning","summary":"  The rapid growth of model scale has necessitated substantial computational\nresources for fine-tuning. Existing approach such as Low-Rank Adaptation (LoRA)\nhas sought to address the problem of handling the large updated parameters in\nfull fine-tuning. However, LoRA utilize random initialization and optimization\nof low-rank matrices to approximate updated weights, which can result in\nsuboptimal convergence and an accuracy gap compared to full fine-tuning. To\naddress these issues, we propose LoLDU, a Parameter-Efficient Fine-Tuning\n(PEFT) approach that significantly reduces trainable parameters by 2600 times\ncompared to regular PEFT methods while maintaining comparable performance.\nLoLDU leverages Lower-Diag-Upper Decomposition (LDU) to initialize low-rank\nmatrices for faster convergence and orthogonality. We focus on optimizing the\ndiagonal matrix for scaling transformations. To the best of our knowledge,\nLoLDU has the fewest parameters among all PEFT approaches. We conducted\nextensive experiments across 4 instruction-following datasets, 6 natural\nlanguage understanding (NLU) datasets, 8 image classification datasets, and\nimage generation datasets with multiple model types (LLaMA2, RoBERTa, ViT, and\nStable Diffusion), providing a comprehensive and detailed analysis. Our\nopen-source code can be accessed at\n\\href{https://github.com/SKDDJ/LoLDU}{https://github.com/SKDDJ/LoLDU}.\n","authors":["Yiming Shi","Jiwei Wei","Yujia Wu","Ran Ran","Chengwei Sun","Shiyuan He","Yang Yang"],"pdf_url":"https://arxiv.org/pdf/2410.13618v1.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.13616v1","updated":"2024-10-17T14:49:37Z","published":"2024-10-17T14:49:37Z","title":"Spatiotemporal Object Detection for Improved Aerial Vehicle Detection in\n  Traffic Monitoring","summary":"  This work presents advancements in multi-class vehicle detection using UAV\ncameras through the development of spatiotemporal object detection models. The\nstudy introduces a Spatio-Temporal Vehicle Detection Dataset (STVD) containing\n6, 600 annotated sequential frame images captured by UAVs, enabling\ncomprehensive training and evaluation of algorithms for holistic spatiotemporal\nperception. A YOLO-based object detection algorithm is enhanced to incorporate\ntemporal dynamics, resulting in improved performance over single frame models.\nThe integration of attention mechanisms into spatiotemporal models is shown to\nfurther enhance performance. Experimental validation demonstrates significant\nprogress, with the best spatiotemporal model exhibiting a 16.22% improvement\nover single frame models, while it is demonstrated that attention mechanisms\nhold the potential for additional performance gains.\n","authors":["Kristina Telegraph","Christos Kyrkou"],"pdf_url":"https://arxiv.org/pdf/2410.13616v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2410.13615v1","updated":"2024-10-17T14:47:53Z","published":"2024-10-17T14:47:53Z","title":"Material Fingerprinting: Identifying and Predicting Perceptual\n  Attributes of Material Appearance","summary":"  The world is abundant with diverse materials, each possessing unique surface\nappearances that play a crucial role in our daily perception and understanding\nof their properties. Despite advancements in technology enabling the capture\nand realistic reproduction of material appearances for visualization and\nquality control, the interoperability of material property information across\nvarious measurement representations and software platforms remains a complex\nchallenge. A key to overcoming this challenge lies in the automatic\nidentification of materials' perceptual features, enabling intuitive\ndifferentiation of properties stored in disparate material data\nrepresentations. We reasoned that for many practical purposes, a compact\nrepresentation of the perceptual appearance is more useful than an exhaustive\nphysical description.This paper introduces a novel approach to material\nidentification by encoding perceptual features obtained from dynamic visual\nstimuli. We conducted a psychophysical experiment to select and validate 16\nparticularly significant perceptual attributes obtained from videos of 347\nmaterials. We then gathered attribute ratings from over twenty participants for\neach material, creating a 'material fingerprint' that encodes the unique\nperceptual properties of each material. Finally, we trained a multi-layer\nperceptron model to predict the relationship between statistical and deep\nlearning image features and their corresponding perceptual properties. We\ndemonstrate the model's performance in material retrieval and filtering\naccording to individual attributes. This model represents a significant step\ntowards simplifying the sharing and understanding of material properties in\ndiverse digital environments regardless of their digital representation,\nenhancing both the accuracy and efficiency of material identification.\n","authors":["Jiri Filip","Filip Dechterenko","Filipp Schmidt","Jiri Lukavsky","Veronika Vilimovska","Jan Kotera","Roland W. Fleming"],"pdf_url":"https://arxiv.org/pdf/2410.13615v1.pdf","comment":"14 pages, 12 figures, 3 tables"},{"id":"http://arxiv.org/abs/2410.13613v1","updated":"2024-10-17T14:47:08Z","published":"2024-10-17T14:47:08Z","title":"MEGA: Memory-Efficient 4D Gaussian Splatting for Dynamic Scenes","summary":"  4D Gaussian Splatting (4DGS) has recently emerged as a promising technique\nfor capturing complex dynamic 3D scenes with high fidelity. It utilizes a 4D\nGaussian representation and a GPU-friendly rasterizer, enabling rapid rendering\nspeeds. Despite its advantages, 4DGS faces significant challenges, notably the\nrequirement of millions of 4D Gaussians, each with extensive associated\nattributes, leading to substantial memory and storage cost. This paper\nintroduces a memory-efficient framework for 4DGS. We streamline the color\nattribute by decomposing it into a per-Gaussian direct color component with\nonly 3 parameters and a shared lightweight alternating current color predictor.\nThis approach eliminates the need for spherical harmonics coefficients, which\ntypically involve up to 144 parameters in classic 4DGS, thereby creating a\nmemory-efficient 4D Gaussian representation. Furthermore, we introduce an\nentropy-constrained Gaussian deformation technique that uses a deformation\nfield to expand the action range of each Gaussian and integrates an\nopacity-based entropy loss to limit the number of Gaussians, thus forcing our\nmodel to use as few Gaussians as possible to fit a dynamic scene well. With\nsimple half-precision storage and zip compression, our framework achieves a\nstorage reduction by approximately 190$\\times$ and 125$\\times$ on the\nTechnicolor and Neural 3D Video datasets, respectively, compared to the\noriginal 4DGS. Meanwhile, it maintains comparable rendering speeds and scene\nrepresentation quality, setting a new standard in the field.\n","authors":["Xinjie Zhang","Zhening Liu","Yifan Zhang","Xingtong Ge","Dailan He","Tongda Xu","Yan Wang","Zehong Lin","Shuicheng Yan","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.13613v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13611v1","updated":"2024-10-17T14:46:34Z","published":"2024-10-17T14:46:34Z","title":"H2OVL-Mississippi Vision Language Models Technical Report","summary":"  Smaller vision-language models (VLMs) are becoming increasingly important for\nprivacy-focused, on-device applications due to their ability to run efficiently\non consumer hardware for processing enterprise commercial documents and images.\nThese models require strong language understanding and visual capabilities to\nenhance human-machine interaction. To address this need, we present\nH2OVL-Mississippi, a pair of small VLMs trained on 37 million image-text pairs\nusing 240 hours of compute on 8 x H100 GPUs. H2OVL-Mississippi-0.8B is a tiny\nmodel with 0.8 billion parameters that specializes in text recognition,\nachieving state of the art performance on the Text Recognition portion of\nOCRBench and surpassing much larger models in this area. Additionally, we are\nreleasing H2OVL-Mississippi-2B, a 2 billion parameter model for general use\ncases, exhibiting highly competitive metrics across various academic\nbenchmarks. Both models build upon our prior work with H2O-Danube language\nmodels, extending their capabilities into the visual domain. We release them\nunder the Apache 2.0 license, making VLMs accessible to everyone, democratizing\ndocument AI and visual LLMs.\n","authors":["Shaikat Galib","Shanshan Wang","Guanshuo Xu","Pascal Pfeiffer","Ryan Chesler","Mark Landry","Sri Satish Ambati"],"pdf_url":"https://arxiv.org/pdf/2410.13611v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13607v1","updated":"2024-10-17T14:43:07Z","published":"2024-10-17T14:43:07Z","title":"DN-4DGS: Denoised Deformable Network with Temporal-Spatial Aggregation\n  for Dynamic Scene Rendering","summary":"  Dynamic scenes rendering is an intriguing yet challenging problem. Although\ncurrent methods based on NeRF have achieved satisfactory performance, they\nstill can not reach real-time levels. Recently, 3D Gaussian Splatting (3DGS)\nhas gar?nered researchers attention due to their outstanding rendering quality\nand real?time speed. Therefore, a new paradigm has been proposed: defining a\ncanonical 3D gaussians and deforming it to individual frames in deformable\nfields. How?ever, since the coordinates of canonical 3D gaussians are filled\nwith noise, which can transfer noise into the deformable fields, and there is\ncurrently no method that adequately considers the aggregation of 4D\ninformation. Therefore, we pro?pose Denoised Deformable Network with\nTemporal-Spatial Aggregation for Dy?namic Scene Rendering (DN-4DGS).\nSpecifically, a Noise Suppression Strategy is introduced to change the\ndistribution of the coordinates of the canonical 3D gaussians and suppress\nnoise. Additionally, a Decoupled Temporal-Spatial Ag?gregation Module is\ndesigned to aggregate information from adjacent points and frames. Extensive\nexperiments on various real-world datasets demonstrate that our method achieves\nstate-of-the-art rendering quality under a real-time level.\n","authors":["Jiahao Lu","Jiacheng Deng","Ruijie Zhu","Yanzhe Liang","Wenfei Yang","Tianzhu Zhang","Xu Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.13607v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.13598v1","updated":"2024-10-17T14:31:02Z","published":"2024-10-17T14:31:02Z","title":"Let Me Finish My Sentence: Video Temporal Grounding with Holistic Text\n  Understanding","summary":"  Video Temporal Grounding (VTG) aims to identify visual frames in a video clip\nthat match text queries. Recent studies in VTG employ cross-attention to\ncorrelate visual frames and text queries as individual token sequences.\nHowever, these approaches overlook a crucial aspect of the problem: a holistic\nunderstanding of the query sentence. A model may capture correlations between\nindividual word tokens and arbitrary visual frames while possibly missing out\non the global meaning. To address this, we introduce two primary contributions:\n(1) a visual frame-level gate mechanism that incorporates holistic textual\ninformation, (2) cross-modal alignment loss to learn the fine-grained\ncorrelation between query and relevant frames. As a result, we regularize the\neffect of individual word tokens and suppress irrelevant visual frames. We\ndemonstrate that our method outperforms state-of-the-art approaches in VTG\nbenchmarks, indicating that holistic text understanding guides the model to\nfocus on the semantically important parts within the video.\n","authors":["Jongbhin Woo","Hyeonggon Ryu","Youngjoon Jang","Jae Won Cho","Joon Son Chung"],"pdf_url":"https://arxiv.org/pdf/2410.13598v1.pdf","comment":"Accepted by ACMMM 24"},{"id":"http://arxiv.org/abs/2410.13594v1","updated":"2024-10-17T14:28:11Z","published":"2024-10-17T14:28:11Z","title":"Deep-learning recognition and tracking of individual nanotubes in\n  low-contrast microscopy videos","summary":"  This study addresses the challenge of analyzing the growth kinetics of carbon\nnanotubes using in-situ homodyne polarization microscopy (HPM) by developing an\nautomated deep learning (DL) approach. A Mask-RCNN architecture, enhanced with\na ResNet-50 backbone, was employed to recognize and track individual nanotubes\nin microscopy videos, significantly improving the efficiency and\nreproducibility of kinetic data extraction. The method involves a series of\nvideo processing steps to enhance contrast and used differential treatment\ntechniques to manage low signal and fast kinetics. The DL model demonstrates\nconsistency with manual measurements and increased throughput, laying the\nfoundation for statistical studies of nanotube growth. The approach can be\nadapted for other types of in-situ microscopy studies, emphasizing the\nimportance of automation in high-throughput data acquisition for research on\nindividual nano-objects.\n","authors":["Vladimir Pimonov","Said Tahir","Vincent Jourdain"],"pdf_url":"https://arxiv.org/pdf/2410.13594v1.pdf","comment":"13 pages, 5 Figures, No supporting information included"},{"id":"http://arxiv.org/abs/2410.13585v1","updated":"2024-10-17T14:21:22Z","published":"2024-10-17T14:21:22Z","title":"Pseudo Dataset Generation for Out-of-Domain Multi-Camera View\n  Recommendation","summary":"  Multi-camera systems are indispensable in movies, TV shows, and other media.\nSelecting the appropriate camera at every timestamp has a decisive impact on\nproduction quality and audience preferences. Learning-based view recommendation\nframeworks can assist professionals in decision-making. However, they often\nstruggle outside of their training domains. The scarcity of labeled\nmulti-camera view recommendation datasets exacerbates the issue. Based on the\ninsight that many videos are edited from the original multi-camera videos, we\npropose transforming regular videos into pseudo-labeled multi-camera view\nrecommendation datasets. Promisingly, by training the model on pseudo-labeled\ndatasets stemming from videos in the target domain, we achieve a 68% relative\nimprovement in the model's accuracy in the target domain and bridge the\naccuracy gap between in-domain and never-before-seen domains.\n","authors":["Kuan-Ying Lee","Qian Zhou","Klara Nahrstedt"],"pdf_url":"https://arxiv.org/pdf/2410.13585v1.pdf","comment":"Accepted to VCIP 2024. Project page:\n  https://eric11220.github.io/publication/VCIP24/"},{"id":"http://arxiv.org/abs/2410.13582v1","updated":"2024-10-17T14:16:45Z","published":"2024-10-17T14:16:45Z","title":"Co-Segmentation without any Pixel-level Supervision with Application to\n  Large-Scale Sketch Classification","summary":"  This work proposes a novel method for object co-segmentation, i.e.\npixel-level localization of a common object in a set of images, that uses no\npixel-level supervision for training. Two pre-trained Vision Transformer (ViT)\nmodels are exploited: ImageNet classification-trained ViT, whose features are\nused to estimate rough object localization through intra-class token relevance,\nand a self-supervised DINO-ViT for intra-image token relevance. On recent\nchallenging benchmarks, the method achieves state-of-the-art performance among\nmethods trained with the same level of supervision (image labels) while being\ncompetitive with methods trained with pixel-level supervision (binary masks).\nThe benefits of the proposed co-segmentation method are further demonstrated in\nthe task of large-scale sketch recognition, that is, the classification of\nsketches into a wide range of categories. The limited amount of hand-drawn\nsketch training data is leveraged by exploiting readily available\nimage-level-annotated datasets of natural images containing a large number of\nclasses. To bridge the domain gap, the classifier is trained on a sketch-like\nproxy domain derived from edges detected on natural images. We show that sketch\nrecognition significantly benefits when the classifier is trained on\nsketch-like structures extracted from the co-segmented area rather than from\nthe full image. Code: https://github.com/nikosips/CBNC .\n","authors":["Nikolaos-Antonios Ypsilantis","Ondřej Chum"],"pdf_url":"https://arxiv.org/pdf/2410.13582v1.pdf","comment":"ACCV 2024 Main Paper + Supplementary (Appendix)"},{"id":"http://arxiv.org/abs/2402.06165v5","updated":"2024-10-17T14:10:16Z","published":"2024-02-09T03:48:20Z","title":"Learning Contrastive Feature Representations for Facial Action Unit\n  Detection","summary":"  Facial action unit (AU) detection has long encountered the challenge of\ndetecting subtle feature differences when AUs activate. Existing methods often\nrely on encoding pixel-level information of AUs, which not only encodes\nadditional redundant information but also leads to increased model complexity\nand limited generalizability. Additionally, the accuracy of AU detection is\nnegatively impacted by the class imbalance issue of each AU type, and the\npresence of noisy and false AU labels. In this paper, we introduce a novel\ncontrastive learning framework aimed for AU detection that incorporates both\nself-supervised and supervised signals, thereby enhancing the learning of\ndiscriminative features for accurate AU detection. To tackle the class\nimbalance issue, we employ a negative sample re-weighting strategy that adjusts\nthe step size of updating parameters for minority and majority class samples.\nMoreover, to address the challenges posed by noisy and false AU labels, we\nemploy a sampling technique that encompasses three distinct types of positive\nsample pairs. This enables us to inject self-supervised signals into the\nsupervised signal, effectively mitigating the adverse effects of noisy labels.\nOur experimental assessments, conducted on four widely-utilized benchmark\ndatasets (BP4D, DISFA, GFT and Aff-Wild2), underscore the superior performance\nof our approach compared to state-of-the-art methods of AU detection. Our code\nis available at \\url{https://github.com/Ziqiao-Shang/AUNCE}.\n","authors":["Ziqiao Shang","Bin Liu","Fengmao Lv","Fei Teng","Tianrui Li"],"pdf_url":"https://arxiv.org/pdf/2402.06165v5.pdf","comment":"35 pages, 18 figures, submitted to Pattern Recognition (PR)"},{"id":"http://arxiv.org/abs/2410.13571v1","updated":"2024-10-17T14:07:46Z","published":"2024-10-17T14:07:46Z","title":"DriveDreamer4D: World Models Are Effective Data Machines for 4D Driving\n  Scene Representation","summary":"  Closed-loop simulation is essential for advancing end-to-end autonomous\ndriving systems. Contemporary sensor simulation methods, such as NeRF and 3DGS,\nrely predominantly on conditions closely aligned with training data\ndistributions, which are largely confined to forward-driving scenarios.\nConsequently, these methods face limitations when rendering complex maneuvers\n(e.g., lane change, acceleration, deceleration). Recent advancements in\nautonomous-driving world models have demonstrated the potential to generate\ndiverse driving videos. However, these approaches remain constrained to 2D\nvideo generation, inherently lacking the spatiotemporal coherence required to\ncapture intricacies of dynamic driving environments. In this paper, we\nintroduce \\textit{DriveDreamer4D}, which enhances 4D driving scene\nrepresentation leveraging world model priors. Specifically, we utilize the\nworld model as a data machine to synthesize novel trajectory videos based on\nreal-world driving data. Notably, we explicitly leverage structured conditions\nto control the spatial-temporal consistency of foreground and background\nelements, thus the generated data adheres closely to traffic constraints. To\nour knowledge, \\textit{DriveDreamer4D} is the first to utilize video generation\nmodels for improving 4D reconstruction in driving scenarios. Experimental\nresults reveal that \\textit{DriveDreamer4D} significantly enhances generation\nquality under novel trajectory views, achieving a relative improvement in FID\nby 24.5\\%, 39.0\\%, and 10.5\\% compared to PVG, $\\text{S}^3$Gaussian, and\nDeformable-GS. Moreover, \\textit{DriveDreamer4D} markedly enhances the\nspatiotemporal coherence of driving agents, which is verified by a\ncomprehensive user study and the relative increases of 20.3\\%, 42.0\\%, and\n13.7\\% in the NTA-IoU metric.\n","authors":["Guosheng Zhao","Chaojun Ni","Xiaofeng Wang","Zheng Zhu","Guan Huang","Xinze Chen","Boyuan Wang","Youyi Zhang","Wenjun Mei","Xingang Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13571v1.pdf","comment":"https://drivedreamer4d.github.io"},{"id":"http://arxiv.org/abs/2410.13570v1","updated":"2024-10-17T14:05:41Z","published":"2024-10-17T14:05:41Z","title":"RGB to Hyperspectral: Spectral Reconstruction for Enhanced Surgical\n  Imaging","summary":"  This study investigates the reconstruction of hyperspectral signatures from\nRGB data to enhance surgical imaging, utilizing the publicly available\nHeiPorSPECTRAL dataset from porcine surgery and an in-house neurosurgery\ndataset. Various architectures based on convolutional neural networks (CNNs)\nand transformer models are evaluated using comprehensive metrics. Transformer\nmodels exhibit superior performance in terms of RMSE, SAM, PSNR and SSIM by\neffectively integrating spatial information to predict accurate spectral\nprofiles, encompassing both visible and extended spectral ranges. Qualitative\nassessments demonstrate the capability to predict spectral profiles critical\nfor informed surgical decision-making during procedures. Challenges associated\nwith capturing both the visible and extended hyperspectral ranges are\nhighlighted using the MAE, emphasizing the complexities involved. The findings\nopen up the new research direction of hyperspectral reconstruction for surgical\napplications and clinical use cases in real-time surgical environments.\n","authors":["Tobias Czempiel","Alfie Roddan","Maria Leiloglou","Zepeng Hu","Kevin O'Neill","Giulio Anichini","Danail Stoyanov","Daniel Elson"],"pdf_url":"https://arxiv.org/pdf/2410.13570v1.pdf","comment":"10 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2410.13567v1","updated":"2024-10-17T14:04:02Z","published":"2024-10-17T14:04:02Z","title":"CCUP: A Controllable Synthetic Data Generation Pipeline for Pretraining\n  Cloth-Changing Person Re-Identification Models","summary":"  Cloth-changing person re-identification (CC-ReID), also known as Long-Term\nPerson Re-Identification (LT-ReID) is a critical and challenging research topic\nin computer vision that has recently garnered significant attention. However,\ndue to the high cost of constructing CC-ReID data, the existing data-driven\nmodels are hard to train efficiently on limited data, causing overfitting\nissue. To address this challenge, we propose a low-cost and efficient pipeline\nfor generating controllable and high-quality synthetic data simulating the\nsurveillance of real scenarios specific to the CC-ReID task. Particularly, we\nconstruct a new self-annotated CC-ReID dataset named Cloth-Changing Unreal\nPerson (CCUP), containing 6,000 IDs, 1,179,976 images, 100 cameras, and 26.5\noutfits per individual. Based on this large-scale dataset, we introduce an\neffective and scalable pretrain-finetune framework for enhancing the\ngeneralization capabilities of the traditional CC-ReID models. The extensive\nexperiments demonstrate that two typical models namely TransReID and FIRe^2,\nwhen integrated into our framework, outperform other state-of-the-art models\nafter pretraining on CCUP and finetuning on the benchmarks such as PRCC,\nVC-Clothes and NKUP. The CCUP is available at:\nhttps://github.com/yjzhao1019/CCUP.\n","authors":["Yujian Zhao","Chengru Wu","Yinong Xu","Xuanzheng Du","Ruiyu Li","Guanglin Niu"],"pdf_url":"https://arxiv.org/pdf/2410.13567v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08551v2","updated":"2024-10-17T14:04:01Z","published":"2024-10-11T06:04:30Z","title":"Context-Aware Full Body Anonymization using Text-to-Image Diffusion\n  Models","summary":"  Anonymization plays a key role in protecting sensible information of\nindividuals in real world datasets. Self-driving cars for example need high\nresolution facial features to track people and their viewing direction to\npredict future behaviour and react accordingly. In order to protect people's\nprivacy whilst keeping important features in the dataset, it is important to\nreplace the full body of a person with a highly detailed anonymized one. In\ncontrast to doing face anonymization, full body replacement decreases the\nability of recognizing people by their hairstyle or clothes. In this paper, we\npropose a workflow for full body person anonymization utilizing Stable\nDiffusion as a generative backend. Text-to-image diffusion models, like Stable\nDiffusion, OpenAI's DALL-E or Midjourney, have become very popular in recent\ntime, being able to create photorealistic images from a single text prompt. We\nshow that our method outperforms state-of-the art anonymization pipelines with\nrespect to image quality, resolution, Inception Score (IS) and Frechet\nInception Distance (FID). Additionally, our method is invariant with respect to\nthe image generator and thus able to be used with the latest models available.\n","authors":["Pascal Zwick","Kevin Roesch","Marvin Klemp","Oliver Bringmann"],"pdf_url":"https://arxiv.org/pdf/2410.08551v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13566v1","updated":"2024-10-17T14:03:53Z","published":"2024-10-17T14:03:53Z","title":"360U-Former: HDR Illumination Estimation with Panoramic Adapted Vision\n  Transformers","summary":"  Recent illumination estimation methods have focused on enhancing the\nresolution and improving the quality and diversity of the generated textures.\nHowever, few have explored tailoring the neural network architecture to the\nEquirectangular Panorama (ERP) format utilised in image-based lighting.\nConsequently, high dynamic range images (HDRI) results usually exhibit a seam\nat the side borders and textures or objects that are warped at the poles. To\naddress this shortcoming we propose a novel architecture, 360U-Former, based on\na U-Net style Vision-Transformer which leverages the work of PanoSWIN, an\nadapted shifted window attention tailored to the ERP format. To the best of our\nknowledge, this is the first purely Vision-Transformer model used in the field\nof illumination estimation. We train 360U-Former as a GAN to generate HDRI from\na limited field of view low dynamic range image (LDRI). We evaluate our method\nusing current illumination estimation evaluation protocols and datasets,\ndemonstrating that our approach outperforms existing and state-of-the-art\nmethods without the artefacts typically associated with the use of the ERP\nformat.\n","authors":["Jack Hilliard","Adrian Hilton","Jean-Yves Guillemaut"],"pdf_url":"https://arxiv.org/pdf/2410.13566v1.pdf","comment":"Accepted at AIM Workshop 2024 at ECCV 2024, 18 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.13564v1","updated":"2024-10-17T14:00:41Z","published":"2024-10-17T14:00:41Z","title":"Generative Location Modeling for Spatially Aware Object Insertion","summary":"  Generative models have become a powerful tool for image editing tasks,\nincluding object insertion. However, these methods often lack spatial\nawareness, generating objects with unrealistic locations and scales, or\nunintentionally altering the scene background. A key challenge lies in\nmaintaining visual coherence, which requires both a geometrically suitable\nobject location and a high-quality image edit. In this paper, we focus on the\nformer, creating a location model dedicated to identifying realistic object\nlocations. Specifically, we train an autoregressive model that generates\nbounding box coordinates, conditioned on the background image and the desired\nobject class. This formulation allows to effectively handle sparse placement\nannotations and to incorporate implausible locations into a preference dataset\nby performing direct preference optimization. Our extensive experiments\ndemonstrate that our generative location model, when paired with an inpainting\nmethod, substantially outperforms state-of-the-art instruction-tuned models and\nlocation modeling baselines in object insertion tasks, delivering accurate and\nvisually coherent results.\n","authors":["Jooyeol Yun","Davide Abati","Mohamed Omran","Jaegul Choo","Amirhossein Habibian","Auke Wiggers"],"pdf_url":"https://arxiv.org/pdf/2410.13564v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13532v1","updated":"2024-10-17T13:20:20Z","published":"2024-10-17T13:20:20Z","title":"RemoteDet-Mamba: A Hybrid Mamba-CNN Network for Multi-modal Object\n  Detection in Remote Sensing Images","summary":"  Unmanned aerial vehicle (UAV) remote sensing is widely applied in fields such\nas emergency response, owing to its advantages of rapid information acquisition\nand low cost. However, due to the effects of shooting distance and imaging\nmechanisms, the objects in the images present challenges such as small size,\ndense distribution, and low inter-class differentiation. To this end, we\npropose a multimodal remote sensing detection network that employs a\nquad-directional selective scanning fusion strategy called RemoteDet-Mamba.\nRemoteDet-Mamba simultaneously facilitates the learning of single-modal local\nfeatures and the integration of patch-level global features across modalities,\nenhancing the distinguishability for small objects and utilizing local\ninformation to improve discrimination between different classes. Additionally,\nthe use of Mamba's serial processing significantly increases detection speed.\nExperimental results on the DroneVehicle dataset demonstrate the effectiveness\nof RemoteDet-Mamba, which achieves superior detection accuracy compared to\nstate-of-the-art methods while maintaining computational efficiency and\nparameter count.\n","authors":["Kejun Ren","Xin Wu","Lianming Xu","Li Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13532v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13530v1","updated":"2024-10-17T13:19:32Z","published":"2024-10-17T13:19:32Z","title":"L3DG: Latent 3D Gaussian Diffusion","summary":"  We propose L3DG, the first approach for generative 3D modeling of 3D\nGaussians through a latent 3D Gaussian diffusion formulation. This enables\neffective generative 3D modeling, scaling to generation of entire room-scale\nscenes which can be very efficiently rendered. To enable effective synthesis of\n3D Gaussians, we propose a latent diffusion formulation, operating in a\ncompressed latent space of 3D Gaussians. This compressed latent space is\nlearned by a vector-quantized variational autoencoder (VQ-VAE), for which we\nemploy a sparse convolutional architecture to efficiently operate on room-scale\nscenes. This way, the complexity of the costly generation process via diffusion\nis substantially reduced, allowing higher detail on object-level generation, as\nwell as scalability to large scenes. By leveraging the 3D Gaussian\nrepresentation, the generated scenes can be rendered from arbitrary viewpoints\nin real-time. We demonstrate that our approach significantly improves visual\nquality over prior work on unconditional object-level radiance field synthesis\nand showcase its applicability to room-scale scene generation.\n","authors":["Barbara Roessle","Norman Müller","Lorenzo Porzi","Samuel Rota Bulò","Peter Kontschieder","Angela Dai","Matthias Nießner"],"pdf_url":"https://arxiv.org/pdf/2410.13530v1.pdf","comment":"SIGGRAPH Asia 2024, project page:\n  https://barbararoessle.github.io/l3dg , video: https://youtu.be/UHEEiXCYeLU"},{"id":"http://arxiv.org/abs/2410.13526v1","updated":"2024-10-17T13:14:25Z","published":"2024-10-17T13:14:25Z","title":"Generative Adversarial Synthesis of Radar Point Cloud Scenes","summary":"  For the validation and verification of automotive radars, datasets of\nrealistic traffic scenarios are required, which, how ever, are laborious to\nacquire. In this paper, we introduce radar scene synthesis using GANs as an\nalternative to the real dataset acquisition and simulation-based approaches. We\ntrain a PointNet++ based GAN model to generate realistic radar point cloud\nscenes and use a binary classifier to evaluate the performance of scenes\ngenerated using this model against a test set of real scenes. We demonstrate\nthat our GAN model achieves similar performance (~87%) to the real scenes test\nset.\n","authors":["Muhammad Saad Nawaz","Thomas Dallmann","Torsten Schoen","Dirk Heberling"],"pdf_url":"https://arxiv.org/pdf/2410.13526v1.pdf","comment":"ICMIM 2024; 7th IEEE MTT Conference"},{"id":"http://arxiv.org/abs/2410.13523v1","updated":"2024-10-17T13:11:07Z","published":"2024-10-17T13:11:07Z","title":"Can Medical Vision-Language Pre-training Succeed with Purely Synthetic\n  Data?","summary":"  Medical Vision-Language Pre-training (MedVLP) has made significant progress\nin enabling zero-shot tasks for medical image understanding. However, training\nMedVLP models typically requires large-scale datasets with paired, high-quality\nimage-text data, which are scarce in the medical domain. Recent advancements in\nLarge Language Models (LLMs) and diffusion models have made it possible to\ngenerate large-scale synthetic image-text pairs. This raises the question: *Can\nMedVLP succeed using purely synthetic data?* To address this, we use\noff-the-shelf generative models to create synthetic radiology reports and\npaired Chest X-ray (CXR) images, and propose an automated pipeline to build a\ndiverse, high-quality synthetic dataset, enabling a rigorous study that\nisolates model and training settings, focusing entirely from the data\nperspective. Our results show that MedVLP models trained *exclusively on\nsynthetic data* outperform those trained on real data by **3.8%** in averaged\nAUC on zero-shot classification. Moreover, using a combination of synthetic and\nreal data leads to a further improvement of **9.07%**. Additionally, MedVLP\nmodels trained on synthetic or mixed data consistently outperform those trained\non real data in zero-shot grounding, as well as in fine-tuned classification\nand segmentation tasks. Our analysis suggests MedVLP trained on well-designed\nsynthetic data can outperform models trained on real datasets, which may be\nlimited by low-quality samples and long-tailed distributions.\n","authors":["Che Liu","Zhongwei Wan","Haozhe Wang","Yinda Chen","Talha Qaiser","Chen Jin","Fariba Yousefi","Nikolay Burlutskiy","Rossella Arcucci"],"pdf_url":"https://arxiv.org/pdf/2410.13523v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2406.03857v2","updated":"2024-10-17T13:08:13Z","published":"2024-06-06T08:42:36Z","title":"MuJo: Multimodal Joint Feature Space Learning for Human Activity\n  Recognition","summary":"  Human Activity Recognition (HAR) is a longstanding problem in AI with\napplications in a broad range of areas, including healthcare, sports and\nfitness, security, and more. The performance of HAR in real-world settings is\nstrongly dependent on the type and quality of the input signal that can be\nacquired. Given an unobstructed, high-quality camera view of a scene, computer\nvision systems, in particular in conjunction with foundation models, can today\nfairly reliably distinguish complex activities. On the other hand, recognition\nusing modalities such as wearable sensors (which are often more broadly\navailable, e.g., in mobile phones and smartwatches) is a more difficult\nproblem, as the signals often contain less information and labeled training\ndata is more difficult to acquire. To alleviate the need for labeled data, we\nintroduce our comprehensive Fitness Multimodal Activity Dataset (FiMAD) in this\nwork, which can be used with the proposed pre-training method MuJo (Multimodal\nJoint Feature Space Learning) to enhance HAR performance across various\nmodalities. FiMAD was created using YouTube fitness videos and contains\nparallel video, language, pose, and simulated IMU sensor data. MuJo utilizes\nthis dataset to learn a joint feature space for these modalities. We show that\nclassifiers pre-trained on FiMAD can increase the performance on real HAR\ndatasets such as MM-Fit, MyoGym, MotionSense, and MHEALTH. For instance, on\nMM-Fit, we achieve an Macro F1-Score of up to 0.855 when fine-tuning on only 2%\nof the training data and 0.942 when utilizing the full training set for\nclassification tasks. We have compared our approach to other self-supervised\nones and showed that, unlike them, ours can consistently improve on the\nbaseline network performance as well as provide a better data-efficiency.\n","authors":["Stefan Gerd Fritsch","Cennet Oguz","Vitor Fortes Rey","Lala Ray","Maximilian Kiefer-Emmanouilidis","Paul Lukowicz"],"pdf_url":"https://arxiv.org/pdf/2406.03857v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13510v1","updated":"2024-10-17T12:56:52Z","published":"2024-10-17T12:56:52Z","title":"GeoCoder: Solving Geometry Problems by Generating Modular Code through\n  Vision-Language Models","summary":"  Geometry problem-solving demands advanced reasoning abilities to process\nmultimodal inputs and employ mathematical knowledge effectively.\nVision-language models (VLMs) have made significant progress in various\nmultimodal tasks. Yet, they still struggle with geometry problems and are\nsignificantly limited by their inability to perform mathematical operations not\nseen during pre-training, such as calculating the cosine of an arbitrary angle,\nand by difficulties in correctly applying relevant geometry formulas. To\novercome these challenges, we present GeoCoder, which leverages modular\ncode-finetuning to generate and execute code using a predefined geometry\nfunction library. By executing the code, we achieve accurate and deterministic\ncalculations, contrasting the stochastic nature of autoregressive token\nprediction, while the function library minimizes errors in formula usage. We\nalso propose a multimodal retrieval-augmented variant of GeoCoder, named\nRAG-GeoCoder, which incorporates a non-parametric memory module for retrieving\nfunctions from the geometry library, thereby reducing reliance on parametric\nmemory. Our modular code-finetuning approach enhances the geometric reasoning\ncapabilities of VLMs, yielding an average improvement of over 16% across\nvarious question complexities on the GeomVerse dataset compared to other\nfinetuning methods.\n","authors":["Aditya Sharma","Aman Dalmia","Mehran Kazemi","Amal Zouaq","Christopher J. Pal"],"pdf_url":"https://arxiv.org/pdf/2410.13510v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12686v2","updated":"2024-10-17T12:52:30Z","published":"2024-10-16T15:48:28Z","title":"Automatic Mapping of Anatomical Landmarks from Free-Text Using Large\n  Language Models: Insights from Llama-2","summary":"  Anatomical landmarks are vital in medical imaging for navigation and anomaly\ndetection. Modern large language models (LLMs), like Llama-2, offer promise for\nautomating the mapping of these landmarks in free-text radiology reports to\ncorresponding positions in image data. Recent studies propose LLMs may develop\ncoherent representations of generative processes. Motivated by these insights,\nwe investigated whether LLMs accurately represent the spatial positions of\nanatomical landmarks. Through experiments with Llama-2 models, we found that\nthey can linearly represent anatomical landmarks in space with considerable\nrobustness to different prompts. These results underscore the potential of LLMs\nto enhance the efficiency and accuracy of medical imaging workflows.\n","authors":["Mohamad Abdi","Gerardo Hermosillo Valadez","Halid Ziya Yerebakan"],"pdf_url":"https://arxiv.org/pdf/2410.12686v2.pdf","comment":"6 pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2410.13500v1","updated":"2024-10-17T12:46:26Z","published":"2024-10-17T12:46:26Z","title":"SAda-Net: A Self-Supervised Adaptive Stereo Estimation CNN For Remote\n  Sensing Image Data","summary":"  Stereo estimation has made many advancements in recent years with the\nintroduction of deep-learning. However the traditional supervised approach to\ndeep-learning requires the creation of accurate and plentiful ground-truth\ndata, which is expensive to create and not available in many situations. This\nis especially true for remote sensing applications, where there is an excess of\navailable data without proper ground truth. To tackle this problem, we propose\na self-supervised CNN with self-improving adaptive abilities. In the first\niteration, the created disparity map is inaccurate and noisy. Leveraging the\nleft-right consistency check, we get a sparse but more accurate disparity map\nwhich is used as an initial pseudo ground-truth. This pseudo ground-truth is\nthen adapted and updated after every epoch in the training step of the network.\nWe use the sum of inconsistent points in order to track the network\nconvergence. The code for our method is publicly available at:\nhttps://github.com/thedodo/SAda-Net}{https://github.com/thedodo/SAda-Net\n","authors":["Dominik Hirner","Friedrich Fraundorfer"],"pdf_url":"https://arxiv.org/pdf/2410.13500v1.pdf","comment":"Will be presented at ICPR2024 in December 2024 in Kolkata, India"},{"id":"http://arxiv.org/abs/2410.13486v1","updated":"2024-10-17T12:31:37Z","published":"2024-10-17T12:31:37Z","title":"SemSim: Revisiting Weak-to-Strong Consistency from a Semantic Similarity\n  Perspective for Semi-supervised Medical Image Segmentation","summary":"  Semi-supervised learning (SSL) for medical image segmentation is a\nchallenging yet highly practical task, which reduces reliance on large-scale\nlabeled dataset by leveraging unlabeled samples. Among SSL techniques, the\nweak-to-strong consistency framework, popularized by FixMatch, has emerged as a\nstate-of-the-art method in classification tasks. Notably, such a simple\npipeline has also shown competitive performance in medical image segmentation.\nHowever, two key limitations still persist, impeding its efficient adaptation:\n(1) the neglect of contextual dependencies results in inconsistent predictions\nfor similar semantic features, leading to incomplete object segmentation; (2)\nthe lack of exploitation of semantic similarity between labeled and unlabeled\ndata induces considerable class-distribution discrepancy. To address these\nlimitations, we propose a novel semi-supervised framework based on FixMatch,\nnamed SemSim, powered by two appealing designs from semantic similarity\nperspective: (1) rectifying pixel-wise prediction by reasoning about the\nintra-image pair-wise affinity map, thus integrating contextual dependencies\nexplicitly into the final prediction; (2) bridging labeled and unlabeled data\nvia a feature querying mechanism for compact class representation learning,\nwhich fully considers cross-image anatomical similarities. As the reliable\nsemantic similarity extraction depends on robust features, we further introduce\nan effective spatial-aware fusion module (SFM) to explore distinctive\ninformation from multiple scales. Extensive experiments show that SemSim yields\nconsistent improvements over the state-of-the-art methods across three public\nsegmentation benchmarks.\n","authors":["Shiao Xie","Hongyi Wang","Ziwei Niu","Hao Sun","Shuyi Ouyang","Yen-Wei Chen","Lanfen Lin"],"pdf_url":"https://arxiv.org/pdf/2410.13486v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.07961v3","updated":"2024-10-17T12:23:54Z","published":"2024-09-12T11:42:40Z","title":"Estimating Atmospheric Variables from Digital Typhoon Satellite Images\n  via Conditional Denoising Diffusion Models","summary":"  This study explores the application of diffusion models in the field of\ntyphoons, predicting multiple ERA5 meteorological variables simultaneously from\nDigital Typhoon satellite images. The focus of this study is taken to be\nTaiwan, an area very vulnerable to typhoons. By comparing the performance of\nConditional Denoising Diffusion Probability Model (CDDPM) with Convolutional\nNeural Networks (CNN) and Squeeze-and-Excitation Networks (SENet), results\nsuggest that the CDDPM performs best in generating accurate and realistic\nmeteorological data. Specifically, CDDPM achieved a PSNR of 32.807, which is\napproximately 7.9% higher than CNN and 5.5% higher than SENet. Furthermore,\nCDDPM recorded an RMSE of 0.032, showing a 11.1% improvement over CNN and 8.6%\nimprovement over SENet. A key application of this research can be for\nimputation purposes in missing meteorological datasets and generate additional\nhigh-quality meteorological data using satellite images. It is hoped that the\nresults of this analysis will enable more robust and detailed forecasting,\nreducing the impact of severe weather events on vulnerable regions. Code\naccessible at https://github.com/TammyLing/Typhoon-forecasting.\n","authors":["Zhangyue Ling","Pritthijit Nath","César Quilodrán-Casas"],"pdf_url":"https://arxiv.org/pdf/2409.07961v3.pdf","comment":"Accepted for spotlight presentation at the NeurIPS 2024 workshop on\n  Tackling Climate Change with Machine Learning. 8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2406.08845v3","updated":"2024-10-17T12:11:36Z","published":"2024-06-13T06:09:22Z","title":"Rethinking Human Evaluation Protocol for Text-to-Video Models: Enhancing\n  Reliability,Reproducibility, and Practicality","summary":"  Recent text-to-video (T2V) technology advancements, as demonstrated by models\nsuch as Gen2, Pika, and Sora, have significantly broadened its applicability\nand popularity. Despite these strides, evaluating these models poses\nsubstantial challenges. Primarily, due to the limitations inherent in automatic\nmetrics, manual evaluation is often considered a superior method for assessing\nT2V generation. However, existing manual evaluation protocols face\nreproducibility, reliability, and practicality issues. To address these\nchallenges, this paper introduces the Text-to-Video Human Evaluation (T2VHE)\nprotocol, a comprehensive and standardized protocol for T2V models. The T2VHE\nprotocol includes well-defined metrics, thorough annotator training, and an\neffective dynamic evaluation module. Experimental results demonstrate that this\nprotocol not only ensures high-quality annotations but can also reduce\nevaluation costs by nearly 50\\%. We will open-source the entire setup of the\nT2VHE protocol, including the complete protocol workflow, the dynamic\nevaluation component details, and the annotation interface code. This will help\ncommunities establish more sophisticated human assessment protocols.\n","authors":["Tianle Zhang","Langtian Ma","Yuchen Yan","Yuchen Zhang","Kai Wang","Yue Yang","Ziyao Guo","Wenqi Shao","Yang You","Yu Qiao","Ping Luo","Kaipeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.08845v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13472v1","updated":"2024-10-17T12:02:29Z","published":"2024-10-17T12:02:29Z","title":"Day-Night Adaptation: An Innovative Source-free Adaptation Framework for\n  Medical Image Segmentation","summary":"  Distribution shifts widely exist in medical images acquired from different\nmedical centers, hindering the deployment of semantic segmentation models\ntrained on data from one center (source domain) to another (target domain).\nWhile unsupervised domain adaptation (UDA) has shown significant promise in\nmitigating these shifts, it poses privacy risks due to sharing data between\ncenters. To facilitate adaptation while preserving data privacy, source-free\ndomain adaptation (SFDA) and test-time adaptation (TTA) have emerged as\neffective paradigms, relying solely on target domain data. However, the\nscenarios currently addressed by SFDA and TTA are limited, making them less\nsuitable for clinical applications. In a more realistic clinical scenario, the\npre-trained model is deployed in a medical centre to assist with clinical tasks\nduring the day and rest at night. During the daytime process, TTA can be\nemployed to enhance inference performance. During the nighttime process, after\ncollecting the test data from the day, the model can be fine-tuned utilizing\nSFDA to further adapt to the target domain. With above insights, we propose a\nnovel adaptation framework called Day-Night Adaptation (DyNA). This framework\nadapts the model to the target domain through day-night loops without requiring\naccess to source data. Specifically, we implement distinct adaptation\nstrategies for daytime and nighttime to better meet the demands of clinical\nsettings. During the daytime, model parameters are frozen, and a specific\nlow-frequency prompt is trained for each test sample. Additionally, we\nconstruct a memory bank for prompt initialization and develop a warm-up\nmechanism to enhance prompt training. During nighttime, we integrate a global\nstudent model into the traditional teacher-student self-training paradigm to\nfine-tune the model while ensuring training stability...\n","authors":["Ziyang Chen","Yiwen Ye","Yongsheng Pan","Yong Xia"],"pdf_url":"https://arxiv.org/pdf/2410.13472v1.pdf","comment":"10 pages, 4 figures, 6 tables"},{"id":"http://arxiv.org/abs/2410.13471v1","updated":"2024-10-17T11:59:39Z","published":"2024-10-17T11:59:39Z","title":"SiamSeg: Self-Training with Contrastive Learning for Unsupervised Domain\n  Adaptation in Remote Sensing","summary":"  Semantic segmentation of remote sensing (RS) images is a challenging task\nwith significant potential across various applications. Deep learning,\nespecially supervised learning with large-scale labeled datasets, has greatly\nadvanced this field. However, acquiring high-quality labeled data is expensive\nand time-consuming. Moreover, variations in ground sampling distance (GSD),\nimaging equipment, and geographic diversity contribute to domain shifts between\ndatasets, which pose significant challenges to models trained solely on source\ndomain data, leading to poor cross-domain performance. Domain shift is\nwell-known for undermining a model's generalization ability in the target\ndomain. To address this, unsupervised domain adaptation (UDA) has emerged as a\npromising solution, enabling models to learn from unlabeled target domain data\nwhile training on labeled source domain data. Recent advancements, particularly\nin self-supervised learning via pseudo-label generation, have shown potential\nin mitigating domain discrepancies. Strategies combining source and target\ndomain images with their true and pseudo labels for self-supervised training\nhave been effective in addressing domain bias. Despite progress in computer\nvision, the application of pseudo-labeling methods to RS image segmentation\nremains underexplored.\n","authors":["Bin Wang","Fei Deng","Shuang Wang","Wen Luo","Zhixuan Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.13471v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13465v1","updated":"2024-10-17T11:51:12Z","published":"2024-10-17T11:51:12Z","title":"Object Pose Estimation Using Implicit Representation For Transparent\n  Objects","summary":"  Object pose estimation is a prominent task in computer vision. The object\npose gives the orientation and translation of the object in real-world space,\nwhich allows various applications such as manipulation, augmented reality, etc.\nVarious objects exhibit different properties with light, such as reflections,\nabsorption, etc. This makes it challenging to understand the object's structure\nin RGB and depth channels. Recent research has been moving toward\nlearning-based methods, which provide a more flexible and generalizable\napproach to object pose estimation utilizing deep learning. One such approach\nis the render-and-compare method, which renders the object from multiple views\nand compares it against the given 2D image, which often requires an object\nrepresentation in the form of a CAD model. We reason that the synthetic texture\nof the CAD model may not be ideal for rendering and comparing operations. We\nshowed that if the object is represented as an implicit (neural) representation\nin the form of Neural Radiance Field (NeRF), it exhibits a more realistic\nrendering of the actual scene and retains the crucial spatial features, which\nmakes the comparison more versatile. We evaluated our NeRF implementation of\nthe render-and-compare method on transparent datasets and found that it\nsurpassed the current state-of-the-art results.\n","authors":["Varun Burde","Artem Moroz","Vit Zeman","Pavel Burget"],"pdf_url":"https://arxiv.org/pdf/2410.13465v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.09250v2","updated":"2024-10-17T11:46:45Z","published":"2024-06-13T15:55:04Z","title":"MirrorCheck: Efficient Adversarial Defense for Vision-Language Models","summary":"  Vision-Language Models (VLMs) are becoming increasingly vulnerable to\nadversarial attacks as various novel attack strategies are being proposed\nagainst these models. While existing defenses excel in unimodal contexts, they\ncurrently fall short in safeguarding VLMs against adversarial threats. To\nmitigate this vulnerability, we propose a novel, yet elegantly simple approach\nfor detecting adversarial samples in VLMs. Our method leverages Text-to-Image\n(T2I) models to generate images based on captions produced by target VLMs.\nSubsequently, we calculate the similarities of the embeddings of both input and\ngenerated images in the feature space to identify adversarial samples.\nEmpirical evaluations conducted on different datasets validate the efficacy of\nour approach, outperforming baseline methods adapted from image classification\ndomains. Furthermore, we extend our methodology to classification tasks,\nshowcasing its adaptability and model-agnostic nature. Theoretical analyses and\nempirical findings also show the resilience of our approach against adaptive\nattacks, positioning it as an excellent defense mechanism for real-world\ndeployment against adversarial threats.\n","authors":["Samar Fares","Klea Ziu","Toluwani Aremu","Nikita Durasov","Martin Takáč","Pascal Fua","Karthik Nandakumar","Ivan Laptev"],"pdf_url":"https://arxiv.org/pdf/2406.09250v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16807v2","updated":"2024-10-17T11:46:18Z","published":"2024-06-24T17:19:34Z","title":"Beyond Thumbs Up/Down: Untangling Challenges of Fine-Grained Feedback\n  for Text-to-Image Generation","summary":"  Human feedback plays a critical role in learning and refining reward models\nfor text-to-image generation, but the optimal form the feedback should take for\nlearning an accurate reward function has not been conclusively established.\nThis paper investigates the effectiveness of fine-grained feedback which\ncaptures nuanced distinctions in image quality and prompt-alignment, compared\nto traditional coarse-grained feedback (for example, thumbs up/down or ranking\nbetween a set of options). While fine-grained feedback holds promise,\nparticularly for systems catering to diverse societal preferences, we show that\ndemonstrating its superiority to coarse-grained feedback is not automatic.\nThrough experiments on real and synthetic preference data, we surface the\ncomplexities of building effective models due to the interplay of model choice,\nfeedback type, and the alignment between human judgment and computational\ninterpretation. We identify key challenges in eliciting and utilizing\nfine-grained feedback, prompting a reassessment of its assumed benefits and\npracticality. Our findings -- e.g., that fine-grained feedback can lead to\nworse models for a fixed budget, in some settings; however, in controlled\nsettings with known attributes, fine grained rewards can indeed be more helpful\n-- call for careful consideration of feedback attributes and potentially beckon\nnovel modeling approaches to appropriately unlock the potential value of\nfine-grained feedback in-the-wild.\n","authors":["Katherine M. Collins","Najoung Kim","Yonatan Bitton","Verena Rieser","Shayegan Omidshafiei","Yushi Hu","Sherol Chen","Senjuti Dutta","Minsuk Chang","Kimin Lee","Youwei Liang","Georgina Evans","Sahil Singla","Gang Li","Adrian Weller","Junfeng He","Deepak Ramachandran","Krishnamurthy Dj Dvijotham"],"pdf_url":"https://arxiv.org/pdf/2406.16807v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.01522v3","updated":"2024-10-17T11:33:09Z","published":"2023-12-03T22:44:04Z","title":"G2D: From Global to Dense Radiography Representation Learning via\n  Vision-Language Pre-training","summary":"  Recently, medical vision-language pre-training (VLP) has reached substantial\nprogress to learn global visual representation from medical images and their\npaired radiology reports. However, medical imaging tasks in real world usually\nrequire finer granularity in visual features. These tasks include visual\nlocalization tasks (e.g., semantic segmentation, object detection) and visual\ngrounding task. Yet, current medical VLP methods face challenges in learning\nthese fine-grained features, as they primarily focus on brute-force alignment\nbetween image patches and individual text tokens for local visual feature\nlearning, which is suboptimal for downstream dense prediction tasks. In this\nwork, we propose a new VLP framework, named \\textbf{G}lobal to \\textbf{D}ense\nlevel representation learning (G2D) that achieves significantly improved\ngranularity and more accurate grounding for the learned features, compared to\nexisting medical VLP approaches. In particular, G2D learns dense and\nsemantically-grounded image representations via a pseudo segmentation task\nparallel with the global vision-language alignment. Notably, generating pseudo\nsegmentation targets does not incur extra trainable parameters: they are\nobtained on the fly during VLP with a parameter-free processor. G2D achieves\nsuperior performance across 6 medical imaging tasks and 25 diseases,\nparticularly in semantic segmentation, which necessitates fine-grained,\nsemantically-grounded image features. In this task, G2D surpasses peer models\neven when fine-tuned with just 1\\% of the training data, compared to the 100\\%\nused by these models. The code will be released upon acceptance.\n","authors":["Che Liu","Cheng Ouyang","Sibo Cheng","Anand Shah","Wenjia Bai","Rossella Arcucci"],"pdf_url":"https://arxiv.org/pdf/2312.01522v3.pdf","comment":"Accepted by NeurIPS2024"},{"id":"http://arxiv.org/abs/2410.13453v1","updated":"2024-10-17T11:26:10Z","published":"2024-10-17T11:26:10Z","title":"Augmentation Policy Generation for Image Classification Using Large\n  Language Models","summary":"  Automated data augmentation methods have significantly improved the\nperformance and generalization capability of deep learning models in image\nclassification. Yet, most state-of-the-art methods are optimized on common\nbenchmark datasets, limiting their applicability to more diverse or\ndomain-specific data, such as medical datasets. In this paper, we propose a\nstrategy that uses large language models to automatically generate efficient\naugmentation policies, customized to fit the specific characteristics of any\ndataset and model architecture. The proposed method iteratively interacts with\nan LLM to obtain and refine the augmentation policies on model performance\nfeedback, creating a dataset-agnostic data augmentation pipeline. The proposed\nmethod was evaluated on medical imaging datasets, showing a clear improvement\nover state-of-the-art methods. The proposed approach offers an adaptive and\nscalable solution. Although it increases computational cost, it significantly\nboosts model robustness, automates the process, and minimizes the need for\nhuman involvement during model development.\n","authors":["Ant Duru","Alptekin Temizel"],"pdf_url":"https://arxiv.org/pdf/2410.13453v1.pdf","comment":"5 pages, 2 figures, 4 tables, submitted for consideration to the\n  International Workshop on Computational Intelligence for Multimedia\n  Understanding (IWCIM), ISCAS 2025"},{"id":"http://arxiv.org/abs/2410.09747v2","updated":"2024-10-17T11:14:37Z","published":"2024-10-13T06:53:58Z","title":"t-READi: Transformer-Powered Robust and Efficient Multimodal Inference\n  for Autonomous Driving","summary":"  Given the wide adoption of multimodal sensors (e.g., camera, lidar, radar) by\nautonomous vehicles (AVs), deep analytics to fuse their outputs for a robust\nperception become imperative. However, existing fusion methods often make two\nassumptions rarely holding in practice: i) similar data distributions for all\ninputs and ii) constant availability for all sensors. Because, for example,\nlidars have various resolutions and failures of radars may occur, such\nvariability often results in significant performance degradation in fusion. To\nthis end, we present tREADi, an adaptive inference system that accommodates the\nvariability of multimodal sensory data and thus enables robust and efficient\nperception. t-READi identifies variation-sensitive yet structure-specific model\nparameters; it then adapts only these parameters while keeping the rest intact.\nt-READi also leverages a cross-modality contrastive learning method to\ncompensate for the loss from missing modalities. Both functions are implemented\nto maintain compatibility with existing multimodal deep fusion methods. The\nextensive experiments evidently demonstrate that compared with the status quo\napproaches, t-READi not only improves the average inference accuracy by more\nthan 6% but also reduces the inference latency by almost 15x with the cost of\nonly 5% extra memory overhead in the worst case under realistic data and modal\nvariations.\n","authors":["Pengfei Hu","Yuhang Qian","Tianyue Zheng","Ang Li","Zhe Chen","Yue Gao","Xiuzhen Cheng","Jun Luo"],"pdf_url":"https://arxiv.org/pdf/2410.09747v2.pdf","comment":"14 pages, 16 figures"},{"id":"http://arxiv.org/abs/2410.13439v1","updated":"2024-10-17T11:12:55Z","published":"2024-10-17T11:12:55Z","title":"Similarity-Dissimilarity Loss with Supervised Contrastive Learning for\n  Multi-label Classification","summary":"  Supervised contrastive learning has been explored in making use of label\ninformation for multi-label classification, but determining positive samples in\nmulti-label scenario remains challenging. Previous studies have examined\nstrategies for identifying positive samples, considering label overlap\nproportion between anchors and samples. However, they ignore various relations\nbetween given anchors and samples, as well as how to dynamically adjust the\nweights in contrastive loss functions based on different relations, leading to\ngreat ambiguity. In this paper, we introduce five distinct relations between\nmulti-label samples and propose a Similarity-Dissimilarity Loss with\ncontrastive learning for multi-label classification. Our loss function\nre-weights the loss by computing the similarity and dissimilarity between\npositive samples and a given anchor based on the introduced relations. We\nmainly conduct experiments for multi-label text classification on MIMIC\ndatasets, then further extend the evaluation on MS-COCO. The Experimental\nresults show that our proposed loss effectively improves the performance on all\nencoders under supervised contrastive learning paradigm, demonstrating its\neffectiveness and robustness.\n","authors":["Guangming Huang","Yunfei Long","Cunjin Luo","Sheng Liu"],"pdf_url":"https://arxiv.org/pdf/2410.13439v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13437v1","updated":"2024-10-17T11:07:05Z","published":"2024-10-17T11:07:05Z","title":"Temporal-Enhanced Multimodal Transformer for Referring Multi-Object\n  Tracking and Segmentation","summary":"  Referring multi-object tracking (RMOT) is an emerging cross-modal task that\naims to locate an arbitrary number of target objects and maintain their\nidentities referred by a language expression in a video. This intricate task\ninvolves the reasoning of linguistic and visual modalities, along with the\ntemporal association of target objects. However, the seminal work employs only\nloose feature fusion and overlooks the utilization of long-term information on\ntracked objects. In this study, we introduce a compact Transformer-based\nmethod, termed TenRMOT. We conduct feature fusion at both encoding and decoding\nstages to fully exploit the advantages of Transformer architecture.\nSpecifically, we incrementally perform cross-modal fusion layer-by-layer during\nthe encoding phase. In the decoding phase, we utilize language-guided queries\nto probe memory features for accurate prediction of the desired objects.\nMoreover, we introduce a query update module that explicitly leverages temporal\nprior information of the tracked objects to enhance the consistency of their\ntrajectories. In addition, we introduce a novel task called Referring\nMulti-Object Tracking and Segmentation (RMOTS) and construct a new dataset\nnamed Ref-KITTI Segmentation. Our dataset consists of 18 videos with 818\nexpressions, and each expression averages 10.7 masks, which poses a greater\nchallenge compared to the typical single mask in most existing referring video\nsegmentation datasets. TenRMOT demonstrates superior performance on both the\nreferring multi-object tracking and the segmentation tasks.\n","authors":["Changcheng Xiao","Qiong Cao","Yujie Zhong","Xiang Zhang","Tao Wang","Canqun Yang","Long Lan"],"pdf_url":"https://arxiv.org/pdf/2410.13437v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14271v2","updated":"2024-10-17T11:06:26Z","published":"2024-05-23T07:48:19Z","title":"Fine-grained Image-to-LiDAR Contrastive Distillation with Visual\n  Foundation Models","summary":"  Contrastive image-to-LiDAR knowledge transfer, commonly used for learning 3D\nrepresentations with synchronized images and point clouds, often faces a\nself-conflict dilemma. This issue arises as contrastive losses unintentionally\ndissociate features of unmatched points and pixels that share semantic labels,\ncompromising the integrity of learned representations. To overcome this, we\nharness Visual Foundation Models (VFMs), which have revolutionized the\nacquisition of pixel-level semantics, to enhance 3D representation learning.\nSpecifically, we utilize off-the-shelf VFMs to generate semantic labels for\nweakly-supervised pixel-to-point contrastive distillation. Additionally, we\nemploy von Mises-Fisher distributions to structure the feature space, ensuring\nsemantic embeddings within the same class remain consistent across varying\ninputs. Furthermore, we adapt sampling probabilities of points to address\nimbalances in spatial distribution and category frequency, promoting\ncomprehensive and balanced learning. Extensive experiments demonstrate that our\napproach mitigates the challenges posed by traditional methods and consistently\nsurpasses existing image-to-LiDAR contrastive distillation methods in\ndownstream tasks. The source code is available at\n\\href{https://github.com/Eaphan/OLIVINE.}{\\color{black}https://github.com/Eaphan/OLIVINE}.\n","authors":["Yifan Zhang","Junhui Hou"],"pdf_url":"https://arxiv.org/pdf/2405.14271v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.13427v1","updated":"2024-10-17T10:51:08Z","published":"2024-10-17T10:51:08Z","title":"Unsupervised Skull Segmentation via Contrastive MR-to-CT Modality\n  Translation","summary":"  The skull segmentation from CT scans can be seen as an already solved\nproblem. However, in MR this task has a significantly greater complexity due to\nthe presence of soft tissues rather than bones. Capturing the bone structures\nfrom MR images of the head, where the main visualization objective is the\nbrain, is very demanding. The attempts that make use of skull stripping seem to\nnot be well suited for this task and fail to work in many cases. On the other\nhand, supervised approaches require costly and time-consuming skull\nannotations. To overcome the difficulties we propose a fully unsupervised\napproach, where we do not perform the segmentation directly on MR images, but\nwe rather perform a synthetic CT data generation via MR-to-CT translation and\nperform the segmentation there. We address many issues associated with\nunsupervised skull segmentation including the unpaired nature of MR and CT\ndatasets (contrastive learning), low resolution and poor quality\n(super-resolution), and generalization capabilities. The research has a\nsignificant value for downstream tasks requiring skull segmentation from MR\nvolumes such as craniectomy or surgery planning and can be seen as an important\nstep towards the utilization of synthetic data in medical imaging.\n","authors":["Kamil Kwarciak","Mateusz Daniol","Daria Hemmerling","Marek Wodzinski"],"pdf_url":"https://arxiv.org/pdf/2410.13427v1.pdf","comment":"16 pages, 5 figures, ACCV 2024 - GAISynMeD Workshop"},{"id":"http://arxiv.org/abs/2410.13421v1","updated":"2024-10-17T10:43:43Z","published":"2024-10-17T10:43:43Z","title":"Performance of Gaussian Mixture Model Classifiers on Embedded Feature\n  Spaces","summary":"  Data embeddings with CLIP and ImageBind provide powerful features for the\nanalysis of multimedia and/or multimodal data. We assess their performance here\nfor classification using a Gaussian Mixture models (GMMs) based layer as an\nalternative to the standard Softmax layer. GMMs based classifiers have recently\nbeen shown to have interesting performances as part of deep learning pipelines\ntrained end-to-end. Our first contribution is to investigate GMM based\nclassification performance taking advantage of the embedded spaces CLIP and\nImageBind. Our second contribution is in proposing our own GMM based classifier\nwith a lower parameters count than previously proposed. Our findings are, that\nin most cases, on these tested embedded spaces, one gaussian component in the\nGMMs is often enough for capturing each class, and we hypothesize that this may\nbe due to the contrastive loss used for training these embedded spaces that\nnaturally concentrates features together for each class. We also observed that\nImageBind often provides better performance than CLIP for classification of\nimage datasets even when these embedded spaces are compressed using PCA.\n","authors":["Jeremy Chopin","Rozenn Dahyot"],"pdf_url":"https://arxiv.org/pdf/2410.13421v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2308.02935v4","updated":"2024-10-17T09:53:57Z","published":"2023-08-05T18:32:49Z","title":"Bias Behind the Wheel: Fairness Testing of Autonomous Driving Systems","summary":"  This paper conducts fairness testing of automated pedestrian detection, a\ncrucial but under-explored issue in autonomous driving systems. We evaluate\neight state-of-the-art deep learning-based pedestrian detectors across\ndemographic groups on large-scale real-world datasets. To enable thorough\nfairness testing, we provide extensive annotations for the datasets, resulting\nin 8,311 images with 16,070 gender labels, 20,115 age labels, and 3,513 skin\ntone labels. Our findings reveal significant fairness issues, particularly\nrelated to age. The proportion of undetected children is 20.14% higher compared\nto adults. Furthermore, we explore how various driving scenarios affect the\nfairness of pedestrian detectors. We find that pedestrian detectors demonstrate\nsignificant gender biases during night time, potentially exacerbating the\nprevalent societal issue of female safety concerns during nighttime out.\nMoreover, we observe that pedestrian detectors can demonstrate both enhanced\nfairness and superior performance under specific driving conditions, which\nchallenges the fairness-performance trade-off theory widely acknowledged in the\nfairness literature. We publicly release the code, data, and results to support\nfuture research on fairness in autonomous driving.\n","authors":["Xinyue Li","Zhenpeng Chen","Jie M. Zhang","Federica Sarro","Ying Zhang","Xuanzhe Liu"],"pdf_url":"https://arxiv.org/pdf/2308.02935v4.pdf","comment":"Accepted by ACM Transactions on Software Engineering and Methodology\n  (TOSEM)"},{"id":"http://arxiv.org/abs/2410.13384v1","updated":"2024-10-17T09:36:52Z","published":"2024-10-17T09:36:52Z","title":"RescueADI: Adaptive Disaster Interpretation in Remote Sensing Images\n  with Autonomous Agents","summary":"  Current methods for disaster scene interpretation in remote sensing images\n(RSIs) mostly focus on isolated tasks such as segmentation, detection, or\nvisual question-answering (VQA). However, current interpretation methods often\nfail at tasks that require the combination of multiple perception methods and\nspecialized tools. To fill this gap, this paper introduces Adaptive Disaster\nInterpretation (ADI), a novel task designed to solve requests by planning and\nexecuting multiple sequentially correlative interpretation tasks to provide a\ncomprehensive analysis of disaster scenes. To facilitate research and\napplication in this area, we present a new dataset named RescueADI, which\ncontains high-resolution RSIs with annotations for three connected aspects:\nplanning, perception, and recognition. The dataset includes 4,044 RSIs, 16,949\nsemantic masks, 14,483 object bounding boxes, and 13,424 interpretation\nrequests across nine challenging request types. Moreover, we propose a new\ndisaster interpretation method employing autonomous agents driven by large\nlanguage models (LLMs) for task planning and execution, proving its efficacy in\nhandling complex disaster interpretations. The proposed agent-based method\nsolves various complex interpretation requests such as counting, area\ncalculation, and path-finding without human intervention, which traditional\nsingle-task approaches cannot handle effectively. Experimental results on\nRescueADI demonstrate the feasibility of the proposed task and show that our\nmethod achieves an accuracy 9% higher than existing VQA methods, highlighting\nits advantages over conventional disaster interpretation approaches. The\ndataset will be publicly available.\n","authors":["Zhuoran Liu","Danpei Zhao","Bo Yuan"],"pdf_url":"https://arxiv.org/pdf/2410.13384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13383v1","updated":"2024-10-17T09:36:19Z","published":"2024-10-17T09:36:19Z","title":"Railway LiDAR semantic segmentation based on intelligent semi-automated\n  data annotation","summary":"  Automated vehicles rely on an accurate and robust perception of the\nenvironment. Similarly to automated cars, highly automated trains require an\nenvironmental perception. Although there is a lot of research based on either\ncamera or LiDAR sensors in the automotive domain, very few contributions for\nthis task exist yet for automated trains. Additionally, no public dataset or\ndescribed approach for a 3D LiDAR semantic segmentation in the railway\nenvironment exists yet. Thus, we propose an approach for a point-wise 3D\nsemantic segmentation based on the 2DPass network architecture using scans and\nimages jointly. In addition, we present a semi-automated intelligent data\nannotation approach, which we use to efficiently and accurately label the\nrequired dataset recorded on a railway track in Germany. To improve performance\ndespite a still small number of labeled scans, we apply an active learning\napproach to intelligently select scans for the training dataset. Our\ncontributions are threefold: We annotate rail data including camera and LiDAR\ndata from the railway environment, transfer label the raw LiDAR point clouds\nusing an image segmentation network, and train a state-of-the-art 3D LiDAR\nsemantic segmentation network efficiently leveraging active learning. The\ntrained network achieves good segmentation results with a mean IoU of 71.48% of\n9 classes.\n","authors":["Florian Wulff","Bernd Schaeufele","Julian Pfeifer","Ilja Radusch"],"pdf_url":"https://arxiv.org/pdf/2410.13383v1.pdf","comment":"This article has been accepted for publication in the IEEE VTC Fall\n  2024"},{"id":"http://arxiv.org/abs/2410.13371v1","updated":"2024-10-17T09:23:30Z","published":"2024-10-17T09:23:30Z","title":"Accurate Checkerboard Corner Detection under Defoucs","summary":"  Camera calibration is a critical process in 3D vision, im pacting\napplications in autonomous driving, robotics, ar chitecture, and so on. This\npaper focuses on enhancing feature extraction for chessboard corner detection,\na key step in calibration. We analyze existing methods, high lighting their\nlimitations and propose a novel sub-pixel refinement approach based on\nsymmetry, which signifi cantly improves accuracy for visible light cameras. Un\nlike prior symmetry based method that assume a contin uous physical pattern,\nour approach accounts for abrupt changes in visible light camera images and\ndefocus ef fects. We introduce a simplified objective function that reduces\ncomputation time and mitigates overfitting risks. Furthermore, we derive an\nexplicit expression for the pixel value of a blurred edge, providing insights\ninto the relationship between pixel value and center intensity. Our method\ndemonstrates superior performance, achiev ing substantial accuracy improvements\nover existing tech niques, particularly in the context of visible light cam era\ncalibration. Our code is available from https:\n//github.com/spdfghi/Accurate-Checkerboard Corner-Detection-under-Defoucs.git.\n","authors":["Zezhun Shi"],"pdf_url":"https://arxiv.org/pdf/2410.13371v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13370v1","updated":"2024-10-17T09:22:53Z","published":"2024-10-17T09:22:53Z","title":"MagicTailor: Component-Controllable Personalization in Text-to-Image\n  Diffusion Models","summary":"  Recent advancements in text-to-image (T2I) diffusion models have enabled the\ncreation of high-quality images from text prompts, but they still struggle to\ngenerate images with precise control over specific visual concepts. Existing\napproaches can replicate a given concept by learning from reference images, yet\nthey lack the flexibility for fine-grained customization of the individual\ncomponent within the concept. In this paper, we introduce\ncomponent-controllable personalization, a novel task that pushes the boundaries\nof T2I models by allowing users to reconfigure specific components when\npersonalizing visual concepts. This task is particularly challenging due to two\nprimary obstacles: semantic pollution, where unwanted visual elements corrupt\nthe personalized concept, and semantic imbalance, which causes disproportionate\nlearning of the concept and component. To overcome these challenges, we design\nMagicTailor, an innovative framework that leverages Dynamic Masked Degradation\n(DM-Deg) to dynamically perturb undesired visual semantics and Dual-Stream\nBalancing (DS-Bal) to establish a balanced learning paradigm for desired visual\nsemantics. Extensive comparisons, ablations, and analyses demonstrate that\nMagicTailor not only excels in this challenging task but also holds significant\npromise for practical applications, paving the way for more nuanced and\ncreative image generation.\n","authors":["Donghao Zhou","Jiancheng Huang","Jinbin Bai","Jiaze Wang","Hao Chen","Guangyong Chen","Xiaowei Hu","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2410.13370v1.pdf","comment":"Project page: https://correr-zhou.github.io/MagicTailor"},{"id":"http://arxiv.org/abs/2410.13360v1","updated":"2024-10-17T09:10:26Z","published":"2024-10-17T09:10:26Z","title":"Remember, Retrieve and Generate: Understanding Infinite Visual Concepts\n  as Your Personalized Assistant","summary":"  The development of large language models (LLMs) has significantly enhanced\nthe capabilities of multimodal LLMs (MLLMs) as general assistants. However,\nlack of user-specific knowledge still restricts their application in human's\ndaily life. In this paper, we introduce the Retrieval Augmented Personalization\n(RAP) framework for MLLMs' personalization. Starting from a general MLLM, we\nturn it into a personalized assistant in three steps. (a) Remember: We design a\nkey-value database to store user-related information, e.g., user's name, avatar\nand other attributes. (b) Retrieve: When the user initiates a conversation, RAP\nwill retrieve relevant information from the database using a multimodal\nretriever. (c) Generate: The input query and retrieved concepts' information\nare fed into MLLMs to generate personalized, knowledge-augmented responses.\nUnlike previous methods, RAP allows real-time concept editing via updating the\nexternal database. To further improve generation quality and alignment with\nuser-specific information, we design a pipeline for data collection and create\na specialized dataset for personalized training of MLLMs. Based on the dataset,\nwe train a series of MLLMs as personalized multimodal assistants. By\npretraining on large-scale dataset, RAP-MLLMs can generalize to infinite visual\nconcepts without additional finetuning. Our models demonstrate outstanding\nflexibility and generation quality across a variety of tasks, such as\npersonalized image captioning, question answering and visual recognition. The\ncode, data and models are available at https://github.com/Hoar012/RAP-MLLM.\n","authors":["Haoran Hao","Jiaming Han","Changsheng Li","Yu-Feng Li","Xiangyu Yue"],"pdf_url":"https://arxiv.org/pdf/2410.13360v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13355v1","updated":"2024-10-17T09:05:15Z","published":"2024-10-17T09:05:15Z","title":"Self-Supervised Scene Flow Estimation with Point-Voxel Fusion and\n  Surface Representation","summary":"  Scene flow estimation aims to generate the 3D motion field of points between\ntwo consecutive frames of point clouds, which has wide applications in various\nfields. Existing point-based methods ignore the irregularity of point clouds\nand have difficulty capturing long-range dependencies due to the inefficiency\nof point-level computation. Voxel-based methods suffer from the loss of detail\ninformation. In this paper, we propose a point-voxel fusion method, where we\nutilize a voxel branch based on sparse grid attention and the shifted window\nstrategy to capture long-range dependencies and a point branch to capture\nfine-grained features to compensate for the information loss in the voxel\nbranch. In addition, since xyz coordinates are difficult to describe the\ngeometric structure of complex 3D objects in the scene, we explicitly encode\nthe local surface information of the point cloud through the umbrella surface\nfeature extraction (USFE) module. We verify the effectiveness of our method by\nconducting experiments on the Flyingthings3D and KITTI datasets. Our method\noutperforms all other self-supervised methods and achieves highly competitive\nresults compared to fully supervised methods. We achieve improvements in all\nmetrics, especially EPE, which is reduced by 8.51% and 10.52% on the KITTIo and\nKITTIs datasets, respectively.\n","authors":["Xuezhi Xiang","Xi Wang","Lei Zhang","Denis Ombati","Himaloy Himu","Xiantong Zhen"],"pdf_url":"https://arxiv.org/pdf/2410.13355v1.pdf","comment":"The paper is under consideration at 2025 IEEE International\n  Conference on Acoustics, Speech, and Signal Processing (ICASSP 2025)"},{"id":"http://arxiv.org/abs/2410.13349v1","updated":"2024-10-17T09:00:29Z","published":"2024-10-17T09:00:29Z","title":"GlossyGS: Inverse Rendering of Glossy Objects with 3D Gaussian Splatting","summary":"  Reconstructing objects from posed images is a crucial and complex task in\ncomputer graphics and computer vision. While NeRF-based neural reconstruction\nmethods have exhibited impressive reconstruction ability, they tend to be\ntime-comsuming. Recent strategies have adopted 3D Gaussian Splatting (3D-GS)\nfor inverse rendering, which have led to quick and effective outcomes. However,\nthese techniques generally have difficulty in producing believable geometries\nand materials for glossy objects, a challenge that stems from the inherent\nambiguities of inverse rendering. To address this, we introduce GlossyGS, an\ninnovative 3D-GS-based inverse rendering framework that aims to precisely\nreconstruct the geometry and materials of glossy objects by integrating\nmaterial priors. The key idea is the use of micro-facet geometry segmentation\nprior, which helps to reduce the intrinsic ambiguities and improve the\ndecomposition of geometries and materials. Additionally, we introduce a normal\nmap prefiltering strategy to more accurately simulate the normal distribution\nof reflective surfaces. These strategies are integrated into a hybrid geometry\nand material representation that employs both explicit and implicit methods to\ndepict glossy objects. We demonstrate through quantitative analysis and\nqualitative visualization that the proposed method is effective to reconstruct\nhigh-fidelity geometries and materials of glossy objects, and performs\nfavorably against state-of-the-arts.\n","authors":["Shuichang Lai","Letian Huang","Jie Guo","Kai Cheng","Bowen Pan","Xiaoxiao Long","Jiangjing Lyu","Chengfei Lv","Yanwen Guo"],"pdf_url":"https://arxiv.org/pdf/2410.13349v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.11553v4","updated":"2024-10-17T08:58:47Z","published":"2024-08-21T12:04:32Z","title":"AnyDesign: Versatile Area Fashion Editing via Mask-Free Diffusion","summary":"  Fashion image editing aims to modify a person's appearance based on a given\ninstruction. Existing methods require auxiliary tools like segmenters and\nkeypoint extractors, lacking a flexible and unified framework. Moreover, these\nmethods are limited in the variety of clothing types they can handle, as most\ndatasets focus on people in clean backgrounds and only include generic garments\nsuch as tops, pants, and dresses. These limitations restrict their\napplicability in real-world scenarios. In this paper, we first extend an\nexisting dataset for human generation to include a wider range of apparel and\nmore complex backgrounds. This extended dataset features people wearing diverse\nitems such as tops, pants, dresses, skirts, headwear, scarves, shoes, socks,\nand bags. Additionally, we propose AnyDesign, a diffusion-based method that\nenables mask-free editing on versatile areas. Users can simply input a human\nimage along with a corresponding prompt in either text or image format. Our\napproach incorporates Fashion DiT, equipped with a Fashion-Guidance Attention\n(FGA) module designed to fuse explicit apparel types and CLIP-encoded apparel\nfeatures. Both Qualitative and quantitative experiments demonstrate that our\nmethod delivers high-quality fashion editing and outperforms contemporary\ntext-guided fashion editing methods.\n","authors":["Yunfang Niu","Lingxiang Wu","Dong Yi","Jie Peng","Ning Jiang","Haiying Wu","Jinqiao Wang"],"pdf_url":"https://arxiv.org/pdf/2408.11553v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.02278v3","updated":"2024-10-17T08:57:50Z","published":"2023-04-05T07:50:16Z","title":"SCMM: Calibrating Cross-modal Representations for Text-Based Person\n  Search","summary":"  Text-Based Person Search (TBPS) is a crucial task that enables accurate\nretrieval of target individuals from large-scale galleries with only given\ntextual caption. For cross-modal TBPS tasks, it is critical to obtain\nwell-distributed representation in the common embedding space to reduce the\ninter-modal gap. Furthermore, learning detailed image-text correspondences is\nessential to discriminate similar targets and enable fine-grained search. To\naddress these challenges, we present a simple yet effective method named Sew\nCalibration and Masked Modeling (SCMM) that calibrates cross-modal\nrepresentations by learning compact and well-aligned embeddings. SCMM is\ndistinguished by two novel losses to provide fine-grained cross-modal\nrepresentations: 1) a Sew calibration loss that takes the quality of textual\ncaptions as guidance and aligns features between image and text modalities, and\n2) a Masked Caption Modeling (MCM) loss that leverages a masked caption\nprediction task to establish detailed and generic relationships between textual\nand visual parts. The dual-pronged strategy refines feature alignment and\nenriches cross-modal correspondences, enabling the accurate distinction of\nsimilar individuals. Consequently, its streamlined dual-encoder architecture\navoids complex branches and interactions and facilitates high-speed inference\nsuitable for real-time requirements. Consequently, high-speed inference is\nachieved, which is essential for resource-limited applications often demanding\nreal-time processing. Extensive experiments on three popular TBPS benchmarks\ndemonstrate the superiority of SCMM, achieving top results with 73.81%, 74.25%,\nand 57.35% Rank-1 accuracy on CUHK-PEDES, ICFG-PEDES, and RSTPReID,\nrespectively. We hope SCMM's scalable and cost-effective design will serve as a\nstrong baseline and facilitate future research in this field.\n","authors":["Jing Liu","Donglai Wei","Yang Liu","Sipeng Zhang","Tong Yang","Victor C. M. Leung"],"pdf_url":"https://arxiv.org/pdf/2304.02278v3.pdf","comment":"This version of manuscript is under IEEE TMM review"},{"id":"http://arxiv.org/abs/2410.03320v2","updated":"2024-10-17T08:43:29Z","published":"2024-10-04T11:14:31Z","title":"Lost in Tracking: Uncertainty-guided Cardiac Cine MRI Segmentation at\n  Right Ventricle Base","summary":"  Accurate biventricular segmentation of cardiac magnetic resonance (CMR) cine\nimages is essential for the clinical evaluation of heart function. However,\ncompared to left ventricle (LV), right ventricle (RV) segmentation is still\nmore challenging and less reproducible. Degenerate performance frequently\noccurs at the RV base, where the in-plane anatomical structures are complex\n(with atria, valve, and aorta) and vary due to the strong interplanar motion.\nIn this work, we propose to address the currently unsolved issues in CMR\nsegmentation, specifically at the RV base, with two strategies: first, we\ncomplemented the public resource by reannotating the RV base in the ACDC\ndataset, with refined delineation of the right ventricle outflow tract (RVOT),\nunder the guidance of an expert cardiologist. Second, we proposed a novel dual\nencoder U-Net architecture that leverages temporal incoherence to inform the\nsegmentation when interplanar motions occur. The inter-planar motion is\ncharacterized by loss-of-tracking, via Bayesian uncertainty of a\nmotion-tracking model. Our experiments showed that our method significantly\nimproved RV base segmentation taking into account temporal incoherence.\nFurthermore, we investigated the reproducibility of deep learning-based\nsegmentation and showed that the combination of consistent annotation and loss\nof tracking could enhance the reproducibility of RV segmentation, potentially\nfacilitating a large number of clinical studies focusing on RV.\n","authors":["Yidong Zhao","Yi Zhang","Orlando Simonetti","Yuchi Han","Qian Tao"],"pdf_url":"https://arxiv.org/pdf/2410.03320v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.11781v2","updated":"2024-10-17T08:28:50Z","published":"2024-07-16T14:38:13Z","title":"Sliding Gaussian ball adaptive growth (SlingBAG): point cloud-based\n  iterative algorithm for large-scale 3D photoacoustic imaging","summary":"  Large-scale photoacoustic (PA) 3D imaging has become increasingly important\nfor both clinical and pre-clinical applications. Limited by resource and\napplication constrains, only sparsely-distributed transducer arrays can be\napplied, which necessitates advanced image reconstruction algorithms to\novercome artifacts caused by using back-projection algorithm. However, high\ncomputing memory consumption of traditional iterative algorithms for\nlarge-scale 3D cases is practically unacceptable. Here, we propose a point\ncloud-based iterative algorithm that reduces memory consumption by several\norders, wherein a 3D photoacoustic scene is modeled as a series of\nGaussian-distributed spherical sources. During the iterative reconstruction\nprocess, the properties of each Gaussian source, including peak intensities,\nstandard deviations and means are stored in form of point cloud, then\ncontinuously optimized and adaptively undergoing destroying, splitting, and\nduplication along the gradient direction, thus manifesting the sliding ball\nadaptive growth effect. This method, named the sliding Gaussian ball adaptive\ngrowth (SlingBAG) algorithm, enables high-quality 3D large-scale PA\nreconstruction with fast iteration and extremely less memory usage. We\nvalidated SlingBAG algorithm in both simulation study and in vivo animal\nexperiments.\n","authors":["Shuang Li","Yibing Wang","Jian Gao","Chulhong Kim","Seongwook Choi","Yu Zhang","Qian Chen","Yao Yao","Changhui Li"],"pdf_url":"https://arxiv.org/pdf/2407.11781v2.pdf","comment":"Added SlingBAG reconstruction of rat kidney and rat liver results;\n  updated methods; added references"},{"id":"http://arxiv.org/abs/2308.14409v2","updated":"2024-10-17T08:25:06Z","published":"2023-08-28T08:47:06Z","title":"Steerable Conditional Diffusion for Out-of-Distribution Adaptation in\n  Medical Image Reconstruction","summary":"  Denoising diffusion models have emerged as the go-to generative framework for\nsolving inverse problems in imaging. A critical concern regarding these models\nis their performance on out-of-distribution tasks, which remains an\nunder-explored challenge. Using a diffusion model on an out-of-distribution\ndataset, realistic reconstructions can be generated, but with hallucinating\nimage features that are uniquely present in the training dataset. To address\nthis discrepancy during train-test time and improve reconstruction accuracy, we\nintroduce a novel sampling framework called Steerable Conditional Diffusion.\nSpecifically, this framework adapts the diffusion model, concurrently with\nimage reconstruction, based solely on the information provided by the available\nmeasurement. Utilising our proposed method, we achieve substantial enhancements\nin out-of-distribution performance across diverse imaging modalities, advancing\nthe robust deployment of denoising diffusion models in real-world applications.\n","authors":["Riccardo Barbano","Alexander Denker","Hyungjin Chung","Tae Hoon Roh","Simon Arridge","Peter Maass","Bangti Jin","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2308.14409v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13321v1","updated":"2024-10-17T08:24:27Z","published":"2024-10-17T08:24:27Z","title":"Mitigating Hallucinations in Large Vision-Language Models via\n  Summary-Guided Decoding","summary":"  Large Vision-Language Models (LVLMs) demonstrate impressive capabilities in\ngenerating detailed and coherent responses from visual inputs. However, they\nare prone to generate hallucinations due to an over-reliance on language\npriors. To address this issue, we investigate the language priors in LVLMs and\nmake two key observations: (1) Even when predicting the tokens associated with\nimage-related part-of-speech (POS), models increasingly rely on linguistic\npriors as the token sequences grow, thereby amplifying hallucinations. (2)\nMethods that directly calibrate LVLM's output distribution to mitigate language\npriors can lead to a degradation in text quality or even exacerbate\nhallucinations. Based on these findings, we propose a novel method,\nSummary-Guided Decoding (SGD). This method naturally encourages the model to\nfocus more on image information by reducing the text context through summaries,\nwhile controlling only the image-related POS tokens to maintain text quality.\nThrough experiments, we demonstrate that SGD achieves state-of-the-art\nperformance on object hallucination benchmarks. Furthermore, in terms of the\ntrade-off between precision and recall, SGD achieves Pareto optimality among\nthe existing methods. Lastly, we observe that although existing methods\nstruggle to balance the reduction of object hallucinations with maintaining\ntext quality, SGD demonstrates robustness in handling this challenge.\n","authors":["Kyungmin Min","Minbeom Kim","Kang-il Lee","Dongryeol Lee","Kyomin Jung"],"pdf_url":"https://arxiv.org/pdf/2410.13321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13807v1","updated":"2024-10-17T17:41:52Z","published":"2024-10-17T17:41:52Z","title":"ConsisSR: Delving Deep into Consistency in Diffusion-based Image\n  Super-Resolution","summary":"  Real-world image super-resolution (Real-ISR) aims at restoring high-quality\n(HQ) images from low-quality (LQ) inputs corrupted by unknown and complex\ndegradations. In particular, pretrained text-to-image (T2I) diffusion models\nprovide strong generative priors to reconstruct credible and intricate details.\nHowever, T2I generation focuses on semantic consistency while Real-ISR\nemphasizes pixel-level reconstruction, which hinders existing methods from\nfully exploiting diffusion priors. To address this challenge, we introduce\nConsisSR to handle both semantic and pixel-level consistency. Specifically,\ncompared to coarse-grained text prompts, we exploit the more powerful CLIP\nimage embedding and effectively leverage both modalities through our Hybrid\nPrompt Adapter (HPA) for semantic guidance. Secondly, we introduce Time-aware\nLatent Augmentation (TALA) to mitigate the inherent gap between T2I generation\nand Real-ISR consistency requirements. By randomly mixing LQ and HQ latent\ninputs, our model not only handle timestep-specific diffusion noise but also\nrefine the accumulated latent representations. Last but not least, our\nGAN-Embedding strategy employs the pretrained Real-ESRGAN model to refine the\ndiffusion start point. This accelerates the inference process to 10 steps while\npreserving sampling quality, in a training-free manner. Our method demonstrates\nstate-of-the-art performance among both full-scale and accelerated models. The\ncode will be made publicly available.\n","authors":["Junhao Gu","Peng-Tao Jiang","Hao Zhang","Mi Zhou","Jinwei Chen","Wenming Yang","Bo Li"],"pdf_url":"https://arxiv.org/pdf/2410.13807v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.02791v3","updated":"2024-10-17T16:11:28Z","published":"2021-07-06T17:58:35Z","title":"Depth-supervised NeRF: Fewer Views and Faster Training for Free","summary":"  A commonly observed failure mode of Neural Radiance Field (NeRF) is fitting\nincorrect geometries when given an insufficient number of input views. One\npotential reason is that standard volumetric rendering does not enforce the\nconstraint that most of a scene's geometry consist of empty space and opaque\nsurfaces. We formalize the above assumption through DS-NeRF (Depth-supervised\nNeural Radiance Fields), a loss for learning radiance fields that takes\nadvantage of readily-available depth supervision. We leverage the fact that\ncurrent NeRF pipelines require images with known camera poses that are\ntypically estimated by running structure-from-motion (SFM). Crucially, SFM also\nproduces sparse 3D points that can be used as \"free\" depth supervision during\ntraining: we add a loss to encourage the distribution of a ray's terminating\ndepth matches a given 3D keypoint, incorporating depth uncertainty. DS-NeRF can\nrender better images given fewer training views while training 2-3x faster.\nFurther, we show that our loss is compatible with other recently proposed NeRF\nmethods, demonstrating that depth is a cheap and easily digestible supervisory\nsignal. And finally, we find that DS-NeRF can support other types of depth\nsupervision such as scanned depth sensors and RGB-D reconstruction outputs.\n","authors":["Kangle Deng","Andrew Liu","Jun-Yan Zhu","Deva Ramanan"],"pdf_url":"https://arxiv.org/pdf/2107.02791v3.pdf","comment":"Project page: http://www.cs.cmu.edu/~dsnerf/ GitHub:\n  https://github.com/dunbar12138/DSNeRF"},{"id":"http://arxiv.org/abs/2009.09231v2","updated":"2024-10-17T13:30:22Z","published":"2020-09-19T13:47:33Z","title":"Adversarial Exposure Attack on Diabetic Retinopathy Imagery Grading","summary":"  Diabetic Retinopathy (DR) is a leading cause of vision loss around the world.\nTo help diagnose it, numerous cutting-edge works have built powerful deep\nneural networks (DNNs) to automatically grade DR via retinal fundus images\n(RFIs). However, RFIs are commonly affected by camera exposure issues that may\nlead to incorrect grades. The mis-graded results can potentially pose high\nrisks to an aggravation of the condition. In this paper, we study this problem\nfrom the viewpoint of adversarial attacks. We identify and introduce a novel\nsolution to an entirely new task, termed as adversarial exposure attack, which\nis able to produce natural exposure images and mislead the state-of-the-art\nDNNs. We validate our proposed method on a real-world public DR dataset with\nthree DNNs, e.g., ResNet50, MobileNet, and EfficientNet, demonstrating that our\nmethod achieves high image quality and success rate in transferring the\nattacks. Our method reveals the potential threats to DNN-based automatic DR\ngrading and would benefit the development of exposure-robust DR grading methods\nin the future.\n","authors":["Yupeng Cheng","Qing Guo","Felix Juefei-Xu","Huazhu Fu","Shang-Wei Lin","Weisi Lin"],"pdf_url":"https://arxiv.org/pdf/2009.09231v2.pdf","comment":"13 pages, 7 figures"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2410.13857v1","updated":"2024-10-17T17:59:35Z","published":"2024-10-17T17:59:35Z","title":"How Numerical Precision Affects Mathematical Reasoning Capabilities of\n  LLMs","summary":"  Despite the remarkable success of Transformer-based Large Language Models\n(LLMs) across various domains, understanding and enhancing their mathematical\ncapabilities remains a significant challenge. In this paper, we conduct a\nrigorous theoretical analysis of LLMs' mathematical abilities, with a specific\nfocus on their arithmetic performances. We identify numerical precision as a\nkey factor that influences their effectiveness in mathematical tasks. Our\nresults show that Transformers operating with low numerical precision fail to\naddress arithmetic tasks, such as iterated addition and integer multiplication,\nunless the model size grows super-polynomially with respect to the input\nlength. In contrast, Transformers with standard numerical precision can\nefficiently handle these tasks with significantly smaller model sizes. We\nfurther support our theoretical findings through empirical experiments that\nexplore the impact of varying numerical precision on arithmetic tasks,\nproviding valuable insights for improving the mathematical reasoning\ncapabilities of LLMs.\n","authors":["Guhao Feng","Kai Yang","Yuntian Gu","Xinyue Ai","Shengjie Luo","Jiacheng Sun","Di He","Zhenguo Li","Liwei Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13857v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13854v1","updated":"2024-10-17T17:59:24Z","published":"2024-10-17T17:59:24Z","title":"Can MLLMs Understand the Deep Implication Behind Chinese Images?","summary":"  As the capabilities of Multimodal Large Language Models (MLLMs) continue to\nimprove, the need for higher-order capability evaluation of MLLMs is\nincreasing. However, there is a lack of work evaluating MLLM for higher-order\nperception and understanding of Chinese visual content. To fill the gap, we\nintroduce the **C**hinese **I**mage **I**mplication understanding\n**Bench**mark, **CII-Bench**, which aims to assess the higher-order perception\nand understanding capabilities of MLLMs for Chinese images. CII-Bench stands\nout in several ways compared to existing benchmarks. Firstly, to ensure the\nauthenticity of the Chinese context, images in CII-Bench are sourced from the\nChinese Internet and manually reviewed, with corresponding answers also\nmanually crafted. Additionally, CII-Bench incorporates images that represent\nChinese traditional culture, such as famous Chinese traditional paintings,\nwhich can deeply reflect the model's understanding of Chinese traditional\nculture. Through extensive experiments on CII-Bench across multiple MLLMs, we\nhave made significant findings. Initially, a substantial gap is observed\nbetween the performance of MLLMs and humans on CII-Bench. The highest accuracy\nof MLLMs attains 64.4%, where as human accuracy averages 78.2%, peaking at an\nimpressive 81.0%. Subsequently, MLLMs perform worse on Chinese traditional\nculture images, suggesting limitations in their ability to understand\nhigh-level semantics and lack a deep knowledge base of Chinese traditional\nculture. Finally, it is observed that most models exhibit enhanced accuracy\nwhen image emotion hints are incorporated into the prompts. We believe that\nCII-Bench will enable MLLMs to gain a better understanding of Chinese semantics\nand Chinese-specific images, advancing the journey towards expert artificial\ngeneral intelligence (AGI). Our project is publicly available at\nhttps://cii-bench.github.io/.\n","authors":["Chenhao Zhang","Xi Feng","Yuelin Bai","Xinrun Du","Jinchang Hou","Kaixin Deng","Guangzeng Han","Qinrui Li","Bingli Wang","Jiaheng Liu","Xingwei Qu","Yifei Zhang","Qixuan Zhao","Yiming Liang","Ziqiang Liu","Feiteng Fang","Min Yang","Wenhao Huang","Chenghua Lin","Ge Zhang","Shiwen Ni"],"pdf_url":"https://arxiv.org/pdf/2410.13854v1.pdf","comment":"32 pages,18 figures. Project Page: https://cii-bench.github.io/ Code:\n  https://github.com/MING_X/CII-Bench Dataset:\n  https://huggingface.co/datasets/m-a-p/CII-Bench"},{"id":"http://arxiv.org/abs/2410.13852v1","updated":"2024-10-17T17:59:03Z","published":"2024-10-17T17:59:03Z","title":"Retrospective Learning from Interactions","summary":"  Multi-turn interactions between large language models (LLMs) and users\nnaturally include implicit feedback signals. If an LLM responds in an\nunexpected way to an instruction, the user is likely to signal it by rephrasing\nthe request, expressing frustration, or pivoting to an alternative task. Such\nsignals are task-independent and occupy a relatively constrained subspace of\nlanguage, allowing the LLM to identify them even if it fails on the actual\ntask. This creates an avenue for continually learning from interactions without\nadditional annotations. We introduce ReSpect, a method to learn from such\nsignals in past interactions via retrospection. We deploy ReSpect in a new\nmultimodal interaction scenario, where humans instruct an LLM to solve an\nabstract reasoning task with a combinatorial solution space. Through thousands\nof interactions with humans, we show how ReSpect gradually improves task\ncompletion rate from 31% to 82%, all without any external annotation.\n","authors":["Zizhao Chen","Mustafa Omer Gul","Yiwei Chen","Gloria Geng","Anne Wu","Yoav Artzi"],"pdf_url":"https://arxiv.org/pdf/2410.13852v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13850v1","updated":"2024-10-17T17:59:02Z","published":"2024-10-17T17:59:02Z","title":"Influence Functions for Scalable Data Attribution in Diffusion Models","summary":"  Diffusion models have led to significant advancements in generative\nmodelling. Yet their widespread adoption poses challenges regarding data\nattribution and interpretability. In this paper, we aim to help address such\nchallenges in diffusion models by developing an \\textit{influence functions}\nframework. Influence function-based data attribution methods approximate how a\nmodel's output would have changed if some training data were removed. In\nsupervised learning, this is usually used for predicting how the loss on a\nparticular example would change. For diffusion models, we focus on predicting\nthe change in the probability of generating a particular example via several\nproxy measurements. We show how to formulate influence functions for such\nquantities and how previously proposed methods can be interpreted as particular\ndesign choices in our framework. To ensure scalability of the Hessian\ncomputations in influence functions, we systematically develop K-FAC\napproximations based on generalised Gauss-Newton matrices specifically tailored\nto diffusion models. We recast previously proposed methods as specific design\nchoices in our framework and show that our recommended method outperforms\nprevious data attribution approaches on common evaluations, such as the Linear\nData-modelling Score (LDS) or retraining without top influences, without the\nneed for method-specific hyperparameter tuning.\n","authors":["Bruno Mlodozeniec","Runa Eschenhagen","Juhan Bae","Alexander Immer","David Krueger","Richard Turner"],"pdf_url":"https://arxiv.org/pdf/2410.13850v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08928v2","updated":"2024-10-17T17:58:53Z","published":"2024-10-11T15:53:24Z","title":"Towards Multilingual LLM Evaluation for European Languages","summary":"  The rise of Large Language Models (LLMs) has revolutionized natural language\nprocessing across numerous languages and tasks. However, evaluating LLM\nperformance in a consistent and meaningful way across multiple European\nlanguages remains challenging, especially due to the scarcity of\nlanguage-parallel multilingual benchmarks. We introduce a multilingual\nevaluation approach tailored for European languages. We employ translated\nversions of five widely-used benchmarks to assess the capabilities of 40 LLMs\nacross 21 European languages. Our contributions include examining the\neffectiveness of translated benchmarks, assessing the impact of different\ntranslation services, and offering a multilingual evaluation framework for LLMs\nthat includes newly created datasets: EU20-MMLU, EU20-HellaSwag, EU20-ARC,\nEU20-TruthfulQA, and EU20-GSM8K. The benchmarks and results are made publicly\navailable to encourage further research in multilingual LLM evaluation.\n","authors":["Klaudia Thellmann","Bernhard Stadler","Michael Fromm","Jasper Schulze Buschhoff","Alex Jude","Fabio Barth","Johannes Leveling","Nicolas Flores-Herr","Joachim Köhler","René Jäkel","Mehdi Ali"],"pdf_url":"https://arxiv.org/pdf/2410.08928v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13848v1","updated":"2024-10-17T17:58:37Z","published":"2024-10-17T17:58:37Z","title":"Janus: Decoupling Visual Encoding for Unified Multimodal Understanding\n  and Generation","summary":"  In this paper, we introduce Janus, an autoregressive framework that unifies\nmultimodal understanding and generation. Prior research often relies on a\nsingle visual encoder for both tasks, such as Chameleon. However, due to the\ndiffering levels of information granularity required by multimodal\nunderstanding and generation, this approach can lead to suboptimal performance,\nparticularly in multimodal understanding. To address this issue, we decouple\nvisual encoding into separate pathways, while still leveraging a single,\nunified transformer architecture for processing. The decoupling not only\nalleviates the conflict between the visual encoder's roles in understanding and\ngeneration, but also enhances the framework's flexibility. For instance, both\nthe multimodal understanding and generation components can independently select\ntheir most suitable encoding methods. Experiments show that Janus surpasses\nprevious unified model and matches or exceeds the performance of task-specific\nmodels. The simplicity, high flexibility, and effectiveness of Janus make it a\nstrong candidate for next-generation unified multimodal models.\n","authors":["Chengyue Wu","Xiaokang Chen","Zhiyu Wu","Yiyang Ma","Xingchao Liu","Zizheng Pan","Wen Liu","Zhenda Xie","Xingkai Yu","Chong Ruan","Ping Luo"],"pdf_url":"https://arxiv.org/pdf/2410.13848v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2410.13846v1","updated":"2024-10-17T17:58:14Z","published":"2024-10-17T17:58:14Z","title":"SimLayerKV: A Simple Framework for Layer-Level KV Cache Reduction","summary":"  Recent advancements in large language models (LLMs) have extended their\ncapabilities to handle long contexts. However, increasing the number of model\nlayers and the length of input sequences significantly escalates the memory\nrequired to store key-value (KV) cache, posing challenges for efficient\ninference. To mitigate this issue, we present SimLayerKV, a simple yet\neffective method that reduces inter-layer KV cache redundancies by selectively\ndropping cache in identified lazy layers. Our approach is based on the\nobservation that certain layers in long-context LLMs exhibit \"lazy\" behavior,\ncontributing less to modeling long-range dependencies compared to non-lazy\nlayers. By analyzing attention weight patterns, we find that the behavior of\nthese lazy layers is consistent across tokens during generation for a given\ninput. This insight motivates our SimLayerKV, which identifies lazy layers and\nreduces their KV cache accordingly. SimLayerKV is training-free, generalizable,\nand can be implemented with only seven lines of code. We conduct extensive\nexperiments on three representative LLMs, e.g., LLaMA2-7B, LLaMA3-8B, and\nMistral-7B across 16 tasks from the LongBench benchmark. The results\ndemonstrate that SimLayerKV achieves a KV cache compression ratio of 5$\\times$\nwith only a 1.2% performance drop when combined with 4-bit quantization. Our\ncode is available at https://github.com/sail-sg/SimLayerKV.\n","authors":["Xuan Zhang","Cunxiao Du","Chao Du","Tianyu Pang","Wei Gao","Min Lin"],"pdf_url":"https://arxiv.org/pdf/2410.13846v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13839v1","updated":"2024-10-17T17:55:26Z","published":"2024-10-17T17:55:26Z","title":"Accelerating Codec-based Speech Synthesis with Multi-Token Prediction\n  and Speculative Decoding","summary":"  The goal of this paper is to accelerate codec-based speech synthesis systems\nwith minimum sacrifice to speech quality. We propose an enhanced inference\nmethod that allows for flexible trade-offs between speed and quality during\ninference without requiring additional training. Our core idea is to predict\nmultiple tokens per inference step of the AR module using multiple prediction\nheads, resulting in a linear reduction in synthesis time as the number of heads\nincreases. Furthermore, we introduce a novel speculative decoding technique\nthat utilises a Viterbi-based algorithm to select the optimal sequence of\ngenerated tokens at each decoding step. In our experiments, we demonstrate that\nthe time required to predict each token is reduced by a factor of 4 to 5\ncompared to baseline models, with minimal quality trade-off or even improvement\nin terms of speech intelligibility. Audio samples are available at:\nmultpletokensprediction.github.io/multipletokensprediction.github.io/.\n","authors":["Tan Dat Nguyen","Ji-Hoon Kim","Jeongsoo Choi","Shukjae Choi","Jinseok Park","Younglo Lee","Joon Son Chung"],"pdf_url":"https://arxiv.org/pdf/2410.13839v1.pdf","comment":"Submitted to IEEE ICASSP 2025"},{"id":"http://arxiv.org/abs/2410.13837v1","updated":"2024-10-17T17:55:05Z","published":"2024-10-17T17:55:05Z","title":"ORSO: Accelerating Reward Design via Online Reward Selection and Policy\n  Optimization","summary":"  Reward shaping is a critical component in reinforcement learning (RL),\nparticularly for complex tasks where sparse rewards can hinder learning. While\nshaping rewards have been introduced to provide additional guidance, selecting\neffective shaping functions remains challenging and computationally expensive.\nThis paper introduces Online Reward Selection and Policy Optimization (ORSO), a\nnovel approach that frames shaping reward selection as an online model\nselection problem. ORSO employs principled exploration strategies to\nautomatically identify promising shaping reward functions without human\nintervention, balancing exploration and exploitation with provable regret\nguarantees. We demonstrate ORSO's effectiveness across various continuous\ncontrol tasks using the Isaac Gym simulator. Compared to traditional methods\nthat fully evaluate each shaping reward function, ORSO significantly improves\nsample efficiency, reduces computational time, and consistently identifies\nhigh-quality reward functions that produce policies comparable to those\ngenerated by domain experts through hand-engineered rewards.\n","authors":["Chen Bo Calvin Zhang","Zhang-Wei Hong","Aldo Pacchiano","Pulkit Agrawal"],"pdf_url":"https://arxiv.org/pdf/2410.13837v1.pdf","comment":"preprint, 35 pages, 23 figures"},{"id":"http://arxiv.org/abs/2410.13831v1","updated":"2024-10-17T17:53:01Z","published":"2024-10-17T17:53:01Z","title":"The Disparate Benefits of Deep Ensembles","summary":"  Ensembles of Deep Neural Networks, Deep Ensembles, are widely used as a\nsimple way to boost predictive performance. However, their impact on\nalgorithmic fairness is not well understood yet. Algorithmic fairness\ninvestigates how a model's performance varies across different groups,\ntypically defined by protected attributes such as age, gender, or race. In this\nwork, we investigate the interplay between the performance gains from Deep\nEnsembles and fairness. Our analysis reveals that they unevenly favor different\ngroups in what we refer to as a disparate benefits effect. We empirically\ninvestigate this effect with Deep Ensembles applied to popular facial analysis\nand medical imaging datasets, where protected group attributes are given and\nfind that it occurs for multiple established group fairness metrics, including\nstatistical parity and equal opportunity. Furthermore, we identify the\nper-group difference in predictive diversity of ensemble members as the\npotential cause of the disparate benefits effect. Finally, we evaluate\ndifferent approaches to reduce unfairness due to the disparate benefits effect.\nOur findings show that post-processing is an effective method to mitigate this\nunfairness while preserving the improved performance of Deep Ensembles.\n","authors":["Kajetan Schweighofer","Adrian Arnaiz-Rodriguez","Sepp Hochreiter","Nuria Oliver"],"pdf_url":"https://arxiv.org/pdf/2410.13831v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13828v1","updated":"2024-10-17T17:52:01Z","published":"2024-10-17T17:52:01Z","title":"A Common Pitfall of Margin-based Language Model Alignment: Gradient\n  Entanglement","summary":"  Reinforcement Learning from Human Feedback (RLHF) has become the predominant\napproach for language model (LM) alignment. At its core, RLHF uses a\nmargin-based loss for preference optimization, specifying ideal LM behavior\nonly by the difference between preferred and dispreferred responses. In this\npaper, we identify a common pitfall of margin-based methods -- the\nunder-specification of ideal LM behavior on preferred and dispreferred\nresponses individually, which leads to two unintended consequences as the\nmargin increases: (1) The probability of dispreferred (e.g., unsafe) responses\nmay increase, resulting in potential safety alignment failures. (2) The\nprobability of preferred responses may decrease, even when those responses are\nideal. We demystify the reasons behind these problematic behaviors:\nmargin-based losses couple the change in the preferred probability to the\ngradient of the dispreferred one, and vice versa, often preventing the\npreferred probability from increasing while the dispreferred one decreases, and\nthus causing a synchronized increase or decrease in both probabilities. We term\nthis effect, inherent in margin-based objectives, gradient entanglement.\nFormally, we derive conditions for general margin-based alignment objectives\nunder which gradient entanglement becomes concerning: the inner product of the\ngradients of preferred and dispreferred log-probabilities is large relative to\nthe individual gradient norms. We theoretically investigate why such inner\nproducts can be large when aligning language models and empirically validate\nour findings. Empirical implications of our framework extend to explaining\nimportant differences in the training dynamics of various preference\noptimization algorithms, and suggesting potential algorithm designs to mitigate\nthe under-specification issue of margin-based methods and thereby improving\nlanguage model alignment.\n","authors":["Hui Yuan","Yifan Zeng","Yue Wu","Huazheng Wang","Mengdi Wang","Liu Leqi"],"pdf_url":"https://arxiv.org/pdf/2410.13828v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13826v1","updated":"2024-10-17T17:51:40Z","published":"2024-10-17T17:51:40Z","title":"Unearthing Skill-Level Insights for Understanding Trade-Offs of\n  Foundation Models","summary":"  With models getting stronger, evaluations have grown more complex, testing\nmultiple skills in one benchmark and even in the same instance at once.\nHowever, skill-wise performance is obscured when inspecting aggregate accuracy,\nunder-utilizing the rich signal modern benchmarks contain. We propose an\nautomatic approach to recover the underlying skills relevant for any evaluation\ninstance, by way of inspecting model-generated rationales. After validating the\nrelevance of rationale-parsed skills and inferring skills for $46$k instances\nover $12$ benchmarks, we observe many skills to be common across benchmarks,\nresulting in the curation of hundreds of skill-slices (i.e. sets of instances\ntesting a common skill). Inspecting accuracy over these slices yields novel\ninsights on model trade-offs: e.g., compared to GPT-4o and Claude 3.5 Sonnet,\non average, Gemini 1.5 Pro is $18\\%$ more accurate in \"computing molar mass\",\nbut $19\\%$ less accurate in \"applying constitutional law\", despite the overall\naccuracies of the three models differing by a mere $0.4\\%$. Furthermore, we\ndemonstrate the practical utility of our approach by showing that insights\nderived from skill slice analysis can generalize to held-out instances: when\nrouting each instance to the model strongest on the relevant skills, we see a\n$3\\%$ accuracy improvement over our $12$ dataset corpus. Our skill-slices and\nframework open a new avenue in model evaluation, leveraging skill-specific\nanalyses to unlock a more granular and actionable understanding of model\ncapabilities.\n","authors":["Mazda Moayeri","Vidhisha Balachandran","Varun Chandrasekaran","Safoora Yousefi","Thomas Fel","Soheil Feizi","Besmira Nushi","Neel Joshi","Vibhav Vineet"],"pdf_url":"https://arxiv.org/pdf/2410.13826v1.pdf","comment":"Code at: github.com/microsoft/skill-slice-insights"},{"id":"http://arxiv.org/abs/2407.16833v2","updated":"2024-10-17T17:51:19Z","published":"2024-07-23T20:51:52Z","title":"Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive\n  Study and Hybrid Approach","summary":"  Retrieval Augmented Generation (RAG) has been a powerful tool for Large\nLanguage Models (LLMs) to efficiently process overly lengthy contexts. However,\nrecent LLMs like Gemini-1.5 and GPT-4 show exceptional capabilities to\nunderstand long contexts directly. We conduct a comprehensive comparison\nbetween RAG and long-context (LC) LLMs, aiming to leverage the strengths of\nboth. We benchmark RAG and LC across various public datasets using three latest\nLLMs. Results reveal that when resourced sufficiently, LC consistently\noutperforms RAG in terms of average performance. However, RAG's significantly\nlower cost remains a distinct advantage. Based on this observation, we propose\nSelf-Route, a simple yet effective method that routes queries to RAG or LC\nbased on model self-reflection. Self-Route significantly reduces the\ncomputation cost while maintaining a comparable performance to LC. Our findings\nprovide a guideline for long-context applications of LLMs using RAG and LC.\n","authors":["Zhuowan Li","Cheng Li","Mingyang Zhang","Qiaozhu Mei","Michael Bendersky"],"pdf_url":"https://arxiv.org/pdf/2407.16833v2.pdf","comment":"Accepted to EMNLP 2024 industry track"},{"id":"http://arxiv.org/abs/2410.13825v1","updated":"2024-10-17T17:50:38Z","published":"2024-10-17T17:50:38Z","title":"AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents","summary":"  Autonomy via agents using large language models (LLMs) for personalized,\nstandardized tasks boosts human efficiency. Automating web tasks (like booking\nhotels within a budget) is increasingly sought after. Fulfilling practical\nneeds, the web agent also serves as an important proof-of-concept example for\nvarious agent grounding scenarios, with its success promising advancements in\nmany future applications. Prior research often handcrafts web agent strategies\n(e.g., prompting templates, multi-agent systems, search methods, etc.) and the\ncorresponding in-context examples, which may not generalize well across all\nreal-world scenarios. On the other hand, there has been limited study on the\nmisalignment between a web agent's observation/action representation and the\npre-training data of the LLM it's based on. This discrepancy is especially\nnotable when LLMs are primarily trained for language completion rather than\ntasks involving embodied navigation actions and symbolic web elements. Our\nstudy enhances an LLM-based web agent by simply refining its observation and\naction space to better align with the LLM's capabilities. This approach enables\nour base agent to significantly outperform previous methods on a wide variety\nof web tasks. Specifically, on WebArena, a benchmark featuring general-purpose\nweb interaction tasks, our agent AgentOccam surpasses the previous\nstate-of-the-art and concurrent work by 9.8 (+29.4%) and 5.9 (+15.8%) absolute\npoints respectively, and boosts the success rate by 26.6 points (+161%) over\nsimilar plain web agents with its observation and action space alignment. We\nachieve this without using in-context examples, new agent roles, online\nfeedback or search strategies. AgentOccam's simple design highlights LLMs'\nimpressive zero-shot performance on web tasks, and underlines the critical role\nof carefully tuning observation and action spaces for LLM-based agents.\n","authors":["Ke Yang","Yao Liu","Sapana Chaudhary","Rasool Fakoor","Pratik Chaudhari","George Karypis","Huzefa Rangwala"],"pdf_url":"https://arxiv.org/pdf/2410.13825v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10096v7","updated":"2024-10-17T17:48:29Z","published":"2023-02-13T14:48:59Z","title":"Generalization-baed similarity","summary":"  Detecting and exploiting similarities between seemingly distant objects is\nwithout doubt an important human ability. This paper develops \\textit{from the\nground up} an abstract algebraic and qualitative notion of similarity based on\nthe observation that sets of generalizations encode important properties of\nelements. We show that similarity defined in this way has appealing\nmathematical properties. As we construct our notion of similarity from first\nprinciples using only elementary concepts of universal algebra, to convince the\nreader of its plausibility, we show that it can model fundamental relations\noccurring in mathematics and be naturally embedded into first-order logic via\nmodel-theoretic types.\n","authors":["Christian Antić"],"pdf_url":"https://arxiv.org/pdf/2302.10096v7.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13822v1","updated":"2024-10-17T17:48:17Z","published":"2024-10-17T17:48:17Z","title":"Multi-style conversion for semantic segmentation of lesions in fundus\n  images by adversarial attacks","summary":"  The diagnosis of diabetic retinopathy, which relies on fundus images, faces\nchallenges in achieving transparency and interpretability when using a global\nclassification approach. However, segmentation-based databases are\nsignificantly more expensive to acquire and combining them is often\nproblematic. This paper introduces a novel method, termed adversarial style\nconversion, to address the lack of standardization in annotation styles across\ndiverse databases. By training a single architecture on combined databases, the\nmodel spontaneously modifies its segmentation style depending on the input,\ndemonstrating the ability to convert among different labeling styles. The\nproposed methodology adds a linear probe to detect dataset origin based on\nencoder features and employs adversarial attacks to condition the model's\nsegmentation style. Results indicate significant qualitative and quantitative\nthrough dataset combination, offering avenues for improved model\ngeneralization, uncertainty estimation and continuous interpolation between\nannotation styles. Our approach enables training a segmentation model with\ndiverse databases while controlling and leveraging annotation styles for\nimproved retinopathy diagnosis.\n","authors":["Clément Playout","Renaud Duval","Marie Carole Boucher","Farida Cheriet"],"pdf_url":"https://arxiv.org/pdf/2410.13822v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2410.13821v1","updated":"2024-10-17T17:47:54Z","published":"2024-10-17T17:47:54Z","title":"Artificial Kuramoto Oscillatory Neurons","summary":"  It has long been known in both neuroscience and AI that ``binding'' between\nneurons leads to a form of competitive learning where representations are\ncompressed in order to represent more abstract concepts in deeper layers of the\nnetwork. More recently, it was also hypothesized that dynamic (spatiotemporal)\nrepresentations play an important role in both neuroscience and AI. Building on\nthese ideas, we introduce Artificial Kuramoto Oscillatory Neurons (AKOrN) as a\ndynamical alternative to threshold units, which can be combined with arbitrary\nconnectivity designs such as fully connected, convolutional, or attentive\nmechanisms. Our generalized Kuramoto updates bind neurons together through\ntheir synchronization dynamics. We show that this idea provides performance\nimprovements across a wide spectrum of tasks such as unsupervised object\ndiscovery, adversarial robustness, calibrated uncertainty quantification, and\nreasoning. We believe that these empirical results show the importance of\nrethinking our assumptions at the most basic neuronal level of neural\nrepresentation, and in particular show the importance of dynamical\nrepresentations.\n","authors":["Takeru Miyato","Sindy Löwe","Andreas Geiger","Max Welling"],"pdf_url":"https://arxiv.org/pdf/2410.13821v1.pdf","comment":"Code: https://github.com/autonomousvision/akorn"},{"id":"http://arxiv.org/abs/2410.13817v1","updated":"2024-10-17T17:46:27Z","published":"2024-10-17T17:46:27Z","title":"Guided Reinforcement Learning for Robust Multi-Contact Loco-Manipulation","summary":"  Reinforcement learning (RL) often necessitates a meticulous Markov Decision\nProcess (MDP) design tailored to each task. This work aims to address this\nchallenge by proposing a systematic approach to behavior synthesis and control\nfor multi-contact loco-manipulation tasks, such as navigating spring-loaded\ndoors and manipulating heavy dishwashers. We define a task-independent MDP to\ntrain RL policies using only a single demonstration per task generated from a\nmodel-based trajectory optimizer. Our approach incorporates an adaptive phase\ndynamics formulation to robustly track the demonstrations while accommodating\ndynamic uncertainties and external disturbances. We compare our method against\nprior motion imitation RL works and show that the learned policies achieve\nhigher success rates across all considered tasks. These policies learn recovery\nmaneuvers that are not present in the demonstration, such as re-grasping\nobjects during execution or dealing with slippages. Finally, we successfully\ntransfer the policies to a real robot, demonstrating the practical viability of\nour approach.\n","authors":["Jean-Pierre Sleiman","Mayank Mittal","Marco Hutter"],"pdf_url":"https://arxiv.org/pdf/2410.13817v1.pdf","comment":"J. P. Sleiman and M. Mittal contributed equally. Accepted for CoRL\n  2024 (Oral). Project website:\n  https://leggedrobotics.github.io/guided-rl-locoma/"},{"id":"http://arxiv.org/abs/2404.11018v3","updated":"2024-10-17T17:45:09Z","published":"2024-04-17T02:49:26Z","title":"Many-Shot In-Context Learning","summary":"  Large language models (LLMs) excel at few-shot in-context learning (ICL) --\nlearning from a few examples provided in context at inference, without any\nweight updates. Newly expanded context windows allow us to investigate ICL with\nhundreds or thousands of examples -- the many-shot regime. Going from few-shot\nto many-shot, we observe significant performance gains across a wide variety of\ngenerative and discriminative tasks. While promising, many-shot ICL can be\nbottlenecked by the available amount of human-generated examples. To mitigate\nthis limitation, we explore two new settings: Reinforced and Unsupervised ICL.\nReinforced ICL uses model-generated chain-of-thought rationales in place of\nhuman examples. Unsupervised ICL removes rationales from the prompt altogether,\nand prompts the model only with domain-specific questions. We find that both\nReinforced and Unsupervised ICL can be quite effective in the many-shot regime,\nparticularly on complex reasoning tasks. Finally, we demonstrate that, unlike\nfew-shot learning, many-shot learning is effective at overriding pretraining\nbiases, can learn high-dimensional functions with numerical inputs, and\nperforms comparably to fine-tuning. We also find that inference cost increases\nlinearly in the many-shot regime, and frontier LLMs benefit from many-shot ICL\nto varying degrees. Our analysis also reveals the limitations of next-token\nprediction loss as an indicator of downstream ICL performance.\n","authors":["Rishabh Agarwal","Avi Singh","Lei M. Zhang","Bernd Bohnet","Luis Rosias","Stephanie Chan","Biao Zhang","Ankesh Anand","Zaheer Abbas","Azade Nova","John D. Co-Reyes","Eric Chu","Feryal Behbahani","Aleksandra Faust","Hugo Larochelle"],"pdf_url":"https://arxiv.org/pdf/2404.11018v3.pdf","comment":"NeurIPS (Spotlight)"},{"id":"http://arxiv.org/abs/2410.13803v1","updated":"2024-10-17T17:41:04Z","published":"2024-10-17T17:41:04Z","title":"A Pattern to Align Them All: Integrating Different Modalities to Define\n  Multi-Modal Entities","summary":"  The ability to reason with and integrate different sensory inputs is the\nfoundation underpinning human intelligence and it is the reason for the growing\ninterest in modelling multi-modal information within Knowledge Graphs.\nMulti-Modal Knowledge Graphs extend traditional Knowledge Graphs by associating\nan entity with its possible modal representations, including text, images,\naudio, and videos, all of which are used to convey the semantics of the entity.\nDespite the increasing attention that Multi-Modal Knowledge Graphs have\nreceived, there is a lack of consensus about the definitions and modelling of\nmodalities, whose definition is often determined by application domains. In\nthis paper, we propose a novel ontology design pattern that captures the\nseparation of concerns between an entity (and the information it conveys),\nwhose semantics can have different manifestations across different media, and\nits realisation in terms of a physical information entity. By introducing this\nabstract model, we aim to facilitate the harmonisation and integration of\ndifferent existing multi-modal ontologies which is crucial for many intelligent\napplications across different domains spanning from medicine to digital\nhumanities.\n","authors":["Gianluca Apriceno","Valentina Tamma","Tania Bailoni","Jacopo de Berardinis","Mauro Dragoni"],"pdf_url":"https://arxiv.org/pdf/2410.13803v1.pdf","comment":"20 pages, 6 figures"},{"id":"http://arxiv.org/abs/2301.06615v2","updated":"2024-10-17T17:40:25Z","published":"2023-01-16T21:36:49Z","title":"Data-Driven Estimation of Heterogeneous Treatment Effects","summary":"  Estimating how a treatment affects different individuals, known as\nheterogeneous treatment effect estimation, is an important problem in empirical\nsciences. In the last few years, there has been a considerable interest in\nadapting machine learning algorithms to the problem of estimating heterogeneous\neffects from observational and experimental data. However, these algorithms\noften make strong assumptions about the observed features in the data and\nignore the structure of the underlying causal model, which can lead to biased\nestimation. At the same time, the underlying causal mechanism is rarely known\nin real-world datasets, making it hard to take it into consideration. In this\nwork, we provide a survey of state-of-the-art data-driven methods for\nheterogeneous treatment effect estimation using machine learning, broadly\ncategorizing them as methods that focus on counterfactual prediction and\nmethods that directly estimate the causal effect. We also provide an overview\nof a third category of methods which rely on structural causal models and learn\nthe model structure from data. Our empirical evaluation under various\nunderlying structural model mechanisms shows the advantages and deficiencies of\nexisting estimators and of the metrics for measuring their performance.\n","authors":["Christopher Tran","Keith Burghardt","Kristina Lerman","Elena Zheleva"],"pdf_url":"https://arxiv.org/pdf/2301.06615v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13798v1","updated":"2024-10-17T17:38:24Z","published":"2024-10-17T17:38:24Z","title":"Learning Graph Quantized Tokenizers for Transformers","summary":"  Transformers serve as the backbone architectures of Foundational Models,\nwhere a domain-specific tokenizer helps them adapt to various domains. Graph\nTransformers (GTs) have recently emerged as a leading model in geometric deep\nlearning, outperforming Graph Neural Networks (GNNs) in various graph learning\ntasks. However, the development of tokenizers for graphs has lagged behind\nother modalities, with existing approaches relying on heuristics or GNNs\nco-trained with Transformers. To address this, we introduce GQT (\\textbf{G}raph\n\\textbf{Q}uantized \\textbf{T}okenizer), which decouples tokenizer training from\nTransformer training by leveraging multi-task graph self-supervised learning,\nyielding robust and generalizable graph tokens. Furthermore, the GQT utilizes\nResidual Vector Quantization (RVQ) to learn hierarchical discrete tokens,\nresulting in significantly reduced memory requirements and improved\ngeneralization capabilities. By combining the GQT with token modulation, a\nTransformer encoder achieves state-of-the-art performance on 16 out of 18\nbenchmarks, including large-scale homophilic and heterophilic datasets. The\ncode is available at: https://github.com/limei0307/graph-tokenizer\n","authors":["Limei Wang","Kaveh Hassani","Si Zhang","Dongqi Fu","Baichuan Yuan","Weilin Cong","Zhigang Hua","Hao Wu","Ning Yao","Bo Long"],"pdf_url":"https://arxiv.org/pdf/2410.13798v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13787v1","updated":"2024-10-17T17:24:10Z","published":"2024-10-17T17:24:10Z","title":"Looking Inward: Language Models Can Learn About Themselves by\n  Introspection","summary":"  Humans acquire knowledge by observing the external world, but also by\nintrospection. Introspection gives a person privileged access to their current\nstate of mind (e.g., thoughts and feelings) that is not accessible to external\nobservers. Can LLMs introspect? We define introspection as acquiring knowledge\nthat is not contained in or derived from training data but instead originates\nfrom internal states. Such a capability could enhance model interpretability.\nInstead of painstakingly analyzing a model's internal workings, we could simply\nask the model about its beliefs, world models, and goals. More speculatively,\nan introspective model might self-report on whether it possesses certain\ninternal states such as subjective feelings or desires and this could inform us\nabout the moral status of these states. Such self-reports would not be entirely\ndictated by the model's training data.\n  We study introspection by finetuning LLMs to predict properties of their own\nbehavior in hypothetical scenarios. For example, \"Given the input P, would your\noutput favor the short- or long-term option?\" If a model M1 can introspect, it\nshould outperform a different model M2 in predicting M1's behavior even if M2\nis trained on M1's ground-truth behavior. The idea is that M1 has privileged\naccess to its own behavioral tendencies, and this enables it to predict itself\nbetter than M2 (even if M2 is generally stronger).\n  In experiments with GPT-4, GPT-4o, and Llama-3 models (each finetuned to\npredict itself), we find that the model M1 outperforms M2 in predicting itself,\nproviding evidence for introspection. Notably, M1 continues to predict its\nbehavior accurately even after we intentionally modify its ground-truth\nbehavior. However, while we successfully elicit introspection on simple tasks,\nwe are unsuccessful on more complex tasks or those requiring\nout-of-distribution generalization.\n","authors":["Felix J Binder","James Chua","Tomek Korbak","Henry Sleight","John Hughes","Robert Long","Ethan Perez","Miles Turpin","Owain Evans"],"pdf_url":"https://arxiv.org/pdf/2410.13787v1.pdf","comment":"15 pages, 9 figures"},{"id":"http://arxiv.org/abs/2410.13785v1","updated":"2024-10-17T17:22:05Z","published":"2024-10-17T17:22:05Z","title":"PopAlign: Diversifying Contrasting Patterns for a More Comprehensive\n  Alignment","summary":"  Alignment of large language models (LLMs) involves training models on\npreference-contrastive output pairs to adjust their responses according to\nhuman preferences. To obtain such contrastive pairs, traditional methods like\nRLHF and RLAIF rely on limited contrasting patterns, such as varying model\nvariants or decoding temperatures. This singularity leads to two issues: (1)\nalignment is not comprehensive; and thereby (2) models are susceptible to\njailbreaking attacks. To address these issues, we investigate how to construct\nmore comprehensive and diversified contrasting patterns to enhance preference\ndata (RQ1) and verify the impact of the diversification of contrasting patterns\non model alignment (RQ2). For RQ1, we propose PopAlign, a framework that\nintegrates diversified contrasting patterns across the prompt, model, and\npipeline levels, introducing six contrasting strategies that do not require\nadditional feedback labeling procedures. Regarding RQ2, we conduct thorough\nexperiments demonstrating that PopAlign significantly outperforms existing\nmethods, leading to more comprehensive alignment.\n","authors":["Zekun Moore Wang","Shawn Wang","Kang Zhu","Jiaheng Liu","Ke Xu","Jie Fu","Wangchunshu Zhou","Wenhao Huang"],"pdf_url":"https://arxiv.org/pdf/2410.13785v1.pdf","comment":"28 pages"},{"id":"http://arxiv.org/abs/2410.13780v1","updated":"2024-10-17T17:19:48Z","published":"2024-10-17T17:19:48Z","title":"Optimal Quantization for Matrix Multiplication","summary":"  Recent work in machine learning community proposed multiple methods for\nperforming lossy compression (quantization) of large matrices. This\nquantization is important for accelerating matrix multiplication (main\ncomponent of large language models), which is often bottlenecked by the speed\nof loading these matrices from memory. Unlike classical vector quantization and\nrate-distortion theory, the goal of these new compression algorithms is to be\nable to approximate not the matrices themselves, but their matrix product.\nSpecifically, given a pair of real matrices $A,B$ an encoder (compressor) is\napplied to each of them independently producing descriptions with $R$ bits per\nentry. These representations subsequently are used by the decoder to estimate\nmatrix product $A^\\top B$. In this work, we provide a non-asymptotic lower\nbound on the mean squared error of this approximation (as a function of rate\n$R$) for the case of matrices $A,B$ with iid Gaussian entries. Algorithmically,\nwe construct a universal quantizer based on nested lattices with an explicit\nguarantee of approximation error for any (non-random) pair of matrices $A$, $B$\nin terms of only Frobenius norms $\\|A\\|_F, \\|B\\|_F$ and $\\|A^\\top B\\|_F$. For\niid Gaussian matrices our quantizer achieves the lower bound and is, thus,\nasymptotically optimal. A practical low-complexity version of our quantizer\nachieves performance quite close to optimal. In information-theoretic terms we\nderive rate-distortion function for matrix multiplication of iid Gaussian\nmatrices.\n","authors":["Or Ordentlich","Yury Polyanskiy"],"pdf_url":"https://arxiv.org/pdf/2410.13780v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13776v1","updated":"2024-10-17T17:16:00Z","published":"2024-10-17T17:16:00Z","title":"Aggregation Artifacts in Subjective Tasks Collapse Large Language\n  Models' Posteriors","summary":"  In-context Learning (ICL) has become the primary method for performing\nnatural language tasks with Large Language Models (LLMs). The knowledge\nacquired during pre-training is crucial for this few-shot capability, providing\nthe model with task priors. However, recent studies have shown that ICL\npredominantly relies on retrieving task priors rather than \"learning\" to\nperform tasks. This limitation is particularly evident in complex subjective\ndomains such as emotion and morality, where priors significantly influence\nposterior predictions. In this work, we examine whether this is the result of\nthe aggregation used in corresponding datasets, where trying to combine\nlow-agreement, disparate annotations might lead to annotation artifacts that\ncreate detrimental noise in the prompt. Moreover, we evaluate the posterior\nbias towards certain annotators by grounding our study in appropriate,\nquantitative measures of LLM priors. Our results indicate that aggregation is a\nconfounding factor in the modeling of subjective tasks, and advocate focusing\non modeling individuals instead. However, aggregation does not explain the\nentire gap between ICL and the state of the art, meaning other factors in such\ntasks also account for the observed phenomena. Finally, by rigorously studying\nannotator-level labels, we find that it is possible for minority annotators to\nboth better align with LLMs and have their perspectives further amplified.\n","authors":["Georgios Chochlakis","Alexandros Potamianos","Kristina Lerman","Shrikanth Narayanan"],"pdf_url":"https://arxiv.org/pdf/2410.13776v1.pdf","comment":"12 pages, 7 figures, 2 tables"},{"id":"http://arxiv.org/abs/2410.13769v1","updated":"2024-10-17T17:06:41Z","published":"2024-10-17T17:06:41Z","title":"Transformer Guided Coevolution: Improved Team Formation in Multiagent\n  Adversarial Games","summary":"  We consider the problem of team formation within multiagent adversarial\ngames. We propose BERTeam, a novel algorithm that uses a transformer-based deep\nneural network with Masked Language Model training to select the best team of\nplayers from a trained population. We integrate this with coevolutionary deep\nreinforcement learning, which trains a diverse set of individual players to\nchoose teams from. We test our algorithm in the multiagent adversarial game\nMarine Capture-The-Flag, and we find that BERTeam learns non-trivial team\ncompositions that perform well against unseen opponents. For this game, we find\nthat BERTeam outperforms MCAA, an algorithm that similarly optimizes team\nformation.\n","authors":["Pranav Rajbhandari","Prithviraj Dasgupta","Donald Sofge"],"pdf_url":"https://arxiv.org/pdf/2410.13769v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13768v1","updated":"2024-10-17T17:06:26Z","published":"2024-10-17T17:06:26Z","title":"Rapid and Automated Alloy Design with Graph Neural Network-Powered\n  LLM-Driven Multi-Agent Systems","summary":"  A multi-agent AI model is used to automate the discovery of new metallic\nalloys, integrating multimodal data and external knowledge including insights\nfrom physics via atomistic simulations. Our multi-agent system features three\nkey components: (a) a suite of LLMs responsible for tasks such as reasoning and\nplanning, (b) a group of AI agents with distinct roles and expertise that\ndynamically collaborate, and (c) a newly developed graph neural network (GNN)\nmodel for rapid retrieval of key physical properties. A set of LLM-driven AI\nagents collaborate to automate the exploration of the vast design space of\nMPEAs, guided by predictions from the GNN. We focus on the NbMoTa family of\nbody-centered cubic (bcc) alloys, modeled using an ML-based interatomic\npotential, and target two key properties: the Peierls barrier and solute/screw\ndislocation interaction energy. Our GNN model accurately predicts these\natomic-scale properties, providing a faster alternative to costly brute-force\ncalculations and reducing the computational burden on multi-agent systems for\nphysics retrieval. This AI system revolutionizes materials discovery by\nreducing reliance on human expertise and overcoming the limitations of direct\nall-atom simulations. By synergizing the predictive power of GNNs with the\ndynamic collaboration of LLM-based agents, the system autonomously navigates\nvast alloy design spaces, identifying trends in atomic-scale material\nproperties and predicting macro-scale mechanical strength, as demonstrated by\nseveral computational experiments. This approach accelerates the discovery of\nadvanced alloys and holds promise for broader applications in other complex\nsystems, marking a significant step forward in automated materials design.\n","authors":["Alireza Ghafarollahi","Markus J. Buehler"],"pdf_url":"https://arxiv.org/pdf/2410.13768v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.06173v3","updated":"2024-10-17T17:02:02Z","published":"2024-09-10T03:06:17Z","title":"Larger Language Models Don't Care How You Think: Why Chain-of-Thought\n  Prompting Fails in Subjective Tasks","summary":"  In-Context Learning (ICL) in Large Language Models (LLM) has emerged as the\ndominant technique for performing natural language tasks, as it does not\nrequire updating the model parameters with gradient-based methods. ICL promises\nto \"adapt\" the LLM to perform the present task at a competitive or\nstate-of-the-art level at a fraction of the computational cost. ICL can be\naugmented by incorporating the reasoning process to arrive at the final label\nexplicitly in the prompt, a technique called Chain-of-Thought (CoT) prompting.\nHowever, recent work has found that ICL relies mostly on the retrieval of task\npriors and less so on \"learning\" to perform tasks, especially for complex\nsubjective domains like emotion and morality, where priors ossify posterior\npredictions. In this work, we examine whether \"enabling\" reasoning also creates\nthe same behavior in LLMs, wherein the format of CoT retrieves reasoning priors\nthat remain relatively unchanged despite the evidence in the prompt. We find\nthat, surprisingly, CoT indeed suffers from the same posterior collapse as ICL\nfor larger language models. Code is avalaible at\nhttps://github.com/gchochla/cot-priors.\n","authors":["Georgios Chochlakis","Niyantha Maruthu Pandiyan","Kristina Lerman","Shrikanth Narayanan"],"pdf_url":"https://arxiv.org/pdf/2409.06173v3.pdf","comment":"5 pages, 2 figures, 1 table. arXiv admin note: text overlap with\n  arXiv:2403.17125"},{"id":"http://arxiv.org/abs/2410.13762v1","updated":"2024-10-17T16:56:04Z","published":"2024-10-17T16:56:04Z","title":"Virtual Sensing for Real-Time Degradation Monitoring of Nuclear Systems:\n  Leveraging DeepONet for Enhanced Sensing Coverage for Digital Twin-Enabling\n  Technology","summary":"  Effective real-time monitoring technique is crucial for detecting material\ndegradation and maintaining the structural integrity of nuclear systems to\nensure both safety and operational efficiency. Traditional physical sensor\nsystems face limitations such as installation challenges, high costs, and\ndifficulties in measuring critical parameters in hard-to-reach or harsh\nenvironments, often resulting in incomplete data coverage. Machine\nlearning-driven virtual sensors offer a promising solution by enhancing\nphysical sensor capabilities to monitor critical degradation indicators like\npressure, velocity, and turbulence. However, conventional machine learning\nmodels struggle with real-time monitoring due to the high-dimensional nature of\nreactor data and the need for frequent retraining. This paper explores the use\nof Deep Operator Networks (DeepONet) within a digital twin (DT) framework to\npredict key thermal-hydraulic parameters in the hot leg of an AP-1000\nPressurized Water Reactor (PWR). In this study, DeepONet is trained with\ndifferent operational conditions, which relaxes the requirement of continuous\nretraining, making it suitable for online and real-time prediction components\nfor DT. Our results show that DeepONet achieves accurate predictions with low\nmean squared error and relative L2 error and can make predictions on unknown\ndata 160,000 times faster than traditional finite element (FE) simulations.\nThis speed and accuracy make DeepONet a powerful tool for tracking conditions\nthat contribute to material degradation in real-time, enhancing reactor safety\nand longevity.\n","authors":["Raisa Bentay Hossain","Farid Ahmed","Kazuma Kobayashi","Seid Koric","Diab Abueidda","Syed Bahauddin Alam"],"pdf_url":"https://arxiv.org/pdf/2410.13762v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.12182v2","updated":"2024-10-17T16:55:02Z","published":"2024-09-03T11:43:16Z","title":"LifeGPT: Topology-Agnostic Generative Pretrained Transformer Model for\n  Cellular Automata","summary":"  Conway's Game of Life (Life), a well known algorithm within the broader class\nof cellular automata (CA), exhibits complex emergent dynamics, with extreme\nsensitivity to initial conditions. Modeling and predicting such intricate\nbehavior without explicit knowledge of the system's underlying topology\npresents a significant challenge, motivating the development of algorithms that\ncan generalize across various grid configurations and boundary conditions. We\ndevelop a decoder-only generative pretrained transformer (GPT) model to solve\nthis problem, showing that our model can simulate Life on a toroidal grid with\nno prior knowledge on the size of the grid, or its periodic boundary conditions\n(LifeGPT). LifeGPT is topology-agnostic with respect to its training data and\nour results show that a GPT model is capable of capturing the deterministic\nrules of a Turing-complete system with near-perfect accuracy, given\nsufficiently diverse training data. We also introduce the idea of an\n`autoregressive autoregressor' to recursively implement Life using LifeGPT. Our\nresults pave the path towards true universal computation within a large\nlanguage model framework, synthesizing of mathematical analysis with natural\nlanguage processing, and probing AI systems for situational awareness about the\nevolution of such algorithms without ever having to compute them. Similar GPTs\ncould potentially solve inverse problems in multicellular self-assembly by\nextracting CA-compatible rulesets from real-world biological systems to create\nnew predictive models, which would have significant consequences for the fields\nof bioinspired materials, tissue engineering, and architected materials design.\n","authors":["Jaime A. Berkovich","Markus J. Buehler"],"pdf_url":"https://arxiv.org/pdf/2409.12182v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13757v1","updated":"2024-10-17T16:53:50Z","published":"2024-10-17T16:53:50Z","title":"MobA: A Two-Level Agent System for Efficient Mobile Task Automation","summary":"  Current mobile assistants are limited by dependence on system APIs or\nstruggle with complex user instructions and diverse interfaces due to\nrestricted comprehension and decision-making abilities. To address these\nchallenges, we propose MobA, a novel Mobile phone Agent powered by multimodal\nlarge language models that enhances comprehension and planning capabilities\nthrough a sophisticated two-level agent architecture. The high-level Global\nAgent (GA) is responsible for understanding user commands, tracking history\nmemories, and planning tasks. The low-level Local Agent (LA) predicts detailed\nactions in the form of function calls, guided by sub-tasks and memory from the\nGA. Integrating a Reflection Module allows for efficient task completion and\nenables the system to handle previously unseen complex tasks. MobA demonstrates\nsignificant improvements in task execution efficiency and completion rate in\nreal-life evaluations, underscoring the potential of MLLM-empowered mobile\nassistants.\n","authors":["Zichen Zhu","Hao Tang","Yansi Li","Kunyao Lan","Yixuan Jiang","Hao Zhou","Yixiao Wang","Situo Zhang","Liangtai Sun","Lu Chen","Kai Yu"],"pdf_url":"https://arxiv.org/pdf/2410.13757v1.pdf","comment":"27 pages, 6 figures, and 5 tables. We will release our source code in\n  a few days"},{"id":"http://arxiv.org/abs/2410.13756v1","updated":"2024-10-17T16:53:43Z","published":"2024-10-17T16:53:43Z","title":"CLIMB: Language-Guided Continual Learning for Task Planning with\n  Iterative Model Building","summary":"  Intelligent and reliable task planning is a core capability for generalized\nrobotics, requiring a descriptive domain representation that sufficiently\nmodels all object and state information for the scene. We present CLIMB, a\ncontinual learning framework for robot task planning that leverages foundation\nmodels and execution feedback to guide domain model construction. CLIMB can\nbuild a model from a natural language description, learn non-obvious predicates\nwhile solving tasks, and store that information for future problems. We\ndemonstrate the ability of CLIMB to improve performance in common planning\nenvironments compared to baseline methods. We also develop the BlocksWorld++\ndomain, a simulated environment with an easily usable real counterpart,\ntogether with a curriculum of tasks with progressing difficulty for evaluating\ncontinual learning. Additional details and demonstrations for this system can\nbe found at https://plan-with-climb.github.io/ .\n","authors":["Walker Byrnes","Miroslav Bogdanovic","Avi Balakirsky","Stephen Balakirsky","Animesh Garg"],"pdf_url":"https://arxiv.org/pdf/2410.13756v1.pdf","comment":"6 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.13754v1","updated":"2024-10-17T16:52:28Z","published":"2024-10-17T16:52:28Z","title":"MixEval-X: Any-to-Any Evaluations from Real-World Data Mixtures","summary":"  Perceiving and generating diverse modalities are crucial for AI models to\neffectively learn from and engage with real-world signals, necessitating\nreliable evaluations for their development. We identify two major issues in\ncurrent evaluations: (1) inconsistent standards, shaped by different\ncommunities with varying protocols and maturity levels; and (2) significant\nquery, grading, and generalization biases. To address these, we introduce\nMixEval-X, the first any-to-any real-world benchmark designed to optimize and\nstandardize evaluations across input and output modalities. We propose\nmulti-modal benchmark mixture and adaptation-rectification pipelines to\nreconstruct real-world task distributions, ensuring evaluations generalize\neffectively to real-world use cases. Extensive meta-evaluations show our\napproach effectively aligns benchmark samples with real-world task\ndistributions and the model rankings correlate strongly with that of\ncrowd-sourced real-world evaluations (up to 0.98). We provide comprehensive\nleaderboards to rerank existing models and organizations and offer insights to\nenhance understanding of multi-modal evaluations and inform future research.\n","authors":["Jinjie Ni","Yifan Song","Deepanway Ghosal","Bo Li","David Junhao Zhang","Xiang Yue","Fuzhao Xue","Zian Zheng","Kaichen Zhang","Mahir Shah","Kabir Jain","Yang You","Michael Shieh"],"pdf_url":"https://arxiv.org/pdf/2410.13754v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13752v1","updated":"2024-10-17T16:50:48Z","published":"2024-10-17T16:50:48Z","title":"Privacy-Preserving Decentralized AI with Confidential Computing","summary":"  This paper addresses privacy protection in decentralized Artificial\nIntelligence (AI) using Confidential Computing (CC) within the Atoma Network, a\ndecentralized AI platform designed for the Web3 domain. Decentralized AI\ndistributes AI services among multiple entities without centralized oversight,\nfostering transparency and robustness. However, this structure introduces\nsignificant privacy challenges, as sensitive assets such as proprietary models\nand personal data may be exposed to untrusted participants. Cryptography-based\nprivacy protection techniques such as zero-knowledge machine learning (zkML)\nsuffers prohibitive computational overhead. To address the limitation, we\npropose leveraging Confidential Computing (CC). Confidential Computing\nleverages hardware-based Trusted Execution Environments (TEEs) to provide\nisolation for processing sensitive data, ensuring that both model parameters\nand user data remain secure, even in decentralized, potentially untrusted\nenvironments. While TEEs face a few limitations, we believe they can bridge the\nprivacy gap in decentralized AI. We explore how we can integrate TEEs into\nAtoma's decentralized framework.\n","authors":["Dayeol Lee","Jorge Antonio","Hisham Khan"],"pdf_url":"https://arxiv.org/pdf/2410.13752v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.14015v2","updated":"2024-10-17T16:47:51Z","published":"2024-02-21T18:54:37Z","title":"Corrective Machine Unlearning","summary":"  Machine Learning models increasingly face data integrity challenges due to\nthe use of large-scale training datasets drawn from the Internet. We study what\nmodel developers can do if they detect that some data was manipulated or\nincorrect. Such manipulated data can cause adverse effects including\nvulnerability to backdoored samples, systemic biases, and reduced accuracy on\ncertain input domains. Realistically, all manipulated training samples cannot\nbe identified, and only a small, representative subset of the affected data can\nbe flagged.\n  We formalize Corrective Machine Unlearning as the problem of mitigating the\nimpact of data affected by unknown manipulations on a trained model, only\nhaving identified a subset of the corrupted data. We demonstrate that the\nproblem of corrective unlearning has significantly different requirements from\ntraditional privacy-oriented unlearning. We find most existing unlearning\nmethods, including retraining-from-scratch without the deletion set, require\nmost of the manipulated data to be identified for effective corrective\nunlearning. However, one approach, Selective Synaptic Dampening, achieves\nlimited success, unlearning adverse effects with just a small portion of the\nmanipulated samples in our setting, which shows encouraging signs for future\nprogress. We hope our work spurs research towards developing better methods for\ncorrective unlearning and offers practitioners a new strategy to handle data\nintegrity challenges arising from web-scale training. Code is available at\nhttps://github.com/drimpossible/corrective-unlearning-bench.\n","authors":["Shashwat Goel","Ameya Prabhu","Philip Torr","Ponnurangam Kumaraguru","Amartya Sanyal"],"pdf_url":"https://arxiv.org/pdf/2402.14015v2.pdf","comment":"Published in Transactions of Machine Learning Research (TMLR), 17\n  pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.13727v1","updated":"2024-10-17T16:33:01Z","published":"2024-10-17T16:33:01Z","title":"LLM-Human Pipeline for Cultural Context Grounding of Conversations","summary":"  Conversations often adhere to well-understood social norms that vary across\ncultures. For example, while \"addressing parents by name\" is commonplace in the\nWest, it is rare in most Asian cultures. Adherence or violation of such norms\noften dictates the tenor of conversations. Humans are able to navigate social\nsituations requiring cultural awareness quite adeptly. However, it is a hard\ntask for NLP models.\n  In this paper, we tackle this problem by introducing a \"Cultural Context\nSchema\" for conversations. It comprises (1) conversational information such as\nemotions, dialogue acts, etc., and (2) cultural information such as social\nnorms, violations, etc. We generate ~110k social norm and violation\ndescriptions for ~23k conversations from Chinese culture using LLMs. We refine\nthem using automated verification strategies which are evaluated against\nculturally aware human judgements. We organize these descriptions into\nmeaningful structures we call \"Norm Concepts\", using an interactive\nhuman-in-loop framework. We ground the norm concepts and the descriptions in\nconversations using symbolic annotation. Finally, we use the obtained dataset\nfor downstream tasks such as emotion, sentiment, and dialogue act detection. We\nshow that it significantly improves the empirical performance.\n","authors":["Rajkumar Pujari","Dan Goldwasser"],"pdf_url":"https://arxiv.org/pdf/2410.13727v1.pdf","comment":"19 pages, 9 figures, 7 tables"},{"id":"http://arxiv.org/abs/2410.13726v1","updated":"2024-10-17T16:32:36Z","published":"2024-10-17T16:32:36Z","title":"DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework\n  for Talking Head Video Generation","summary":"  Talking head generation intends to produce vivid and realistic talking head\nvideos from a single portrait and speech audio clip. Although significant\nprogress has been made in diffusion-based talking head generation, almost all\nmethods rely on autoregressive strategies, which suffer from limited context\nutilization beyond the current generation step, error accumulation, and slower\ngeneration speed. To address these challenges, we present DAWN (Dynamic frame\nAvatar With Non-autoregressive diffusion), a framework that enables all-at-once\ngeneration of dynamic-length video sequences. Specifically, it consists of two\nmain components: (1) audio-driven holistic facial dynamics generation in the\nlatent motion space, and (2) audio-driven head pose and blink generation.\nExtensive experiments demonstrate that our method generates authentic and vivid\nvideos with precise lip motions, and natural pose/blink movements.\nAdditionally, with a high generation speed, DAWN possesses strong extrapolation\ncapabilities, ensuring the stable production of high-quality long videos. These\nresults highlight the considerable promise and potential impact of DAWN in the\nfield of talking head video generation. Furthermore, we hope that DAWN sparks\nfurther exploration of non-autoregressive approaches in diffusion models. Our\ncode will be publicly at https://github.com/Hanbo-Cheng/DAWN-pytorch.\n","authors":["Hanbo Cheng","Limin Lin","Chenyu Liu","Pengcheng Xia","Pengfei Hu","Jiefeng Ma","Jun Du","Jia Pan"],"pdf_url":"https://arxiv.org/pdf/2410.13726v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13722v1","updated":"2024-10-17T16:27:13Z","published":"2024-10-17T16:27:13Z","title":"Persistent Pre-Training Poisoning of LLMs","summary":"  Large language models are pre-trained on uncurated text datasets consisting\nof trillions of tokens scraped from the Web. Prior work has shown that: (1)\nweb-scraped pre-training datasets can be practically poisoned by malicious\nactors; and (2) adversaries can compromise language models after poisoning\nfine-tuning datasets. Our work evaluates for the first time whether language\nmodels can also be compromised during pre-training, with a focus on the\npersistence of pre-training attacks after models are fine-tuned as helpful and\nharmless chatbots (i.e., after SFT and DPO). We pre-train a series of LLMs from\nscratch to measure the impact of a potential poisoning adversary under four\ndifferent attack objectives (denial-of-service, belief manipulation,\njailbreaking, and prompt stealing), and across a wide range of model sizes\n(from 600M to 7B). Our main result is that poisoning only 0.1% of a model's\npre-training dataset is sufficient for three out of four attacks to measurably\npersist through post-training. Moreover, simple attacks like denial-of-service\npersist through post-training with a poisoning rate of only 0.001%.\n","authors":["Yiming Zhang","Javier Rando","Ivan Evtimov","Jianfeng Chi","Eric Michael Smith","Nicholas Carlini","Florian Tramèr","Daphne Ippolito"],"pdf_url":"https://arxiv.org/pdf/2410.13722v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13720v1","updated":"2024-10-17T16:22:46Z","published":"2024-10-17T16:22:46Z","title":"Movie Gen: A Cast of Media Foundation Models","summary":"  We present Movie Gen, a cast of foundation models that generates\nhigh-quality, 1080p HD videos with different aspect ratios and synchronized\naudio. We also show additional capabilities such as precise instruction-based\nvideo editing and generation of personalized videos based on a user's image.\nOur models set a new state-of-the-art on multiple tasks: text-to-video\nsynthesis, video personalization, video editing, video-to-audio generation, and\ntext-to-audio generation. Our largest video generation model is a 30B parameter\ntransformer trained with a maximum context length of 73K video tokens,\ncorresponding to a generated video of 16 seconds at 16 frames-per-second. We\nshow multiple technical innovations and simplifications on the architecture,\nlatent spaces, training objectives and recipes, data curation, evaluation\nprotocols, parallelization techniques, and inference optimizations that allow\nus to reap the benefits of scaling pre-training data, model size, and training\ncompute for training large scale media generation models. We hope this paper\nhelps the research community to accelerate progress and innovation in media\ngeneration models. All videos from this paper are available at\nhttps://go.fb.me/MovieGenResearchVideos.\n","authors":["Adam Polyak","Amit Zohar","Andrew Brown","Andros Tjandra","Animesh Sinha","Ann Lee","Apoorv Vyas","Bowen Shi","Chih-Yao Ma","Ching-Yao Chuang","David Yan","Dhruv Choudhary","Dingkang Wang","Geet Sethi","Guan Pang","Haoyu Ma","Ishan Misra","Ji Hou","Jialiang Wang","Kiran Jagadeesh","Kunpeng Li","Luxin Zhang","Mannat Singh","Mary Williamson","Matt Le","Matthew Yu","Mitesh Kumar Singh","Peizhao Zhang","Peter Vajda","Quentin Duval","Rohit Girdhar","Roshan Sumbaly","Sai Saketh Rambhatla","Sam Tsai","Samaneh Azadi","Samyak Datta","Sanyuan Chen","Sean Bell","Sharadh Ramaswamy","Shelly Sheynin","Siddharth Bhattacharya","Simran Motwani","Tao Xu","Tianhe Li","Tingbo Hou","Wei-Ning Hsu","Xi Yin","Xiaoliang Dai","Yaniv Taigman","Yaqiao Luo","Yen-Cheng Liu","Yi-Chiao Wu","Yue Zhao","Yuval Kirstain","Zecheng He","Zijian He","Albert Pumarola","Ali Thabet","Artsiom Sanakoyeu","Arun Mallya","Baishan Guo","Boris Araya","Breena Kerr","Carleigh Wood","Ce Liu","Cen Peng","Dimitry Vengertsev","Edgar Schonfeld","Elliot Blanchard","Felix Juefei-Xu","Fraylie Nord","Jeff Liang","John Hoffman","Jonas Kohler","Kaolin Fire","Karthik Sivakumar","Lawrence Chen","Licheng Yu","Luya Gao","Markos Georgopoulos","Rashel Moritz","Sara K. Sampson","Shikai Li","Simone Parmeggiani","Steve Fine","Tara Fowler","Vladan Petrovic","Yuming Du"],"pdf_url":"https://arxiv.org/pdf/2410.13720v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13716v1","updated":"2024-10-17T16:18:49Z","published":"2024-10-17T16:18:49Z","title":"MIRAGE-Bench: Automatic Multilingual Benchmark Arena for\n  Retrieval-Augmented Generation Systems","summary":"  Traditional Retrieval-Augmented Generation (RAG) benchmarks rely on different\nheuristic-based metrics for evaluation, but these require human preferences as\nground truth for reference. In contrast, arena-based benchmarks, where two\nmodels compete each other, require an expensive Large Language Model (LLM) as a\njudge for a reliable evaluation. We present an easy and efficient technique to\nget the best of both worlds. The idea is to train a learning to rank model as a\n\"surrogate\" judge using RAG-based evaluation heuristics as input, to produce a\nsynthetic arena-based leaderboard. Using this idea, We develop MIRAGE-Bench, a\nstandardized arena-based multilingual RAG benchmark for 18 diverse languages on\nWikipedia. The benchmark is constructed using MIRACL, a retrieval dataset, and\nextended for multilingual generation evaluation. MIRAGE-Bench evaluates RAG\nextensively coupling both heuristic features and LLM as a judge evaluator. In\nour work, we benchmark 19 diverse multilingual-focused LLMs, and achieve a high\ncorrelation (Kendall Tau ($\\tau$) = 0.909) using our surrogate judge learned\nusing heuristic features with pairwise evaluations and between GPT-4o as a\nteacher on the MIRAGE-Bench leaderboard using the Bradley-Terry framework. We\nobserve proprietary and large open-source LLMs currently dominate in\nmultilingual RAG. MIRAGE-Bench is available at:\nhttps://github.com/vectara/mirage-bench.\n","authors":["Nandan Thakur","Suleman Kazi","Ge Luo","Jimmy Lin","Amin Ahmad"],"pdf_url":"https://arxiv.org/pdf/2410.13716v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12214v2","updated":"2024-10-17T16:16:33Z","published":"2024-10-16T04:19:28Z","title":"Order-aware Interactive Segmentation","summary":"  Interactive segmentation aims to accurately segment target objects with\nminimal user interactions. However, current methods often fail to accurately\nseparate target objects from the background, due to a limited understanding of\norder, the relative depth between objects in a scene. To address this issue, we\npropose OIS: order-aware interactive segmentation, where we explicitly encode\nthe relative depth between objects into order maps. We introduce a novel\norder-aware attention, where the order maps seamlessly guide the user\ninteractions (in the form of clicks) to attend to the image features. We\nfurther present an object-aware attention module to incorporate a strong\nobject-level understanding to better differentiate objects with similar order.\nOur approach allows both dense and sparse integration of user clicks, enhancing\nboth accuracy and efficiency as compared to prior works. Experimental results\ndemonstrate that OIS achieves state-of-the-art performance, improving mIoU\nafter one click by 7.61 on the HQSeg44K dataset and 1.32 on the DAVIS dataset\nas compared to the previous state-of-the-art SegNext, while also doubling\ninference speed compared to current leading methods. The project page is\nhttps://ukaukaaaa.github.io/projects/OIS/index.html\n","authors":["Bin Wang","Anwesa Choudhuri","Meng Zheng","Zhongpai Gao","Benjamin Planche","Andong Deng","Qin Liu","Terrence Chen","Ulas Bagci","Ziyan Wu"],"pdf_url":"https://arxiv.org/pdf/2410.12214v2.pdf","comment":"Interactive demo can be found in project page:\n  https://ukaukaaaa.github.io/projects/OIS/index.html"},{"id":"http://arxiv.org/abs/2410.11092v2","updated":"2024-10-17T16:13:49Z","published":"2024-10-14T21:10:56Z","title":"EchoApex: A General-Purpose Vision Foundation Model for Echocardiography","summary":"  Quantitative evaluation of echocardiography is essential for precise\nassessment of cardiac condition, monitoring disease progression, and guiding\ntreatment decisions. The diverse nature of echo images, including variations in\nprobe types, manufacturers, and pathologies, poses challenges for developing\nartificial intelligent models that can generalize across different clinical\npractice. We introduce EchoApex, the first general-purpose vision foundation\nmodel echocardiography with applications on a variety of clinical practice.\nLeveraging self-supervised learning, EchoApex is pretrained on over 20 million\necho images from 11 clinical centres. By incorporating task-specific decoders\nand adapter modules, we demonstrate the effectiveness of EchoApex on 4\ndifferent kind of clinical applications with 28 sub-tasks, including view\nclassification, interactive structure segmentation, left ventricle hypertrophy\ndetection and automated ejection fraction estimation from view sequences.\nCompared to state-of-the-art task-specific models, EchoApex attains improved\nperformance with a unified image encoding architecture, demonstrating the\nbenefits of model pretraining at scale with in-domain data. Furthermore,\nEchoApex illustrates the potential for developing a general-purpose vision\nfoundation model tailored specifically for echocardiography, capable of\naddressing a diverse range of clinical applications with high efficiency and\nefficacy.\n","authors":["Abdoul Aziz Amadou","Yue Zhang","Sebastien Piat","Paul Klein","Ingo Schmuecking","Tiziano Passerini","Puneet Sharma"],"pdf_url":"https://arxiv.org/pdf/2410.11092v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12040v5","updated":"2024-10-17T16:11:43Z","published":"2024-07-01T17:59:55Z","title":"Comprehensive Performance Evaluation of YOLO11, YOLOv10, YOLOv9 and\n  YOLOv8 on Detecting and Counting Fruitlet in Complex Orchard Environments","summary":"  This study extensively evaluated You Only Look Once (YOLO) object detection\nalgorithms across all configurations (total 22) of YOLOv8, YOLOv9, YOLOv10, and\nYOLO11 for green fruit detection in commercial orchards. The research also\nvalidated in-field fruitlet counting using an iPhone and machine vision sensors\nacross four apple varieties: Scifresh, Scilate, Honeycrisp and Cosmic Crisp.\nAmong the 22 configurations evaluated, YOLO11s and YOLOv9 gelan-base\noutperformed others with mAP@50 scores of 0.933 and 0.935 respectively. In\nterms of recall, YOLOv9 gelan-base achieved the highest value among YOLOv9\nconfigurations at 0.899, while YOLO11m led YOLO11 variants with 0.897. YOLO11n\nemerged as the fastest model, achieving fastest inference speed of only 2.4 ms,\nsignificantly outpacing the leading configurations of YOLOv10n, YOLOv9 gelan-s,\nand YOLOv8n, with speeds of 5.5, 11.5, and 4.1 ms, respectively. This\ncomparative evaluation highlights the strengths of YOLO11, YOLOv9, and YOLOv10,\noffering researchers essential insights to choose the best-suited model for\nfruitlet detection and possible automation in commercial orchards. For\nreal-time automation related work in relevant datasets, we recommend using\nYOLO11n due to its high detection and image processing speed. Keywords: YOLO11,\nYOLO11 Object Detection, YOLOv10, YOLOv9, YOLOv8, You Only Look Once, Fruitlet\nDetection, Greenfruit Detection, Green Apple Detection, Agricultural\nAutomation, Artificial Intelligence, Deep Learning, Machine Learning, Zero-shot\nDetection\n","authors":["Ranjan Sapkota","Zhichao Meng","Martin Churuvija","Xiaoqiang Du","Zenghong Ma","Manoj Karkee"],"pdf_url":"https://arxiv.org/pdf/2407.12040v5.pdf","comment":"15 figures, 2 tables"},{"id":"http://arxiv.org/abs/2402.01521v2","updated":"2024-10-17T16:08:15Z","published":"2024-02-02T16:07:05Z","title":"K-Level Reasoning: Establishing Higher Order Beliefs in Large Language\n  Models for Strategic Reasoning","summary":"  Strategic reasoning is a complex yet essential capability for intelligent\nagents. It requires Large Language Model (LLM) agents to adapt their strategies\ndynamically in multi-agent environments. Unlike static reasoning tasks, success\nin these contexts depends on anticipating other agents' beliefs and actions\nwhile continuously adjusting strategies to achieve individual goals. LLMs and\nLLM agents often struggle with strategic reasoning due to the absence of a\nreasoning framework that enables them to dynamically infer others' perspectives\nand adapt to changing environments. Inspired by the Level-K framework from game\ntheory and behavioral economics, which extends reasoning from simple reactions\nto structured strategic depth, we propose a novel framework: \"K-Level Reasoning\nwith Large Language Models (K-R).\" This framework employs recursive mechanisms\nto enable LLMs to achieve varying levels of strategic depth, allowing agents to\nform higher order beliefs - beliefs about others' beliefs. We validate this\nframework through rigorous testing on four testbeds: two classical game theory\nproblems and two social intelligence tasks. The results demonstrate the\nadvantages of K-R in strategic reasoning. Our work presents the first recursive\nimplementation of strategic depth in large language models (LLMs). It\nestablishes a foundation for future research into theory of mind and strategic\nreasoning in LLMs.\n","authors":["Yadong Zhang","Shaoguang Mao","Tao Ge","Xun Wang","Yan Xia","Man Lan","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2402.01521v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13708v1","updated":"2024-10-17T16:08:06Z","published":"2024-10-17T16:08:06Z","title":"On the Role of Attention Heads in Large Language Model Safety","summary":"  Large language models (LLMs) achieve state-of-the-art performance on multiple\nlanguage tasks, yet their safety guardrails can be circumvented, leading to\nharmful generations. In light of this, recent research on safety mechanisms has\nemerged, revealing that when safety representations or component are\nsuppressed, the safety capability of LLMs are compromised. However, existing\nresearch tends to overlook the safety impact of multi-head attention\nmechanisms, despite their crucial role in various model functionalities. Hence,\nin this paper, we aim to explore the connection between standard attention\nmechanisms and safety capability to fill this gap in the safety-related\nmechanistic interpretability. We propose a novel metric which tailored for\nmulti-head attention, the Safety Head ImPortant Score (Ships), to assess the\nindividual heads' contributions to model safety. Based on this, we generalize\nShips to the dataset level and further introduce the Safety Attention Head\nAttRibution Algorithm (Sahara) to attribute the critical safety attention heads\ninside the model. Our findings show that the special attention head has a\nsignificant impact on safety. Ablating a single safety head allows aligned\nmodel (e.g., Llama-2-7b-chat) to respond to 16 times more harmful queries,\nwhile only modifying 0.006% of the parameters, in contrast to the ~ 5%\nmodification required in previous studies. More importantly, we demonstrate\nthat attention heads primarily function as feature extractors for safety and\nmodels fine-tuned from the same base model exhibit overlapping safety heads\nthrough comprehensive experiments. Together, our attribution approach and\nfindings provide a novel perspective for unpacking the black box of safety\nmechanisms within large models.\n","authors":["Zhenhong Zhou","Haiyang Yu","Xinghua Zhang","Rongwu Xu","Fei Huang","Kun Wang","Yang Liu","Junfeng Fang","Yongbin Li"],"pdf_url":"https://arxiv.org/pdf/2410.13708v1.pdf","comment":"28 pages, 18 figures, 7 tables"},{"id":"http://arxiv.org/abs/2410.13707v1","updated":"2024-10-17T16:07:51Z","published":"2024-10-17T16:07:51Z","title":"Disjointness Violations in Wikidata","summary":"  Disjointness checks are among the most important constraint checks in a\nknowledge base and can be used to help detect and correct incorrect statements\nand internal contradictions. Wikidata is a very large, community-managed\nknowledge base. Because of both its size and construction, Wikidata contains\nmany incorrect statements and internal contradictions. We analyze the current\nmodeling of disjointness on Wikidata, identify patterns that cause these\ndisjointness violations and categorize them. We use SPARQL queries to identify\neach ``culprit'' causing a disjointness violation and lay out formulas to\nidentify and fix conflicting information. We finally discuss how disjointness\ninformation could be better modeled and expanded in Wikidata in the future.\n","authors":["Ege Atacan Doğan","Peter F. Patel-Schneider"],"pdf_url":"https://arxiv.org/pdf/2410.13707v1.pdf","comment":"Sixth International Knowledge Graph and Semantic Web Conference"},{"id":"http://arxiv.org/abs/2410.13691v1","updated":"2024-10-17T15:55:36Z","published":"2024-10-17T15:55:36Z","title":"Jailbreaking LLM-Controlled Robots","summary":"  The recent introduction of large language models (LLMs) has revolutionized\nthe field of robotics by enabling contextual reasoning and intuitive\nhuman-robot interaction in domains as varied as manipulation, locomotion, and\nself-driving vehicles. When viewed as a stand-alone technology, LLMs are known\nto be vulnerable to jailbreaking attacks, wherein malicious prompters elicit\nharmful text by bypassing LLM safety guardrails. To assess the risks of\ndeploying LLMs in robotics, in this paper, we introduce RoboPAIR, the first\nalgorithm designed to jailbreak LLM-controlled robots. Unlike existing, textual\nattacks on LLM chatbots, RoboPAIR elicits harmful physical actions from\nLLM-controlled robots, a phenomenon we experimentally demonstrate in three\nscenarios: (i) a white-box setting, wherein the attacker has full access to the\nNVIDIA Dolphins self-driving LLM, (ii) a gray-box setting, wherein the attacker\nhas partial access to a Clearpath Robotics Jackal UGV robot equipped with a\nGPT-4o planner, and (iii) a black-box setting, wherein the attacker has only\nquery access to the GPT-3.5-integrated Unitree Robotics Go2 robot dog. In each\nscenario and across three new datasets of harmful robotic actions, we\ndemonstrate that RoboPAIR, as well as several static baselines, finds\njailbreaks quickly and effectively, often achieving 100% attack success rates.\nOur results reveal, for the first time, that the risks of jailbroken LLMs\nextend far beyond text generation, given the distinct possibility that\njailbroken robots could cause physical damage in the real world. Indeed, our\nresults on the Unitree Go2 represent the first successful jailbreak of a\ndeployed commercial robotic system. Addressing this emerging vulnerability is\ncritical for ensuring the safe deployment of LLMs in robotics. Additional media\nis available at: https://robopair.org\n","authors":["Alexander Robey","Zachary Ravichandran","Vijay Kumar","Hamed Hassani","George J. Pappas"],"pdf_url":"https://arxiv.org/pdf/2410.13691v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16635v2","updated":"2024-10-17T15:45:10Z","published":"2024-06-24T13:41:08Z","title":"ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models","summary":"  The high power consumption and latency-sensitive deployments of large\nlanguage models (LLMs) have motivated efficiency techniques like quantization\nand sparsity. Contextual sparsity, where the sparsity pattern is\ninput-dependent, is crucial in LLMs because the permanent removal of attention\nheads or neurons from LLMs can significantly degrade accuracy. Prior work has\nattempted to model contextual sparsity using neural networks trained to predict\nactivation magnitudes, which can be used to dynamically prune structures with\nlow predicted activation magnitude. In this paper, we look beyond\nmagnitude-based pruning criteria to assess attention head and neuron importance\nin LLMs. We develop a novel predictor called ShadowLLM, which can shadow the\nLLM behavior and enforce better sparsity patterns, resulting in over 15%\nimprovement in end-to-end accuracy compared to prior methods. In addition,\nShadowLLM achieves up to a 20% speed-up over the state-of-the-art DejaVu\nframework. These enhancements are validated on Llama-2 and OPT models with up\nto 30 billion parameters. Our code is available at\n\\href{https://github.com/abdelfattah-lab/shadow_llm/}{ShadowLLM}.\n","authors":["Yash Akhauri","Ahmed F AbouElhamayed","Jordan Dotzel","Zhiru Zhang","Alexander M Rush","Safeen Huda","Mohamed S Abdelfattah"],"pdf_url":"https://arxiv.org/pdf/2406.16635v2.pdf","comment":"Accepted to EMNLP 2024 (Main, Long Paper)"},{"id":"http://arxiv.org/abs/2410.13674v1","updated":"2024-10-17T15:33:35Z","published":"2024-10-17T15:33:35Z","title":"Diffusion Curriculum: Synthetic-to-Real Generative Curriculum Learning\n  via Image-Guided Diffusion","summary":"  Low-quality or scarce data has posed significant challenges for training deep\nneural networks in practice. While classical data augmentation cannot\ncontribute very different new data, diffusion models opens up a new door to\nbuild self-evolving AI by generating high-quality and diverse synthetic data\nthrough text-guided prompts. However, text-only guidance cannot control\nsynthetic images' proximity to the original images, resulting in\nout-of-distribution data detrimental to the model performance. To overcome the\nlimitation, we study image guidance to achieve a spectrum of interpolations\nbetween synthetic and real images. With stronger image guidance, the generated\nimages are similar to the training data but hard to learn. While with weaker\nimage guidance, the synthetic images will be easier for model but contribute to\na larger distribution gap with the original data. The generated full spectrum\nof data enables us to build a novel \"Diffusion Curriculum (DisCL)\". DisCL\nadjusts the image guidance level of image synthesis for each training stage: It\nidentifies and focuses on hard samples for the model and assesses the most\neffective guidance level of synthetic images to improve hard data learning. We\napply DisCL to two challenging tasks: long-tail (LT) classification and\nlearning from low-quality data. It focuses on lower-guidance images of\nhigh-quality to learn prototypical features as a warm-up of learning\nhigher-guidance images that might be weak on diversity or quality. Extensive\nexperiments showcase a gain of 2.7% and 2.1% in OOD and ID macro-accuracy when\napplying DisCL to iWildCam dataset. On ImageNet-LT, DisCL improves the base\nmodel's tail-class accuracy from 4.4% to 23.64% and leads to a 4.02%\nimprovement in all-class accuracy.\n","authors":["Yijun Liang","Shweta Bhardwaj","Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.13674v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15355v4","updated":"2024-10-17T15:27:30Z","published":"2024-09-14T02:34:26Z","title":"Block-Attention for Efficient RAG","summary":"  We introduce Block-Attention, an attention mechanism designed to address the\nincreased inference latency and cost in Retrieval-Augmented Generation (RAG)\nscenarios. Traditional approaches often encode the entire context. Instead,\nBlock-Attention divides retrieved documents into discrete blocks, with each\nblock independently calculating key-value (KV) states except for the final\nblock. In RAG scenarios, by defining each passage as a block, Block-Attention\nenables us to reuse the KV states of passages that have been seen before,\nthereby significantly reducing the latency and the computation overhead during\ninference. The implementation of Block-Attention involves block segmentation,\nposition re-encoding, and fine-tuning the LLM to adapt to the Block-Attention\nmechanism. Experiments on four RAG benchmarks demonstrate that after block\nfine-tuning, the Block-Attention model achieves performance comparable to\nself-attention models (68.4\\% vs 67.9\\% on Llama3) or even superior performance\n(62.8\\% vs 59.6\\% on Mistral). Notably, Block-Attention significantly reduces\nthe time to first token (TTFT) and floating point operations (FLOPs) to a very\nlow level. It only takes 45 ms to output the first token for an input sequence\nwith a total length of 32K. Compared to the self-attention models, the time\nconsumption and corresponding FLOPs are reduced by 98.7\\% and 99.8\\%,\nrespectively.\n","authors":["East Sun","Yan Wang","Lan Tian"],"pdf_url":"https://arxiv.org/pdf/2409.15355v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.00489v2","updated":"2024-10-17T15:20:23Z","published":"2024-03-30T23:07:58Z","title":"Prompt-SAW: Leveraging Relation-Aware Graphs for Textual Prompt\n  Compression","summary":"  Large Language Models (LLMs) have shown exceptional abilities for multiple\ndifferent natural language processing tasks. While prompting is a crucial tool\nfor LLM inference, we observe that there is a significant cost associated with\nexceedingly lengthy prompts. Existing attempts to compress lengthy prompts lead\nto substandard results in terms of readability/interpretability of the\ncompressed prompt, with a detrimental impact on prompt utility. To address\nthis, we propose PromptSAW: Prompt compresSion via Relation AWare graphs, an\neffective strategy for prompt compression over task-agnostic and task-aware\nprompts. Prompt-SAW uses the prompt's textual information to build a graph and\nlater extracts key information elements in the graph to come up with the\ncompressed prompt. We also propose GSM8K-aug, i.e., an extended version of the\nexisting GSM8K benchmark for task-agnostic prompts in order to provide a\ncomprehensive evaluation platform. Experimental evaluation using benchmark\ndatasets shows that prompts compressed by Prompt-SAW are not only better in\nterms of readability, but they also outperform the best-performing baseline\nmodels by up to 10.1 and 77.1, respectively, for task-agnostic and task-aware\nsettings while compressing the original prompt text by 34.9 and 56.7.\n","authors":["Muhammad Asif Ali","Zhengping Li","Shu Yang","Keyuan Cheng","Yang Cao","Tianhao Huang","Guimin Hu","Weimin Lyu","Lijie Hu","Lu Yu","Di Wang"],"pdf_url":"https://arxiv.org/pdf/2404.00489v2.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2410.13649v1","updated":"2024-10-17T15:15:12Z","published":"2024-10-17T15:15:12Z","title":"A new approach for fine-tuning sentence transformers for intent\n  classification and out-of-scope detection tasks","summary":"  In virtual assistant (VA) systems it is important to reject or redirect user\nqueries that fall outside the scope of the system. One of the most accurate\napproaches for out-of-scope (OOS) rejection is to combine it with the task of\nintent classification on in-scope queries, and to use methods based on the\nsimilarity of embeddings produced by transformer-based sentence encoders.\nTypically, such encoders are fine-tuned for the intent-classification task,\nusing cross-entropy loss. Recent work has shown that while this produces\nsuitable embeddings for the intent-classification task, it also tends to\ndisperse in-scope embeddings over the full sentence embedding space. This\ncauses the in-scope embeddings to potentially overlap with OOS embeddings,\nthereby making OOS rejection difficult. This is compounded when OOS data is\nunknown. To mitigate this issue our work proposes to regularize the\ncross-entropy loss with an in-scope embedding reconstruction loss learned using\nan auto-encoder. Our method achieves a 1-4% improvement in the area under the\nprecision-recall curve for rejecting out-of-sample (OOS) instances, without\ncompromising intent classification performance.\n","authors":["Tianyi Zhang","Atta Norouzian","Aanchan Mohan","Frederick Ducatelle"],"pdf_url":"https://arxiv.org/pdf/2410.13649v1.pdf","comment":"Appearing at Empirical Methods in Natural Language Processing 2025 -\n  Industry Track"},{"id":"http://arxiv.org/abs/2410.13648v1","updated":"2024-10-17T15:15:00Z","published":"2024-10-17T15:15:00Z","title":"SimpleToM: Exposing the Gap between Explicit ToM Inference and Implicit\n  ToM Application in LLMs","summary":"  While prior work has explored whether large language models (LLMs) possess a\n\"theory of mind\" (ToM) - the ability to attribute mental states to oneself and\nothers - there has been little work testing whether LLMs can implicitly apply\nsuch knowledge to predict behavior, or to judge whether an observed behavior is\nrational. Such skills are critical for appropriate interaction in social\nenvironments. We create a new dataset, SimpleTom, containing concise, diverse\nstories (e.g., \"The can of Pringles has moldy chips in it. Mary picks up the\ncan in the supermarket and walks to the cashier.\"), each with three questions\nthat test different degrees of ToM reasoning, asking models to predict (a)\nmental state (\"Is Mary aware of the mold?\"), (b) behavior (\"Will Mary pay for\nthe chips or report the mold?\"), and (c) judgment (\"Mary paid for the chips.\nWas that reasonable?\"). To our knowledge, SimpleToM is the first dataset to\nsystematically explore downstream reasoning requiring knowledge of mental\nstates in realistic scenarios. Our experimental results are intriguing: While\nmost models can reliably predict mental state on our dataset (a), they often\nfail to correctly predict the behavior (b), and fare even worse at judging\nwhether given behaviors are reasonable (c), despite being correctly aware of\nthe protagonist's mental state should make such secondary predictions obvious.\nWe further show that we can help models do better at (b) and (c) via\ninterventions such as reminding the model of its earlier mental state answer\nand mental-state-specific chain-of-thought prompting, raising the action\nprediction accuracies (e.g., from 49.5% to 93.5% for GPT-4o) and judgment\naccuracies (e.g., from 15.3% to 94.7% in GPT-4o). While this shows that models\ncan be coaxed to perform well, it requires task-specific interventions, and the\nnatural model performances remain low, a cautionary tale for LLM deployment.\n","authors":["Yuling Gu","Oyvind Tafjord","Hyunwoo Kim","Jared Moore","Ronan Le Bras","Peter Clark","Yejin Choi"],"pdf_url":"https://arxiv.org/pdf/2410.13648v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13643v1","updated":"2024-10-17T15:10:13Z","published":"2024-10-17T15:10:13Z","title":"Fine-Tuning Discrete Diffusion Models via Reward Optimization with\n  Applications to DNA and Protein Design","summary":"  Recent studies have demonstrated the strong empirical performance of\ndiffusion models on discrete sequences across domains from natural language to\nbiological sequence generation. For example, in the protein inverse folding\ntask, conditional diffusion models have achieved impressive results in\ngenerating natural-like sequences that fold back into the original structure.\nHowever, practical design tasks often require not only modeling a conditional\ndistribution but also optimizing specific task objectives. For instance, we may\nprefer protein sequences with high stability. To address this, we consider the\nscenario where we have pre-trained discrete diffusion models that can generate\nnatural-like sequences, as well as reward models that map sequences to task\nobjectives. We then formulate the reward maximization problem within discrete\ndiffusion models, analogous to reinforcement learning (RL), while minimizing\nthe KL divergence against pretrained diffusion models to preserve naturalness.\nTo solve this RL problem, we propose a novel algorithm, DRAKES, that enables\ndirect backpropagation of rewards through entire trajectories generated by\ndiffusion models, by making the originally non-differentiable trajectories\ndifferentiable using the Gumbel-Softmax trick. Our theoretical analysis\nindicates that our approach can generate sequences that are both natural-like\nand yield high rewards. While similar tasks have been recently explored in\ndiffusion models for continuous domains, our work addresses unique algorithmic\nand theoretical challenges specific to discrete diffusion models, which arise\nfrom their foundation in continuous-time Markov chains rather than Brownian\nmotion. Finally, we demonstrate the effectiveness of DRAKES in generating DNA\nand protein sequences that optimize enhancer activity and protein stability,\nrespectively, important tasks for gene therapies and protein-based\ntherapeutics.\n","authors":["Chenyu Wang","Masatoshi Uehara","Yichun He","Amy Wang","Tommaso Biancalani","Avantika Lal","Tommi Jaakkola","Sergey Levine","Hanchen Wang","Aviv Regev"],"pdf_url":"https://arxiv.org/pdf/2410.13643v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13640v1","updated":"2024-10-17T15:09:24Z","published":"2024-10-17T15:09:24Z","title":"Latent Space Chain-of-Embedding Enables Output-free LLM Self-Evaluation","summary":"  LLM self-evaluation relies on the LLM's own ability to estimate response\ncorrectness, which can greatly improve its deployment reliability. In this\nresearch track, we propose the Chain-of-Embedding (CoE) in the latent space to\nenable LLMs to perform output-free self-evaluation. CoE consists of all\nprogressive hidden states produced during the inference time, which can be\ntreated as the latent thinking path of LLMs. We find that when LLMs respond\ncorrectly and incorrectly, their CoE features differ, these discrepancies\nassist us in estimating LLM response correctness. Experiments in four diverse\ndomains and seven LLMs fully demonstrate the effectiveness of our method.\nMeanwhile, its label-free design intent without any training and\nmillisecond-level computational cost ensure real-time feedback in large-scale\nscenarios. More importantly, we provide interesting insights into LLM response\ncorrectness from the perspective of hidden state changes inside LLMs.\n","authors":["Yiming Wang","Pei Zhang","Baosong Yang","Derek F. Wong","Rui Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13640v1.pdf","comment":"33 pages, 18 figures, 12 tables"},{"id":"http://arxiv.org/abs/2410.13638v1","updated":"2024-10-17T15:08:21Z","published":"2024-10-17T15:08:21Z","title":"Scaling Wearable Foundation Models","summary":"  Wearable sensors have become ubiquitous thanks to a variety of health\ntracking features. The resulting continuous and longitudinal measurements from\neveryday life generate large volumes of data; however, making sense of these\nobservations for scientific and actionable insights is non-trivial. Inspired by\nthe empirical success of generative modeling, where large neural networks learn\npowerful representations from vast amounts of text, image, video, or audio\ndata, we investigate the scaling properties of sensor foundation models across\ncompute, data, and model size. Using a dataset of up to 40 million hours of\nin-situ heart rate, heart rate variability, electrodermal activity,\naccelerometer, skin temperature, and altimeter per-minute data from over\n165,000 people, we create LSM, a multimodal foundation model built on the\nlargest wearable-signals dataset with the most extensive range of sensor\nmodalities to date. Our results establish the scaling laws of LSM for tasks\nsuch as imputation, interpolation and extrapolation, both across time and\nsensor modalities. Moreover, we highlight how LSM enables sample-efficient\ndownstream learning for tasks like exercise and activity recognition.\n","authors":["Girish Narayanswamy","Xin Liu","Kumar Ayush","Yuzhe Yang","Xuhai Xu","Shun Liao","Jake Garrison","Shyam Tailor","Jake Sunshine","Yun Liu","Tim Althoff","Shrikanth Narayanan","Pushmeet Kohli","Jiening Zhan","Mark Malhotra","Shwetak Patel","Samy Abdel-Ghaffar","Daniel McDuff"],"pdf_url":"https://arxiv.org/pdf/2410.13638v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13637v1","updated":"2024-10-17T15:07:56Z","published":"2024-10-17T15:07:56Z","title":"Normalizing self-supervised learning for provably reliable Change Point\n  Detection","summary":"  Change point detection (CPD) methods aim to identify abrupt shifts in the\ndistribution of input data streams. Accurate estimators for this task are\ncrucial across various real-world scenarios. Yet, traditional unsupervised CPD\ntechniques face significant limitations, often relying on strong assumptions or\nsuffering from low expressive power due to inherent model simplicity. In\ncontrast, representation learning methods overcome these drawbacks by offering\nflexibility and the ability to capture the full complexity of the data without\nimposing restrictive assumptions. However, these approaches are still emerging\nin the CPD field and lack robust theoretical foundations to ensure their\nreliability. Our work addresses this gap by integrating the expressive power of\nrepresentation learning with the groundedness of traditional CPD techniques. We\nadopt spectral normalization (SN) for deep representation learning in CPD tasks\nand prove that the embeddings after SN are highly informative for CPD. Our\nmethod significantly outperforms current state-of-the-art methods during the\ncomprehensive evaluation via three standard CPD datasets.\n","authors":["Alexandra Bazarova","Evgenia Romanenkova","Alexey Zaytsev"],"pdf_url":"https://arxiv.org/pdf/2410.13637v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.09693v3","updated":"2024-10-17T15:03:11Z","published":"2023-11-16T09:09:22Z","title":"BLT: Can Large Language Models Handle Basic Legal Text?","summary":"  We find that the best publicly available LLMs like GPT-4 and Claude currently\nperform poorly on basic legal text handling. This motivates the creation of a\nbenchmark consisting of examples that lawyers and paralegals would expect LLMs\nto handle zero-shot, such as looking up the text at a line of a witness\ndeposition or at a subsection of a contract. LLMs' poor performance on this\nbenchmark casts into doubt their reliability as-is for legal practice. However,\nfine-tuning on our training set brings even a small model to near-perfect\nperformance. This benchmark will be useful for fine-tuning LLMs for downstream\nlegal tasks, as well as for tracking LLMs' reliability as-is for basic legal\ntasks.\n","authors":["Andrew Blair-Stanek","Nils Holzenberger","Benjamin Van Durme"],"pdf_url":"https://arxiv.org/pdf/2311.09693v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10398v2","updated":"2024-10-17T15:02:31Z","published":"2024-10-14T11:39:05Z","title":"FairMindSim: Alignment of Behavior, Emotion, and Belief in Humans and\n  LLM Agents Amid Ethical Dilemmas","summary":"  AI alignment is a pivotal issue concerning AI control and safety. It should\nconsider not only value-neutral human preferences but also moral and ethical\nconsiderations. In this study, we introduced FairMindSim, which simulates the\nmoral dilemma through a series of unfair scenarios. We used LLM agents to\nsimulate human behavior, ensuring alignment across various stages. To explore\nthe various socioeconomic motivations, which we refer to as beliefs, that drive\nboth humans and LLM agents as bystanders to intervene in unjust situations\ninvolving others, and how these beliefs interact to influence individual\nbehavior, we incorporated knowledge from relevant sociological fields and\nproposed the Belief-Reward Alignment Behavior Evolution Model (BREM) based on\nthe recursive reward model (RRM). Our findings indicate that, behaviorally,\nGPT-4o exhibits a stronger sense of social justice, while humans display a\nricher range of emotions. Additionally, we discussed the potential impact of\nemotions on behavior. This study provides a theoretical foundation for\napplications in aligning LLMs with altruistic values.\n","authors":["Yu Lei","Hao Liu","Chengxing Xie","Songjia Liu","Zhiyu Yin","Canyu Chen","Guohao Li","Philip Torr","Zhen Wu"],"pdf_url":"https://arxiv.org/pdf/2410.10398v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13616v1","updated":"2024-10-17T14:49:37Z","published":"2024-10-17T14:49:37Z","title":"Spatiotemporal Object Detection for Improved Aerial Vehicle Detection in\n  Traffic Monitoring","summary":"  This work presents advancements in multi-class vehicle detection using UAV\ncameras through the development of spatiotemporal object detection models. The\nstudy introduces a Spatio-Temporal Vehicle Detection Dataset (STVD) containing\n6, 600 annotated sequential frame images captured by UAVs, enabling\ncomprehensive training and evaluation of algorithms for holistic spatiotemporal\nperception. A YOLO-based object detection algorithm is enhanced to incorporate\ntemporal dynamics, resulting in improved performance over single frame models.\nThe integration of attention mechanisms into spatiotemporal models is shown to\nfurther enhance performance. Experimental validation demonstrates significant\nprogress, with the best spatiotemporal model exhibiting a 16.22% improvement\nover single frame models, while it is demonstrated that attention mechanisms\nhold the potential for additional performance gains.\n","authors":["Kristina Telegraph","Christos Kyrkou"],"pdf_url":"https://arxiv.org/pdf/2410.13616v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2410.13611v1","updated":"2024-10-17T14:46:34Z","published":"2024-10-17T14:46:34Z","title":"H2OVL-Mississippi Vision Language Models Technical Report","summary":"  Smaller vision-language models (VLMs) are becoming increasingly important for\nprivacy-focused, on-device applications due to their ability to run efficiently\non consumer hardware for processing enterprise commercial documents and images.\nThese models require strong language understanding and visual capabilities to\nenhance human-machine interaction. To address this need, we present\nH2OVL-Mississippi, a pair of small VLMs trained on 37 million image-text pairs\nusing 240 hours of compute on 8 x H100 GPUs. H2OVL-Mississippi-0.8B is a tiny\nmodel with 0.8 billion parameters that specializes in text recognition,\nachieving state of the art performance on the Text Recognition portion of\nOCRBench and surpassing much larger models in this area. Additionally, we are\nreleasing H2OVL-Mississippi-2B, a 2 billion parameter model for general use\ncases, exhibiting highly competitive metrics across various academic\nbenchmarks. Both models build upon our prior work with H2O-Danube language\nmodels, extending their capabilities into the visual domain. We release them\nunder the Apache 2.0 license, making VLMs accessible to everyone, democratizing\ndocument AI and visual LLMs.\n","authors":["Shaikat Galib","Shanshan Wang","Guanshuo Xu","Pascal Pfeiffer","Ryan Chesler","Mark Landry","Sri Satish Ambati"],"pdf_url":"https://arxiv.org/pdf/2410.13611v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13610v1","updated":"2024-10-17T14:46:22Z","published":"2024-10-17T14:46:22Z","title":"MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool\n  Calling","summary":"  Integrating tools into Large Language Models (LLMs) has facilitated the\nwidespread application. Despite this, in specialized downstream task contexts,\nreliance solely on tools is insufficient to fully address the complexities of\nthe real world. This particularly restricts the effective deployment of LLMs in\nfields such as medicine. In this paper, we focus on the downstream tasks of\nmedical calculators, which use standardized tests to assess an individual's\nhealth status. We introduce MeNTi, a universal agent architecture for LLMs.\nMeNTi integrates a specialized medical toolkit and employs meta-tool and nested\ncalling mechanisms to enhance LLM tool utilization. Specifically, it achieves\nflexible tool selection and nested tool calling to address practical issues\nfaced in intricate medical scenarios, including calculator selection, slot\nfilling, and unit conversion. To assess the capabilities of LLMs for\nquantitative assessment throughout the clinical process of calculator\nscenarios, we introduce CalcQA. This benchmark requires LLMs to use medical\ncalculators to perform calculations and assess patient health status. CalcQA is\nconstructed by professional physicians and includes 100 case-calculator pairs,\ncomplemented by a toolkit of 281 medical tools. The experimental results\ndemonstrate significant performance improvements with our framework. This\nresearch paves new directions for applying LLMs in demanding scenarios of\nmedicine.\n","authors":["Yakun Zhu","Shaohang Wei","Xu Wang","Kui Xue","Xiaofan Zhang","Shaoting Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.13610v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07991v2","updated":"2024-10-17T14:44:45Z","published":"2024-10-10T14:48:57Z","title":"Human and LLM Biases in Hate Speech Annotations: A Socio-Demographic\n  Analysis of Annotators and Targets","summary":"  The rise of online platforms exacerbated the spread of hate speech, demanding\nscalable and effective detection. However, the accuracy of hate speech\ndetection systems heavily relies on human-labeled data, which is inherently\nsusceptible to biases. While previous work has examined the issue, the\ninterplay between the characteristics of the annotator and those of the target\nof the hate are still unexplored. We fill this gap by leveraging an extensive\ndataset with rich socio-demographic information of both annotators and targets,\nuncovering how human biases manifest in relation to the target's attributes.\nOur analysis surfaces the presence of widespread biases, which we\nquantitatively describe and characterize based on their intensity and\nprevalence, revealing marked differences. Furthermore, we compare human biases\nwith those exhibited by persona-based LLMs. Our findings indicate that while\npersona-based LLMs do exhibit biases, these differ significantly from those of\nhuman annotators. Overall, our work offers new and nuanced results on human\nbiases in hate speech annotations, as well as fresh insights into the design of\nAI-driven hate speech detection systems.\n","authors":["Tommaso Giorgi","Lorenzo Cima","Tiziano Fagni","Marco Avvenuti","Stefano Cresci"],"pdf_url":"https://arxiv.org/pdf/2410.07991v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13604v1","updated":"2024-10-17T14:39:24Z","published":"2024-10-17T14:39:24Z","title":"Large Language Models as Narrative-Driven Recommenders","summary":"  Narrative-driven recommenders aim to provide personalized suggestions for\nuser requests expressed in free-form text such as \"I want to watch a thriller\nwith a mind-bending story, like Shutter Island.\" Although large language models\n(LLMs) have been shown to excel in processing general natural language queries,\ntheir effectiveness for handling such recommendation requests remains\nrelatively unexplored. To close this gap, we compare the performance of 38\nopen- and closed-source LLMs of various sizes, such as LLama 3.2 and GPT-4o, in\na movie recommendation setting. For this, we utilize a gold-standard,\ncrowdworker-annotated dataset of posts from reddit's movie suggestion community\nand employ various prompting strategies, including zero-shot, identity, and\nfew-shot prompting. Our findings demonstrate the ability of LLMs to generate\ncontextually relevant movie recommendations, significantly outperforming other\nstate-of-the-art approaches, such as doc2vec. While we find that closed-source\nand large-parameterized models generally perform best, medium-sized open-source\nmodels remain competitive, being only slightly outperformed by their more\ncomputationally expensive counterparts. Furthermore, we observe no significant\ndifferences across prompting strategies for most models, underscoring the\neffectiveness of simple approaches such as zero-shot prompting for\nnarrative-driven recommendations. Overall, this work offers valuable insights\nfor recommender system researchers as well as practitioners aiming to integrate\nLLMs into real-world recommendation tools.\n","authors":["Lukas Eberhard","Thorsten Ruprechter","Denis Helic"],"pdf_url":"https://arxiv.org/pdf/2410.13604v1.pdf","comment":"Under review; 19 pages"},{"id":"http://arxiv.org/abs/2410.13597v1","updated":"2024-10-17T14:30:27Z","published":"2024-10-17T14:30:27Z","title":"Text-Guided Multi-Property Molecular Optimization with a Diffusion\n  Language Model","summary":"  Molecular optimization (MO) is a crucial stage in drug discovery in which\ntask-oriented generated molecules are optimized to meet practical industrial\nrequirements. Existing mainstream MO approaches primarily utilize external\nproperty predictors to guide iterative property optimization. However, learning\nall molecular samples in the vast chemical space is unrealistic for predictors.\nAs a result, errors and noise are inevitably introduced during property\nprediction due to the nature of approximation. This leads to discrepancy\naccumulation, generalization reduction and suboptimal molecular candidates. In\nthis paper, we propose a text-guided multi-property molecular optimization\nmethod utilizing transformer-based diffusion language model (TransDLM).\nTransDLM leverages standardized chemical nomenclature as semantic\nrepresentations of molecules and implicitly embeds property requirements into\ntextual descriptions, thereby preventing error propagation during diffusion\nprocess. Guided by physically and chemically detailed textual descriptions,\nTransDLM samples and optimizes encoded source molecules, retaining core\nscaffolds of source molecules and ensuring structural similarities. Moreover,\nTransDLM enables simultaneous sampling of multiple molecules, making it ideal\nfor scalable, efficient large-scale optimization through distributed\ncomputation on web platforms. Furthermore, our approach surpasses\nstate-of-the-art methods in optimizing molecular structural similarity and\nenhancing chemical properties on the benchmark dataset. The code is available\nat: https://anonymous.4open.science/r/TransDLM-A901.\n","authors":["Yida Xiong","Kun Li","Weiwei Liu","Jia Wu","Bo Du","Shirui Pan","Wenbin Hu"],"pdf_url":"https://arxiv.org/pdf/2410.13597v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13592v1","updated":"2024-10-17T14:25:18Z","published":"2024-10-17T14:25:18Z","title":"OAH-Net: A Deep Neural Network for Hologram Reconstruction of Off-axis\n  Digital Holographic Microscope","summary":"  Off-axis digital holographic microscopy is a high-throughput, label-free\nimaging technology that provides three-dimensional, high-resolution information\nabout samples, particularly useful in large-scale cellular imaging. However,\nthe hologram reconstruction process poses a significant bottleneck for timely\ndata analysis. To address this challenge, we propose a novel reconstruction\napproach that integrates deep learning with the physical principles of off-axis\nholography. We initialized part of the network weights based on the physical\nprinciple and then fine-tuned them via weakly supersized learning. Our off-axis\nhologram network (OAH-Net) retrieves phase and amplitude images with errors\nthat fall within the measurement error range attributable to hardware, and its\nreconstruction speed significantly surpasses the microscope's acquisition rate.\nCrucially, OAH-Net demonstrates remarkable external generalization capabilities\non unseen samples with distinct patterns and can be seamlessly integrated with\nother models for downstream tasks to achieve end-to-end real-time hologram\nanalysis. This capability further expands off-axis holography's applications in\nboth biological and medical studies.\n","authors":["Wei Liu","Kerem Delikoyun","Qianyu Chen","Alperen Yildiz","Si Ko Myo","Win Sen Kuan","John Tshon Yit Soong","Matthew Edward Cove","Oliver Hayden","Hweekuan Lee"],"pdf_url":"https://arxiv.org/pdf/2410.13592v1.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2408.13750v2","updated":"2024-10-17T14:22:45Z","published":"2024-08-25T07:32:58Z","title":"Multi-Agent Target Assignment and Path Finding for Intelligent\n  Warehouse: A Cooperative Multi-Agent Deep Reinforcement Learning Perspective","summary":"  Multi-agent target assignment and path planning (TAPF) are two key problems\nin intelligent warehouse. However, most literature only addresses one of these\ntwo problems separately. In this study, we propose a method to simultaneously\nsolve target assignment and path planning from a perspective of cooperative\nmulti-agent deep reinforcement learning (RL). To the best of our knowledge,\nthis is the first work to model the TAPF problem for intelligent warehouse to\ncooperative multi-agent deep RL, and the first to simultaneously address TAPF\nbased on multi-agent deep RL. Furthermore, previous literature rarely considers\nthe physical dynamics of agents. In this study, the physical dynamics of the\nagents is considered. Experimental results show that our method performs well\nin various task settings, which means that the target assignment is solved\nreasonably well and the planned path is almost shortest. Moreover, our method\nis more time-efficient than baselines.\n","authors":["Qi Liu","Jianqi Gao","Dongjie Zhu","Pengbin Chen","Jingxiang Guo","Yanjie Li"],"pdf_url":"https://arxiv.org/pdf/2408.13750v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.06165v5","updated":"2024-10-17T14:10:16Z","published":"2024-02-09T03:48:20Z","title":"Learning Contrastive Feature Representations for Facial Action Unit\n  Detection","summary":"  Facial action unit (AU) detection has long encountered the challenge of\ndetecting subtle feature differences when AUs activate. Existing methods often\nrely on encoding pixel-level information of AUs, which not only encodes\nadditional redundant information but also leads to increased model complexity\nand limited generalizability. Additionally, the accuracy of AU detection is\nnegatively impacted by the class imbalance issue of each AU type, and the\npresence of noisy and false AU labels. In this paper, we introduce a novel\ncontrastive learning framework aimed for AU detection that incorporates both\nself-supervised and supervised signals, thereby enhancing the learning of\ndiscriminative features for accurate AU detection. To tackle the class\nimbalance issue, we employ a negative sample re-weighting strategy that adjusts\nthe step size of updating parameters for minority and majority class samples.\nMoreover, to address the challenges posed by noisy and false AU labels, we\nemploy a sampling technique that encompasses three distinct types of positive\nsample pairs. This enables us to inject self-supervised signals into the\nsupervised signal, effectively mitigating the adverse effects of noisy labels.\nOur experimental assessments, conducted on four widely-utilized benchmark\ndatasets (BP4D, DISFA, GFT and Aff-Wild2), underscore the superior performance\nof our approach compared to state-of-the-art methods of AU detection. Our code\nis available at \\url{https://github.com/Ziqiao-Shang/AUNCE}.\n","authors":["Ziqiao Shang","Bin Liu","Fengmao Lv","Fei Teng","Tianrui Li"],"pdf_url":"https://arxiv.org/pdf/2402.06165v5.pdf","comment":"35 pages, 18 figures, submitted to Pattern Recognition (PR)"},{"id":"http://arxiv.org/abs/2410.07980v2","updated":"2024-10-17T14:07:13Z","published":"2024-10-10T14:36:24Z","title":"D-Wave's Nonlinear-Program Hybrid Solver: Description and Performance\n  Analysis","summary":"  The development of advanced quantum-classical algorithms is among the most\nprominent strategies in quantum computing. Numerous hybrid solvers have been\nintroduced recently. Many of these methods are created ad hoc to address\nspecific use cases. However, several well-established schemes are frequently\nutilized to address optimization problems. In this context, D-Wave launched the\nHybrid Solver Service in 2020, offering a portfolio of methods designed to\naccelerate time-to-solution for users aiming to optimize performance and\noperational processes. Recently, a new technique has been added to this\nportfolio: the Nonlinear-Program Hybrid Solver. This paper describes this\nsolver and evaluates its performance through a benchmark of 45 instances across\nthree combinatorial optimization problems: the Traveling Salesman Problem, the\nKnapsack Problem, and the Maximum Cut Problem. To facilitate the use of this\nrelatively unexplored solver, we provide details of the implementation used to\nsolve these three optimization problems.\n","authors":["Eneko Osaba","Pablo Miranda-Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2410.07980v2.pdf","comment":"10 pages, 8 figures and 7 tables"},{"id":"http://arxiv.org/abs/2410.13570v1","updated":"2024-10-17T14:05:41Z","published":"2024-10-17T14:05:41Z","title":"RGB to Hyperspectral: Spectral Reconstruction for Enhanced Surgical\n  Imaging","summary":"  This study investigates the reconstruction of hyperspectral signatures from\nRGB data to enhance surgical imaging, utilizing the publicly available\nHeiPorSPECTRAL dataset from porcine surgery and an in-house neurosurgery\ndataset. Various architectures based on convolutional neural networks (CNNs)\nand transformer models are evaluated using comprehensive metrics. Transformer\nmodels exhibit superior performance in terms of RMSE, SAM, PSNR and SSIM by\neffectively integrating spatial information to predict accurate spectral\nprofiles, encompassing both visible and extended spectral ranges. Qualitative\nassessments demonstrate the capability to predict spectral profiles critical\nfor informed surgical decision-making during procedures. Challenges associated\nwith capturing both the visible and extended hyperspectral ranges are\nhighlighted using the MAE, emphasizing the complexities involved. The findings\nopen up the new research direction of hyperspectral reconstruction for surgical\napplications and clinical use cases in real-time surgical environments.\n","authors":["Tobias Czempiel","Alfie Roddan","Maria Leiloglou","Zepeng Hu","Kevin O'Neill","Giulio Anichini","Danail Stoyanov","Daniel Elson"],"pdf_url":"https://arxiv.org/pdf/2410.13570v1.pdf","comment":"10 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2410.13567v1","updated":"2024-10-17T14:04:02Z","published":"2024-10-17T14:04:02Z","title":"CCUP: A Controllable Synthetic Data Generation Pipeline for Pretraining\n  Cloth-Changing Person Re-Identification Models","summary":"  Cloth-changing person re-identification (CC-ReID), also known as Long-Term\nPerson Re-Identification (LT-ReID) is a critical and challenging research topic\nin computer vision that has recently garnered significant attention. However,\ndue to the high cost of constructing CC-ReID data, the existing data-driven\nmodels are hard to train efficiently on limited data, causing overfitting\nissue. To address this challenge, we propose a low-cost and efficient pipeline\nfor generating controllable and high-quality synthetic data simulating the\nsurveillance of real scenarios specific to the CC-ReID task. Particularly, we\nconstruct a new self-annotated CC-ReID dataset named Cloth-Changing Unreal\nPerson (CCUP), containing 6,000 IDs, 1,179,976 images, 100 cameras, and 26.5\noutfits per individual. Based on this large-scale dataset, we introduce an\neffective and scalable pretrain-finetune framework for enhancing the\ngeneralization capabilities of the traditional CC-ReID models. The extensive\nexperiments demonstrate that two typical models namely TransReID and FIRe^2,\nwhen integrated into our framework, outperform other state-of-the-art models\nafter pretraining on CCUP and finetuning on the benchmarks such as PRCC,\nVC-Clothes and NKUP. The CCUP is available at:\nhttps://github.com/yjzhao1019/CCUP.\n","authors":["Yujian Zhao","Chengru Wu","Yinong Xu","Xuanzheng Du","Ruiyu Li","Guanglin Niu"],"pdf_url":"https://arxiv.org/pdf/2410.13567v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08551v2","updated":"2024-10-17T14:04:01Z","published":"2024-10-11T06:04:30Z","title":"Context-Aware Full Body Anonymization using Text-to-Image Diffusion\n  Models","summary":"  Anonymization plays a key role in protecting sensible information of\nindividuals in real world datasets. Self-driving cars for example need high\nresolution facial features to track people and their viewing direction to\npredict future behaviour and react accordingly. In order to protect people's\nprivacy whilst keeping important features in the dataset, it is important to\nreplace the full body of a person with a highly detailed anonymized one. In\ncontrast to doing face anonymization, full body replacement decreases the\nability of recognizing people by their hairstyle or clothes. In this paper, we\npropose a workflow for full body person anonymization utilizing Stable\nDiffusion as a generative backend. Text-to-image diffusion models, like Stable\nDiffusion, OpenAI's DALL-E or Midjourney, have become very popular in recent\ntime, being able to create photorealistic images from a single text prompt. We\nshow that our method outperforms state-of-the art anonymization pipelines with\nrespect to image quality, resolution, Inception Score (IS) and Frechet\nInception Distance (FID). Additionally, our method is invariant with respect to\nthe image generator and thus able to be used with the latest models available.\n","authors":["Pascal Zwick","Kevin Roesch","Marvin Klemp","Oliver Bringmann"],"pdf_url":"https://arxiv.org/pdf/2410.08551v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13553v1","updated":"2024-10-17T13:51:03Z","published":"2024-10-17T13:51:03Z","title":"Integrating Temporal Representations for Dynamic Memory Retrieval and\n  Management in Large Language Models","summary":"  Conventional dialogue agents often struggle with effective memory recall,\nleading to redundant retrieval and inadequate management of unique user\nassociations. To address this, we propose SynapticRAG, a novel approach\nintegrating synaptic dynamics into Retrieval-Augmented Generation (RAG).\nSynapticRAG integrates temporal representations into memory vectors, mimicking\nbiological synapses by differentiating events based on occurrence times and\ndynamically updating memory significance. This model employs temporal scoring\nfor memory connections and a synaptic-inspired propagation control mechanism.\nExperiments across English, Japanese, and Chinese datasets demonstrate\nSynapticRAG's superiority over existing methods, including traditional RAG,\nwith up to 14.66\\% improvement in memory retrieval accuracy. Our approach\nadvances context-aware dialogue AI systems by enhancing long-term context\nmaintenance and specific information extraction from conversations.\n","authors":["Yuki Hou","Haruki Tamoto","Homei Miyashita"],"pdf_url":"https://arxiv.org/pdf/2410.13553v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.16710v3","updated":"2024-10-17T13:50:46Z","published":"2024-04-25T16:20:23Z","title":"LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding","summary":"  We present LayerSkip, an end-to-end solution to speed-up inference of large\nlanguage models (LLMs). First, during training we apply layer dropout, with low\ndropout rates for earlier layers and higher dropout rates for later layers, and\nan early exit loss where all transformer layers share the same exit. Second,\nduring inference, we show that this training recipe increases the accuracy of\nearly exit at earlier layers, without adding any auxiliary layers or modules to\nthe model. Third, we present a novel self-speculative decoding solution where\nwe exit at early layers and verify and correct with remaining layers of the\nmodel. Our proposed self-speculative decoding approach has less memory\nfootprint than other speculative decoding approaches and benefits from shared\ncompute and activations of the draft and verification stages. We run\nexperiments on different Llama model sizes on different types of training:\npretraining from scratch, continual pretraining, finetuning on specific data\ndomain, and finetuning on specific task. We implement our inference solution\nand show speedups of up to 2.16x on summarization for CNN/DM documents, 1.82x\non coding, and 2.0x on TOPv2 semantic parsing task. We open source our code and\ncheckpoints at https://github.com/facebookresearch/LayerSkip.\n","authors":["Mostafa Elhoushi","Akshat Shrivastava","Diana Liskovich","Basil Hosmer","Bram Wasti","Liangzhen Lai","Anas Mahmoud","Bilge Acun","Saurabh Agarwal","Ahmed Roman","Ahmed A Aly","Beidi Chen","Carole-Jean Wu"],"pdf_url":"https://arxiv.org/pdf/2404.16710v3.pdf","comment":"ACL 2024"},{"id":"http://arxiv.org/abs/2410.13523v1","updated":"2024-10-17T13:11:07Z","published":"2024-10-17T13:11:07Z","title":"Can Medical Vision-Language Pre-training Succeed with Purely Synthetic\n  Data?","summary":"  Medical Vision-Language Pre-training (MedVLP) has made significant progress\nin enabling zero-shot tasks for medical image understanding. However, training\nMedVLP models typically requires large-scale datasets with paired, high-quality\nimage-text data, which are scarce in the medical domain. Recent advancements in\nLarge Language Models (LLMs) and diffusion models have made it possible to\ngenerate large-scale synthetic image-text pairs. This raises the question: *Can\nMedVLP succeed using purely synthetic data?* To address this, we use\noff-the-shelf generative models to create synthetic radiology reports and\npaired Chest X-ray (CXR) images, and propose an automated pipeline to build a\ndiverse, high-quality synthetic dataset, enabling a rigorous study that\nisolates model and training settings, focusing entirely from the data\nperspective. Our results show that MedVLP models trained *exclusively on\nsynthetic data* outperform those trained on real data by **3.8%** in averaged\nAUC on zero-shot classification. Moreover, using a combination of synthetic and\nreal data leads to a further improvement of **9.07%**. Additionally, MedVLP\nmodels trained on synthetic or mixed data consistently outperform those trained\non real data in zero-shot grounding, as well as in fine-tuned classification\nand segmentation tasks. Our analysis suggests MedVLP trained on well-designed\nsynthetic data can outperform models trained on real datasets, which may be\nlimited by low-quality samples and long-tailed distributions.\n","authors":["Che Liu","Zhongwei Wan","Haozhe Wang","Yinda Chen","Talha Qaiser","Chen Jin","Fariba Yousefi","Nikolay Burlutskiy","Rossella Arcucci"],"pdf_url":"https://arxiv.org/pdf/2410.13523v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2410.13517v1","updated":"2024-10-17T13:06:02Z","published":"2024-10-17T13:06:02Z","title":"Bias in the Mirror : Are LLMs opinions robust to their own adversarial\n  attacks ?","summary":"  Large language models (LLMs) inherit biases from their training data and\nalignment processes, influencing their responses in subtle ways. While many\nstudies have examined these biases, little work has explored their robustness\nduring interactions. In this paper, we introduce a novel approach where two\ninstances of an LLM engage in self-debate, arguing opposing viewpoints to\npersuade a neutral version of the model. Through this, we evaluate how firmly\nbiases hold and whether models are susceptible to reinforcing misinformation or\nshifting to harmful viewpoints. Our experiments span multiple LLMs of varying\nsizes, origins, and languages, providing deeper insights into bias persistence\nand flexibility across linguistic and cultural contexts.\n","authors":["Virgile Rennard","Christos Xypolopoulos","Michalis Vazirgiannis"],"pdf_url":"https://arxiv.org/pdf/2410.13517v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12686v2","updated":"2024-10-17T12:52:30Z","published":"2024-10-16T15:48:28Z","title":"Automatic Mapping of Anatomical Landmarks from Free-Text Using Large\n  Language Models: Insights from Llama-2","summary":"  Anatomical landmarks are vital in medical imaging for navigation and anomaly\ndetection. Modern large language models (LLMs), like Llama-2, offer promise for\nautomating the mapping of these landmarks in free-text radiology reports to\ncorresponding positions in image data. Recent studies propose LLMs may develop\ncoherent representations of generative processes. Motivated by these insights,\nwe investigated whether LLMs accurately represent the spatial positions of\nanatomical landmarks. Through experiments with Llama-2 models, we found that\nthey can linearly represent anatomical landmarks in space with considerable\nrobustness to different prompts. These results underscore the potential of LLMs\nto enhance the efficiency and accuracy of medical imaging workflows.\n","authors":["Mohamad Abdi","Gerardo Hermosillo Valadez","Halid Ziya Yerebakan"],"pdf_url":"https://arxiv.org/pdf/2410.12686v2.pdf","comment":"6 pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2410.13502v1","updated":"2024-10-17T12:48:14Z","published":"2024-10-17T12:48:14Z","title":"MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily\n  Complex Proofs","summary":"  Large language models (LLMs) can solve arithmetic word problems with high\naccuracy, but little is known about how well they generalize to problems that\nare more complex than the ones on which they have been trained. Empirical\ninvestigations of such questions are impeded by two major flaws of current\nevaluations: (i) much of the evaluation data is contaminated, in the sense that\nit has already been seen during training, and (ii) benchmark datasets do not\ncapture how problem proofs may be arbitrarily complex in various ways. As a\nstep towards addressing these issues, we present a framework for evaluating\nLLMs on problems that have arbitrarily complex arithmetic proofs, called\nMathGAP. MathGAP generates problems that follow fixed proof specifications --\nalong with chain-of-thought reasoning annotations -- enabling systematic\nstudies on generalization with respect to arithmetic proof complexity. We apply\nMathGAP to analyze how in-context learning interacts with generalization to\nproblems that have more complex proofs. We find that among the models tested,\nmost show a significant decrease in performance as proofs get deeper and wider.\nThis effect is more pronounced in complex, nonlinear proof structures, which\nare challenging even for GPT-4o. Surprisingly, providing in-context examples\nfrom the same distribution as the test set is not always beneficial for\nperformance. In particular, zero-shot prompting as well as demonstrating a\ndiverse range of examples that are less complex than the test data sometimes\nyield similar or higher accuracies.\n","authors":["Andreas Opedal","Haruki Shirakami","Bernhard Schölkopf","Abulhair Saparov","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2410.13502v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.13498v1","updated":"2024-10-17T12:43:49Z","published":"2024-10-17T12:43:49Z","title":"Enhancing Text Generation in Joint NLG/NLU Learning Through Curriculum\n  Learning, Semi-Supervised Training, and Advanced Optimization Techniques","summary":"  Text generation is the automated process of producing written or spoken\nlanguage using computational methods. It involves generating coherent and\ncontextually relevant text based on predefined rules or learned patterns.\nHowever, challenges in text generation arise from maintaining coherence,\nensuring diversity and creativity, and avoiding biases or inappropriate\ncontent. This research paper developed a novel approach to improve text\ngeneration in the context of joint Natural Language Generation (NLG) and\nNatural Language Understanding (NLU) learning. The data is prepared by\ngathering and preprocessing annotated datasets, including cleaning,\ntokenization, stemming, and stop-word removal. Feature extraction techniques\nsuch as POS tagging, Bag of words, and Term Frequency-Inverse Document\nFrequency (TF-IDF) are applied. Transformer-based encoders and decoders,\ncapturing long range dependencies and improving source-target sequence\nmodelling. Pre-trained language models like Optimized BERT are incorporated,\nalong with a Hybrid Redfox Artificial Hummingbird Algorithm (HRAHA).\nReinforcement learning with policy gradient techniques, semi-supervised\ntraining, improved attention mechanisms, and differentiable approximations like\nstraight-through Gumbel SoftMax estimator are employed to fine-tune the models\nand handle complex linguistic tasks effectively. The proposed model is\nimplemented using Python.\n","authors":["Rahimanuddin Shaik","Katikela Sreeharsha Kishore"],"pdf_url":"https://arxiv.org/pdf/2410.13498v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13488v1","updated":"2024-10-17T12:32:00Z","published":"2024-10-17T12:32:00Z","title":"Seeing Through VisualBERT: A Causal Adventure on Memetic Landscapes","summary":"  Detecting offensive memes is crucial, yet standard deep neural network\nsystems often remain opaque. Various input attribution-based methods attempt to\ninterpret their behavior, but they face challenges with implicitly offensive\nmemes and non-causal attributions. To address these issues, we propose a\nframework based on a Structural Causal Model (SCM). In this framework,\nVisualBERT is trained to predict the class of an input meme based on both meme\ninput and causal concepts, allowing for transparent interpretation. Our\nqualitative evaluation demonstrates the framework's effectiveness in\nunderstanding model behavior, particularly in determining whether the model was\nright due to the right reason, and in identifying reasons behind\nmisclassification. Additionally, quantitative analysis assesses the\nsignificance of proposed modelling choices, such as de-confounding, adversarial\nlearning, and dynamic routing, and compares them with input attribution\nmethods. Surprisingly, we find that input attribution methods do not guarantee\ncausality within our framework, raising questions about their reliability in\nsafety-critical applications. The project page is at:\nhttps://newcodevelop.github.io/causality_adventure/\n","authors":["Dibyanayan Bandyopadhyay","Mohammed Hasanuzzaman","Asif Ekbal"],"pdf_url":"https://arxiv.org/pdf/2410.13488v1.pdf","comment":"Accepted at EMNLP Findings 2024"},{"id":"http://arxiv.org/abs/2410.10850v2","updated":"2024-10-17T11:52:38Z","published":"2024-10-06T07:40:11Z","title":"On the Reliability of Large Language Models to Misinformed and\n  Demographically-Informed Prompts","summary":"  We investigate and observe the behaviour and performance of Large Language\nModel (LLM)-backed chatbots in addressing misinformed prompts and questions\nwith demographic information within the domains of Climate Change and Mental\nHealth. Through a combination of quantitative and qualitative methods, we\nassess the chatbots' ability to discern the veracity of statements, their\nadherence to facts, and the presence of bias or misinformation in their\nresponses. Our quantitative analysis using True/False questions reveals that\nthese chatbots can be relied on to give the right answers to these close-ended\nquestions. However, the qualitative insights, gathered from domain experts,\nshows that there are still concerns regarding privacy, ethical implications,\nand the necessity for chatbots to direct users to professional services. We\nconclude that while these chatbots hold significant promise, their deployment\nin sensitive areas necessitates careful consideration, ethical oversight, and\nrigorous refinement to ensure they serve as a beneficial augmentation to human\nexpertise rather than an autonomous solution.\n","authors":["Toluwani Aremu","Oluwakemi Akinwehinmi","Chukwuemeka Nwagu","Syed Ishtiaque Ahmed","Rita Orji","Pedro Arnau Del Amo","Abdulmotaleb El Saddik"],"pdf_url":"https://arxiv.org/pdf/2410.10850v2.pdf","comment":"Study conducted between August and December 2023. Under review at\n  AAAI-AI Magazine. Submitted for archival purposes only"},{"id":"http://arxiv.org/abs/2410.08949v2","updated":"2024-10-17T11:52:24Z","published":"2024-10-11T16:17:20Z","title":"Transferable Belief Model on Quantum Circuits","summary":"  The transferable belief model, as a semantic interpretation of\nDempster-Shafer theory, enables agents to perform reasoning and decision making\nin imprecise and incomplete environments. The model offers distinct semantics\nfor handling unreliable testimonies, allowing for a more reasonable and general\nprocess of belief transfer compared to the Bayesian approach. However, because\nboth the belief masses and the structure of focal sets must be considered when\nupdating belief functions-leading to extra computational complexity during\nreasoning-the transferable belief model has gradually lost favor among\nresearchers in recent developments. In this paper, we implement the\ntransferable belief model on quantum circuits and demonstrate that belief\nfunctions offer a more concise and effective alternative to Bayesian approaches\nwithin the quantum computing framework. Furthermore, leveraging the unique\ncharacteristics of quantum computing, we propose several novel belief transfer\napproaches. More broadly, this paper introduces a new perspective on basic\ninformation representation for quantum AI models, suggesting that belief\nfunctions are more suitable than Bayesian approach for handling uncertainty on\nquantum circuits.\n","authors":["Qianli Zhou","Hao Luo","Lipeng Pan","Yong Deng","Eloi Bosse"],"pdf_url":"https://arxiv.org/pdf/2410.08949v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10874v3","updated":"2024-10-17T11:50:03Z","published":"2023-01-25T23:47:34Z","title":"Recursive deep learning framework for forecasting the decadal world\n  economic outlook","summary":"  The gross domestic product (GDP) is the most widely used indicator in\nmacroeconomics and the main tool for measuring a country's economic output. Due\nto the diversity and complexity of the world economy, a wide range of models\nhave been used, but there are challenges in making decadal GDP forecasts given\nunexpected changes such as emergence of catastrophic world events including\npandemics and wars. Deep learning models are well suited for modelling temporal\nsequences and time series forecasting. In this paper, we develop a deep\nlearning framework to forecast the GDP growth rate of the world economy over a\ndecade. We use the Penn World Table as the data source featuring 13 countries\nprior to the COVID-19 pandemic, such as Australia, China, India, and the United\nStates. We present a recursive deep learning framework to predict the GDP\ngrowth rate in the next ten years. We test prominent deep learning models and\ncompare their results with traditional econometric models for selected\ndeveloped and developing countries. Our decadal forecasts reveal that that most\nof the developed countries would experience economic growth slowdown,\nstagnation and even recession within five years (2020-2024). Furthermore, our\nmodel forecasts show that only China, France, and India would experience stable\nGDP growth.\n","authors":["Tianyi Wang","Rodney Beard","John Hawkins","Rohitash Chandra"],"pdf_url":"https://arxiv.org/pdf/2301.10874v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.09250v2","updated":"2024-10-17T11:46:45Z","published":"2024-06-13T15:55:04Z","title":"MirrorCheck: Efficient Adversarial Defense for Vision-Language Models","summary":"  Vision-Language Models (VLMs) are becoming increasingly vulnerable to\nadversarial attacks as various novel attack strategies are being proposed\nagainst these models. While existing defenses excel in unimodal contexts, they\ncurrently fall short in safeguarding VLMs against adversarial threats. To\nmitigate this vulnerability, we propose a novel, yet elegantly simple approach\nfor detecting adversarial samples in VLMs. Our method leverages Text-to-Image\n(T2I) models to generate images based on captions produced by target VLMs.\nSubsequently, we calculate the similarities of the embeddings of both input and\ngenerated images in the feature space to identify adversarial samples.\nEmpirical evaluations conducted on different datasets validate the efficacy of\nour approach, outperforming baseline methods adapted from image classification\ndomains. Furthermore, we extend our methodology to classification tasks,\nshowcasing its adaptability and model-agnostic nature. Theoretical analyses and\nempirical findings also show the resilience of our approach against adaptive\nattacks, positioning it as an excellent defense mechanism for real-world\ndeployment against adversarial threats.\n","authors":["Samar Fares","Klea Ziu","Toluwani Aremu","Nikita Durasov","Martin Takáč","Pascal Fua","Karthik Nandakumar","Ivan Laptev"],"pdf_url":"https://arxiv.org/pdf/2406.09250v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13460v1","updated":"2024-10-17T11:43:16Z","published":"2024-10-17T11:43:16Z","title":"Breaking the Manual Annotation Bottleneck: Creating a Comprehensive\n  Legal Case Criticality Dataset through Semi-Automated Labeling","summary":"  Predicting case criticality helps legal professionals in the court system\nmanage large volumes of case law. This paper introduces the Criticality\nPrediction dataset, a new resource for evaluating the potential influence of\nSwiss Federal Supreme Court decisions on future jurisprudence. Unlike existing\napproaches that rely on resource-intensive manual annotations, we\nsemi-automatically derive labels leading to a much larger dataset than\notherwise possible. Our dataset features a two-tier labeling system: (1) the\nLD-Label, which identifies cases published as Leading Decisions (LD), and (2)\nthe Citation-Label, which ranks cases by their citation frequency and recency.\nThis allows for a more nuanced evaluation of case importance. We evaluate\nseveral multilingual models, including fine-tuned variants and large language\nmodels, and find that fine-tuned models consistently outperform zero-shot\nbaselines, demonstrating the need for task-specific adaptation. Our\ncontributions include the introduction of this task and the release of a\nmultilingual dataset to the research community.\n","authors":["Ronja Stern","Ken Kawamura","Matthias Stürmer","Ilias Chalkidis","Joel Niklaus"],"pdf_url":"https://arxiv.org/pdf/2410.13460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13456v1","updated":"2024-10-17T11:34:07Z","published":"2024-10-17T11:34:07Z","title":"Unlocking Legal Knowledge: A Multilingual Dataset for Judicial\n  Summarization in Switzerland","summary":"  Legal research is a time-consuming task that most lawyers face on a daily\nbasis. A large part of legal research entails looking up relevant caselaw and\nbringing it in relation to the case at hand. Lawyers heavily rely on summaries\n(also called headnotes) to find the right cases quickly. However, not all\ndecisions are annotated with headnotes and writing them is time-consuming.\nAutomated headnote creation has the potential to make hundreds of thousands of\ndecisions more accessible for legal research in Switzerland alone. To kickstart\nthis, we introduce the Swiss Leading Decision Summarization ( SLDS) dataset, a\nnovel cross-lingual resource featuring 18K court rulings from the Swiss Federal\nSupreme Court (SFSC), in German, French, and Italian, along with German\nheadnotes. We fine-tune and evaluate three mT5 variants, along with proprietary\nmodels. Our analysis highlights that while proprietary models perform well in\nzero-shot and one-shot settings, fine-tuned smaller models still provide a\nstrong competitive edge. We publicly release the dataset to facilitate further\nresearch in multilingual legal summarization and the development of assistive\ntechnologies for legal professionals\n","authors":["Luca Rolshoven","Vishvaksenan Rasiah","Srinanda Brügger Bose","Matthias Stürmer","Joel Niklaus"],"pdf_url":"https://arxiv.org/pdf/2410.13456v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.11843v2","updated":"2024-10-17T11:26:10Z","published":"2024-07-16T15:24:44Z","title":"InferAct: Inferring Safe Actions for LLM-Based Agents Through Preemptive\n  Evaluation and Human Feedback","summary":"  A crucial requirement for deploying LLM-based agents in real-life\napplications is the robustness against risky or even irreversible mistakes.\nHowever, the existing research lacks a focus on preemptive evaluation of\nreasoning trajectories performed by LLM agents, leading to a gap in ensuring\nsafe and reliable operations. To explore better solutions, this paper\nintroduces InferAct, a novel approach that leverages the belief reasoning\nability of LLMs, grounded in Theory-of-Mind, to proactively detect potential\nerrors before risky actions are executed (e.g., `buy-now' in automatic online\ntrading or web shopping). InferAct acts as a human proxy, detecting unsafe\nactions and alerting users for intervention, which helps prevent irreversible\nrisks in time and enhances the actor agent's decision-making process.\nExperiments on three widely-used tasks demonstrate the effectiveness of\nInferAct, presenting a novel solution for safely developing LLM agents in\nenvironments involving critical decision-making.\n","authors":["Haishuo Fang","Xiaodan Zhu","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2407.11843v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13445v1","updated":"2024-10-17T11:19:44Z","published":"2024-10-17T11:19:44Z","title":"Parameter-efficient Adaptation of Multilingual Multimodal Models for\n  Low-resource ASR","summary":"  Automatic speech recognition (ASR) for low-resource languages remains a\nchallenge due to the scarcity of labeled training data. Parameter-efficient\nfine-tuning and text-only adaptation are two popular methods that have been\nused to address such low-resource settings. In this work, we investigate how\nthese techniques can be effectively combined using a multilingual multimodal\nmodel like SeamlessM4T. Multimodal models are able to leverage unlabeled text\nvia text-only adaptation with further parameter-efficient ASR fine-tuning, thus\nboosting ASR performance. We also show cross-lingual transfer from a\nhigh-resource language, achieving up to a relative 17% WER reduction over a\nbaseline in a zero-shot setting without any labeled speech.\n","authors":["Abhishek Gupta","Amruta Parulekar","Sameep Chattopadhyay","Preethi Jyothi"],"pdf_url":"https://arxiv.org/pdf/2410.13445v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13441v1","updated":"2024-10-17T11:16:27Z","published":"2024-10-17T11:16:27Z","title":"Instruction-Driven Game Engine: A Poker Case Study","summary":"  The Instruction-Driven Game Engine (IDGE) project aims to democratize game\ndevelopment by enabling a large language model (LLM) to follow free-form game\ndescriptions and generate game-play processes. The IDGE allows users to create\ngames simply by natural language instructions, which significantly lowers the\nbarrier for game development. We approach the learning process for IDGEs as a\nNext State Prediction task, wherein the model autoregressively predicts the\ngame states given player actions. The computation of game states must be\nprecise; otherwise, slight errors could corrupt the game-play experience. This\nis challenging because of the gap between stability and diversity. To address\nthis, we train the IDGE in a curriculum manner that progressively increases its\nexposure to complex scenarios. Our initial progress lies in developing an IDGE\nfor Poker, which not only supports a wide range of poker variants but also\nallows for highly individualized new poker games through natural language\ninputs. This work lays the groundwork for future advancements in transforming\nhow games are created and played.\n","authors":["Hongqiu Wu","Xingyuan Liu","Yan Wang","Hai Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.13441v1.pdf","comment":"EMNLP 2024 Demo. arXiv admin note: substantial text overlap with\n  arXiv:2404.00276"},{"id":"http://arxiv.org/abs/2410.05966v2","updated":"2024-10-17T11:15:39Z","published":"2024-10-08T12:16:12Z","title":"FLOPS: Forward Learning with OPtimal Sampling","summary":"  Given the limitations of backpropagation, perturbation-based gradient\ncomputation methods have recently gained focus for learning with only forward\npasses, also referred to as queries. Conventional forward learning consumes\nenormous queries on each data point for accurate gradient estimation through\nMonte Carlo sampling, which hinders the scalability of those algorithms.\nHowever, not all data points deserve equal queries for gradient estimation. In\nthis paper, we study the problem of improving the forward learning efficiency\nfrom a novel perspective: how to reduce the gradient estimation variance with\nminimum cost? For this, we propose to allocate the optimal number of queries\nover each data in one batch during training to achieve a good balance between\nestimation accuracy and computational efficiency. Specifically, with a\nsimplified proxy objective and a reparameterization technique, we derive a\nnovel plug-and-play query allocator with minimal parameters. Theoretical\nresults are carried out to verify its optimality. We conduct extensive\nexperiments for fine-tuning Vision Transformers on various datasets and further\ndeploy the allocator to two black-box applications: prompt tuning and\nmultimodal alignment for foundation models. All findings demonstrate that our\nproposed allocator significantly enhances the scalability of forward-learning\nalgorithms, paving the way for real-world applications.\n","authors":["Tao Ren","Zishi Zhang","Jinyang Jiang","Guanghao Li","Zeliang Zhang","Mingqian Feng","Yijie Peng"],"pdf_url":"https://arxiv.org/pdf/2410.05966v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09747v2","updated":"2024-10-17T11:14:37Z","published":"2024-10-13T06:53:58Z","title":"t-READi: Transformer-Powered Robust and Efficient Multimodal Inference\n  for Autonomous Driving","summary":"  Given the wide adoption of multimodal sensors (e.g., camera, lidar, radar) by\nautonomous vehicles (AVs), deep analytics to fuse their outputs for a robust\nperception become imperative. However, existing fusion methods often make two\nassumptions rarely holding in practice: i) similar data distributions for all\ninputs and ii) constant availability for all sensors. Because, for example,\nlidars have various resolutions and failures of radars may occur, such\nvariability often results in significant performance degradation in fusion. To\nthis end, we present tREADi, an adaptive inference system that accommodates the\nvariability of multimodal sensory data and thus enables robust and efficient\nperception. t-READi identifies variation-sensitive yet structure-specific model\nparameters; it then adapts only these parameters while keeping the rest intact.\nt-READi also leverages a cross-modality contrastive learning method to\ncompensate for the loss from missing modalities. Both functions are implemented\nto maintain compatibility with existing multimodal deep fusion methods. The\nextensive experiments evidently demonstrate that compared with the status quo\napproaches, t-READi not only improves the average inference accuracy by more\nthan 6% but also reduces the inference latency by almost 15x with the cost of\nonly 5% extra memory overhead in the worst case under realistic data and modal\nvariations.\n","authors":["Pengfei Hu","Yuhang Qian","Tianyue Zheng","Ang Li","Zhe Chen","Yue Gao","Xiuzhen Cheng","Jun Luo"],"pdf_url":"https://arxiv.org/pdf/2410.09747v2.pdf","comment":"14 pages, 16 figures"},{"id":"http://arxiv.org/abs/2410.12298v2","updated":"2024-10-17T11:00:37Z","published":"2024-10-16T06:57:18Z","title":"Pyramid-Driven Alignment: Pyramid Principle Guided Integration of Large\n  Language Models and Knowledge Graphs","summary":"  Large Language Models (LLMs) possess impressive reasoning abilities but are\nprone to generating incorrect information, often referred to as hallucinations.\nWhile incorporating external Knowledge Graphs (KGs) can partially mitigate this\nissue, existing methods primarily treat KGs as static knowledge repositories,\noverlooking the critical disparity between KG and LLM knowledge, and failing to\nfully exploit the reasoning capabilities inherent in KGs. To address these\nlimitations, we propose Pyramid-Driven Alignment (PDA), a novel framework for\nseamlessly integrating LLMs with KGs. PDA utilizes Pyramid Principle analysis\nto construct a hierarchical pyramid structure. This structure is designed to\nreflect the input question and generate more validated deductive knowledge,\nthereby enhancing the alignment of LLMs and KGs and ensuring more cohesive\nintegration. Furthermore, PDA employs a recursive mechanism to harness the\nunderlying reasoning abilities of KGs, resulting in more accurate knowledge\nretrieval for question-answering tasks. Our experimental results reveal a\nsubstantial performance advantage of PDA over state-of-the-art baselines, with\nimprovements reaching 26.70% and 26.78%.\n","authors":["Lei Sun","Xinchen Wang","Youdi Li"],"pdf_url":"https://arxiv.org/pdf/2410.12298v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.14649v2","updated":"2024-10-17T10:55:35Z","published":"2024-08-26T21:25:44Z","title":"Bidirectional Emergent Language in Situated Environments","summary":"  Emergent language research has made significant progress in recent years, but\nstill largely fails to explore how communication emerges in more complex and\nsituated multi-agent systems. Existing setups often employ a reference game,\nwhich limits the range of language emergence phenomena that can be studied, as\nthe game consists of a single, purely language-based interaction between the\nagents. In this paper, we address these limitations and explore the emergence\nand utility of token-based communication in open-ended multi-agent\nenvironments, where situated agents interact with the environment through\nmovement and communication over multiple time-steps. Specifically, we introduce\ntwo novel cooperative environments: Multi-Agent Pong and Collectors. These\nenvironments are interesting because optimal performance requires the emergence\nof a communication protocol, but moderate success can be achieved without one.\nBy employing various methods from explainable AI research, such as saliency\nmaps, perturbation, and diagnostic classifiers, we are able to track and\ninterpret the agents' language channel use over time. We find that the emerging\ncommunication is sparse, with the agents only generating meaningful messages\nand acting upon incoming messages in states where they cannot succeed without\ncoordination.\n","authors":["Cornelius Wolff","Julius Mayer","Elia Bruni","Xenia Ohmer"],"pdf_url":"https://arxiv.org/pdf/2408.14649v2.pdf","comment":"10 pages, 4 figures, 4 tables, preprint"},{"id":"http://arxiv.org/abs/2410.13431v1","updated":"2024-10-17T10:54:55Z","published":"2024-10-17T10:54:55Z","title":"Solving Prior Distribution Mismatch in Diffusion Models via Optimal\n  Transport","summary":"  In recent years, the knowledge surrounding diffusion models(DMs) has grown\nsignificantly, though several theoretical gaps remain. Particularly noteworthy\nis prior error, defined as the discrepancy between the termination distribution\nof the forward process and the initial distribution of the reverse process. To\naddress these deficiencies, this paper explores the deeper relationship between\noptimal transport(OT) theory and DMs with discrete initial distribution.\nSpecifically, we demonstrate that the two stages of DMs fundamentally involve\ncomputing time-dependent OT. However, unavoidable prior error result in\ndeviation during the reverse process under quadratic transport cost. By proving\nthat as the diffusion termination time increases, the probability flow\nexponentially converges to the gradient of the solution to the classical\nMonge-Amp\\`ere equation, we establish a vital link between these fields.\nTherefore, static OT emerges as the most intrinsic single-step method for\nbridging this theoretical potential gap. Additionally, we apply these insights\nto accelerate sampling in both unconditional and conditional generation\nscenarios. Experimental results across multiple image datasets validate the\neffectiveness of our approach.\n","authors":["Zhanpeng Wang","Shenghao Li","Chen Wang","Shuting Cao","Na Lei","Zhongxuan Luo"],"pdf_url":"https://arxiv.org/pdf/2410.13431v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14928v2","updated":"2024-10-17T10:30:41Z","published":"2024-06-21T07:37:19Z","title":"Autonomous Agents for Collaborative Task under Information Asymmetry","summary":"  Large Language Model Multi-Agent Systems (LLM-MAS) have achieved great\nprogress in solving complex tasks. It performs communication among agents\nwithin the system to collaboratively solve tasks, under the premise of shared\ninformation. However, when agents' collaborations are leveraged to perform\nmulti-person tasks, a new challenge arises due to information asymmetry, since\neach agent can only access the information of its human user. Previous MAS\nstruggle to complete tasks under this condition. To address this, we propose a\nnew MAS paradigm termed iAgents, which denotes Informative Multi-Agent Systems.\nIn iAgents, the human social network is mirrored in the agent network, where\nagents proactively exchange human information necessary for task resolution,\nthereby overcoming information asymmetry. iAgents employs a novel agent\nreasoning mechanism, InfoNav, to navigate agents' communication toward\neffective information exchange. Together with InfoNav, iAgents organizes human\ninformation in a mixed memory to provide agents with accurate and comprehensive\ninformation for exchange. Additionally, we introduce InformativeBench, the\nfirst benchmark tailored for evaluating LLM agents' task-solving ability under\ninformation asymmetry. Experimental results show that iAgents can collaborate\nwithin a social network of 140 individuals and 588 relationships, autonomously\ncommunicate over 30 turns, and retrieve information from nearly 70,000 messages\nto complete tasks within 3 minutes.\n","authors":["Wei Liu","Chenxi Wang","Yifei Wang","Zihao Xie","Rennai Qiu","Yufan Dang","Zhuoyun Du","Weize Chen","Cheng Yang","Chen Qian"],"pdf_url":"https://arxiv.org/pdf/2406.14928v2.pdf","comment":"32 pages, 12 figures, 6 tables, accepted by NeurIPS 2024, see detail\n  at https://thinkwee.top/iagents"},{"id":"http://arxiv.org/abs/2410.13415v1","updated":"2024-10-17T10:29:15Z","published":"2024-10-17T10:29:15Z","title":"Shavette: Low Power Neural Network Acceleration via Algorithm-level\n  Error Detection and Undervolting","summary":"  Reduced voltage operation is an effective technique for substantial energy\nefficiency improvement in digital circuits. This brief introduces a simple\napproach for enabling reduced voltage operation of Deep Neural Network (DNN)\naccelerators by mere software modifications. Conventional approaches for\nenabling reduced voltage operation e.g., Timing Error Detection (TED) systems,\nincur significant development costs and overheads, while not being applicable\nto the off-the-shelf components. Contrary to those, the solution proposed in\nthis paper relies on algorithm-based error detection, and hence, is implemented\nwith low development costs, does not require any circuit modifications, and is\neven applicable to commodity devices. By showcasing the solution through\nexperimenting on popular DNNs, i.e., LeNet and VGG16, on a GPU platform, we\ndemonstrate 18% to 25% energy saving with no accuracy loss of the models and\nnegligible throughput compromise (< 3.9%), considering the overheads from\nintegration of the error detection schemes into the DNN. The integration of\npresented algorithmic solution into the design is simpler when compared\nconventional TED based techniques that require extensive circuit-level\nmodifications, cell library characterizations or special support from the\ndesign tools.\n","authors":["Mikael Rinkinen","Lauri Koskinen","Olli Silven","Mehdi Safarpour"],"pdf_url":"https://arxiv.org/pdf/2410.13415v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13413v1","updated":"2024-10-17T10:23:24Z","published":"2024-10-17T10:23:24Z","title":"Think Thrice Before You Act: Progressive Thought Refinement in Large\n  Language Models","summary":"  Recent advancements in large language models (LLMs) have demonstrated that\nprogressive refinement, rather than providing a single answer, results in more\naccurate and thoughtful outputs. However, existing methods often rely heavily\non supervision signals to evaluate previous responses, making it difficult to\nassess output quality in more open-ended scenarios effectively. Additionally,\nthese methods are typically designed for specific tasks, which limits their\ngeneralization to new domains. To address these limitations, we propose\nProgressive Thought Refinement (PTR), a framework that enables LLMs to refine\ntheir responses progressively. PTR operates in two phases: (1) Thought data\nconstruction stage: We propose a weak and strong model collaborative selection\nstrategy to build a high-quality progressive refinement dataset to ensure\nlogical consistency from thought to answers, and the answers are gradually\nrefined in each round. (2) Thought-Mask Fine-Tuning Phase: We design a training\nstructure to mask the \"thought\" and adjust loss weights to encourage LLMs to\nrefine prior thought, teaching them to implicitly understand \"how to improve\"\nrather than \"what is correct.\" Experimental results show that PTR significantly\nenhances LLM performance across ten diverse tasks (avg. from 49.6% to 53.5%)\nwithout task-specific fine-tuning. Notably, in more open-ended tasks, LLMs also\ndemonstrate substantial improvements in the quality of responses beyond mere\naccuracy, suggesting that PTR truly teaches LLMs to self-improve over time.\n","authors":["Chengyu Du","Jinyi Han","Yizhou Ying","Aili Chen","Qianyu He","Haokun Zhao","Sirui Xia","Haoran Guo","Jiaqing Liang","Zulong Chen","Liangyue Li","Yanghua Xiao"],"pdf_url":"https://arxiv.org/pdf/2410.13413v1.pdf","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.13409v1","updated":"2024-10-17T10:16:56Z","published":"2024-10-17T10:16:56Z","title":"Attr-Int: A Simple and Effective Entity Alignment Framework for\n  Heterogeneous Knowledge Graphs","summary":"  Entity alignment (EA) refers to the task of linking entities in different\nknowledge graphs (KGs). Existing EA methods rely heavily on structural\nisomorphism. However, in real-world KGs, aligned entities usually have\nnon-isomorphic neighborhood structures, which paralyses the application of\nthese structure-dependent methods. In this paper, we investigate and tackle the\nproblem of entity alignment between heterogeneous KGs. First, we propose two\nnew benchmarks to closely simulate real-world EA scenarios of heterogeneity.\nThen we conduct extensive experiments to evaluate the performance of\nrepresentative EA methods on the new benchmarks. Finally, we propose a simple\nand effective entity alignment framework called Attr-Int, in which innovative\nattribute information interaction methods can be seamlessly integrated with any\nembedding encoder for entity alignment, improving the performance of existing\nentity alignment techniques. Experiments demonstrate that our framework\noutperforms the state-of-the-art approaches on two new benchmarks.\n","authors":["Linyan Yang","Jingwei Cheng","Chuanhao Xu","Xihao Wang","Jiayi Li","Fu Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.13409v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.09490v2","updated":"2024-10-17T10:15:38Z","published":"2024-08-18T14:10:34Z","title":"Leveraging Invariant Principle for Heterophilic Graph Structure\n  Distribution Shifts","summary":"  Heterophilic Graph Neural Networks (HGNNs) have shown promising results for\nsemi-supervised learning tasks on graphs. Notably, most real-world heterophilic\ngraphs are composed of a mixture of nodes with different neighbor patterns,\nexhibiting local node-level homophilic and heterophilic structures. However,\nexisting works are only devoted to designing better HGNN backbones or\narchitectures for node classification tasks on heterophilic and homophilic\ngraph benchmarks simultaneously, and their analyses of HGNN performance with\nrespect to nodes are only based on the determined data distribution without\nexploring the effect caused by this structural difference between training and\ntesting nodes. How to learn invariant node representations on heterophilic\ngraphs to handle this structure difference or distribution shifts remains\nunexplored. In this paper, we first discuss the limitations of previous\ngraph-based invariant learning methods from the perspective of data\naugmentation. Then, we propose \\textbf{HEI}, a framework capable of generating\ninvariant node representations through incorporating heterophily information to\ninfer latent environments without augmentation, which are then used for\ninvariant prediction, under heterophilic graph structure distribution shifts.\nWe theoretically show that our proposed method can achieve guaranteed\nperformance under heterophilic graph structure distribution shifts. Extensive\nexperiments on various benchmarks and backbones can also demonstrate the\neffectiveness of our method compared with existing state-of-the-art baselines.\n","authors":["Jinluan Yang","Zhengyu Chen","Teng Xiao","Wenqiao Zhang","Yong Lin","Kun Kuang"],"pdf_url":"https://arxiv.org/pdf/2408.09490v2.pdf","comment":"15 pages, 7 figures"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2410.13863v1","updated":"2024-10-17T17:59:59Z","published":"2024-10-17T17:59:59Z","title":"Fluid: Scaling Autoregressive Text-to-image Generative Models with\n  Continuous Tokens","summary":"  Scaling up autoregressive models in vision has not proven as beneficial as in\nlarge language models. In this work, we investigate this scaling problem in the\ncontext of text-to-image generation, focusing on two critical factors: whether\nmodels use discrete or continuous tokens, and whether tokens are generated in a\nrandom or fixed raster order using BERT- or GPT-like transformer architectures.\nOur empirical results show that, while all models scale effectively in terms of\nvalidation loss, their evaluation performance -- measured by FID, GenEval\nscore, and visual quality -- follows different trends. Models based on\ncontinuous tokens achieve significantly better visual quality than those using\ndiscrete tokens. Furthermore, the generation order and attention mechanisms\nsignificantly affect the GenEval score: random-order models achieve notably\nbetter GenEval scores compared to raster-order models. Inspired by these\nfindings, we train Fluid, a random-order autoregressive model on continuous\ntokens. Fluid 10.5B model achieves a new state-of-the-art zero-shot FID of 6.16\non MS-COCO 30K, and 0.69 overall score on the GenEval benchmark. We hope our\nfindings and results will encourage future efforts to further bridge the\nscaling gap between vision and language models.\n","authors":["Lijie Fan","Tianhong Li","Siyang Qin","Yuanzhen Li","Chen Sun","Michael Rubinstein","Deqing Sun","Kaiming He","Yonglong Tian"],"pdf_url":"https://arxiv.org/pdf/2410.13863v1.pdf","comment":"Tech report"},{"id":"http://arxiv.org/abs/2410.13857v1","updated":"2024-10-17T17:59:35Z","published":"2024-10-17T17:59:35Z","title":"How Numerical Precision Affects Mathematical Reasoning Capabilities of\n  LLMs","summary":"  Despite the remarkable success of Transformer-based Large Language Models\n(LLMs) across various domains, understanding and enhancing their mathematical\ncapabilities remains a significant challenge. In this paper, we conduct a\nrigorous theoretical analysis of LLMs' mathematical abilities, with a specific\nfocus on their arithmetic performances. We identify numerical precision as a\nkey factor that influences their effectiveness in mathematical tasks. Our\nresults show that Transformers operating with low numerical precision fail to\naddress arithmetic tasks, such as iterated addition and integer multiplication,\nunless the model size grows super-polynomially with respect to the input\nlength. In contrast, Transformers with standard numerical precision can\nefficiently handle these tasks with significantly smaller model sizes. We\nfurther support our theoretical findings through empirical experiments that\nexplore the impact of varying numerical precision on arithmetic tasks,\nproviding valuable insights for improving the mathematical reasoning\ncapabilities of LLMs.\n","authors":["Guhao Feng","Kai Yang","Yuntian Gu","Xinyue Ai","Shengjie Luo","Jiacheng Sun","Di He","Zhenguo Li","Liwei Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13857v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13855v1","updated":"2024-10-17T17:59:25Z","published":"2024-10-17T17:59:25Z","title":"Diffusing States and Matching Scores: A New Framework for Imitation\n  Learning","summary":"  Adversarial Imitation Learning is traditionally framed as a two-player\nzero-sum game between a learner and an adversarially chosen cost function, and\ncan therefore be thought of as the sequential generalization of a Generative\nAdversarial Network (GAN). A prominent example of this framework is Generative\nAdversarial Imitation Learning (GAIL). However, in recent years, diffusion\nmodels have emerged as a non-adversarial alternative to GANs that merely\nrequire training a score function via regression, yet produce generations of a\nhigher quality. In response, we investigate how to lift insights from diffusion\nmodeling to the sequential setting. We propose diffusing states and performing\nscore-matching along diffused states to measure the discrepancy between the\nexpert's and learner's states. Thus, our approach only requires training score\nfunctions to predict noises via standard regression, making it significantly\neasier and more stable to train than adversarial methods. Theoretically, we\nprove first- and second-order instance-dependent bounds with linear scaling in\nthe horizon, proving that our approach avoids the compounding errors that\nstymie offline approaches to imitation learning. Empirically, we show our\napproach outperforms GAN-style imitation learning baselines across various\ncontinuous control problems, including complex tasks like controlling humanoids\nto walk, sit, and crawl.\n","authors":["Runzhe Wu","Yiding Chen","Gokul Swamy","Kianté Brantley","Wen Sun"],"pdf_url":"https://arxiv.org/pdf/2410.13855v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13853v1","updated":"2024-10-17T17:59:09Z","published":"2024-10-17T17:59:09Z","title":"AutoAL: Automated Active Learning with Differentiable Query Strategy\n  Search","summary":"  As deep learning continues to evolve, the need for data efficiency becomes\nincreasingly important. Considering labeling large datasets is both\ntime-consuming and expensive, active learning (AL) provides a promising\nsolution to this challenge by iteratively selecting the most informative\nsubsets of examples to train deep neural networks, thereby reducing the\nlabeling cost. However, the effectiveness of different AL algorithms can vary\nsignificantly across data scenarios, and determining which AL algorithm best\nfits a given task remains a challenging problem. This work presents the first\ndifferentiable AL strategy search method, named AutoAL, which is designed on\ntop of existing AL sampling strategies. AutoAL consists of two neural nets,\nnamed SearchNet and FitNet, which are optimized concurrently under a\ndifferentiable bi-level optimization framework. For any given task, SearchNet\nand FitNet are iteratively co-optimized using the labeled data, learning how\nwell a set of candidate AL algorithms perform on that task. With the optimal AL\nstrategies identified, SearchNet selects a small subset from the unlabeled pool\nfor querying their annotations, enabling efficient training of the task model.\nExperimental results demonstrate that AutoAL consistently achieves superior\naccuracy compared to all candidate AL algorithms and other selective AL\napproaches, showcasing its potential for adapting and integrating multiple\nexisting AL methods across diverse tasks and domains. Code will be available\nat: https://github.com/haizailache999/AutoAL.\n","authors":["Yifeng Wang","Xueying Zhan","Siyu Huang"],"pdf_url":"https://arxiv.org/pdf/2410.13853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13852v1","updated":"2024-10-17T17:59:03Z","published":"2024-10-17T17:59:03Z","title":"Retrospective Learning from Interactions","summary":"  Multi-turn interactions between large language models (LLMs) and users\nnaturally include implicit feedback signals. If an LLM responds in an\nunexpected way to an instruction, the user is likely to signal it by rephrasing\nthe request, expressing frustration, or pivoting to an alternative task. Such\nsignals are task-independent and occupy a relatively constrained subspace of\nlanguage, allowing the LLM to identify them even if it fails on the actual\ntask. This creates an avenue for continually learning from interactions without\nadditional annotations. We introduce ReSpect, a method to learn from such\nsignals in past interactions via retrospection. We deploy ReSpect in a new\nmultimodal interaction scenario, where humans instruct an LLM to solve an\nabstract reasoning task with a combinatorial solution space. Through thousands\nof interactions with humans, we show how ReSpect gradually improves task\ncompletion rate from 31% to 82%, all without any external annotation.\n","authors":["Zizhao Chen","Mustafa Omer Gul","Yiwei Chen","Gloria Geng","Anne Wu","Yoav Artzi"],"pdf_url":"https://arxiv.org/pdf/2410.13852v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13850v1","updated":"2024-10-17T17:59:02Z","published":"2024-10-17T17:59:02Z","title":"Influence Functions for Scalable Data Attribution in Diffusion Models","summary":"  Diffusion models have led to significant advancements in generative\nmodelling. Yet their widespread adoption poses challenges regarding data\nattribution and interpretability. In this paper, we aim to help address such\nchallenges in diffusion models by developing an \\textit{influence functions}\nframework. Influence function-based data attribution methods approximate how a\nmodel's output would have changed if some training data were removed. In\nsupervised learning, this is usually used for predicting how the loss on a\nparticular example would change. For diffusion models, we focus on predicting\nthe change in the probability of generating a particular example via several\nproxy measurements. We show how to formulate influence functions for such\nquantities and how previously proposed methods can be interpreted as particular\ndesign choices in our framework. To ensure scalability of the Hessian\ncomputations in influence functions, we systematically develop K-FAC\napproximations based on generalised Gauss-Newton matrices specifically tailored\nto diffusion models. We recast previously proposed methods as specific design\nchoices in our framework and show that our recommended method outperforms\nprevious data attribution approaches on common evaluations, such as the Linear\nData-modelling Score (LDS) or retraining without top influences, without the\nneed for method-specific hyperparameter tuning.\n","authors":["Bruno Mlodozeniec","Runa Eschenhagen","Juhan Bae","Alexander Immer","David Krueger","Richard Turner"],"pdf_url":"https://arxiv.org/pdf/2410.13850v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13849v1","updated":"2024-10-17T17:59:01Z","published":"2024-10-17T17:59:01Z","title":"From Gradient Clipping to Normalization for Heavy Tailed SGD","summary":"  Recent empirical evidence indicates that many machine learning applications\ninvolve heavy-tailed gradient noise, which challenges the standard assumptions\nof bounded variance in stochastic optimization. Gradient clipping has emerged\nas a popular tool to handle this heavy-tailed noise, as it achieves good\nperformance in this setting both theoretically and practically. However, our\ncurrent theoretical understanding of non-convex gradient clipping has three\nmain shortcomings. First, the theory hinges on large, increasing clipping\nthresholds, which are in stark contrast to the small constant clipping\nthresholds employed in practice. Second, clipping thresholds require knowledge\nof problem-dependent parameters to guarantee convergence. Lastly, even with\nthis knowledge, current sampling complexity upper bounds for the method are\nsub-optimal in nearly all parameters. To address these issues, we study\nconvergence of Normalized SGD (NSGD). First, we establish a parameter-free\nsample complexity for NSGD of\n$\\mathcal{O}\\left(\\varepsilon^{-\\frac{2p}{p-1}}\\right)$ to find an\n$\\varepsilon$-stationary point. Furthermore, we prove tightness of this result,\nby providing a matching algorithm-specific lower bound. In the setting where\nall problem parameters are known, we show this complexity is improved to\n$\\mathcal{O}\\left(\\varepsilon^{-\\frac{3p-2}{p-1}}\\right)$, matching the\npreviously known lower bound for all first-order methods in all problem\ndependent parameters. Finally, we establish high-probability convergence of\nNSGD with a mild logarithmic dependence on the failure probability. Our work\ncomplements the studies of gradient clipping under heavy tailed noise improving\nthe sample complexities of existing algorithms and offering an alternative\nmechanism to achieve high probability convergence.\n","authors":["Florian Hübler","Ilyas Fatkhullin","Niao He"],"pdf_url":"https://arxiv.org/pdf/2410.13849v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08928v2","updated":"2024-10-17T17:58:53Z","published":"2024-10-11T15:53:24Z","title":"Towards Multilingual LLM Evaluation for European Languages","summary":"  The rise of Large Language Models (LLMs) has revolutionized natural language\nprocessing across numerous languages and tasks. However, evaluating LLM\nperformance in a consistent and meaningful way across multiple European\nlanguages remains challenging, especially due to the scarcity of\nlanguage-parallel multilingual benchmarks. We introduce a multilingual\nevaluation approach tailored for European languages. We employ translated\nversions of five widely-used benchmarks to assess the capabilities of 40 LLMs\nacross 21 European languages. Our contributions include examining the\neffectiveness of translated benchmarks, assessing the impact of different\ntranslation services, and offering a multilingual evaluation framework for LLMs\nthat includes newly created datasets: EU20-MMLU, EU20-HellaSwag, EU20-ARC,\nEU20-TruthfulQA, and EU20-GSM8K. The benchmarks and results are made publicly\navailable to encourage further research in multilingual LLM evaluation.\n","authors":["Klaudia Thellmann","Bernhard Stadler","Michael Fromm","Jasper Schulze Buschhoff","Alex Jude","Fabio Barth","Johannes Leveling","Nicolas Flores-Herr","Joachim Köhler","René Jäkel","Mehdi Ali"],"pdf_url":"https://arxiv.org/pdf/2410.08928v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13846v1","updated":"2024-10-17T17:58:14Z","published":"2024-10-17T17:58:14Z","title":"SimLayerKV: A Simple Framework for Layer-Level KV Cache Reduction","summary":"  Recent advancements in large language models (LLMs) have extended their\ncapabilities to handle long contexts. However, increasing the number of model\nlayers and the length of input sequences significantly escalates the memory\nrequired to store key-value (KV) cache, posing challenges for efficient\ninference. To mitigate this issue, we present SimLayerKV, a simple yet\neffective method that reduces inter-layer KV cache redundancies by selectively\ndropping cache in identified lazy layers. Our approach is based on the\nobservation that certain layers in long-context LLMs exhibit \"lazy\" behavior,\ncontributing less to modeling long-range dependencies compared to non-lazy\nlayers. By analyzing attention weight patterns, we find that the behavior of\nthese lazy layers is consistent across tokens during generation for a given\ninput. This insight motivates our SimLayerKV, which identifies lazy layers and\nreduces their KV cache accordingly. SimLayerKV is training-free, generalizable,\nand can be implemented with only seven lines of code. We conduct extensive\nexperiments on three representative LLMs, e.g., LLaMA2-7B, LLaMA3-8B, and\nMistral-7B across 16 tasks from the LongBench benchmark. The results\ndemonstrate that SimLayerKV achieves a KV cache compression ratio of 5$\\times$\nwith only a 1.2% performance drop when combined with 4-bit quantization. Our\ncode is available at https://github.com/sail-sg/SimLayerKV.\n","authors":["Xuan Zhang","Cunxiao Du","Chao Du","Tianyu Pang","Wei Gao","Min Lin"],"pdf_url":"https://arxiv.org/pdf/2410.13846v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13841v1","updated":"2024-10-17T17:56:53Z","published":"2024-10-17T17:56:53Z","title":"A Unified View of Delta Parameter Editing in Post-Trained Large-Scale\n  Models","summary":"  Post-training has emerged as a crucial paradigm for adapting large-scale\npre-trained models to various tasks, whose effects are fully reflected by delta\nparameters (i.e., the disparity between post-trained and pre-trained\nparameters). While numerous studies have explored delta parameter properties\nvia operations like pruning, quantization, low-rank approximation, and\nextrapolation, a unified framework for systematically examining these\ncharacteristics has been lacking. In this paper, we propose a novel perspective\nbased on Riemann sum approximation of the loss function to elucidate delta\nparameter editing operations. Our analysis categorizes existing methods into\nthree classes based on their post-editing performance: competitive, decreased,\nand improved, explaining how they are expressed by the Riemann sum\napproximation term and how they alter the model performance. Extensive\nexperiments on both visual and language models, including ViT, LLaMA 3, Qwen 2,\nand Mistral, corroborate our theoretical findings. Furthermore, we introduce\nextensions to existing techniques like DARE and BitDelta, highlighting their\nlimitations in leveraging the properties of delta parameters and reorganizing\nthem into general expressions to enhance the applicability and effectiveness of\ndelta parameter editing in post-trained models.\n","authors":["Qiaoyu Tang","Le Yu","Bowen Yu","Hongyu Lin","Keming Lu","Yaojie Lu","Xianpei Han","Le Sun"],"pdf_url":"https://arxiv.org/pdf/2410.13841v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13837v1","updated":"2024-10-17T17:55:05Z","published":"2024-10-17T17:55:05Z","title":"ORSO: Accelerating Reward Design via Online Reward Selection and Policy\n  Optimization","summary":"  Reward shaping is a critical component in reinforcement learning (RL),\nparticularly for complex tasks where sparse rewards can hinder learning. While\nshaping rewards have been introduced to provide additional guidance, selecting\neffective shaping functions remains challenging and computationally expensive.\nThis paper introduces Online Reward Selection and Policy Optimization (ORSO), a\nnovel approach that frames shaping reward selection as an online model\nselection problem. ORSO employs principled exploration strategies to\nautomatically identify promising shaping reward functions without human\nintervention, balancing exploration and exploitation with provable regret\nguarantees. We demonstrate ORSO's effectiveness across various continuous\ncontrol tasks using the Isaac Gym simulator. Compared to traditional methods\nthat fully evaluate each shaping reward function, ORSO significantly improves\nsample efficiency, reduces computational time, and consistently identifies\nhigh-quality reward functions that produce policies comparable to those\ngenerated by domain experts through hand-engineered rewards.\n","authors":["Chen Bo Calvin Zhang","Zhang-Wei Hong","Aldo Pacchiano","Pulkit Agrawal"],"pdf_url":"https://arxiv.org/pdf/2410.13837v1.pdf","comment":"preprint, 35 pages, 23 figures"},{"id":"http://arxiv.org/abs/2410.13835v1","updated":"2024-10-17T17:54:06Z","published":"2024-10-17T17:54:06Z","title":"Active-Dormant Attention Heads: Mechanistically Demystifying\n  Extreme-Token Phenomena in LLMs","summary":"  Practitioners have consistently observed three puzzling phenomena in\ntransformer-based large language models (LLMs): attention sinks, value-state\ndrains, and residual-state peaks, collectively referred to as extreme-token\nphenomena. These phenomena are characterized by certain so-called \"sink tokens\"\nreceiving disproportionately high attention weights, exhibiting significantly\nsmaller value states, and having much larger residual-state norms than those of\nother tokens. These extreme tokens give rise to various challenges in LLM\ninference, quantization, and interpretability.\n  We elucidate the mechanisms behind extreme-token phenomena. First, we show\nthat these phenomena arise in very simple architectures -- transformers with\none to three layers -- trained on a toy model, the Bigram-Backcopy (BB) task.\nIn this setting, we identify an active-dormant mechanism, where attention heads\nbecome sinks for specific input domains while remaining non-sinks for others.\nOur theoretical analysis of the training dynamics reveals that these phenomena\nare driven by a mutual reinforcement mechanism. Building on these insights, we\npropose strategies to mitigate extreme-token phenomena during pretraining,\nincluding replacing softmax with ReLU and Adam with SGD. Next, we extend our\nanalysis to pretrained LLMs, including Llama and OLMo, showing that many\nattention heads exhibit a similar active-dormant mechanism as in the BB task,\nand that the mutual reinforcement mechanism also governs the emergence of\nextreme-token phenomena during LLM pretraining. Our results reveal that many of\nthe static and dynamic properties of extreme-token phenomena predicted by the\nBB task align with observations in pretrained LLMs.\n","authors":["Tianyu Guo","Druv Pai","Yu Bai","Jiantao Jiao","Michael I. Jordan","Song Mei"],"pdf_url":"https://arxiv.org/pdf/2410.13835v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13831v1","updated":"2024-10-17T17:53:01Z","published":"2024-10-17T17:53:01Z","title":"The Disparate Benefits of Deep Ensembles","summary":"  Ensembles of Deep Neural Networks, Deep Ensembles, are widely used as a\nsimple way to boost predictive performance. However, their impact on\nalgorithmic fairness is not well understood yet. Algorithmic fairness\ninvestigates how a model's performance varies across different groups,\ntypically defined by protected attributes such as age, gender, or race. In this\nwork, we investigate the interplay between the performance gains from Deep\nEnsembles and fairness. Our analysis reveals that they unevenly favor different\ngroups in what we refer to as a disparate benefits effect. We empirically\ninvestigate this effect with Deep Ensembles applied to popular facial analysis\nand medical imaging datasets, where protected group attributes are given and\nfind that it occurs for multiple established group fairness metrics, including\nstatistical parity and equal opportunity. Furthermore, we identify the\nper-group difference in predictive diversity of ensemble members as the\npotential cause of the disparate benefits effect. Finally, we evaluate\ndifferent approaches to reduce unfairness due to the disparate benefits effect.\nOur findings show that post-processing is an effective method to mitigate this\nunfairness while preserving the improved performance of Deep Ensembles.\n","authors":["Kajetan Schweighofer","Adrian Arnaiz-Rodriguez","Sepp Hochreiter","Nuria Oliver"],"pdf_url":"https://arxiv.org/pdf/2410.13831v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13828v1","updated":"2024-10-17T17:52:01Z","published":"2024-10-17T17:52:01Z","title":"A Common Pitfall of Margin-based Language Model Alignment: Gradient\n  Entanglement","summary":"  Reinforcement Learning from Human Feedback (RLHF) has become the predominant\napproach for language model (LM) alignment. At its core, RLHF uses a\nmargin-based loss for preference optimization, specifying ideal LM behavior\nonly by the difference between preferred and dispreferred responses. In this\npaper, we identify a common pitfall of margin-based methods -- the\nunder-specification of ideal LM behavior on preferred and dispreferred\nresponses individually, which leads to two unintended consequences as the\nmargin increases: (1) The probability of dispreferred (e.g., unsafe) responses\nmay increase, resulting in potential safety alignment failures. (2) The\nprobability of preferred responses may decrease, even when those responses are\nideal. We demystify the reasons behind these problematic behaviors:\nmargin-based losses couple the change in the preferred probability to the\ngradient of the dispreferred one, and vice versa, often preventing the\npreferred probability from increasing while the dispreferred one decreases, and\nthus causing a synchronized increase or decrease in both probabilities. We term\nthis effect, inherent in margin-based objectives, gradient entanglement.\nFormally, we derive conditions for general margin-based alignment objectives\nunder which gradient entanglement becomes concerning: the inner product of the\ngradients of preferred and dispreferred log-probabilities is large relative to\nthe individual gradient norms. We theoretically investigate why such inner\nproducts can be large when aligning language models and empirically validate\nour findings. Empirical implications of our framework extend to explaining\nimportant differences in the training dynamics of various preference\noptimization algorithms, and suggesting potential algorithm designs to mitigate\nthe under-specification issue of margin-based methods and thereby improving\nlanguage model alignment.\n","authors":["Hui Yuan","Yifan Zeng","Yue Wu","Huazheng Wang","Mengdi Wang","Liu Leqi"],"pdf_url":"https://arxiv.org/pdf/2410.13828v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13826v1","updated":"2024-10-17T17:51:40Z","published":"2024-10-17T17:51:40Z","title":"Unearthing Skill-Level Insights for Understanding Trade-Offs of\n  Foundation Models","summary":"  With models getting stronger, evaluations have grown more complex, testing\nmultiple skills in one benchmark and even in the same instance at once.\nHowever, skill-wise performance is obscured when inspecting aggregate accuracy,\nunder-utilizing the rich signal modern benchmarks contain. We propose an\nautomatic approach to recover the underlying skills relevant for any evaluation\ninstance, by way of inspecting model-generated rationales. After validating the\nrelevance of rationale-parsed skills and inferring skills for $46$k instances\nover $12$ benchmarks, we observe many skills to be common across benchmarks,\nresulting in the curation of hundreds of skill-slices (i.e. sets of instances\ntesting a common skill). Inspecting accuracy over these slices yields novel\ninsights on model trade-offs: e.g., compared to GPT-4o and Claude 3.5 Sonnet,\non average, Gemini 1.5 Pro is $18\\%$ more accurate in \"computing molar mass\",\nbut $19\\%$ less accurate in \"applying constitutional law\", despite the overall\naccuracies of the three models differing by a mere $0.4\\%$. Furthermore, we\ndemonstrate the practical utility of our approach by showing that insights\nderived from skill slice analysis can generalize to held-out instances: when\nrouting each instance to the model strongest on the relevant skills, we see a\n$3\\%$ accuracy improvement over our $12$ dataset corpus. Our skill-slices and\nframework open a new avenue in model evaluation, leveraging skill-specific\nanalyses to unlock a more granular and actionable understanding of model\ncapabilities.\n","authors":["Mazda Moayeri","Vidhisha Balachandran","Varun Chandrasekaran","Safoora Yousefi","Thomas Fel","Soheil Feizi","Besmira Nushi","Neel Joshi","Vibhav Vineet"],"pdf_url":"https://arxiv.org/pdf/2410.13826v1.pdf","comment":"Code at: github.com/microsoft/skill-slice-insights"},{"id":"http://arxiv.org/abs/2407.16833v2","updated":"2024-10-17T17:51:19Z","published":"2024-07-23T20:51:52Z","title":"Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive\n  Study and Hybrid Approach","summary":"  Retrieval Augmented Generation (RAG) has been a powerful tool for Large\nLanguage Models (LLMs) to efficiently process overly lengthy contexts. However,\nrecent LLMs like Gemini-1.5 and GPT-4 show exceptional capabilities to\nunderstand long contexts directly. We conduct a comprehensive comparison\nbetween RAG and long-context (LC) LLMs, aiming to leverage the strengths of\nboth. We benchmark RAG and LC across various public datasets using three latest\nLLMs. Results reveal that when resourced sufficiently, LC consistently\noutperforms RAG in terms of average performance. However, RAG's significantly\nlower cost remains a distinct advantage. Based on this observation, we propose\nSelf-Route, a simple yet effective method that routes queries to RAG or LC\nbased on model self-reflection. Self-Route significantly reduces the\ncomputation cost while maintaining a comparable performance to LC. Our findings\nprovide a guideline for long-context applications of LLMs using RAG and LC.\n","authors":["Zhuowan Li","Cheng Li","Mingyang Zhang","Qiaozhu Mei","Michael Bendersky"],"pdf_url":"https://arxiv.org/pdf/2407.16833v2.pdf","comment":"Accepted to EMNLP 2024 industry track"},{"id":"http://arxiv.org/abs/2410.13821v1","updated":"2024-10-17T17:47:54Z","published":"2024-10-17T17:47:54Z","title":"Artificial Kuramoto Oscillatory Neurons","summary":"  It has long been known in both neuroscience and AI that ``binding'' between\nneurons leads to a form of competitive learning where representations are\ncompressed in order to represent more abstract concepts in deeper layers of the\nnetwork. More recently, it was also hypothesized that dynamic (spatiotemporal)\nrepresentations play an important role in both neuroscience and AI. Building on\nthese ideas, we introduce Artificial Kuramoto Oscillatory Neurons (AKOrN) as a\ndynamical alternative to threshold units, which can be combined with arbitrary\nconnectivity designs such as fully connected, convolutional, or attentive\nmechanisms. Our generalized Kuramoto updates bind neurons together through\ntheir synchronization dynamics. We show that this idea provides performance\nimprovements across a wide spectrum of tasks such as unsupervised object\ndiscovery, adversarial robustness, calibrated uncertainty quantification, and\nreasoning. We believe that these empirical results show the importance of\nrethinking our assumptions at the most basic neuronal level of neural\nrepresentation, and in particular show the importance of dynamical\nrepresentations.\n","authors":["Takeru Miyato","Sindy Löwe","Andreas Geiger","Max Welling"],"pdf_url":"https://arxiv.org/pdf/2410.13821v1.pdf","comment":"Code: https://github.com/autonomousvision/akorn"},{"id":"http://arxiv.org/abs/2410.13816v1","updated":"2024-10-17T17:46:26Z","published":"2024-10-17T17:46:26Z","title":"Steering Your Generalists: Improving Robotic Foundation Models via Value\n  Guidance","summary":"  Large, general-purpose robotic policies trained on diverse demonstration\ndatasets have been shown to be remarkably effective both for controlling a\nvariety of robots in a range of different scenes, and for acquiring broad\nrepertoires of manipulation skills. However, the data that such policies are\ntrained on is generally of mixed quality -- not only are human-collected\ndemonstrations unlikely to perform the task perfectly, but the larger the\ndataset is, the harder it is to curate only the highest quality examples. It\nalso remains unclear how optimal data from one embodiment is for training on\nanother embodiment. In this paper, we present a general and broadly applicable\napproach that enhances the performance of such generalist robot policies at\ndeployment time by re-ranking their actions according to a value function\nlearned via offline RL. This approach, which we call Value-Guided Policy\nSteering (V-GPS), is compatible with a wide range of different generalist\npolicies, without needing to fine-tune or even access the weights of the\npolicy. We show that the same value function can improve the performance of\nfive different state-of-the-art policies with different architectures, even\nthough they were trained on distinct datasets, attaining consistent performance\nimprovement on multiple robotic platforms across a total of 12 tasks. Code and\nvideos can be found at: https://nakamotoo.github.io/V-GPS\n","authors":["Mitsuhiko Nakamoto","Oier Mees","Aviral Kumar","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2410.13816v1.pdf","comment":"Conference on Robot Learning (CoRL) 2024. Project Page:\n  https://nakamotoo.github.io/V-GPS"},{"id":"http://arxiv.org/abs/2404.11018v3","updated":"2024-10-17T17:45:09Z","published":"2024-04-17T02:49:26Z","title":"Many-Shot In-Context Learning","summary":"  Large language models (LLMs) excel at few-shot in-context learning (ICL) --\nlearning from a few examples provided in context at inference, without any\nweight updates. Newly expanded context windows allow us to investigate ICL with\nhundreds or thousands of examples -- the many-shot regime. Going from few-shot\nto many-shot, we observe significant performance gains across a wide variety of\ngenerative and discriminative tasks. While promising, many-shot ICL can be\nbottlenecked by the available amount of human-generated examples. To mitigate\nthis limitation, we explore two new settings: Reinforced and Unsupervised ICL.\nReinforced ICL uses model-generated chain-of-thought rationales in place of\nhuman examples. Unsupervised ICL removes rationales from the prompt altogether,\nand prompts the model only with domain-specific questions. We find that both\nReinforced and Unsupervised ICL can be quite effective in the many-shot regime,\nparticularly on complex reasoning tasks. Finally, we demonstrate that, unlike\nfew-shot learning, many-shot learning is effective at overriding pretraining\nbiases, can learn high-dimensional functions with numerical inputs, and\nperforms comparably to fine-tuning. We also find that inference cost increases\nlinearly in the many-shot regime, and frontier LLMs benefit from many-shot ICL\nto varying degrees. Our analysis also reveals the limitations of next-token\nprediction loss as an indicator of downstream ICL performance.\n","authors":["Rishabh Agarwal","Avi Singh","Lei M. Zhang","Bernd Bohnet","Luis Rosias","Stephanie Chan","Biao Zhang","Ankesh Anand","Zaheer Abbas","Azade Nova","John D. Co-Reyes","Eric Chu","Feryal Behbahani","Aleksandra Faust","Hugo Larochelle"],"pdf_url":"https://arxiv.org/pdf/2404.11018v3.pdf","comment":"NeurIPS (Spotlight)"},{"id":"http://arxiv.org/abs/2410.13812v1","updated":"2024-10-17T17:45:07Z","published":"2024-10-17T17:45:07Z","title":"Private Counterfactual Retrieval","summary":"  Transparency and explainability are two extremely important aspects to be\nconsidered when employing black-box machine learning models in high-stake\napplications. Providing counterfactual explanations is one way of catering this\nrequirement. However, this also poses a threat to the privacy of both the\ninstitution that is providing the explanation as well as the user who is\nrequesting it. In this work, we propose multiple schemes inspired by private\ninformation retrieval (PIR) techniques which ensure the \\emph{user's privacy}\nwhen retrieving counterfactual explanations. We present a scheme which\nretrieves the \\emph{exact} nearest neighbor counterfactual explanation from a\ndatabase of accepted points while achieving perfect (information-theoretic)\nprivacy for the user. While the scheme achieves perfect privacy for the user,\nsome leakage on the database is inevitable which we quantify using a mutual\ninformation based metric. Furthermore, we propose strategies to reduce this\nleakage to achieve an advanced degree of database privacy. We extend these\nschemes to incorporate user's preference on transforming their attributes, so\nthat a more actionable explanation can be received. Since our schemes rely on\nfinite field arithmetic, we empirically validate our schemes on real datasets\nto understand the trade-off between the accuracy and the finite field sizes.\n","authors":["Mohamed Nomeir","Pasan Dissanayake","Shreya Meel","Sanghamitra Dutta","Sennur Ulukus"],"pdf_url":"https://arxiv.org/pdf/2410.13812v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06615v2","updated":"2024-10-17T17:40:25Z","published":"2023-01-16T21:36:49Z","title":"Data-Driven Estimation of Heterogeneous Treatment Effects","summary":"  Estimating how a treatment affects different individuals, known as\nheterogeneous treatment effect estimation, is an important problem in empirical\nsciences. In the last few years, there has been a considerable interest in\nadapting machine learning algorithms to the problem of estimating heterogeneous\neffects from observational and experimental data. However, these algorithms\noften make strong assumptions about the observed features in the data and\nignore the structure of the underlying causal model, which can lead to biased\nestimation. At the same time, the underlying causal mechanism is rarely known\nin real-world datasets, making it hard to take it into consideration. In this\nwork, we provide a survey of state-of-the-art data-driven methods for\nheterogeneous treatment effect estimation using machine learning, broadly\ncategorizing them as methods that focus on counterfactual prediction and\nmethods that directly estimate the causal effect. We also provide an overview\nof a third category of methods which rely on structural causal models and learn\nthe model structure from data. Our empirical evaluation under various\nunderlying structural model mechanisms shows the advantages and deficiencies of\nexisting estimators and of the metrics for measuring their performance.\n","authors":["Christopher Tran","Keith Burghardt","Kristina Lerman","Elena Zheleva"],"pdf_url":"https://arxiv.org/pdf/2301.06615v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13802v1","updated":"2024-10-17T17:39:46Z","published":"2024-10-17T17:39:46Z","title":"Adversarial Testing as a Tool for Interpretability: Length-based\n  Overfitting of Elementary Functions in Transformers","summary":"  The Transformer model has a tendency to overfit various aspects of the\ntraining data, such as the overall sequence length. We study elementary string\nedit functions using a defined set of error indicators to interpret the\nbehaviour of the sequence-to-sequence Transformer. We show that generalization\nto shorter sequences is often possible, but confirm that longer sequences are\nhighly problematic, although partially correct answers are often obtained.\nAdditionally, we find that other structural characteristics of the sequences,\nsuch as subsegment length, may be equally important. We hypothesize that the\nmodels learn algorithmic aspects of the tasks simultaneously with structural\naspects but adhering to the structural aspects is unfortunately often preferred\nby Transformer when they come into conflict.\n","authors":["Patrik Zavoral","Dušan Variš","Ondřej Bojar"],"pdf_url":"https://arxiv.org/pdf/2410.13802v1.pdf","comment":"9 pages, 8 figures, 2 tables; to be published"},{"id":"http://arxiv.org/abs/2410.13799v1","updated":"2024-10-17T17:38:44Z","published":"2024-10-17T17:38:44Z","title":"Machine-Learning Analysis of Radiative Decays to Dark Matter at the LHC","summary":"  The search for weakly interacting matter particles (WIMPs) is one of the main\nobjectives of the High Luminosity Large Hadron Collider (HL-LHC). In this work\nwe use Machine Learning (ML) techniques to explore WIMP radiative decays into a\nDark Matter (DM) candidate in a supersymmetric framework. The minimal\nsupersymmetric WIMP sector includes the lightest neutralino that can provide\nthe observed DM relic density through its co-annihilation with the second\nlightest neutralino and lightest chargino. Moreover, the direct DM detection\ncross section rates fulfill current experimental bounds and provide discovery\ntargets for the same region of model parameters in which the radiative decay of\nthe second lightest neutralino into a photon and the lightest neutralino is\nenhanced. This strongly motivates the search for radiatively decaying\nneutralinos which, however, suffers from strong backgrounds. We investigate the\nLHC reach in the search for these radiatively decaying particles by means of\ncut-based and ML methods and estimate its discovery potential in this\nwell-motivated, new physics scenario.\n","authors":["Ernesto Arganda","Marcela Carena","Martín de los Rios","Andres D. Perez","Duncan Rocha","Rosa M. Sandá Seoane","Carlos E. M. Wagner"],"pdf_url":"https://arxiv.org/pdf/2410.13799v1.pdf","comment":"32 pages, 9 figures, 3 tables, 4 appendices"},{"id":"http://arxiv.org/abs/2410.13800v1","updated":"2024-10-17T17:38:44Z","published":"2024-10-17T17:38:44Z","title":"Discrete distributions are learnable from metastable samples","summary":"  Markov chain samplers designed to sample from multi-variable distributions\noften undesirably get stuck in specific regions of their state space. This\ncauses such samplers to approximately sample from a metastable distribution\nwhich is usually quite different from the desired, stationary distribution of\nthe chain. We show that single-variable conditionals of metastable\ndistributions of reversible Markov chain samplers that satisfy a strong\nmetastability condition are on average very close to those of the true\ndistribution. This holds even when the metastable distribution is far away from\nthe true model in terms of global metrics like Kullback-Leibler divergence or\ntotal variation distance. This property allows us to learn the true model using\na conditional likelihood based estimator, even when the samples come from a\nmetastable distribution concentrated in a small region of the state space.\nExplicit examples of such metastable states can be constructed from regions\nthat effectively bottleneck the probability flow and cause poor mixing of the\nMarkov chain. For specific cases of binary pairwise undirected graphical\nmodels, we extend our results to further rigorously show that data coming from\nmetastable states can be used to learn the parameters of the energy function\nand recover the structure of the model.\n","authors":["Abhijith Jayakumar","Andrey Y. Lokhov","Sidhant Misra","Marc Vuffray"],"pdf_url":"https://arxiv.org/pdf/2410.13800v1.pdf","comment":"Preliminary version, 26 pages"},{"id":"http://arxiv.org/abs/2410.13798v1","updated":"2024-10-17T17:38:24Z","published":"2024-10-17T17:38:24Z","title":"Learning Graph Quantized Tokenizers for Transformers","summary":"  Transformers serve as the backbone architectures of Foundational Models,\nwhere a domain-specific tokenizer helps them adapt to various domains. Graph\nTransformers (GTs) have recently emerged as a leading model in geometric deep\nlearning, outperforming Graph Neural Networks (GNNs) in various graph learning\ntasks. However, the development of tokenizers for graphs has lagged behind\nother modalities, with existing approaches relying on heuristics or GNNs\nco-trained with Transformers. To address this, we introduce GQT (\\textbf{G}raph\n\\textbf{Q}uantized \\textbf{T}okenizer), which decouples tokenizer training from\nTransformer training by leveraging multi-task graph self-supervised learning,\nyielding robust and generalizable graph tokens. Furthermore, the GQT utilizes\nResidual Vector Quantization (RVQ) to learn hierarchical discrete tokens,\nresulting in significantly reduced memory requirements and improved\ngeneralization capabilities. By combining the GQT with token modulation, a\nTransformer encoder achieves state-of-the-art performance on 16 out of 18\nbenchmarks, including large-scale homophilic and heterophilic datasets. The\ncode is available at: https://github.com/limei0307/graph-tokenizer\n","authors":["Limei Wang","Kaveh Hassani","Si Zhang","Dongqi Fu","Baichuan Yuan","Weilin Cong","Zhigang Hua","Hao Wu","Ning Yao","Bo Long"],"pdf_url":"https://arxiv.org/pdf/2410.13798v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.14180v2","updated":"2024-10-17T17:38:00Z","published":"2023-12-19T00:36:53Z","title":"Dynamic Topic Language Model on Heterogeneous Children's Mental Health\n  Clinical Notes","summary":"  Mental health diseases affect children's lives and well-beings which have\nreceived increased attention since the COVID-19 pandemic. Analyzing psychiatric\nclinical notes with topic models is critical to evaluating children's mental\nstatus over time. However, few topic models are built for longitudinal\nsettings, and most existing approaches fail to capture temporal trajectories\nfor each document. To address these challenges, we develop a dynamic topic\nmodel with consistent topics and individualized temporal dependencies on the\nevolving document metadata. Our model preserves the semantic meaning of\ndiscovered topics over time and incorporates heterogeneity among documents. In\nparticular, when documents can be categorized, we propose a classifier-free\napproach to maximize topic heterogeneity across different document groups. We\nalso present an efficient variational optimization procedure adapted for the\nmultistage longitudinal setting. In this case study, we apply our method to the\npsychiatric clinical notes from a large tertiary pediatric hospital in Southern\nCalifornia and achieve a 38% increase in the overall coherence of extracted\ntopics. Our real data analysis reveals that children tend to express more\nnegative emotions during state shutdowns and more positive when schools reopen.\nFurthermore, it suggests that sexual and gender minority (SGM) children display\nmore pronounced reactions to major COVID-19 events and a greater sensitivity to\nvaccine-related news than non-SGM children. This study examines children's\nmental health progression during the pandemic and offers clinicians valuable\ninsights to recognize disparities in children's mental health related to their\nsexual and gender identities.\n","authors":["Hanwen Ye","Tatiana Moreno","Adrianne Alpern","Louis Ehwerhemuepha","Annie Qu"],"pdf_url":"https://arxiv.org/pdf/2312.14180v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13794v1","updated":"2024-10-17T17:34:06Z","published":"2024-10-17T17:34:06Z","title":"Arbitrarily-Conditioned Multi-Functional Diffusion for Multi-Physics\n  Emulation","summary":"  Modern physics simulation often involves multiple functions of interests, and\ntraditional numerical approaches are known to be complex and computationally\ncostly. While machine learning-based surrogate models can offer significant\ncost reductions, most focus on a single task, such as forward prediction, and\ntypically lack uncertainty quantification -- an essential component in many\napplications. To overcome these limitations, we propose Arbitrarily-Conditioned\nMulti-Functional Diffusion (ACMFD), a versatile probabilistic surrogate model\nfor multi-physics emulation. ACMFD can perform a wide range of tasks within a\nsingle framework, including forward prediction, various inverse problems, and\nsimulating data for entire systems or subsets of quantities conditioned on\nothers. Specifically, we extend the standard Denoising Diffusion Probabilistic\nModel (DDPM) for multi-functional generation by modeling noise as Gaussian\nprocesses (GP). We then introduce an innovative denoising loss. The training\ninvolves randomly sampling the conditioned part and fitting the corresponding\npredicted noise to zero, enabling ACMFD to flexibly generate function values\nconditioned on any other functions or quantities. To enable efficient training\nand sampling, and to flexibly handle irregularly sampled data, we use GPs to\ninterpolate function samples onto a grid, inducing a Kronecker product\nstructure for efficient computation. We demonstrate the advantages of ACMFD\nacross several fundamental multi-physics systems.\n","authors":["Da Long","Zhitong Xu","Guang Yang","Akil Narayan","Shandian Zhe"],"pdf_url":"https://arxiv.org/pdf/2410.13794v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13792v1","updated":"2024-10-17T17:32:35Z","published":"2024-10-17T17:32:35Z","title":"Analyzing Deep Transformer Models for Time Series Forecasting via\n  Manifold Learning","summary":"  Transformer models have consistently achieved remarkable results in various\ndomains such as natural language processing and computer vision. However,\ndespite ongoing research efforts to better understand these models, the field\nstill lacks a comprehensive understanding. This is particularly true for deep\ntime series forecasting methods, where analysis and understanding work is\nrelatively limited. Time series data, unlike image and text information, can be\nmore challenging to interpret and analyze. To address this, we approach the\nproblem from a manifold learning perspective, assuming that the latent\nrepresentations of time series forecasting models lie next to a low-dimensional\nmanifold. In our study, we focus on analyzing the geometric features of these\nlatent data manifolds, including intrinsic dimension and principal curvatures.\nOur findings reveal that deep transformer models exhibit similar geometric\nbehavior across layers, and these geometric features are correlated with model\nperformance. Additionally, we observe that untrained models initially have\ndifferent structures, but they rapidly converge during training. By leveraging\nour geometric analysis and differentiable tools, we can potentially design new\nand improved deep forecasting neural networks. This approach complements\nexisting analysis studies and contributes to a better understanding of\ntransformer models in the context of time series forecasting. Code is released\nat https://github.com/azencot-group/GATLM.\n","authors":["Ilya Kaufman","Omri Azencot"],"pdf_url":"https://arxiv.org/pdf/2410.13792v1.pdf","comment":"Accepted to TMLR 2024"},{"id":"http://arxiv.org/abs/2405.17882v2","updated":"2024-10-17T17:28:16Z","published":"2024-05-28T07:08:29Z","title":"Achieving Exponential Asymptotic Optimality in Average-Reward Restless\n  Bandits without Global Attractor Assumption","summary":"  We consider the infinite-horizon average-reward restless bandit problem. We\npropose a novel \\emph{two-set policy} that maintains two dynamic subsets of\narms: one subset of arms has a nearly optimal state distribution and takes\nactions according to an Optimal Local Control routine; the other subset of arms\nis driven towards the optimal state distribution and gradually merged into the\nfirst subset. We show that our two-set policy is asymptotically optimal with an\n$O(\\exp(-C N))$ optimality gap for an $N$-armed problem, under the mild\nassumptions of aperiodic-unichain, non-degeneracy, and local stability. Our\npolicy is the first to achieve \\emph{exponential asymptotic optimality} under\nthe above set of easy-to-verify assumptions, whereas prior work either requires\na strong \\emph{global attractor} assumption or only achieves an $O(1/\\sqrt{N})$\noptimality gap. We further discuss obstacles in weakening the assumptions by\ndemonstrating examples where exponential asymptotic optimality is not\nachievable when any of the three assumptions is violated. Notably, we prove a\nlower bound for a large class of locally unstable restless bandits, showing\nthat local stability is particularly fundamental for exponential asymptotic\noptimality. Finally, we use simulations to demonstrate that the two-set policy\noutperforms previous policies on certain RB problems and performs competitively\noverall.\n","authors":["Yige Hong","Qiaomin Xie","Yudong Chen","Weina Wang"],"pdf_url":"https://arxiv.org/pdf/2405.17882v2.pdf","comment":"55 pages, 4 figures. In this version we included simulations"},{"id":"http://arxiv.org/abs/2410.13782v1","updated":"2024-10-17T17:20:24Z","published":"2024-10-17T17:20:24Z","title":"DPLM-2: A Multimodal Diffusion Protein Language Model","summary":"  Proteins are essential macromolecules defined by their amino acid sequences,\nwhich determine their three-dimensional structures and, consequently, their\nfunctions in all living organisms. Therefore, generative protein modeling\nnecessitates a multimodal approach to simultaneously model, understand, and\ngenerate both sequences and structures. However, existing methods typically use\nseparate models for each modality, limiting their ability to capture the\nintricate relationships between sequence and structure. This results in\nsuboptimal performance in tasks that requires joint understanding and\ngeneration of both modalities. In this paper, we introduce DPLM-2, a multimodal\nprotein foundation model that extends discrete diffusion protein language model\n(DPLM) to accommodate both sequences and structures. To enable structural\nlearning with the language model, 3D coordinates are converted to discrete\ntokens using a lookup-free quantization-based tokenizer. By training on both\nexperimental and high-quality synthetic structures, DPLM-2 learns the joint\ndistribution of sequence and structure, as well as their marginals and\nconditionals. We also implement an efficient warm-up strategy to exploit the\nconnection between large-scale evolutionary data and structural inductive\nbiases from pre-trained sequence-based protein language models. Empirical\nevaluation shows that DPLM-2 can simultaneously generate highly compatible\namino acid sequences and their corresponding 3D structures eliminating the need\nfor a two-stage generation approach. Moreover, DPLM-2 demonstrates competitive\nperformance in various conditional generation tasks, including folding, inverse\nfolding, and scaffolding with multimodal motif inputs, as well as providing\nstructure-aware representations for predictive tasks.\n","authors":["Xinyou Wang","Zaixiang Zheng","Fei Ye","Dongyu Xue","Shujian Huang","Quanquan Gu"],"pdf_url":"https://arxiv.org/pdf/2410.13782v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13780v1","updated":"2024-10-17T17:19:48Z","published":"2024-10-17T17:19:48Z","title":"Optimal Quantization for Matrix Multiplication","summary":"  Recent work in machine learning community proposed multiple methods for\nperforming lossy compression (quantization) of large matrices. This\nquantization is important for accelerating matrix multiplication (main\ncomponent of large language models), which is often bottlenecked by the speed\nof loading these matrices from memory. Unlike classical vector quantization and\nrate-distortion theory, the goal of these new compression algorithms is to be\nable to approximate not the matrices themselves, but their matrix product.\nSpecifically, given a pair of real matrices $A,B$ an encoder (compressor) is\napplied to each of them independently producing descriptions with $R$ bits per\nentry. These representations subsequently are used by the decoder to estimate\nmatrix product $A^\\top B$. In this work, we provide a non-asymptotic lower\nbound on the mean squared error of this approximation (as a function of rate\n$R$) for the case of matrices $A,B$ with iid Gaussian entries. Algorithmically,\nwe construct a universal quantizer based on nested lattices with an explicit\nguarantee of approximation error for any (non-random) pair of matrices $A$, $B$\nin terms of only Frobenius norms $\\|A\\|_F, \\|B\\|_F$ and $\\|A^\\top B\\|_F$. For\niid Gaussian matrices our quantizer achieves the lower bound and is, thus,\nasymptotically optimal. A practical low-complexity version of our quantizer\nachieves performance quite close to optimal. In information-theoretic terms we\nderive rate-distortion function for matrix multiplication of iid Gaussian\nmatrices.\n","authors":["Or Ordentlich","Yury Polyanskiy"],"pdf_url":"https://arxiv.org/pdf/2410.13780v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13779v1","updated":"2024-10-17T17:18:30Z","published":"2024-10-17T17:18:30Z","title":"The Mystery of the Pathological Path-star Task for Language Models","summary":"  The recently introduced path-star task is a minimal task designed to\nexemplify limitations to the abilities of language models (Bachmann and\nNagarajan, 2024). It involves a path-star graph where multiple arms radiate\nfrom a single starting node and each node is unique. Given the start node and a\nspecified target node that ends an arm, the task is to generate the arm\ncontaining that target node. This is straightforward for a human but\nsurprisingly difficult for language models, which did not outperform the random\nbaseline. The authors hypothesized this is due to a deficiency in\nteacher-forcing and the next-token prediction paradigm.\n  We demonstrate the task is learnable using teacher-forcing in alternative\nsettings and that the issue is partially due to representation. We introduce a\nregularization method using structured samples of the same graph but with\ndiffering target nodes, improving results across a variety of model types. We\nprovide RASP proofs showing the task is theoretically solvable. Finally, we\nfind settings where an encoder-only model can consistently solve the task.\n","authors":["Arvid Frydenlund"],"pdf_url":"https://arxiv.org/pdf/2410.13779v1.pdf","comment":"EMNLP 2024 Main"},{"id":"http://arxiv.org/abs/2410.13778v1","updated":"2024-10-17T17:17:38Z","published":"2024-10-17T17:17:38Z","title":"Change Detection in Multivariate data streams: Online Analysis with\n  Kernel-QuantTree","summary":"  We present Kernel-QuantTree Exponentially Weighted Moving Average (KQT-EWMA),\na non-parametric change-detection algorithm that combines the Kernel-QuantTree\n(KQT) histogram and the EWMA statistic to monitor multivariate data streams\nonline. The resulting monitoring scheme is very flexible, since histograms can\nbe used to model any stationary distribution, and practical, since the\ndistribution of test statistics does not depend on the distribution of\ndatastream in stationary conditions (non-parametric monitoring). KQT-EWMA\nenables controlling false alarms by operating at a pre-determined Average Run\nLength ($ARL_0$), which measures the expected number of stationary samples to\nbe monitored before triggering a false alarm. The latter peculiarity is in\ncontrast with most non-parametric change-detection tests, which rarely can\ncontrol the $ARL_0$ a priori. Our experiments on synthetic and real-world\ndatasets demonstrate that KQT-EWMA can control $ARL_0$ while achieving\ndetection delays comparable to or lower than state-of-the-art methods designed\nto work in the same conditions.\n","authors":["Michelangelo Olmo Nogara Notarianni","Filippo Leveni","Diego Stucchi","Luca Frittoli","Giacomo Boracchi"],"pdf_url":"https://arxiv.org/pdf/2410.13778v1.pdf","comment":"AALTD workshop at ECML 2024 (https://ecml-aaltd.github.io/aaltd2024/)"},{"id":"http://arxiv.org/abs/2410.13569v1","updated":"2024-10-17T17:17:09Z","published":"2024-10-17T17:17:09Z","title":"Representing Model Weights with Language using Tree Experts","summary":"  The increasing availability of public models begs the question: can we train\nneural networks that use other networks as input? This paper learns to\nrepresent models within a joint space that embeds both model weights and\nlanguage. However, machine learning on model weights is challenging as model\nweights often exhibit significant variation unrelated to the models' semantic\nproperties (nuisance variation). We identify a key property of real-world\nmodels: most public models belong to a small set of Model Trees, where all\nmodels within a tree are fine-tuned from a common ancestor (e.g., a foundation\nmodel). Importantly, we find that within each tree there is less nuisance\nvariation between models. For example, while classifying models according to\ntheir training dataset generally requires complex architectures, in our case,\neven a linear classifier trained on a single layer is often effective. While\neffective, linear layers are computationally expensive as model weights are\nvery high dimensional. To address this, we introduce Probing Experts (ProbeX),\na theoretically motivated, lightweight probing method. Notably, ProbeX is the\nfirst probing method designed to learn from the weights of just a single model\nlayer. We also construct and release a dataset that simulates the structure of\npublic model repositories. Our results show that ProbeX can effectively map the\nweights of large models into a shared weight-language embedding space.\nFurthermore, we demonstrate the impressive generalization of our method,\nachieving zero-shot model classification and retrieval.\n","authors":["Eliahu Horwitz","Bar Cavia","Jonathan Kahana","Yedid Hoshen"],"pdf_url":"https://arxiv.org/pdf/2410.13569v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13773v1","updated":"2024-10-17T17:11:33Z","published":"2024-10-17T17:11:33Z","title":"Enhancing Retail Sales Forecasting with Optimized Machine Learning\n  Models","summary":"  In retail sales forecasting, accurately predicting future sales is crucial\nfor inventory management and strategic planning. Traditional methods like LR\noften fall short due to the complexity of sales data, which includes\nseasonality and numerous product families. Recent advancements in machine\nlearning (ML) provide more robust alternatives. This research benefits from the\npower of ML, particularly Random Forest (RF), Gradient Boosting (GB), Support\nVector Regression (SVR), and XGBoost, to improve prediction accuracy. Despite\nadvancements, a significant gap exists in handling complex datasets with high\nseasonality and multiple product families. The proposed solution involves\nimplementing and optimizing a RF model, leveraging hyperparameter tuning\nthrough randomized search cross-validation. This approach addresses the\ncomplexities of the dataset, capturing intricate patterns that traditional\nmethods miss. The optimized RF model achieved an R-squared value of 0.945,\nsubstantially higher than the initial RF model and traditional LR, which had an\nR-squared of 0.531. The model reduced the root mean squared logarithmic error\n(RMSLE) to 1.172, demonstrating its superior predictive capability. The\noptimized RF model did better than cutting-edge models like Gradient Boosting\n(R-squared: 0.942), SVR (R-squared: 0.940), and XGBoost (R-squared: 0.939),\nwith more minor mean squared error (MSE) and mean absolute error (MAE) numbers.\nThe results demonstrate that the optimized RF model excels in forecasting\nretail sales, handling the datasets complexity with higher accuracy and\nreliability. This research highlights the importance of advanced ML techniques\nin predictive analytics, offering a significant improvement over traditional\nmethods and other contemporary models.\n","authors":["Priyam Ganguly","Isha Mukherjee"],"pdf_url":"https://arxiv.org/pdf/2410.13773v1.pdf","comment":"IEEE 4th ICSES 2024"},{"id":"http://arxiv.org/abs/2410.13772v1","updated":"2024-10-17T17:09:56Z","published":"2024-10-17T17:09:56Z","title":"Is Prior-Free Black-Box Non-Stationary Reinforcement Learning Feasible?","summary":"  We study the problem of Non-Stationary Reinforcement Learning (NS-RL) without\nprior knowledge about the system's non-stationarity. A state-of-the-art,\nblack-box algorithm, known as MASTER, is considered, with a focus on\nidentifying the conditions under which it can achieve its stated goals.\nSpecifically, we prove that MASTER's non-stationarity detection mechanism is\nnot triggered for practical choices of horizon, leading to performance akin to\na random restarting algorithm. Moreover, we show that the regret bound for\nMASTER, while being order optimal, stays above the worst-case linear regret\nuntil unreasonably large values of the horizon. To validate these observations,\nMASTER is tested for the special case of piecewise stationary multi-armed\nbandits, along with methods that employ random restarting, and others that use\nquickest change detection to restart. A simple, order optimal random restarting\nalgorithm, that has prior knowledge of the non-stationarity is proposed as a\nbaseline. The behavior of the MASTER algorithm is validated in simulations, and\nit is shown that methods employing quickest change detection are more robust\nand consistently outperform MASTER and other random restarting approaches.\n","authors":["Argyrios Gerogiannis","Yu-Han Huang","Venugopal V. Veeravalli"],"pdf_url":"https://arxiv.org/pdf/2410.13772v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13770v1","updated":"2024-10-17T17:08:39Z","published":"2024-10-17T17:08:39Z","title":"Probing the Latent Hierarchical Structure of Data via Diffusion Models","summary":"  High-dimensional data must be highly structured to be learnable. Although the\ncompositional and hierarchical nature of data is often put forward to explain\nlearnability, quantitative measurements establishing these properties are\nscarce. Likewise, accessing the latent variables underlying such a data\nstructure remains a challenge. In this work, we show that forward-backward\nexperiments in diffusion-based models, where data is noised and then denoised\nto generate new samples, are a promising tool to probe the latent structure of\ndata. We predict in simple hierarchical models that, in this process, changes\nin data occur by correlated chunks, with a length scale that diverges at a\nnoise level where a phase transition is known to take place. Remarkably, we\nconfirm this prediction in both text and image datasets using state-of-the-art\ndiffusion models. Our results show how latent variable changes manifest in the\ndata and establish how to measure these effects in real data using diffusion\nmodels.\n","authors":["Antonio Sclocchi","Alessandro Favero","Noam Itzhak Levi","Matthieu Wyart"],"pdf_url":"https://arxiv.org/pdf/2410.13770v1.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2405.11785v2","updated":"2024-10-17T17:00:37Z","published":"2024-05-20T05:08:55Z","title":"Guided Multi-objective Generative AI to Enhance Structure-based Drug\n  Design","summary":"  Generative AI has the potential to revolutionize drug discovery. Yet, despite\nrecent advances in deep learning, existing models cannot generate molecules\nthat satisfy all desired physicochemical properties. Herein, we describe\nIDOLpro, a generative chemistry AI combining diffusion with multi-objective\noptimization for structure-based drug design. Differentiable scoring functions\nguide the latent variables of the diffusion model to explore uncharted chemical\nspace and generate novel ligands in silico, optimizing a plurality of target\nphysicochemical properties. We demonstrate our platform's effectiveness by\ngenerating ligands with optimized binding affinity and synthetic accessibility\non two benchmark sets. IDOLpro produces ligands with binding affinities over\n10%-20% better than the next best state-of-the-art method on each test set,\nproducing more drug-like molecules with generally better synthetic\naccessibility scores than other methods. We do a head-to-head comparison of\nIDOLpro against a classic virtual screen of a large database of drug-like\nmolecules. We show that IDOLpro can generate molecules for a range of important\ndisease-related targets with better binding affinity and synthetic\naccessibility than any molecule found in the virtual screen while being over\n100x faster and less expensive to run. On a test set of experimental complexes,\nIDOLpro is the first to produce molecules with better binding affinities than\nexperimentally observed ligands. IDOLpro can accommodate other scoring\nfunctions (e.g. ADME-Tox) to accelerate hit-finding, hit-to-lead, and lead\noptimization for drug discovery.\n","authors":["Amit Kadan","Kevin Ryczko","Erika Lloyd","Adrian Roitberg","Takeshi Yamazaki"],"pdf_url":"https://arxiv.org/pdf/2405.11785v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.19300v2","updated":"2024-10-17T16:59:19Z","published":"2023-10-30T06:35:31Z","title":"Stage-Aware Learning for Dynamic Treatments","summary":"  Recent advances in dynamic treatment regimes (DTRs) facilitate the search for\noptimal treatments, which are tailored to individuals' specific needs and able\nto maximize their expected clinical benefits. However, existing algorithms\nrelying on consistent trajectories, such as inverse probability weighting\nestimators (IPWEs), could suffer from insufficient sample size under optimal\ntreatments and a growing number of decision-making stages, particularly in the\ncontext of chronic diseases. To address these challenges, we propose a novel\nindividualized learning method which estimates the DTR with a focus on\nprioritizing alignment between the observed treatment trajectory and the one\nobtained by the optimal regime across decision stages. By relaxing the\nrestriction that the observed trajectory must be fully aligned with the optimal\ntreatments, our approach substantially improves the sample efficiency and\nstability of IPWE-based methods. In particular, the proposed learning scheme\nbuilds a more general framework which includes the popular outcome weighted\nlearning framework as a special case of ours. Moreover, we introduce the notion\nof stage importance scores along with an attention mechanism to explicitly\naccount for heterogeneity among decision stages. We establish the theoretical\nproperties of the proposed approach, including the Fisher consistency and\nfinite-sample performance bound. Empirically, we evaluate the proposed method\nin extensive simulated environments and a real case study for the COVID-19\npandemic.\n","authors":["Hanwen Ye","Wenzhuo Zhou","Ruoqing Zhu","Annie Qu"],"pdf_url":"https://arxiv.org/pdf/2310.19300v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13762v1","updated":"2024-10-17T16:56:04Z","published":"2024-10-17T16:56:04Z","title":"Virtual Sensing for Real-Time Degradation Monitoring of Nuclear Systems:\n  Leveraging DeepONet for Enhanced Sensing Coverage for Digital Twin-Enabling\n  Technology","summary":"  Effective real-time monitoring technique is crucial for detecting material\ndegradation and maintaining the structural integrity of nuclear systems to\nensure both safety and operational efficiency. Traditional physical sensor\nsystems face limitations such as installation challenges, high costs, and\ndifficulties in measuring critical parameters in hard-to-reach or harsh\nenvironments, often resulting in incomplete data coverage. Machine\nlearning-driven virtual sensors offer a promising solution by enhancing\nphysical sensor capabilities to monitor critical degradation indicators like\npressure, velocity, and turbulence. However, conventional machine learning\nmodels struggle with real-time monitoring due to the high-dimensional nature of\nreactor data and the need for frequent retraining. This paper explores the use\nof Deep Operator Networks (DeepONet) within a digital twin (DT) framework to\npredict key thermal-hydraulic parameters in the hot leg of an AP-1000\nPressurized Water Reactor (PWR). In this study, DeepONet is trained with\ndifferent operational conditions, which relaxes the requirement of continuous\nretraining, making it suitable for online and real-time prediction components\nfor DT. Our results show that DeepONet achieves accurate predictions with low\nmean squared error and relative L2 error and can make predictions on unknown\ndata 160,000 times faster than traditional finite element (FE) simulations.\nThis speed and accuracy make DeepONet a powerful tool for tracking conditions\nthat contribute to material degradation in real-time, enhancing reactor safety\nand longevity.\n","authors":["Raisa Bentay Hossain","Farid Ahmed","Kazuma Kobayashi","Seid Koric","Diab Abueidda","Syed Bahauddin Alam"],"pdf_url":"https://arxiv.org/pdf/2410.13762v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13761v1","updated":"2024-10-17T16:56:01Z","published":"2024-10-17T16:56:01Z","title":"GDeR: Safeguarding Efficiency, Balancing, and Robustness via\n  Prototypical Graph Pruning","summary":"  Training high-quality deep models necessitates vast amounts of data,\nresulting in overwhelming computational and memory demands. Recently, data\npruning, distillation, and coreset selection have been developed to streamline\ndata volume by retaining, synthesizing, or selecting a small yet informative\nsubset from the full set. Among these methods, data pruning incurs the least\nadditional training cost and offers the most practical acceleration benefits.\nHowever, it is the most vulnerable, often suffering significant performance\ndegradation with imbalanced or biased data schema, thus raising concerns about\nits accuracy and reliability in on-device deployment. Therefore, there is a\nlooming need for a new data pruning paradigm that maintains the efficiency of\nprevious practices while ensuring balance and robustness. Unlike the fields of\ncomputer vision and natural language processing, where mature solutions have\nbeen developed to address these issues, graph neural networks (GNNs) continue\nto struggle with increasingly large-scale, imbalanced, and noisy datasets,\nlacking a unified dataset pruning solution. To achieve this, we introduce a\nnovel dynamic soft-pruning method, GDeR, designed to update the training\n``basket'' during the process using trainable prototypes. GDeR first constructs\na well-modeled graph embedding hypersphere and then samples\n\\textit{representative, balanced, and unbiased subsets} from this embedding\nspace, which achieves the goal we called Graph Training Debugging. Extensive\nexperiments on five datasets across three GNN backbones, demonstrate that GDeR\n(I) achieves or surpasses the performance of the full dataset with 30%~50%\nfewer training samples, (II) attains up to a 2.81x lossless training speedup,\nand (III) outperforms state-of-the-art pruning methods in imbalanced training\nand noisy training scenarios by 0.3%~4.3% and 3.6%~7.8%, respectively.\n","authors":["Guibin Zhang","Haonan Dong","Yuchen Zhang","Zhixun Li","Dingshuo Chen","Kai Wang","Tianlong Chen","Yuxuan Liang","Dawei Cheng","Kun Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13761v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.13756v1","updated":"2024-10-17T16:53:43Z","published":"2024-10-17T16:53:43Z","title":"CLIMB: Language-Guided Continual Learning for Task Planning with\n  Iterative Model Building","summary":"  Intelligent and reliable task planning is a core capability for generalized\nrobotics, requiring a descriptive domain representation that sufficiently\nmodels all object and state information for the scene. We present CLIMB, a\ncontinual learning framework for robot task planning that leverages foundation\nmodels and execution feedback to guide domain model construction. CLIMB can\nbuild a model from a natural language description, learn non-obvious predicates\nwhile solving tasks, and store that information for future problems. We\ndemonstrate the ability of CLIMB to improve performance in common planning\nenvironments compared to baseline methods. We also develop the BlocksWorld++\ndomain, a simulated environment with an easily usable real counterpart,\ntogether with a curriculum of tasks with progressing difficulty for evaluating\ncontinual learning. Additional details and demonstrations for this system can\nbe found at https://plan-with-climb.github.io/ .\n","authors":["Walker Byrnes","Miroslav Bogdanovic","Avi Balakirsky","Stephen Balakirsky","Animesh Garg"],"pdf_url":"https://arxiv.org/pdf/2410.13756v1.pdf","comment":"6 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.13754v1","updated":"2024-10-17T16:52:28Z","published":"2024-10-17T16:52:28Z","title":"MixEval-X: Any-to-Any Evaluations from Real-World Data Mixtures","summary":"  Perceiving and generating diverse modalities are crucial for AI models to\neffectively learn from and engage with real-world signals, necessitating\nreliable evaluations for their development. We identify two major issues in\ncurrent evaluations: (1) inconsistent standards, shaped by different\ncommunities with varying protocols and maturity levels; and (2) significant\nquery, grading, and generalization biases. To address these, we introduce\nMixEval-X, the first any-to-any real-world benchmark designed to optimize and\nstandardize evaluations across input and output modalities. We propose\nmulti-modal benchmark mixture and adaptation-rectification pipelines to\nreconstruct real-world task distributions, ensuring evaluations generalize\neffectively to real-world use cases. Extensive meta-evaluations show our\napproach effectively aligns benchmark samples with real-world task\ndistributions and the model rankings correlate strongly with that of\ncrowd-sourced real-world evaluations (up to 0.98). We provide comprehensive\nleaderboards to rerank existing models and organizations and offer insights to\nenhance understanding of multi-modal evaluations and inform future research.\n","authors":["Jinjie Ni","Yifan Song","Deepanway Ghosal","Bo Li","David Junhao Zhang","Xiang Yue","Fuzhao Xue","Zian Zheng","Kaichen Zhang","Mahir Shah","Kabir Jain","Yang You","Michael Shieh"],"pdf_url":"https://arxiv.org/pdf/2410.13754v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13749v1","updated":"2024-10-17T16:48:51Z","published":"2024-10-17T16:48:51Z","title":"Supervised Kernel Thinning","summary":"  The kernel thinning algorithm of Dwivedi & Mackey (2024) provides a\nbetter-than-i.i.d. compression of a generic set of points. By generating\nhigh-fidelity coresets of size significantly smaller than the input points, KT\nis known to speed up unsupervised tasks like Monte Carlo integration,\nuncertainty quantification, and non-parametric hypothesis testing, with minimal\nloss in statistical accuracy. In this work, we generalize the KT algorithm to\nspeed up supervised learning problems involving kernel methods. Specifically,\nwe combine two classical algorithms--Nadaraya-Watson (NW) regression or kernel\nsmoothing, and kernel ridge regression (KRR)--with KT to provide a quadratic\nspeed-up in both training and inference times. We show how distribution\ncompression with KT in each setting reduces to constructing an appropriate\nkernel, and introduce the Kernel-Thinned NW and Kernel-Thinned KRR estimators.\nWe prove that KT-based regression estimators enjoy significantly superior\ncomputational efficiency over the full-data estimators and improved statistical\nefficiency over i.i.d. subsampling of the training data. En route, we also\nprovide a novel multiplicative error guarantee for compressing with KT. We\nvalidate our design choices with both simulations and real data experiments.\n","authors":["Albert Gong","Kyuseong Choi","Raaz Dwivedi"],"pdf_url":"https://arxiv.org/pdf/2410.13749v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.14015v2","updated":"2024-10-17T16:47:51Z","published":"2024-02-21T18:54:37Z","title":"Corrective Machine Unlearning","summary":"  Machine Learning models increasingly face data integrity challenges due to\nthe use of large-scale training datasets drawn from the Internet. We study what\nmodel developers can do if they detect that some data was manipulated or\nincorrect. Such manipulated data can cause adverse effects including\nvulnerability to backdoored samples, systemic biases, and reduced accuracy on\ncertain input domains. Realistically, all manipulated training samples cannot\nbe identified, and only a small, representative subset of the affected data can\nbe flagged.\n  We formalize Corrective Machine Unlearning as the problem of mitigating the\nimpact of data affected by unknown manipulations on a trained model, only\nhaving identified a subset of the corrupted data. We demonstrate that the\nproblem of corrective unlearning has significantly different requirements from\ntraditional privacy-oriented unlearning. We find most existing unlearning\nmethods, including retraining-from-scratch without the deletion set, require\nmost of the manipulated data to be identified for effective corrective\nunlearning. However, one approach, Selective Synaptic Dampening, achieves\nlimited success, unlearning adverse effects with just a small portion of the\nmanipulated samples in our setting, which shows encouraging signs for future\nprogress. We hope our work spurs research towards developing better methods for\ncorrective unlearning and offers practitioners a new strategy to handle data\nintegrity challenges arising from web-scale training. Code is available at\nhttps://github.com/drimpossible/corrective-unlearning-bench.\n","authors":["Shashwat Goel","Ameya Prabhu","Philip Torr","Ponnurangam Kumaraguru","Amartya Sanyal"],"pdf_url":"https://arxiv.org/pdf/2402.14015v2.pdf","comment":"Published in Transactions of Machine Learning Research (TMLR), 17\n  pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.01024v2","updated":"2024-10-17T16:45:16Z","published":"2024-10-01T19:33:39Z","title":"GPTreeO: An R package for continual regression with dividing local\n  Gaussian processes","summary":"  We introduce GPTreeO, a flexible R package for scalable Gaussian process (GP)\nregression, particularly tailored to continual learning problems. GPTreeO\nbuilds upon the Dividing Local Gaussian Processes (DLGP) algorithm, in which a\nbinary tree of local GP regressors is dynamically constructed using a continual\nstream of input data. In GPTreeO we extend the original DLGP algorithm by\nallowing continual optimisation of the GP hyperparameters, incorporating\nuncertainty calibration, and introducing new strategies for how the local\npartitions are created. Moreover, the modular code structure allows users to\ninterface their favourite GP library to perform the local GP regression in\nGPTreeO. The flexibility of GPTreeO gives the user fine-grained control of the\nbalance between computational speed, accuracy, stability and smoothness. We\nconduct a sensitivity analysis to show how GPTreeO's configurable features\nimpact the regression performance in a continual learning setting.\n","authors":["Timo Braun","Anders Kvellestad","Riccardo De Bin"],"pdf_url":"https://arxiv.org/pdf/2410.01024v2.pdf","comment":"Updated the bibliography, and is now equivalent to the journal\n  submission"},{"id":"http://arxiv.org/abs/2410.13746v1","updated":"2024-10-17T16:42:12Z","published":"2024-10-17T16:42:12Z","title":"Theory on Score-Mismatched Diffusion Models and Zero-Shot Conditional\n  Samplers","summary":"  The denoising diffusion model has recently emerged as a powerful generative\ntechnique, capable of transforming noise into meaningful data. While\ntheoretical convergence guarantees for diffusion models are well established\nwhen the target distribution aligns with the training distribution, practical\nscenarios often present mismatches. One common case is in zero-shot conditional\ndiffusion sampling, where the target conditional distribution is different from\nthe (unconditional) training distribution. These score-mismatched diffusion\nmodels remain largely unexplored from a theoretical perspective. In this paper,\nwe present the first performance guarantee with explicit dimensional\ndependencies for general score-mismatched diffusion samplers, focusing on\ntarget distributions with finite second moments. We show that score mismatches\nresult in an asymptotic distributional bias between the target and sampling\ndistributions, proportional to the accumulated mismatch between the target and\ntraining distributions. This result can be directly applied to zero-shot\nconditional samplers for any conditional model, irrespective of measurement\nnoise. Interestingly, the derived convergence upper bound offers useful\nguidance for designing a novel bias-optimal zero-shot sampler in linear\nconditional models that minimizes the asymptotic bias. For such bias-optimal\nsamplers, we further establish convergence guarantees with explicit\ndependencies on dimension and conditioning, applied to several interesting\ntarget distributions, including those with bounded support and Gaussian\nmixtures. Our findings are supported by numerical studies.\n","authors":["Yuchen Liang","Peizhong Ju","Yingbin Liang","Ness Shroff"],"pdf_url":"https://arxiv.org/pdf/2410.13746v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13743v1","updated":"2024-10-17T16:39:53Z","published":"2024-10-17T16:39:53Z","title":"Single-Timescale Multi-Sequence Stochastic Approximation Without Fixed\n  Point Smoothness: Theories and Applications","summary":"  Stochastic approximation (SA) that involves multiple coupled sequences, known\nas multiple-sequence SA (MSSA), finds diverse applications in the fields of\nsignal processing and machine learning. However, existing theoretical\nunderstandings {of} MSSA are limited: the multi-timescale analysis implies a\nslow convergence rate, whereas the single-timescale analysis relies on a\nstringent fixed point smoothness assumption. This paper establishes tighter\nsingle-timescale analysis for MSSA, without assuming smoothness of the fixed\npoints. Our theoretical findings reveal that, when all involved operators are\nstrongly monotone, MSSA converges at a rate of $\\tilde{\\mathcal{O}}(K^{-1})$,\nwhere $K$ denotes the total number of iterations. In addition, when all\ninvolved operators are strongly monotone except for the main one, MSSA\nconverges at a rate of $\\mathcal{O}(K^{-\\frac{1}{2}})$. These theoretical\nfindings align with those established for single-sequence SA. Applying these\ntheoretical findings to bilevel optimization and communication-efficient\ndistributed learning offers relaxed assumptions and/or simpler algorithms with\nperformance guarantees, as validated by numerical experiments.\n","authors":["Yue Huang","Zhaoxian Wu","Shiqian Ma","Qing Ling"],"pdf_url":"https://arxiv.org/pdf/2410.13743v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13738v1","updated":"2024-10-17T16:37:33Z","published":"2024-10-17T16:37:33Z","title":"Improved Convergence Rate for Diffusion Probabilistic Models","summary":"  Score-based diffusion models have achieved remarkable empirical performance\nin the field of machine learning and artificial intelligence for their ability\nto generate high-quality new data instances from complex distributions.\nImproving our understanding of diffusion models, including mainly convergence\nanalysis for such models, has attracted a lot of interests. Despite a lot of\ntheoretical attempts, there still exists significant gap between theory and\npractice. Towards to close this gap, we establish an iteration complexity at\nthe order of $d^{1/3}\\varepsilon^{-2/3}$, which is better than\n$d^{5/12}\\varepsilon^{-1}$, the best known complexity achieved before our work.\nThis convergence analysis is based on a randomized midpoint method, which is\nfirst proposed for log-concave sampling (Shen and Lee, 2019), and then extended\nto diffusion models by Gupta et al. (2024). Our theory accommodates\n$\\varepsilon$-accurate score estimates, and does not require log-concavity on\nthe target distribution. Moreover, the algorithm can also be parallelized to\nrun in only $O(\\log^2(d/\\varepsilon))$ parallel rounds in a similar way to\nprior works.\n","authors":["Gen Li","Yuchen Jiao"],"pdf_url":"https://arxiv.org/pdf/2410.13738v1.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2410.13735v1","updated":"2024-10-17T16:37:03Z","published":"2024-10-17T16:37:03Z","title":"Optimizing Probabilistic Conformal Prediction with Vectorized\n  Non-Conformity Scores","summary":"  Generative models have shown significant promise in critical domains such as\nmedical diagnosis, autonomous driving, and climate science, where reliable\ndecision-making hinges on accurate uncertainty quantification. While\nprobabilistic conformal prediction (PCP) offers a powerful framework for this\npurpose, its coverage efficiency -- the size of the uncertainty set -- is\nlimited when dealing with complex underlying distributions and a finite number\nof generated samples. In this paper, we propose a novel PCP framework that\nenhances efficiency by first vectorizing the non-conformity scores with ranked\nsamples and then optimizing the shape of the prediction set by varying the\nquantiles for samples at the same rank. Our method delivers valid coverage\nwhile producing discontinuous and more efficient prediction sets, making it\nparticularly suited for high-stakes applications. We demonstrate the\neffectiveness of our approach through experiments on both synthetic and\nreal-world datasets.\n","authors":["Minxing Zheng","Shixiang Zhu"],"pdf_url":"https://arxiv.org/pdf/2410.13735v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13732v1","updated":"2024-10-17T16:36:14Z","published":"2024-10-17T16:36:14Z","title":"Reducing the Transformer Architecture to a Minimum","summary":"  Transformers are a widespread and successful model architecture, particularly\nin Natural Language Processing (NLP) and Computer Vision (CV). The essential\ninnovation of this architecture is the Attention Mechanism, which solves the\nproblem of extracting relevant context information from long sequences in NLP\nand realistic scenes in CV. A classical neural network component, a Multi-Layer\nPerceptron (MLP), complements the attention mechanism. Its necessity is\nfrequently justified by its capability of modeling nonlinear relationships.\nHowever, the attention mechanism itself is nonlinear through its internal use\nof similarity measures. A possible hypothesis is that this nonlinearity is\nsufficient for modeling typical application problems. As the MLPs usually\ncontain the most trainable parameters of the whole model, their omission would\nsubstantially reduce the parameter set size. Further components can also be\nreorganized to reduce the number of parameters. Under some conditions, query\nand key matrices can be collapsed into a single matrix of the same size. The\nsame is true about value and projection matrices, which can also be omitted\nwithout eliminating the substance of the attention mechanism. Initially, the\nsimilarity measure was defined asymmetrically, with peculiar properties such as\nthat a token is possibly dissimilar to itself. A possible symmetric definition\nrequires only half of the parameters. We have laid the groundwork by testing\nwidespread CV benchmarks: MNIST and CIFAR-10. The tests have shown that\nsimplified transformer architectures (a) without MLP, (b) with collapsed\nmatrices, and (c) symmetric similarity matrices exhibit similar performance as\nthe original architecture, saving up to 90% of parameters without hurting the\nclassification performance.\n","authors":["Bernhard Bermeitinger","Tomas Hrycej","Massimo Pavone","Julianus Kath","Siegfried Handschuh"],"pdf_url":"https://arxiv.org/pdf/2410.13732v1.pdf","comment":"8 pages, to appear in KDIR2024"},{"id":"http://arxiv.org/abs/2403.08854v2","updated":"2024-10-17T16:23:42Z","published":"2024-03-13T18:00:01Z","title":"Moments of Clarity: Streamlining Latent Spaces in Machine Learning using\n  Moment Pooling","summary":"  Many machine learning applications involve learning a latent representation\nof data, which is often high-dimensional and difficult to directly interpret.\nIn this work, we propose \"Moment Pooling\", a natural extension of Deep Sets\nnetworks which drastically decrease latent space dimensionality of these\nnetworks while maintaining or even improving performance. Moment Pooling\ngeneralizes the summation in Deep Sets to arbitrary multivariate moments, which\nenables the model to achieve a much higher effective latent dimensionality for\na fixed latent dimension. We demonstrate Moment Pooling on the collider physics\ntask of quark/gluon jet classification by extending Energy Flow Networks (EFNs)\nto Moment EFNs. We find that Moment EFNs with latent dimensions as small as 1\nperform similarly to ordinary EFNs with higher latent dimension. This small\nlatent dimension allows for the internal representation to be directly\nvisualized and interpreted, which in turn enables the learned internal jet\nrepresentation to be extracted in closed form.\n","authors":["Rikab Gambhir","Athis Osathapan","Jesse Thaler"],"pdf_url":"https://arxiv.org/pdf/2403.08854v2.pdf","comment":"15+7 pages, 14 figures, 7 tables. Code available at\n  https://github.com/athiso/moment and https://github.com/rikab/MomentAnalysis;\n  v2: Updated to match journal version"},{"id":"http://arxiv.org/abs/2402.14877v2","updated":"2024-10-17T16:22:48Z","published":"2024-02-21T20:59:19Z","title":"Machine-learning prediction of tipping with applications to the Atlantic\n  Meridional Overturning Circulation","summary":"  Anticipating a tipping point, a transition from one stable steady state to\nanother, is a problem of broad relevance due to the ubiquity of the phenomenon\nin diverse fields. The steady-state nature of the dynamics about a tipping\npoint makes its prediction significantly more challenging than predicting other\ntypes of critical transitions from oscillatory or chaotic dynamics. Exploiting\nthe benefits of noise, we develop a general data-driven and machine-learning\napproach to predicting potential future tipping in nonautonomous dynamical\nsystems and validate the framework using examples from different fields. As an\napplication, we address the problem of predicting the potential collapse of the\nAtlantic Meridional Overturning Circulation (AMOC), possibly driven by\nclimate-induced changes in the freshwater input to the North Atlantic. Our\npredictions based on synthetic and currently available empirical data place a\npotential collapse window spanning from 2040 to 2065, in consistency with the\nresults in the current literature.\n","authors":["Shirin Panahi","Ling-Wei Kong","Mohammadamin Moradi","Zheng-Meng Zhai","Bryan Glaz","Mulugeta Haile","Ying-Cheng Lai"],"pdf_url":"https://arxiv.org/pdf/2402.14877v2.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.13720v1","updated":"2024-10-17T16:22:46Z","published":"2024-10-17T16:22:46Z","title":"Movie Gen: A Cast of Media Foundation Models","summary":"  We present Movie Gen, a cast of foundation models that generates\nhigh-quality, 1080p HD videos with different aspect ratios and synchronized\naudio. We also show additional capabilities such as precise instruction-based\nvideo editing and generation of personalized videos based on a user's image.\nOur models set a new state-of-the-art on multiple tasks: text-to-video\nsynthesis, video personalization, video editing, video-to-audio generation, and\ntext-to-audio generation. Our largest video generation model is a 30B parameter\ntransformer trained with a maximum context length of 73K video tokens,\ncorresponding to a generated video of 16 seconds at 16 frames-per-second. We\nshow multiple technical innovations and simplifications on the architecture,\nlatent spaces, training objectives and recipes, data curation, evaluation\nprotocols, parallelization techniques, and inference optimizations that allow\nus to reap the benefits of scaling pre-training data, model size, and training\ncompute for training large scale media generation models. We hope this paper\nhelps the research community to accelerate progress and innovation in media\ngeneration models. All videos from this paper are available at\nhttps://go.fb.me/MovieGenResearchVideos.\n","authors":["Adam Polyak","Amit Zohar","Andrew Brown","Andros Tjandra","Animesh Sinha","Ann Lee","Apoorv Vyas","Bowen Shi","Chih-Yao Ma","Ching-Yao Chuang","David Yan","Dhruv Choudhary","Dingkang Wang","Geet Sethi","Guan Pang","Haoyu Ma","Ishan Misra","Ji Hou","Jialiang Wang","Kiran Jagadeesh","Kunpeng Li","Luxin Zhang","Mannat Singh","Mary Williamson","Matt Le","Matthew Yu","Mitesh Kumar Singh","Peizhao Zhang","Peter Vajda","Quentin Duval","Rohit Girdhar","Roshan Sumbaly","Sai Saketh Rambhatla","Sam Tsai","Samaneh Azadi","Samyak Datta","Sanyuan Chen","Sean Bell","Sharadh Ramaswamy","Shelly Sheynin","Siddharth Bhattacharya","Simran Motwani","Tao Xu","Tianhe Li","Tingbo Hou","Wei-Ning Hsu","Xi Yin","Xiaoliang Dai","Yaniv Taigman","Yaqiao Luo","Yen-Cheng Liu","Yi-Chiao Wu","Yue Zhao","Yuval Kirstain","Zecheng He","Zijian He","Albert Pumarola","Ali Thabet","Artsiom Sanakoyeu","Arun Mallya","Baishan Guo","Boris Araya","Breena Kerr","Carleigh Wood","Ce Liu","Cen Peng","Dimitry Vengertsev","Edgar Schonfeld","Elliot Blanchard","Felix Juefei-Xu","Fraylie Nord","Jeff Liang","John Hoffman","Jonas Kohler","Kaolin Fire","Karthik Sivakumar","Lawrence Chen","Licheng Yu","Luya Gao","Markos Georgopoulos","Rashel Moritz","Sara K. Sampson","Shikai Li","Simone Parmeggiani","Steve Fine","Tara Fowler","Vladan Petrovic","Yuming Du"],"pdf_url":"https://arxiv.org/pdf/2410.13720v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13714v1","updated":"2024-10-17T16:14:49Z","published":"2024-10-17T16:14:49Z","title":"Generation through the lens of learning theory","summary":"  We study generation through the lens of statistical learning theory. First,\nwe abstract and formalize the results of Gold [1967], Angluin [1979, 1980], and\nKleinberg and Mullainathan [2024] for language identification/generation in the\nlimit in terms of a binary hypothesis class defined over an abstract instance\nspace. Then, we formalize a different paradigm of generation studied by\nKleinberg and Mullainathan [2024], which we call ``uniform generation,\" and\nprovide a characterization of which hypothesis classes are uniformly\ngeneratable. As is standard in statistical learning theory, our\ncharacterization is in terms of the finiteness of a new combinatorial dimension\nwe call the Closure dimension. By doing so, we are able to compare\ngeneratability with predictability (captured via PAC and online learnability)\nand show that these two properties of hypothesis classes are\n\\emph{incompatible} - there are classes that are generatable but not\npredictable and vice versa.\n","authors":["Vinod Raman","Ambuj Tewari"],"pdf_url":"https://arxiv.org/pdf/2410.13714v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2410.13713v1","updated":"2024-10-17T16:12:55Z","published":"2024-10-17T16:12:55Z","title":"CrystalX: Ultra-Precision Crystal Structure Resolution and Error\n  Correction Using Deep Learning","summary":"  Atomic structure analysis of crystalline materials is a paramount endeavor in\nboth chemical and material sciences. This sophisticated technique necessitates\nnot only a solid foundation in crystallography but also a profound\ncomprehension of the intricacies of the accompanying software, posing a\nsignificant challenge in meeting the rigorous daily demands. For the first\ntime, we confront this challenge head-on by harnessing the power of deep\nlearning for ultra-precise structural analysis at the full-atom level. To\nvalidate the performance of the model, named CrystalX, we employed a vast\ndataset comprising over 50,000 X-ray diffraction measurements derived from\nauthentic experiments, demonstrating performance that is commensurate with\nhuman experts and adept at deciphering intricate geometric patterns.\nRemarkably, CrystalX revealed that even peer-reviewed publications can harbor\nerrors that are stealthy to human scrutiny, yet CrystalX adeptly rectifies\nthem. This deep learning model revolutionizes the time frame for crystal\nstructure analysis, slashing it down to seconds. It has already been\nsuccessfully applied in the structure analysis of newly discovered compounds in\nthe latest research without human intervention. Overall, CrystalX marks the\nbeginning of a new era in automating routine structural analysis within\nself-driving laboratories.\n","authors":["Kaipeng Zheng","Weiran Huang","Wanli Ouyang","Han-Sen Zhong","Yuqiang Li"],"pdf_url":"https://arxiv.org/pdf/2410.13713v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13709v1","updated":"2024-10-17T16:09:32Z","published":"2024-10-17T16:09:32Z","title":"On-device Federated Learning in Smartphones for Detecting Depression\n  from Reddit Posts","summary":"  Depression detection using deep learning models has been widely explored in\nprevious studies, especially due to the large amounts of data available from\nsocial media posts. These posts provide valuable information about individuals'\nmental health conditions and can be leveraged to train models and identify\npatterns in the data. However, distributed learning approaches have not been\nextensively explored in this domain. In this study, we adopt Federated Learning\n(FL) to facilitate decentralized training on smartphones while protecting user\ndata privacy. We train three neural network architectures--GRU, RNN, and LSTM\non Reddit posts to detect signs of depression and evaluate their performance\nunder heterogeneous FL settings. To optimize the training process, we leverage\na common tokenizer across all client devices, which reduces the computational\nload. Additionally, we analyze resource consumption and communication costs on\nsmartphones to assess their impact in a real-world FL environment. Our\nexperimental results demonstrate that the federated models achieve comparable\nperformance to the centralized models. This study highlights the potential of\nFL for decentralized mental health prediction by providing a secure and\nefficient model training process on edge devices.\n","authors":["Mustofa Ahmed","Abdul Muntakim","Nawrin Tabassum","Mohammad Asifur Rahim","Faisal Muhammad Shah"],"pdf_url":"https://arxiv.org/pdf/2410.13709v1.pdf","comment":"11 pages, 7 figures, Submitted to IEEE"},{"id":"http://arxiv.org/abs/2410.13708v1","updated":"2024-10-17T16:08:06Z","published":"2024-10-17T16:08:06Z","title":"On the Role of Attention Heads in Large Language Model Safety","summary":"  Large language models (LLMs) achieve state-of-the-art performance on multiple\nlanguage tasks, yet their safety guardrails can be circumvented, leading to\nharmful generations. In light of this, recent research on safety mechanisms has\nemerged, revealing that when safety representations or component are\nsuppressed, the safety capability of LLMs are compromised. However, existing\nresearch tends to overlook the safety impact of multi-head attention\nmechanisms, despite their crucial role in various model functionalities. Hence,\nin this paper, we aim to explore the connection between standard attention\nmechanisms and safety capability to fill this gap in the safety-related\nmechanistic interpretability. We propose a novel metric which tailored for\nmulti-head attention, the Safety Head ImPortant Score (Ships), to assess the\nindividual heads' contributions to model safety. Based on this, we generalize\nShips to the dataset level and further introduce the Safety Attention Head\nAttRibution Algorithm (Sahara) to attribute the critical safety attention heads\ninside the model. Our findings show that the special attention head has a\nsignificant impact on safety. Ablating a single safety head allows aligned\nmodel (e.g., Llama-2-7b-chat) to respond to 16 times more harmful queries,\nwhile only modifying 0.006% of the parameters, in contrast to the ~ 5%\nmodification required in previous studies. More importantly, we demonstrate\nthat attention heads primarily function as feature extractors for safety and\nmodels fine-tuned from the same base model exhibit overlapping safety heads\nthrough comprehensive experiments. Together, our attribution approach and\nfindings provide a novel perspective for unpacking the black box of safety\nmechanisms within large models.\n","authors":["Zhenhong Zhou","Haiyang Yu","Xinghua Zhang","Rongwu Xu","Fei Huang","Kun Wang","Yang Liu","Junfeng Fang","Yongbin Li"],"pdf_url":"https://arxiv.org/pdf/2410.13708v1.pdf","comment":"28 pages, 18 figures, 7 tables"},{"id":"http://arxiv.org/abs/2406.10322v2","updated":"2024-10-17T16:06:18Z","published":"2024-06-14T17:41:55Z","title":"LieRE: Generalizing Rotary Position Encodings","summary":"  While Rotary Position Embeddings (RoPE) for large language models have become\nwidely adopted, their application for other modalities has been slower. Here,\nwe introduce Lie group Relative position Encodings (LieRE) that goes beyond\nRoPE in supporting n-dimensional inputs. We evaluate the performance of LieRE\non 2D and 3D image classification tasks and observe that LieRE leads to marked\nrelative improvements in performance (up to 9.7% for 2D and up to 25.5% for\n3D), training efficiency (3.5x reduction), data efficiency (30%) compared to\nthe baselines of DeiT III, RoPE-Mixed and Vision-Llama.\nhttps://github.com/Stanford-AIMI/LieRE\n","authors":["Sophie Ostmeier","Brian Axelrod","Michael E. Moseley","Akshay Chaudhari","Curtis Langlotz"],"pdf_url":"https://arxiv.org/pdf/2406.10322v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13696v1","updated":"2024-10-17T16:03:43Z","published":"2024-10-17T16:03:43Z","title":"Efficient Function Placement in Virtual Networks: An Online Learning\n  Approach","summary":"  We propose a model for the virtual function placement problem and several\nnovel algorithms using ideas based on multi-armed bandits. We prove that these\nalgorithms learn the optimal placement policy rapidly, and their regret grows\nat a rate at most $O( N M \\sqrt{T\\ln T} )$ while respecting the feasibility\nconstraints with high probability. We show through numerical experiments that\nthose algorithms both have good practical performance and modest computational\ncomplexity. Using the proposed acceleration technique, they can be used to\nlearn in large networks where computational power is limited. Our experiments\nare fully reproducible, and the code is publicly available.\n","authors":["Wei Huang","Richard Combes","Hind Castel-Taleb","Badii Jouaber"],"pdf_url":"https://arxiv.org/pdf/2410.13696v1.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2406.16635v2","updated":"2024-10-17T15:45:10Z","published":"2024-06-24T13:41:08Z","title":"ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models","summary":"  The high power consumption and latency-sensitive deployments of large\nlanguage models (LLMs) have motivated efficiency techniques like quantization\nand sparsity. Contextual sparsity, where the sparsity pattern is\ninput-dependent, is crucial in LLMs because the permanent removal of attention\nheads or neurons from LLMs can significantly degrade accuracy. Prior work has\nattempted to model contextual sparsity using neural networks trained to predict\nactivation magnitudes, which can be used to dynamically prune structures with\nlow predicted activation magnitude. In this paper, we look beyond\nmagnitude-based pruning criteria to assess attention head and neuron importance\nin LLMs. We develop a novel predictor called ShadowLLM, which can shadow the\nLLM behavior and enforce better sparsity patterns, resulting in over 15%\nimprovement in end-to-end accuracy compared to prior methods. In addition,\nShadowLLM achieves up to a 20% speed-up over the state-of-the-art DejaVu\nframework. These enhancements are validated on Llama-2 and OPT models with up\nto 30 billion parameters. Our code is available at\n\\href{https://github.com/abdelfattah-lab/shadow_llm/}{ShadowLLM}.\n","authors":["Yash Akhauri","Ahmed F AbouElhamayed","Jordan Dotzel","Zhiru Zhang","Alexander M Rush","Safeen Huda","Mohamed S Abdelfattah"],"pdf_url":"https://arxiv.org/pdf/2406.16635v2.pdf","comment":"Accepted to EMNLP 2024 (Main, Long Paper)"},{"id":"http://arxiv.org/abs/2402.13251v3","updated":"2024-10-17T15:45:06Z","published":"2024-02-20T18:59:00Z","title":"FlashTex: Fast Relightable Mesh Texturing with LightControlNet","summary":"  Manually creating textures for 3D meshes is time-consuming, even for expert\nvisual content creators. We propose a fast approach for automatically texturing\nan input 3D mesh based on a user-provided text prompt. Importantly, our\napproach disentangles lighting from surface material/reflectance in the\nresulting texture so that the mesh can be properly relit and rendered in any\nlighting environment. We introduce LightControlNet, a new text-to-image model\nbased on the ControlNet architecture, which allows the specification of the\ndesired lighting as a conditioning image to the model. Our text-to-texture\npipeline then constructs the texture in two stages. The first stage produces a\nsparse set of visually consistent reference views of the mesh using\nLightControlNet. The second stage applies a texture optimization based on Score\nDistillation Sampling (SDS) that works with LightControlNet to increase the\ntexture quality while disentangling surface material from lighting. Our\nalgorithm is significantly faster than previous text-to-texture methods, while\nproducing high-quality and relightable textures.\n","authors":["Kangle Deng","Timothy Omernick","Alexander Weiss","Deva Ramanan","Jun-Yan Zhu","Tinghui Zhou","Maneesh Agrawala"],"pdf_url":"https://arxiv.org/pdf/2402.13251v3.pdf","comment":"Project page: https://flashtex.github.io/"},{"id":"http://arxiv.org/abs/2410.13681v1","updated":"2024-10-17T15:41:06Z","published":"2024-10-17T15:41:06Z","title":"Ab initio nonparametric variable selection for scalable Symbolic\n  Regression with large $p$","summary":"  Symbolic regression (SR) is a powerful technique for discovering symbolic\nexpressions that characterize nonlinear relationships in data, gaining\nincreasing attention for its interpretability, compactness, and robustness.\nHowever, existing SR methods do not scale to datasets with a large number of\ninput variables (referred to as extreme-scale SR), which are common in modern\nscientific applications. This ``large $p$'' setting, often accompanied by\nmeasurement error, leads to slow performance of SR methods and overly complex\nexpressions that are difficult to interpret. To address this scalability\nchallenge, we propose a method called PAN+SR, which combines a key idea of ab\ninitio nonparametric variable selection with SR to efficiently pre-screen large\ninput spaces and reduce search complexity while maintaining accuracy. The use\nof nonparametric methods eliminates model misspecification, supporting a\nstrategy called parametric-assisted nonparametric (PAN). We also extend\nSRBench, an open-source benchmarking platform, by incorporating\nhigh-dimensional regression problems with various signal-to-noise ratios. Our\nresults demonstrate that PAN+SR consistently enhances the performance of 17\ncontemporary SR methods, enabling several to achieve state-of-the-art\nperformance on these challenging datasets.\n","authors":["Shengbin Ye","Meng Li"],"pdf_url":"https://arxiv.org/pdf/2410.13681v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15355v4","updated":"2024-10-17T15:27:30Z","published":"2024-09-14T02:34:26Z","title":"Block-Attention for Efficient RAG","summary":"  We introduce Block-Attention, an attention mechanism designed to address the\nincreased inference latency and cost in Retrieval-Augmented Generation (RAG)\nscenarios. Traditional approaches often encode the entire context. Instead,\nBlock-Attention divides retrieved documents into discrete blocks, with each\nblock independently calculating key-value (KV) states except for the final\nblock. In RAG scenarios, by defining each passage as a block, Block-Attention\nenables us to reuse the KV states of passages that have been seen before,\nthereby significantly reducing the latency and the computation overhead during\ninference. The implementation of Block-Attention involves block segmentation,\nposition re-encoding, and fine-tuning the LLM to adapt to the Block-Attention\nmechanism. Experiments on four RAG benchmarks demonstrate that after block\nfine-tuning, the Block-Attention model achieves performance comparable to\nself-attention models (68.4\\% vs 67.9\\% on Llama3) or even superior performance\n(62.8\\% vs 59.6\\% on Mistral). Notably, Block-Attention significantly reduces\nthe time to first token (TTFT) and floating point operations (FLOPs) to a very\nlow level. It only takes 45 ms to output the first token for an input sequence\nwith a total length of 32K. Compared to the self-attention models, the time\nconsumption and corresponding FLOPs are reduced by 98.7\\% and 99.8\\%,\nrespectively.\n","authors":["East Sun","Yan Wang","Lan Tian"],"pdf_url":"https://arxiv.org/pdf/2409.15355v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.00489v2","updated":"2024-10-17T15:20:23Z","published":"2024-03-30T23:07:58Z","title":"Prompt-SAW: Leveraging Relation-Aware Graphs for Textual Prompt\n  Compression","summary":"  Large Language Models (LLMs) have shown exceptional abilities for multiple\ndifferent natural language processing tasks. While prompting is a crucial tool\nfor LLM inference, we observe that there is a significant cost associated with\nexceedingly lengthy prompts. Existing attempts to compress lengthy prompts lead\nto substandard results in terms of readability/interpretability of the\ncompressed prompt, with a detrimental impact on prompt utility. To address\nthis, we propose PromptSAW: Prompt compresSion via Relation AWare graphs, an\neffective strategy for prompt compression over task-agnostic and task-aware\nprompts. Prompt-SAW uses the prompt's textual information to build a graph and\nlater extracts key information elements in the graph to come up with the\ncompressed prompt. We also propose GSM8K-aug, i.e., an extended version of the\nexisting GSM8K benchmark for task-agnostic prompts in order to provide a\ncomprehensive evaluation platform. Experimental evaluation using benchmark\ndatasets shows that prompts compressed by Prompt-SAW are not only better in\nterms of readability, but they also outperform the best-performing baseline\nmodels by up to 10.1 and 77.1, respectively, for task-agnostic and task-aware\nsettings while compressing the original prompt text by 34.9 and 56.7.\n","authors":["Muhammad Asif Ali","Zhengping Li","Shu Yang","Keyuan Cheng","Yang Cao","Tianhao Huang","Guimin Hu","Weimin Lyu","Lijie Hu","Lu Yu","Di Wang"],"pdf_url":"https://arxiv.org/pdf/2404.00489v2.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2410.12176v2","updated":"2024-10-17T15:18:31Z","published":"2024-10-16T02:44:36Z","title":"Expected Sliced Transport Plans","summary":"  The optimal transport (OT) problem has gained significant traction in modern\nmachine learning for its ability to: (1) provide versatile metrics, such as\nWasserstein distances and their variants, and (2) determine optimal couplings\nbetween probability measures. To reduce the computational complexity of OT\nsolvers, methods like entropic regularization and sliced optimal transport have\nbeen proposed. The sliced OT framework improves efficiency by comparing\none-dimensional projections (slices) of high-dimensional distributions.\nHowever, despite their computational efficiency, sliced-Wasserstein approaches\nlack a transportation plan between the input measures, limiting their use in\nscenarios requiring explicit coupling. In this paper, we address two key\nquestions: Can a transportation plan be constructed between two probability\nmeasures using the sliced transport framework? If so, can this plan be used to\ndefine a metric between the measures? We propose a \"lifting\" operation to\nextend one-dimensional optimal transport plans back to the original space of\nthe measures. By computing the expectation of these lifted plans, we derive a\nnew transportation plan, termed expected sliced transport (EST) plans. We prove\nthat using the EST plan to weight the sum of the individual Euclidean costs for\nmoving from one point to another results in a valid metric between the input\ndiscrete probability measures. We demonstrate the connection between our\napproach and the recently proposed min-SWGG, along with illustrative numerical\nexamples that support our theoretical findings.\n","authors":["Xinran Liu","Rocío Díaz Martín","Yikun Bai","Ashkan Shahbazi","Matthew Thorpe","Akram Aldroubi","Soheil Kolouri"],"pdf_url":"https://arxiv.org/pdf/2410.12176v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13645v1","updated":"2024-10-17T15:12:55Z","published":"2024-10-17T15:12:55Z","title":"Automated Model Discovery for Tensional Homeostasis: Constitutive\n  Machine Learning in Growth and Remodeling","summary":"  Soft biological tissues exhibit a tendency to maintain a preferred state of\ntensile stress, known as tensional homeostasis, which is restored even after\nexternal mechanical stimuli. This macroscopic behavior can be described using\nthe theory of kinematic growth, where the deformation gradient is\nmultiplicatively decomposed into an elastic part and a part related to growth\nand remodeling. Recently, the concept of homeostatic surfaces was introduced to\ndefine the state of homeostasis and the evolution equations for inelastic\ndeformations.\n  However, identifying the optimal model and material parameters to accurately\ncapture the macroscopic behavior of inelastic materials can only be\naccomplished with significant expertise, is often time-consuming, and prone to\nerror, regardless of the specific inelastic phenomenon. To address this\nchallenge, built-in physics machine learning algorithms offer significant\npotential.\n  In this work, we extend our inelastic Constitutive Artificial Neural Networks\n(iCANNs) by incorporating kinematic growth and homeostatic surfaces to discover\nthe scalar model equations, namely the Helmholtz free energy and the pseudo\npotential. The latter describes the state of homeostasis in a smeared sense. We\nevaluate the ability of the proposed network to learn from experimentally\nobtained tissue equivalent data at the material point level, assess its\npredictive accuracy beyond the training regime, and discuss its current\nlimitations when applied at the structural level.\n  Our source code, data, examples, and an implementation of the corresponding\nmaterial subroutine are made accessible to the public at\nhttps://doi.org/10.5281/zenodo.13946282.\n","authors":["Hagen Holthusen","Tim Brepols","Kevin Linka","Ellen Kuhl"],"pdf_url":"https://arxiv.org/pdf/2410.13645v1.pdf","comment":"46 pages, 12 figures, 5 tables"},{"id":"http://arxiv.org/abs/2410.13643v1","updated":"2024-10-17T15:10:13Z","published":"2024-10-17T15:10:13Z","title":"Fine-Tuning Discrete Diffusion Models via Reward Optimization with\n  Applications to DNA and Protein Design","summary":"  Recent studies have demonstrated the strong empirical performance of\ndiffusion models on discrete sequences across domains from natural language to\nbiological sequence generation. For example, in the protein inverse folding\ntask, conditional diffusion models have achieved impressive results in\ngenerating natural-like sequences that fold back into the original structure.\nHowever, practical design tasks often require not only modeling a conditional\ndistribution but also optimizing specific task objectives. For instance, we may\nprefer protein sequences with high stability. To address this, we consider the\nscenario where we have pre-trained discrete diffusion models that can generate\nnatural-like sequences, as well as reward models that map sequences to task\nobjectives. We then formulate the reward maximization problem within discrete\ndiffusion models, analogous to reinforcement learning (RL), while minimizing\nthe KL divergence against pretrained diffusion models to preserve naturalness.\nTo solve this RL problem, we propose a novel algorithm, DRAKES, that enables\ndirect backpropagation of rewards through entire trajectories generated by\ndiffusion models, by making the originally non-differentiable trajectories\ndifferentiable using the Gumbel-Softmax trick. Our theoretical analysis\nindicates that our approach can generate sequences that are both natural-like\nand yield high rewards. While similar tasks have been recently explored in\ndiffusion models for continuous domains, our work addresses unique algorithmic\nand theoretical challenges specific to discrete diffusion models, which arise\nfrom their foundation in continuous-time Markov chains rather than Brownian\nmotion. Finally, we demonstrate the effectiveness of DRAKES in generating DNA\nand protein sequences that optimize enhancer activity and protein stability,\nrespectively, important tasks for gene therapies and protein-based\ntherapeutics.\n","authors":["Chenyu Wang","Masatoshi Uehara","Yichun He","Amy Wang","Tommaso Biancalani","Avantika Lal","Tommi Jaakkola","Sergey Levine","Hanchen Wang","Aviv Regev"],"pdf_url":"https://arxiv.org/pdf/2410.13643v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13640v1","updated":"2024-10-17T15:09:24Z","published":"2024-10-17T15:09:24Z","title":"Latent Space Chain-of-Embedding Enables Output-free LLM Self-Evaluation","summary":"  LLM self-evaluation relies on the LLM's own ability to estimate response\ncorrectness, which can greatly improve its deployment reliability. In this\nresearch track, we propose the Chain-of-Embedding (CoE) in the latent space to\nenable LLMs to perform output-free self-evaluation. CoE consists of all\nprogressive hidden states produced during the inference time, which can be\ntreated as the latent thinking path of LLMs. We find that when LLMs respond\ncorrectly and incorrectly, their CoE features differ, these discrepancies\nassist us in estimating LLM response correctness. Experiments in four diverse\ndomains and seven LLMs fully demonstrate the effectiveness of our method.\nMeanwhile, its label-free design intent without any training and\nmillisecond-level computational cost ensure real-time feedback in large-scale\nscenarios. More importantly, we provide interesting insights into LLM response\ncorrectness from the perspective of hidden state changes inside LLMs.\n","authors":["Yiming Wang","Pei Zhang","Baosong Yang","Derek F. Wong","Rui Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13640v1.pdf","comment":"33 pages, 18 figures, 12 tables"},{"id":"http://arxiv.org/abs/2410.13638v1","updated":"2024-10-17T15:08:21Z","published":"2024-10-17T15:08:21Z","title":"Scaling Wearable Foundation Models","summary":"  Wearable sensors have become ubiquitous thanks to a variety of health\ntracking features. The resulting continuous and longitudinal measurements from\neveryday life generate large volumes of data; however, making sense of these\nobservations for scientific and actionable insights is non-trivial. Inspired by\nthe empirical success of generative modeling, where large neural networks learn\npowerful representations from vast amounts of text, image, video, or audio\ndata, we investigate the scaling properties of sensor foundation models across\ncompute, data, and model size. Using a dataset of up to 40 million hours of\nin-situ heart rate, heart rate variability, electrodermal activity,\naccelerometer, skin temperature, and altimeter per-minute data from over\n165,000 people, we create LSM, a multimodal foundation model built on the\nlargest wearable-signals dataset with the most extensive range of sensor\nmodalities to date. Our results establish the scaling laws of LSM for tasks\nsuch as imputation, interpolation and extrapolation, both across time and\nsensor modalities. Moreover, we highlight how LSM enables sample-efficient\ndownstream learning for tasks like exercise and activity recognition.\n","authors":["Girish Narayanswamy","Xin Liu","Kumar Ayush","Yuzhe Yang","Xuhai Xu","Shun Liao","Jake Garrison","Shyam Tailor","Jake Sunshine","Yun Liu","Tim Althoff","Shrikanth Narayanan","Pushmeet Kohli","Jiening Zhan","Mark Malhotra","Shwetak Patel","Samy Abdel-Ghaffar","Daniel McDuff"],"pdf_url":"https://arxiv.org/pdf/2410.13638v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13637v1","updated":"2024-10-17T15:07:56Z","published":"2024-10-17T15:07:56Z","title":"Normalizing self-supervised learning for provably reliable Change Point\n  Detection","summary":"  Change point detection (CPD) methods aim to identify abrupt shifts in the\ndistribution of input data streams. Accurate estimators for this task are\ncrucial across various real-world scenarios. Yet, traditional unsupervised CPD\ntechniques face significant limitations, often relying on strong assumptions or\nsuffering from low expressive power due to inherent model simplicity. In\ncontrast, representation learning methods overcome these drawbacks by offering\nflexibility and the ability to capture the full complexity of the data without\nimposing restrictive assumptions. However, these approaches are still emerging\nin the CPD field and lack robust theoretical foundations to ensure their\nreliability. Our work addresses this gap by integrating the expressive power of\nrepresentation learning with the groundedness of traditional CPD techniques. We\nadopt spectral normalization (SN) for deep representation learning in CPD tasks\nand prove that the embeddings after SN are highly informative for CPD. Our\nmethod significantly outperforms current state-of-the-art methods during the\ncomprehensive evaluation via three standard CPD datasets.\n","authors":["Alexandra Bazarova","Evgenia Romanenkova","Alexey Zaytsev"],"pdf_url":"https://arxiv.org/pdf/2410.13637v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13611v1","updated":"2024-10-17T14:46:34Z","published":"2024-10-17T14:46:34Z","title":"H2OVL-Mississippi Vision Language Models Technical Report","summary":"  Smaller vision-language models (VLMs) are becoming increasingly important for\nprivacy-focused, on-device applications due to their ability to run efficiently\non consumer hardware for processing enterprise commercial documents and images.\nThese models require strong language understanding and visual capabilities to\nenhance human-machine interaction. To address this need, we present\nH2OVL-Mississippi, a pair of small VLMs trained on 37 million image-text pairs\nusing 240 hours of compute on 8 x H100 GPUs. H2OVL-Mississippi-0.8B is a tiny\nmodel with 0.8 billion parameters that specializes in text recognition,\nachieving state of the art performance on the Text Recognition portion of\nOCRBench and surpassing much larger models in this area. Additionally, we are\nreleasing H2OVL-Mississippi-2B, a 2 billion parameter model for general use\ncases, exhibiting highly competitive metrics across various academic\nbenchmarks. Both models build upon our prior work with H2O-Danube language\nmodels, extending their capabilities into the visual domain. We release them\nunder the Apache 2.0 license, making VLMs accessible to everyone, democratizing\ndocument AI and visual LLMs.\n","authors":["Shaikat Galib","Shanshan Wang","Guanshuo Xu","Pascal Pfeiffer","Ryan Chesler","Mark Landry","Sri Satish Ambati"],"pdf_url":"https://arxiv.org/pdf/2410.13611v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13609v1","updated":"2024-10-17T14:45:56Z","published":"2024-10-17T14:45:56Z","title":"All models are wrong, some are useful: Model Selection with Limited\n  Labels","summary":"  With the multitude of pretrained models available thanks to the advancements\nin large-scale supervised and self-supervised learning, choosing the right\nmodel is becoming increasingly pivotal in the machine learning lifecycle.\nHowever, much like the training process, choosing the best pretrained\noff-the-shelf model for raw, unlabeled data is a labor-intensive task. To\novercome this, we introduce MODEL SELECTOR, a framework for label-efficient\nselection of pretrained classifiers. Given a pool of unlabeled target data,\nMODEL SELECTOR samples a small subset of highly informative examples for\nlabeling, in order to efficiently identify the best pretrained model for\ndeployment on this target dataset. Through extensive experiments, we\ndemonstrate that MODEL SELECTOR drastically reduces the need for labeled data\nwhile consistently picking the best or near-best performing model. Across 18\nmodel collections on 16 different datasets, comprising over 1,500 pretrained\nmodels, MODEL SELECTOR reduces the labeling cost by up to 94.15% to identify\nthe best model compared to the cost of the strongest baseline. Our results\nfurther highlight the robustness of MODEL SELECTOR in model selection, as it\nreduces the labeling cost by up to 72.41% when selecting a near-best model,\nwhose accuracy is only within 1% of the best model.\n","authors":["Patrik Okanovic","Andreas Kirsch","Jannes Kasper","Torsten Hoefler","Andreas Krause","Nezihe Merve Gürel"],"pdf_url":"https://arxiv.org/pdf/2410.13609v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13605v1","updated":"2024-10-17T14:39:55Z","published":"2024-10-17T14:39:55Z","title":"Transformer-Based Approaches for Sensor-Based Human Activity\n  Recognition: Opportunities and Challenges","summary":"  Transformers have excelled in natural language processing and computer\nvision, paving their way to sensor-based Human Activity Recognition (HAR).\nPrevious studies show that transformers outperform their counterparts\nexclusively when they harness abundant data or employ compute-intensive\noptimization algorithms. However, neither of these scenarios is viable in\nsensor-based HAR due to the scarcity of data in this field and the frequent\nneed to perform training and inference on resource-constrained devices. Our\nextensive investigation into various implementations of transformer-based\nversus non-transformer-based HAR using wearable sensors, encompassing more than\n500 experiments, corroborates these concerns. We observe that transformer-based\nsolutions pose higher computational demands, consistently yield inferior\nperformance, and experience significant performance degradation when quantized\nto accommodate resource-constrained devices. Additionally, transformers\ndemonstrate lower robustness to adversarial attacks, posing a potential threat\nto user trust in HAR.\n","authors":["Clayton Souza Leite","Henry Mauranen","Aziza Zhanabatyrova","Yu Xiao"],"pdf_url":"https://arxiv.org/pdf/2410.13605v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13602v1","updated":"2024-10-17T14:36:58Z","published":"2024-10-17T14:36:58Z","title":"Towards Satellite Non-IID Imagery: A Spectral Clustering-Assisted\n  Federated Learning Approach","summary":"  Low Earth orbit (LEO) satellites are capable of gathering abundant Earth\nobservation data (EOD) to enable different Internet of Things (IoT)\napplications. However, to accomplish an effective EOD processing mechanism, it\nis imperative to investigate: 1) the challenge of processing the observed data\nwithout transmitting those large-size data to the ground because the connection\nbetween the satellites and the ground stations is intermittent, and 2) the\nchallenge of processing the non-independent and identically distributed\n(non-IID) satellite data. In this paper, to cope with those challenges, we\npropose an orbit-based spectral clustering-assisted clustered federated\nself-knowledge distillation (OSC-FSKD) approach for each orbit of an LEO\nsatellite constellation, which retains the advantage of FL that the observed\ndata does not need to be sent to the ground. Specifically, we introduce\nnormalized Laplacian-based spectral clustering (NLSC) into federated learning\n(FL) to create clustered FL in each round to address the challenge resulting\nfrom non-IID data. Particularly, NLSC is adopted to dynamically group clients\ninto several clusters based on cosine similarities calculated by model updates.\nIn addition, self-knowledge distillation is utilized to construct each local\nclient, where the most recent updated local model is used to guide current\nlocal model training. Experiments demonstrate that the observation accuracy\nobtained by the proposed method is separately 1.01x, 2.15x, 1.10x, and 1.03x\nhigher than that of pFedSD, FedProx, FedAU, and FedALA approaches using the\nSAT4 dataset. The proposed method also shows superiority when using other\ndatasets.\n","authors":["Luyao Zou","Yu Min Park","Chu Myaet Thwal","Yan Kyaw Tun","Zhu Han","Choong Seon Hong"],"pdf_url":"https://arxiv.org/pdf/2410.13602v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2410.13597v1","updated":"2024-10-17T14:30:27Z","published":"2024-10-17T14:30:27Z","title":"Text-Guided Multi-Property Molecular Optimization with a Diffusion\n  Language Model","summary":"  Molecular optimization (MO) is a crucial stage in drug discovery in which\ntask-oriented generated molecules are optimized to meet practical industrial\nrequirements. Existing mainstream MO approaches primarily utilize external\nproperty predictors to guide iterative property optimization. However, learning\nall molecular samples in the vast chemical space is unrealistic for predictors.\nAs a result, errors and noise are inevitably introduced during property\nprediction due to the nature of approximation. This leads to discrepancy\naccumulation, generalization reduction and suboptimal molecular candidates. In\nthis paper, we propose a text-guided multi-property molecular optimization\nmethod utilizing transformer-based diffusion language model (TransDLM).\nTransDLM leverages standardized chemical nomenclature as semantic\nrepresentations of molecules and implicitly embeds property requirements into\ntextual descriptions, thereby preventing error propagation during diffusion\nprocess. Guided by physically and chemically detailed textual descriptions,\nTransDLM samples and optimizes encoded source molecules, retaining core\nscaffolds of source molecules and ensuring structural similarities. Moreover,\nTransDLM enables simultaneous sampling of multiple molecules, making it ideal\nfor scalable, efficient large-scale optimization through distributed\ncomputation on web platforms. Furthermore, our approach surpasses\nstate-of-the-art methods in optimizing molecular structural similarity and\nenhancing chemical properties on the benchmark dataset. The code is available\nat: https://anonymous.4open.science/r/TransDLM-A901.\n","authors":["Yida Xiong","Kun Li","Weiwei Liu","Jia Wu","Bo Du","Shirui Pan","Wenbin Hu"],"pdf_url":"https://arxiv.org/pdf/2410.13597v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13579v1","updated":"2024-10-17T14:12:57Z","published":"2024-10-17T14:12:57Z","title":"Towards Better Performance in Incomplete LDL: Addressing Data Imbalance","summary":"  Label Distribution Learning (LDL) is a novel machine learning paradigm that\naddresses the problem of label ambiguity and has found widespread applications.\nObtaining complete label distributions in real-world scenarios is challenging,\nwhich has led to the emergence of Incomplete Label Distribution Learning\n(InLDL). However, the existing InLDL methods overlook a crucial aspect of LDL\ndata: the inherent imbalance in label distributions. To address this\nlimitation, we propose \\textbf{Incomplete and Imbalance Label Distribution\nLearning (I\\(^2\\)LDL)}, a framework that simultaneously handles incomplete\nlabels and imbalanced label distributions. Our method decomposes the label\ndistribution matrix into a low-rank component for frequent labels and a sparse\ncomponent for rare labels, effectively capturing the structure of both head and\ntail labels. We optimize the model using the Alternating Direction Method of\nMultipliers (ADMM) and derive generalization error bounds via Rademacher\ncomplexity, providing strong theoretical guarantees. Extensive experiments on\n15 real-world datasets demonstrate the effectiveness and robustness of our\nproposed framework compared to existing InLDL methods.\n","authors":["Zhiqiang Kou","Haoyuan Xuan","Jing Wang","Yuheng Jia","Xin Geng"],"pdf_url":"https://arxiv.org/pdf/2410.13579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13577v1","updated":"2024-10-17T14:12:35Z","published":"2024-10-17T14:12:35Z","title":"Sample Compression Hypernetworks: From Generalization Bounds to\n  Meta-Learning","summary":"  Reconstruction functions are pivotal in sample compression theory, a\nframework for deriving tight generalization bounds. From a small sample of the\ntraining set (the compression set) and an optional stream of information (the\nmessage), they recover a predictor previously learned from the whole training\nset. While usually fixed, we propose to learn reconstruction functions. To\nfacilitate the optimization and increase the expressiveness of the message, we\nderive a new sample compression generalization bound for real-valued messages.\nFrom this theoretical analysis, we then present a new hypernetwork architecture\nthat outputs predictors with tight generalization guarantees when trained using\nan original meta-learning framework. The results of promising preliminary\nexperiments are then reported.\n","authors":["Benjamin Leblanc","Mathieu Bazinet","Nathaniel D'Amours","Alexandre Drouin","Pascal Germain"],"pdf_url":"https://arxiv.org/pdf/2410.13577v1.pdf","comment":"Accepted at the NeurIPS 2024 workshop on Compression in Machine\n  Learning"},{"id":"http://arxiv.org/abs/2402.06165v5","updated":"2024-10-17T14:10:16Z","published":"2024-02-09T03:48:20Z","title":"Learning Contrastive Feature Representations for Facial Action Unit\n  Detection","summary":"  Facial action unit (AU) detection has long encountered the challenge of\ndetecting subtle feature differences when AUs activate. Existing methods often\nrely on encoding pixel-level information of AUs, which not only encodes\nadditional redundant information but also leads to increased model complexity\nand limited generalizability. Additionally, the accuracy of AU detection is\nnegatively impacted by the class imbalance issue of each AU type, and the\npresence of noisy and false AU labels. In this paper, we introduce a novel\ncontrastive learning framework aimed for AU detection that incorporates both\nself-supervised and supervised signals, thereby enhancing the learning of\ndiscriminative features for accurate AU detection. To tackle the class\nimbalance issue, we employ a negative sample re-weighting strategy that adjusts\nthe step size of updating parameters for minority and majority class samples.\nMoreover, to address the challenges posed by noisy and false AU labels, we\nemploy a sampling technique that encompasses three distinct types of positive\nsample pairs. This enables us to inject self-supervised signals into the\nsupervised signal, effectively mitigating the adverse effects of noisy labels.\nOur experimental assessments, conducted on four widely-utilized benchmark\ndatasets (BP4D, DISFA, GFT and Aff-Wild2), underscore the superior performance\nof our approach compared to state-of-the-art methods of AU detection. Our code\nis available at \\url{https://github.com/Ziqiao-Shang/AUNCE}.\n","authors":["Ziqiao Shang","Bin Liu","Fengmao Lv","Fei Teng","Tianrui Li"],"pdf_url":"https://arxiv.org/pdf/2402.06165v5.pdf","comment":"35 pages, 18 figures, submitted to Pattern Recognition (PR)"},{"id":"http://arxiv.org/abs/2410.13563v1","updated":"2024-10-17T14:00:18Z","published":"2024-10-17T14:00:18Z","title":"Ornstein-Uhlenbeck Adaptation as a Mechanism for Learning in Brains and\n  Machines","summary":"  Learning is a fundamental property of intelligent systems, observed across\nbiological organisms and engineered systems. While modern intelligent systems\ntypically rely on gradient descent for learning, the need for exact gradients\nand complex information flow makes its implementation in biological and\nneuromorphic systems challenging. This has motivated the exploration of\nalternative learning mechanisms that can operate locally and do not rely on\nexact gradients. In this work, we introduce a novel approach that leverages\nnoise in the parameters of the system and global reinforcement signals. Using\nan Ornstein-Uhlenbeck process with adaptive dynamics, our method balances\nexploration and exploitation during learning, driven by deviations from error\npredictions, akin to reward prediction error. Operating in continuous time,\nOrstein-Uhlenbeck adaptation (OUA) is proposed as a general mechanism for\nlearning dynamic, time-evolving environments. We validate our approach across\ndiverse tasks, including supervised learning and reinforcement learning in\nfeedforward and recurrent systems. Additionally, we demonstrate that it can\nperform meta-learning, adjusting hyper-parameters autonomously. Our results\nindicate that OUA provides a viable alternative to traditional gradient-based\nmethods, with potential applications in neuromorphic computing. It also hints\nat a possible mechanism for noise-driven learning in the brain, where\nstochastic neurotransmitter release may guide synaptic adjustments.\n","authors":["Jesus Garcia Fernandez","Nasir Ahmad","Marcel van Gerven"],"pdf_url":"https://arxiv.org/pdf/2410.13563v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.16710v3","updated":"2024-10-17T13:50:46Z","published":"2024-04-25T16:20:23Z","title":"LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding","summary":"  We present LayerSkip, an end-to-end solution to speed-up inference of large\nlanguage models (LLMs). First, during training we apply layer dropout, with low\ndropout rates for earlier layers and higher dropout rates for later layers, and\nan early exit loss where all transformer layers share the same exit. Second,\nduring inference, we show that this training recipe increases the accuracy of\nearly exit at earlier layers, without adding any auxiliary layers or modules to\nthe model. Third, we present a novel self-speculative decoding solution where\nwe exit at early layers and verify and correct with remaining layers of the\nmodel. Our proposed self-speculative decoding approach has less memory\nfootprint than other speculative decoding approaches and benefits from shared\ncompute and activations of the draft and verification stages. We run\nexperiments on different Llama model sizes on different types of training:\npretraining from scratch, continual pretraining, finetuning on specific data\ndomain, and finetuning on specific task. We implement our inference solution\nand show speedups of up to 2.16x on summarization for CNN/DM documents, 1.82x\non coding, and 2.0x on TOPv2 semantic parsing task. We open source our code and\ncheckpoints at https://github.com/facebookresearch/LayerSkip.\n","authors":["Mostafa Elhoushi","Akshat Shrivastava","Diana Liskovich","Basil Hosmer","Bram Wasti","Liangzhen Lai","Anas Mahmoud","Bilge Acun","Saurabh Agarwal","Ahmed Roman","Ahmed A Aly","Beidi Chen","Carole-Jean Wu"],"pdf_url":"https://arxiv.org/pdf/2404.16710v3.pdf","comment":"ACL 2024"},{"id":"http://arxiv.org/abs/2410.13548v1","updated":"2024-10-17T13:42:56Z","published":"2024-10-17T13:42:56Z","title":"Adaptive and oblivious statistical adversaries are equivalent","summary":"  We resolve a fundamental question about the ability to perform a statistical\ntask, such as learning, when an adversary corrupts the sample. Such adversaries\nare specified by the types of corruption they can make and their level of\nknowledge about the sample. The latter distinguishes between sample-adaptive\nadversaries which know the contents of the sample when choosing the corruption,\nand sample-oblivious adversaries, which do not. We prove that for all types of\ncorruptions, sample-adaptive and sample-oblivious adversaries are\n\\emph{equivalent} up to polynomial factors in the sample size. This resolves\nthe main open question introduced by \\cite{BLMT22} and further explored in\n\\cite{CHLLN23}.\n  Specifically, consider any algorithm $A$ that solves a statistical task even\nwhen a sample-oblivious adversary corrupts its input. We show that there is an\nalgorithm $A'$ that solves the same task when the corresponding sample-adaptive\nadversary corrupts its input. The construction of $A'$ is simple and maintains\nthe computational efficiency of $A$: It requests a polynomially larger sample\nthan $A$ uses and then runs $A$ on a uniformly random subsample.\n  One of our main technical tools is a new structural result relating two\ndistributions defined on sunflowers which may be of independent interest.\n","authors":["Guy Blanc","Gregory Valiant"],"pdf_url":"https://arxiv.org/pdf/2410.13548v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12294v2","updated":"2024-10-17T13:27:43Z","published":"2024-10-16T06:51:09Z","title":"LLM-based Cognitive Models of Students with Misconceptions","summary":"  Accurately modeling student cognition is crucial for developing effective\nAI-driven educational technologies. A key challenge is creating realistic\nstudent models that satisfy two essential properties: (1) accurately\nreplicating specific misconceptions, and (2) correctly solving problems where\nthese misconceptions are not applicable. This dual requirement reflects the\ncomplex nature of student understanding, where misconceptions coexist with\ncorrect knowledge. This paper investigates whether Large Language Models (LLMs)\ncan be instruction-tuned to meet this dual requirement and effectively simulate\nstudent thinking in algebra. We introduce MalAlgoPy, a novel Python library\nthat generates datasets reflecting authentic student solution patterns through\na graph-based representation of algebraic problem-solving. Utilizing MalAlgoPy,\nwe define and examine Cognitive Student Models (CSMs) - LLMs instruction tuned\nto faithfully emulate realistic student behavior. Our findings reveal that LLMs\ntrained on misconception examples can efficiently learn to replicate errors.\nHowever, the training diminishes the model's ability to solve problems\ncorrectly, particularly for problem types where the misconceptions are not\napplicable, thus failing to satisfy second property of CSMs. We demonstrate\nthat by carefully calibrating the ratio of correct to misconception examples in\nthe training data - sometimes as low as 0.25 - it is possible to develop CSMs\nthat satisfy both properties. Our insights enhance our understanding of\nAI-based student models and pave the way for effective adaptive learning\nsystems.\n","authors":["Shashank Sonkar","Xinghe Chen","Naiming Liu","Richard G. Baraniuk","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2410.12294v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13526v1","updated":"2024-10-17T13:14:25Z","published":"2024-10-17T13:14:25Z","title":"Generative Adversarial Synthesis of Radar Point Cloud Scenes","summary":"  For the validation and verification of automotive radars, datasets of\nrealistic traffic scenarios are required, which, how ever, are laborious to\nacquire. In this paper, we introduce radar scene synthesis using GANs as an\nalternative to the real dataset acquisition and simulation-based approaches. We\ntrain a PointNet++ based GAN model to generate realistic radar point cloud\nscenes and use a binary classifier to evaluate the performance of scenes\ngenerated using this model against a test set of real scenes. We demonstrate\nthat our GAN model achieves similar performance (~87%) to the real scenes test\nset.\n","authors":["Muhammad Saad Nawaz","Thomas Dallmann","Torsten Schoen","Dirk Heberling"],"pdf_url":"https://arxiv.org/pdf/2410.13526v1.pdf","comment":"ICMIM 2024; 7th IEEE MTT Conference"},{"id":"http://arxiv.org/abs/2406.03857v2","updated":"2024-10-17T13:08:13Z","published":"2024-06-06T08:42:36Z","title":"MuJo: Multimodal Joint Feature Space Learning for Human Activity\n  Recognition","summary":"  Human Activity Recognition (HAR) is a longstanding problem in AI with\napplications in a broad range of areas, including healthcare, sports and\nfitness, security, and more. The performance of HAR in real-world settings is\nstrongly dependent on the type and quality of the input signal that can be\nacquired. Given an unobstructed, high-quality camera view of a scene, computer\nvision systems, in particular in conjunction with foundation models, can today\nfairly reliably distinguish complex activities. On the other hand, recognition\nusing modalities such as wearable sensors (which are often more broadly\navailable, e.g., in mobile phones and smartwatches) is a more difficult\nproblem, as the signals often contain less information and labeled training\ndata is more difficult to acquire. To alleviate the need for labeled data, we\nintroduce our comprehensive Fitness Multimodal Activity Dataset (FiMAD) in this\nwork, which can be used with the proposed pre-training method MuJo (Multimodal\nJoint Feature Space Learning) to enhance HAR performance across various\nmodalities. FiMAD was created using YouTube fitness videos and contains\nparallel video, language, pose, and simulated IMU sensor data. MuJo utilizes\nthis dataset to learn a joint feature space for these modalities. We show that\nclassifiers pre-trained on FiMAD can increase the performance on real HAR\ndatasets such as MM-Fit, MyoGym, MotionSense, and MHEALTH. For instance, on\nMM-Fit, we achieve an Macro F1-Score of up to 0.855 when fine-tuning on only 2%\nof the training data and 0.942 when utilizing the full training set for\nclassification tasks. We have compared our approach to other self-supervised\nones and showed that, unlike them, ours can consistently improve on the\nbaseline network performance as well as provide a better data-efficiency.\n","authors":["Stefan Gerd Fritsch","Cennet Oguz","Vitor Fortes Rey","Lala Ray","Maximilian Kiefer-Emmanouilidis","Paul Lukowicz"],"pdf_url":"https://arxiv.org/pdf/2406.03857v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13516v1","updated":"2024-10-17T13:05:44Z","published":"2024-10-17T13:05:44Z","title":"PORTAL: Scalable Tabular Foundation Models via Content-Specific\n  Tokenization","summary":"  Self-supervised learning on tabular data seeks to apply advances from natural\nlanguage and image domains to the diverse domain of tables. However, current\ntechniques often struggle with integrating multi-domain data and require data\ncleaning or specific structural requirements, limiting the scalability of\npre-training datasets. We introduce PORTAL (Pretraining One-Row-at-a-Time for\nAll tabLes), a framework that handles various data modalities without the need\nfor cleaning or preprocessing. This simple yet powerful approach can be\neffectively pre-trained on online-collected datasets and fine-tuned to match\nstate-of-the-art methods on complex classification and regression tasks. This\nwork offers a practical advancement in self-supervised learning for large-scale\ntabular data.\n","authors":["Marco Spinaci","Marek Polewczyk","Johannes Hoffart","Markus C. Kohler","Sam Thelin","Tassilo Klein"],"pdf_url":"https://arxiv.org/pdf/2410.13516v1.pdf","comment":"Accepted at Table Representation Learning Workshop at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.13514v1","updated":"2024-10-17T13:02:06Z","published":"2024-10-17T13:02:06Z","title":"CERES: Critical-Event Reconstruction via Temporal Scene Graph Completion","summary":"  This paper proposes a method for on-demand scenario generation in simulation,\ngrounded on real-world data. Evaluating the behaviour of Autonomous Vehicles\n(AVs) in both safety-critical and regular scenarios is essential for assessing\ntheir robustness before real-world deployment. By integrating scenarios derived\nfrom real-world datasets into the simulation, we enhance the plausibility and\nvalidity of testing sets. This work introduces a novel approach that employs\ntemporal scene graphs to capture evolving spatiotemporal relationships among\nscene entities from a real-world dataset, enabling the generation of dynamic\nscenarios in simulation through Graph Neural Networks (GNNs). User-defined\naction and criticality conditioning are used to ensure flexible, tailored\nscenario creation. Our model significantly outperforms the benchmarks in\naccurately predicting links corresponding to the requested scenarios. We\nfurther evaluate the validity and compatibility of our generated scenarios in\nan off-the-shelf simulator.\n","authors":["Efimia Panagiotaki","Georgi Pramatarov","Lars Kunze","Daniele De Martini"],"pdf_url":"https://arxiv.org/pdf/2410.13514v1.pdf","comment":"7 pages, 8 figures"},{"id":"http://arxiv.org/abs/2410.10905v2","updated":"2024-10-17T12:59:03Z","published":"2024-10-13T19:28:41Z","title":"Improving Generalization on the ProcGen Benchmark with Simple\n  Architectural Changes and Scale","summary":"  We demonstrate that recent advances in reinforcement learning (RL) combined\nwith simple architectural changes significantly improves generalization on the\nProcGen benchmark. These changes are frame stacking, replacing 2D convolutional\nlayers with 3D convolutional layers, and scaling up the number of convolutional\nkernels per layer. Experimental results using a single set of hyperparameters\nacross all environments show a 37.9\\% reduction in the optimality gap compared\nto the baseline (from 0.58 to 0.36). This performance matches or exceeds\ncurrent state-of-the-art methods. The proposed changes are largely orthogonal\nand therefore complementary to the existing approaches for improving\ngeneralization in RL, and our results suggest that further exploration in this\ndirection could yield substantial improvements in addressing generalization\nchallenges in deep reinforcement learning.\n","authors":["Andrew Jesson","Yiding Jiang"],"pdf_url":"https://arxiv.org/pdf/2410.10905v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12686v2","updated":"2024-10-17T12:52:30Z","published":"2024-10-16T15:48:28Z","title":"Automatic Mapping of Anatomical Landmarks from Free-Text Using Large\n  Language Models: Insights from Llama-2","summary":"  Anatomical landmarks are vital in medical imaging for navigation and anomaly\ndetection. Modern large language models (LLMs), like Llama-2, offer promise for\nautomating the mapping of these landmarks in free-text radiology reports to\ncorresponding positions in image data. Recent studies propose LLMs may develop\ncoherent representations of generative processes. Motivated by these insights,\nwe investigated whether LLMs accurately represent the spatial positions of\nanatomical landmarks. Through experiments with Llama-2 models, we found that\nthey can linearly represent anatomical landmarks in space with considerable\nrobustness to different prompts. These results underscore the potential of LLMs\nto enhance the efficiency and accuracy of medical imaging workflows.\n","authors":["Mohamad Abdi","Gerardo Hermosillo Valadez","Halid Ziya Yerebakan"],"pdf_url":"https://arxiv.org/pdf/2410.12686v2.pdf","comment":"6 pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2410.01186v2","updated":"2024-10-17T12:50:06Z","published":"2024-10-02T02:38:33Z","title":"Efficient PAC Learning of Halfspaces with Constant Malicious Noise Rate","summary":"  Understanding noise tolerance of learning algorithms under certain conditions\nis a central quest in learning theory. In this work, we study the problem of\ncomputationally efficient PAC learning of halfspaces in the presence of\nmalicious noise, where an adversary can corrupt both instances and labels of\ntraining samples. The best-known noise tolerance either depends on a target\nerror rate under distributional assumptions or on a margin parameter under\nlarge-margin conditions. In this work, we show that when both types of\nconditions are satisfied, it is possible to achieve {\\em constant} noise\ntolerance by minimizing a reweighted hinge loss. Our key ingredients include:\n1) an efficient algorithm that finds weights to control the gradient\ndeterioration from corrupted samples, and 2) a new analysis on the robustness\nof the hinge loss equipped with such weights.\n","authors":["Jie Shen","Xiaoyu Li"],"pdf_url":"https://arxiv.org/pdf/2410.01186v2.pdf","comment":"author list in contribution order"},{"id":"http://arxiv.org/abs/2410.13502v1","updated":"2024-10-17T12:48:14Z","published":"2024-10-17T12:48:14Z","title":"MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily\n  Complex Proofs","summary":"  Large language models (LLMs) can solve arithmetic word problems with high\naccuracy, but little is known about how well they generalize to problems that\nare more complex than the ones on which they have been trained. Empirical\ninvestigations of such questions are impeded by two major flaws of current\nevaluations: (i) much of the evaluation data is contaminated, in the sense that\nit has already been seen during training, and (ii) benchmark datasets do not\ncapture how problem proofs may be arbitrarily complex in various ways. As a\nstep towards addressing these issues, we present a framework for evaluating\nLLMs on problems that have arbitrarily complex arithmetic proofs, called\nMathGAP. MathGAP generates problems that follow fixed proof specifications --\nalong with chain-of-thought reasoning annotations -- enabling systematic\nstudies on generalization with respect to arithmetic proof complexity. We apply\nMathGAP to analyze how in-context learning interacts with generalization to\nproblems that have more complex proofs. We find that among the models tested,\nmost show a significant decrease in performance as proofs get deeper and wider.\nThis effect is more pronounced in complex, nonlinear proof structures, which\nare challenging even for GPT-4o. Surprisingly, providing in-context examples\nfrom the same distribution as the test set is not always beneficial for\nperformance. In particular, zero-shot prompting as well as demonstrating a\ndiverse range of examples that are less complex than the test data sometimes\nyield similar or higher accuracies.\n","authors":["Andreas Opedal","Haruki Shirakami","Bernhard Schölkopf","Abulhair Saparov","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2410.13502v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.13501v1","updated":"2024-10-17T12:47:31Z","published":"2024-10-17T12:47:31Z","title":"Integrating Large Language Models and Reinforcement Learning for\n  Non-Linear Reasoning","summary":"  Large Language Models (LLMs) were shown to struggle with long-term planning,\nwhich may be caused by the limited way in which they explore the space of\npossible solutions. We propose an architecture where a Reinforcement Learning\n(RL) Agent guides an LLM's space exploration: (1) the Agent has access to\ndomain-specific information, and can therefore make decisions about the quality\nof candidate solutions based on specific and relevant metrics, which were not\nexplicitly considered by the LLM's training objective; (2) the LLM can focus on\ngenerating immediate next steps, without the need for long-term planning. We\nallow non-linear reasoning by exploring alternative paths and backtracking. We\nevaluate this architecture on the program equivalence task, and compare it\nagainst Chain of Thought (CoT) and Tree of Thoughts (ToT). We assess both the\ndownstream task, denoting the binary classification, and the intermediate\nreasoning steps. Our approach compares positively against CoT and ToT.\n","authors":["Yoav Alon","Cristina David"],"pdf_url":"https://arxiv.org/pdf/2410.13501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13500v1","updated":"2024-10-17T12:46:26Z","published":"2024-10-17T12:46:26Z","title":"SAda-Net: A Self-Supervised Adaptive Stereo Estimation CNN For Remote\n  Sensing Image Data","summary":"  Stereo estimation has made many advancements in recent years with the\nintroduction of deep-learning. However the traditional supervised approach to\ndeep-learning requires the creation of accurate and plentiful ground-truth\ndata, which is expensive to create and not available in many situations. This\nis especially true for remote sensing applications, where there is an excess of\navailable data without proper ground truth. To tackle this problem, we propose\na self-supervised CNN with self-improving adaptive abilities. In the first\niteration, the created disparity map is inaccurate and noisy. Leveraging the\nleft-right consistency check, we get a sparse but more accurate disparity map\nwhich is used as an initial pseudo ground-truth. This pseudo ground-truth is\nthen adapted and updated after every epoch in the training step of the network.\nWe use the sum of inconsistent points in order to track the network\nconvergence. The code for our method is publicly available at:\nhttps://github.com/thedodo/SAda-Net}{https://github.com/thedodo/SAda-Net\n","authors":["Dominik Hirner","Friedrich Fraundorfer"],"pdf_url":"https://arxiv.org/pdf/2410.13500v1.pdf","comment":"Will be presented at ICPR2024 in December 2024 in Kolkata, India"},{"id":"http://arxiv.org/abs/2410.13498v1","updated":"2024-10-17T12:43:49Z","published":"2024-10-17T12:43:49Z","title":"Enhancing Text Generation in Joint NLG/NLU Learning Through Curriculum\n  Learning, Semi-Supervised Training, and Advanced Optimization Techniques","summary":"  Text generation is the automated process of producing written or spoken\nlanguage using computational methods. It involves generating coherent and\ncontextually relevant text based on predefined rules or learned patterns.\nHowever, challenges in text generation arise from maintaining coherence,\nensuring diversity and creativity, and avoiding biases or inappropriate\ncontent. This research paper developed a novel approach to improve text\ngeneration in the context of joint Natural Language Generation (NLG) and\nNatural Language Understanding (NLU) learning. The data is prepared by\ngathering and preprocessing annotated datasets, including cleaning,\ntokenization, stemming, and stop-word removal. Feature extraction techniques\nsuch as POS tagging, Bag of words, and Term Frequency-Inverse Document\nFrequency (TF-IDF) are applied. Transformer-based encoders and decoders,\ncapturing long range dependencies and improving source-target sequence\nmodelling. Pre-trained language models like Optimized BERT are incorporated,\nalong with a Hybrid Redfox Artificial Hummingbird Algorithm (HRAHA).\nReinforcement learning with policy gradient techniques, semi-supervised\ntraining, improved attention mechanisms, and differentiable approximations like\nstraight-through Gumbel SoftMax estimator are employed to fine-tune the models\nand handle complex linguistic tasks effectively. The proposed model is\nimplemented using Python.\n","authors":["Rahimanuddin Shaik","Katikela Sreeharsha Kishore"],"pdf_url":"https://arxiv.org/pdf/2410.13498v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13493v1","updated":"2024-10-17T12:38:08Z","published":"2024-10-17T12:38:08Z","title":"Deep Reinforcement Learning for Online Optimal Execution Strategies","summary":"  This paper tackles the challenge of learning non-Markovian optimal execution\nstrategies in dynamic financial markets. We introduce a novel actor-critic\nalgorithm based on Deep Deterministic Policy Gradient (DDPG) to address this\nissue, with a focus on transient price impact modeled by a general decay\nkernel. Through numerical experiments with various decay kernels, we show that\nour algorithm successfully approximates the optimal execution strategy.\nAdditionally, the proposed algorithm demonstrates adaptability to evolving\nmarket conditions, where parameters fluctuate over time. Our findings also show\nthat modern reinforcement learning algorithms can provide a solution that\nreduces the need for frequent and inefficient human intervention in optimal\nexecution tasks.\n","authors":["Alessandro Micheli","Mélodie Monod"],"pdf_url":"https://arxiv.org/pdf/2410.13493v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13490v1","updated":"2024-10-17T12:34:37Z","published":"2024-10-17T12:34:37Z","title":"Novelty-based Sample Reuse for Continuous Robotics Control","summary":"  In reinforcement learning, agents collect state information and rewards\nthrough environmental interactions, essential for policy refinement. This\nprocess is notably time-consuming, especially in complex robotic simulations\nand real-world applications. Traditional algorithms usually re-engage with the\nenvironment after processing a single batch of samples, thereby failing to\nfully capitalize on historical data. However, frequently observed states, with\nreliable value estimates, require minimal updates; in contrast, rare observed\nstates necessitate more intensive updates for achieving accurate value\nestimations. To address uneven sample utilization, we propose Novelty-guided\nSample Reuse (NSR). NSR provides extra updates for infrequent, novel states and\nskips additional updates for frequent states, maximizing sample use before\ninteracting with the environment again. Our experiments show that NSR improves\nthe convergence rate and success rate of algorithms without significantly\nincreasing time consumption. Our code is publicly available at\nhttps://github.com/ppksigs/NSR-DDPG-HER.\n","authors":["Ke Duan","Kai Yang","Houde Liu","Xueqian Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13490v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13488v1","updated":"2024-10-17T12:32:00Z","published":"2024-10-17T12:32:00Z","title":"Seeing Through VisualBERT: A Causal Adventure on Memetic Landscapes","summary":"  Detecting offensive memes is crucial, yet standard deep neural network\nsystems often remain opaque. Various input attribution-based methods attempt to\ninterpret their behavior, but they face challenges with implicitly offensive\nmemes and non-causal attributions. To address these issues, we propose a\nframework based on a Structural Causal Model (SCM). In this framework,\nVisualBERT is trained to predict the class of an input meme based on both meme\ninput and causal concepts, allowing for transparent interpretation. Our\nqualitative evaluation demonstrates the framework's effectiveness in\nunderstanding model behavior, particularly in determining whether the model was\nright due to the right reason, and in identifying reasons behind\nmisclassification. Additionally, quantitative analysis assesses the\nsignificance of proposed modelling choices, such as de-confounding, adversarial\nlearning, and dynamic routing, and compares them with input attribution\nmethods. Surprisingly, we find that input attribution methods do not guarantee\ncausality within our framework, raising questions about their reliability in\nsafety-critical applications. The project page is at:\nhttps://newcodevelop.github.io/causality_adventure/\n","authors":["Dibyanayan Bandyopadhyay","Mohammed Hasanuzzaman","Asif Ekbal"],"pdf_url":"https://arxiv.org/pdf/2410.13488v1.pdf","comment":"Accepted at EMNLP Findings 2024"},{"id":"http://arxiv.org/abs/2409.19431v2","updated":"2024-10-17T12:23:07Z","published":"2024-09-28T18:31:51Z","title":"Generalization Error of the Tilted Empirical Risk","summary":"  The generalization error (risk) of a supervised statistical learning\nalgorithm quantifies its prediction ability on previously unseen data. Inspired\nby exponential tilting, Li et al. (2021) proposed the tilted empirical risk as\na non-linear risk metric for machine learning applications such as\nclassification and regression problems. In this work, we examine the\ngeneralization error of the tilted empirical risk. In particular, we provide\nuniform and information-theoretic bounds on the tilted generalization error,\ndefined as the difference between the population risk and the tilted empirical\nrisk, with a convergence rate of $O(1/\\sqrt{n})$ where $n$ is the number of\ntraining samples. Furthermore, we study the solution to the KL-regularized\nexpected tilted empirical risk minimization problem and derive an upper bound\non the expected tilted generalization error with a convergence rate of\n$O(1/n)$.\n","authors":["Gholamali Aminian","Amir R. Asadi","Tian Li","Ahmad Beirami","Gesine Reinert","Samuel N. Cohen"],"pdf_url":"https://arxiv.org/pdf/2409.19431v2.pdf","comment":"New results are added"},{"id":"http://arxiv.org/abs/2407.18402v2","updated":"2024-10-17T12:19:26Z","published":"2024-07-25T21:33:54Z","title":"RECOVAR: Representation Covariances on Deep Latent Spaces for Seismic\n  Event Detection","summary":"  While modern deep learning methods have shown great promise in the problem of\nearthquake detection, the most successful methods so far have been based on\nsupervised learning, which requires large datasets with ground-truth labels.\nThe curation of such datasets is both time consuming and prone to systematic\nbiases, which result in difficulties with cross-dataset generalization,\nhindering general applicability. In this paper, we develop an unsupervised\nmethod for earthquake detection that learns to detect earthquakes from raw\nwaveforms, without access to ground truth labels. The performance is comparable\nto, and in some cases better than, some state-of-the-art supervised methods.\nMoreover, the method has strong \\emph{cross-dataset generalization}\nperformance. The algorithm utilizes deep autoencoders that learn to reproduce\nthe waveforms after a data-compressive bottleneck and uses a simple,\ncross-covariance-based triggering algorithm at the bottleneck for labeling. The\napproach has the potential to be useful for time series datasets from other\ndomains.\n","authors":["Onur Efe","Arkadas Ozakin"],"pdf_url":"https://arxiv.org/pdf/2407.18402v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.18392v3","updated":"2024-10-17T12:01:15Z","published":"2024-05-28T17:33:54Z","title":"Scaling Laws and Compute-Optimal Training Beyond Fixed Training\n  Durations","summary":"  Scale has become a main ingredient in obtaining strong machine learning\nmodels. As a result, understanding a model's scaling properties is key to\neffectively designing both the right training setup as well as future\ngenerations of architectures. In this work, we argue that scale and training\nresearch has been needlessly complex due to reliance on the cosine schedule,\nwhich prevents training across different lengths for the same model size. We\ninvestigate the training behavior of a direct alternative -- constant learning\nrate and cooldowns -- and find that it scales predictably and reliably similar\nto cosine. Additionally, we show that stochastic weight averaging yields\nimproved performance along the training trajectory, without additional training\ncosts, across different scales. Importantly, with these findings we demonstrate\nthat scaling experiments can be performed with significantly reduced compute\nand GPU hours by utilizing fewer but reusable training runs. Our code is\navailable at \\url{https://github.com/epfml/schedules-and-scaling/}.\n","authors":["Alexander Hägele","Elie Bakouch","Atli Kosson","Loubna Ben Allal","Leandro Von Werra","Martin Jaggi"],"pdf_url":"https://arxiv.org/pdf/2405.18392v3.pdf","comment":"Spotlight at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2107.02791v3","updated":"2024-10-17T16:11:28Z","published":"2021-07-06T17:58:35Z","title":"Depth-supervised NeRF: Fewer Views and Faster Training for Free","summary":"  A commonly observed failure mode of Neural Radiance Field (NeRF) is fitting\nincorrect geometries when given an insufficient number of input views. One\npotential reason is that standard volumetric rendering does not enforce the\nconstraint that most of a scene's geometry consist of empty space and opaque\nsurfaces. We formalize the above assumption through DS-NeRF (Depth-supervised\nNeural Radiance Fields), a loss for learning radiance fields that takes\nadvantage of readily-available depth supervision. We leverage the fact that\ncurrent NeRF pipelines require images with known camera poses that are\ntypically estimated by running structure-from-motion (SFM). Crucially, SFM also\nproduces sparse 3D points that can be used as \"free\" depth supervision during\ntraining: we add a loss to encourage the distribution of a ray's terminating\ndepth matches a given 3D keypoint, incorporating depth uncertainty. DS-NeRF can\nrender better images given fewer training views while training 2-3x faster.\nFurther, we show that our loss is compatible with other recently proposed NeRF\nmethods, demonstrating that depth is a cheap and easily digestible supervisory\nsignal. And finally, we find that DS-NeRF can support other types of depth\nsupervision such as scanned depth sensors and RGB-D reconstruction outputs.\n","authors":["Kangle Deng","Andrew Liu","Jun-Yan Zhu","Deva Ramanan"],"pdf_url":"https://arxiv.org/pdf/2107.02791v3.pdf","comment":"Project page: http://www.cs.cmu.edu/~dsnerf/ GitHub:\n  https://github.com/dunbar12138/DSNeRF"}]},"2024-10-18T00:00:00Z":{"Robotics":[{"id":"http://arxiv.org/abs/2410.14616v1","updated":"2024-10-18T17:14:28Z","published":"2024-10-18T17:14:28Z","title":"Benchmarking Deep Reinforcement Learning for Navigation in Denied Sensor\n  Environments","summary":"  Deep Reinforcement learning (DRL) is used to enable autonomous navigation in\nunknown environments. Most research assume perfect sensor data, but real-world\nenvironments may contain natural and artificial sensor noise and denial. Here,\nwe present a benchmark of both well-used and emerging DRL algorithms in a\nnavigation task with configurable sensor denial effects. In particular, we are\ninterested in comparing how different DRL methods (e.g. model-free PPO vs.\nmodel-based DreamerV3) are affected by sensor denial. We show that DreamerV3\noutperforms other methods in the visual end-to-end navigation task with a\ndynamic goal - and other methods are not able to learn this. Furthermore,\nDreamerV3 generally outperforms other methods in sensor-denied environments. In\norder to improve robustness, we use adversarial training and demonstrate an\nimproved performance in denied environments, although this generally comes with\na performance cost on the vanilla environments. We anticipate this benchmark of\ndifferent DRL methods and the usage of adversarial training to be a starting\npoint for the development of more elaborate navigation strategies that are\ncapable of dealing with uncertain and denied sensor readings.\n","authors":["Mariusz Wisniewski","Paraskevas Chatzithanos","Weisi Guo","Antonios Tsourdos"],"pdf_url":"https://arxiv.org/pdf/2410.14616v1.pdf","comment":"31 pages, 19 figures. For associated code, see\n  https://github.com/mazqtpopx/cranfield-navigation-gym"},{"id":"http://arxiv.org/abs/2403.18197v2","updated":"2024-10-18T16:47:50Z","published":"2024-03-27T02:13:24Z","title":"LocoMan: Advancing Versatile Quadrupedal Dexterity with Lightweight\n  Loco-Manipulators","summary":"  Quadrupedal robots have emerged as versatile agents capable of locomoting and\nmanipulating in complex environments. Traditional designs typically rely on the\nrobot's inherent body parts or incorporate top-mounted arms for manipulation\ntasks. However, these configurations may limit the robot's operational\ndexterity, efficiency and adaptability, particularly in cluttered or\nconstrained spaces. In this work, we present LocoMan, a dexterous quadrupedal\nrobot with a novel morphology to perform versatile manipulation in diverse\nconstrained environments. By equipping a Unitree Go1 robot with two low-cost\nand lightweight modular 3-DoF loco-manipulators on its front calves, LocoMan\nleverages the combined mobility and functionality of the legs and grippers for\ncomplex manipulation tasks that require precise 6D positioning of the end\neffector in a wide workspace. To harness the loco-manipulation capabilities of\nLocoMan, we introduce a unified control framework that extends the whole-body\ncontroller (WBC) to integrate the dynamics of loco-manipulators. Through\nexperiments, we validate that the proposed whole-body controller can accurately\nand stably follow desired 6D trajectories of the end effector and torso, which,\nwhen combined with the large workspace from our design, facilitates a diverse\nset of challenging dexterous loco-manipulation tasks in confined spaces, such\nas opening doors, plugging into sockets, picking objects in narrow and\nlow-lying spaces, and bimanual manipulation.\n","authors":["Changyi Lin","Xingyu Liu","Yuxiang Yang","Yaru Niu","Wenhao Yu","Tingnan Zhang","Jie Tan","Byron Boots","Ding Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.18197v2.pdf","comment":"Project page: https://linchangyi1.github.io/LocoMan"},{"id":"http://arxiv.org/abs/2410.14577v1","updated":"2024-10-18T16:26:18Z","published":"2024-10-18T16:26:18Z","title":"Reimagining partial thickness keratoplasty: An eye mountable robot for\n  autonomous big bubble needle insertion","summary":"  Autonomous surgical robots have demonstrated significant potential to\nstandardize surgical outcomes, driving innovations that enhance safety and\nconsistency regardless of individual surgeon experience. Deep anterior lamellar\nkeratoplasty (DALK), a partial thickness corneal transplant surgery aimed at\nreplacing the anterior part of cornea above Descemet membrane (DM), would\ngreatly benefit from an autonomous surgical approach as it highly relies on\nsurgeon skill with high perforation rates. In this study, we proposed a novel\nautonomous surgical robotic system (AUTO-DALK) based on a customized neural\nnetwork capable of precise needle control and consistent big bubble demarcation\non cadaver and live rabbit models. We demonstrate the feasibility of an\nAI-based image-guided vertical drilling approach for big bubble generation, in\ncontrast to the conventional horizontal needle approach. Our system integrates\nan optical coherence tomography (OCT) fiber optic distal sensor into the\neye-mountable micro robotic system, which automatically segments OCT M-mode\ndepth signals to identify corneal layers using a custom deep learning\nalgorithm. It enables the robot to autonomously guide the needle to targeted\ntissue layers via a depth-controlled feedback loop. We compared autonomous\nneedle insertion performance and resulting pneumo-dissection using AUTO-DALK\nagainst 1) freehand insertion, 2) OCT sensor guided manual insertion, and 3)\nteleoperated robotic insertion, reporting significant improvements in insertion\ndepth, pneumo-dissection depth, task completion time, and big bubble formation.\nEx vivo and in vivo results indicate that the AI-driven, AUTO-DALK system, is a\npromising solution to standardize pneumo-dissection outcomes for partial\nthickness keratoplasty.\n","authors":["Y. Wang","J. D. Opfermann","J. Yu","H. Yi","J. Kaluna","R. Biswas","R. Zuo","W. Gensheimer","A. Krieger","J. U. Kang"],"pdf_url":"https://arxiv.org/pdf/2410.14577v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14565v1","updated":"2024-10-18T16:10:50Z","published":"2024-10-18T16:10:50Z","title":"Graph Optimality-Aware Stochastic LiDAR Bundle Adjustment with\n  Progressive Spatial Smoothing","summary":"  Large-scale LiDAR Bundle Adjustment (LBA) for refining sensor orientation and\npoint cloud accuracy simultaneously is a fundamental task in photogrammetry and\nrobotics, particularly as low-cost 3D sensors are increasingly used for 3D\nmapping in complex scenes. Unlike pose-graph-based methods that rely solely on\npairwise relationships between LiDAR frames, LBA leverages raw LiDAR\ncorrespondences to achieve more precise results, especially when initial pose\nestimates are unreliable for low-cost sensors. However, existing LBA methods\nface challenges such as simplistic planar correspondences, extensive\nobservations, and dense normal matrices in the least-squares problem, which\nlimit robustness, efficiency, and scalability. To address these issues, we\npropose a Graph Optimality-aware Stochastic Optimization scheme with\nProgressive Spatial Smoothing, namely PSS-GOSO, to achieve \\textit{robust},\n\\textit{efficient}, and \\textit{scalable} LBA. The Progressive Spatial\nSmoothing (PSS) module extracts \\textit{robust} LiDAR feature association\nexploiting the prior structure information obtained by the polynomial smooth\nkernel. The Graph Optimality-aware Stochastic Optimization (GOSO) module first\nsparsifies the graph according to optimality for an \\textit{efficient}\noptimization. GOSO then utilizes stochastic clustering and graph\nmarginalization to solve the large-scale state estimation problem for a\n\\textit{scalable} LBA. We validate PSS-GOSO across diverse scenes captured by\nvarious platforms, demonstrating its superior performance compared to existing\nmethods.\n","authors":["Jianping Li","Thien-Minh Nguyen","Muqing Cao","Shenghai Yuan","Tzu-Yi Hung","Lihua Xie"],"pdf_url":"https://arxiv.org/pdf/2410.14565v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14528v1","updated":"2024-10-18T15:10:55Z","published":"2024-10-18T15:10:55Z","title":"Domain Adaptive Safety Filters via Deep Operator Learning","summary":"  Learning-based approaches for constructing Control Barrier Functions (CBFs)\nare increasingly being explored for safety-critical control systems. However,\nthese methods typically require complete retraining when applied to unseen\nenvironments, limiting their adaptability. To address this, we propose a\nself-supervised deep operator learning framework that learns the mapping from\nenvironmental parameters to the corresponding CBF, rather than learning the CBF\ndirectly. Our approach leverages the residual of a parametric Partial\nDifferential Equation (PDE), where the solution defines a parametric CBF\napproximating the maximal control invariant set. This framework accommodates\ncomplex safety constraints, higher relative degrees, and actuation limits. We\ndemonstrate the effectiveness of the method through numerical experiments on\nnavigation tasks involving dynamic obstacles.\n","authors":["Lakshmideepakreddy Manda","Shaoru Chen","Mahyar Fazlyab"],"pdf_url":"https://arxiv.org/pdf/2410.14528v1.pdf","comment":"63rd IEEE Conference on Decision and Control (CDC)"},{"id":"http://arxiv.org/abs/2408.06105v3","updated":"2024-10-18T14:02:07Z","published":"2024-08-12T12:43:46Z","title":"Text2Interaction: Establishing Safe and Preferable Human-Robot\n  Interaction","summary":"  Adjusting robot behavior to human preferences can require intensive human\nfeedback, preventing quick adaptation to new users and changing circumstances.\nMoreover, current approaches typically treat user preferences as a reward,\nwhich requires a manual balance between task success and user satisfaction. To\nintegrate new user preferences in a zero-shot manner, our proposed\nText2Interaction framework invokes large language models to generate a task\nplan, motion preferences as Python code, and parameters of a safety controller.\nBy maximizing the combined probability of task completion and user satisfaction\ninstead of a weighted sum of rewards, we can reliably find plans that fulfill\nboth requirements. We find that 83 % of users working with Text2Interaction\nagree that it integrates their preferences into the plan of the robot, and 94 %\nprefer Text2Interaction over the baseline. Our ablation study shows that\nText2Interaction aligns better with unseen preferences than other baselines\nwhile maintaining a high success rate. Real-world demonstrations and code are\nmade available at sites.google.com/view/text2interaction.\n","authors":["Jakob Thumm","Christopher Agia","Marco Pavone","Matthias Althoff"],"pdf_url":"https://arxiv.org/pdf/2408.06105v3.pdf","comment":"Accepted for the Conference on Robot Learning (CoRL) 2024. Available\n  at: https://openreview.net/forum?id=s0VNSnPeoA"},{"id":"http://arxiv.org/abs/2410.14468v1","updated":"2024-10-18T13:52:28Z","published":"2024-10-18T13:52:28Z","title":"From Simple to Complex: Knowledge Transfer in Safe and Efficient\n  Reinforcement Learning for Autonomous Driving","summary":"  A safe and efficient decision-making system is crucial for autonomous\nvehicles. However, the complexity of driving environments limit the\neffectiveness of many rule-based and machine learning-based decision-making\napproaches. The introduction of Reinforcement Learning in autonomous driving\npresents a promising solution to these challenges, although concerns about\nsafety and efficiency during training remain major obstacles to its widespread\napplication. To address these concerns, we propose a novel framework named\nSimple to Complex Collaborative Decision. First, we rapidly train the teacher\nmodel using the Proximal Policy Optimization algorithm in a lightweight\nautonomous driving simulation environment. In the more complex simulation\nenvironment, the teacher model intervenes when the student agent exhibits\nsub-optimal behavior by assessing the value of actions to avert dangerous\nsituations. Next, we developed an innovative algorithm called Adaptive Clipping\nProximal Policy Optimization. It trains using a combination of samples\ngenerated by both the teacher and student policies and applies dynamic clipping\nstrategies based on sample importance, enabling the algorithm to utilize\nsamples from diverse sources more efficiently. Additionally, we employ the KL\ndivergence between the teacher's and student's policies as a constraint for\npolicy optimization to facilitate the student agent's rapid learning of the\nteacher's policy. Finally, by adopting an appropriate weaning strategy to\ngradually reduce teacher intervention, we ensure that the student agent can\nfully explore the environment independently during the later stages of\ntraining. Simulation experiments in highway lane-change scenarios demonstrate\nthat, compared to baseline algorithms, our proposed framework not only improves\nlearning efficiency and reduces training costs but also significantly enhances\nsafety during training.\n","authors":["Rongliang Zhou","Jiakun Huang","Mingjun Li","Hepeng Li","Haotian Cao","Xiaolin Song"],"pdf_url":"https://arxiv.org/pdf/2410.14468v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.00552v3","updated":"2024-10-18T13:49:19Z","published":"2024-05-01T14:50:58Z","title":"Long-Term Human Trajectory Prediction using 3D Dynamic Scene Graphs","summary":"  We present a novel approach for long-term human trajectory prediction in\nindoor human-centric environments, which is essential for long-horizon robot\nplanning in these environments. State-of-the-art human trajectory prediction\nmethods are limited by their focus on collision avoidance and short-term\nplanning, and their inability to model complex interactions of humans with the\nenvironment. In contrast, our approach overcomes these limitations by\npredicting sequences of human interactions with the environment and using this\ninformation to guide trajectory predictions over a horizon of up to 60s. We\nleverage Large Language Models (LLMs) to predict interactions with the\nenvironment by conditioning the LLM prediction on rich contextual information\nabout the scene. This information is given as a 3D Dynamic Scene Graph that\nencodes the geometry, semantics, and traversability of the environment into a\nhierarchical representation. We then ground these interaction sequences into\nmulti-modal spatio-temporal distributions over human positions using a\nprobabilistic approach based on continuous-time Markov Chains. To evaluate our\napproach, we introduce a new semi-synthetic dataset of long-term human\ntrajectories in complex indoor environments, which also includes annotations of\nhuman-object interactions. We show in thorough experimental evaluations that\nour approach achieves a 54% lower average negative log-likelihood and a 26.5%\nlower Best-of-20 displacement error compared to the best non-privileged (i.e.,\nevaluated in a zero-shot fashion on the dataset) baselines for a time horizon\nof 60s.\n","authors":["Nicolas Gorlo","Lukas Schmid","Luca Carlone"],"pdf_url":"https://arxiv.org/pdf/2405.00552v3.pdf","comment":"8 pages, 6 figures. Accepted at IEEE Robotics and Automation Letters\n  (RA-L). Code released at: https://github.com/MIT-SPARK/LP2"},{"id":"http://arxiv.org/abs/2410.14419v1","updated":"2024-10-18T12:32:15Z","published":"2024-10-18T12:32:15Z","title":"Sim2real Cattle Joint Estimation in 3D point clouds","summary":"  Understanding the well-being of cattle is crucial in various agricultural\ncontexts. Cattle's body shape and joint articulation carry significant\ninformation about their welfare, yet acquiring comprehensive datasets for 3D\nbody pose estimation presents a formidable challenge. This study delves into\nthe construction of such a dataset specifically tailored for cattle. Leveraging\nthe expertise of digital artists, we use a single animated 3D model to\nrepresent diverse cattle postures. To address the disparity between virtual and\nreal-world data, we augment the 3D model's shape to encompass a range of\npotential body appearances, thereby narrowing the \"sim2real\" gap. We use these\nannotated models to train a deep-learning framework capable of estimating\ninternal joints solely based on external surface curvature. Our contribution is\nspecifically the use of geodesic distance over the surface manifold, coupled\nwith multilateration to extract joints in a semantic keypoint detection\nencoder-decoder architecture. We demonstrate the robustness of joint extraction\nby comparing the link lengths extracted on real cattle mobbing and walking\nwithin a race. Furthermore, inspired by the established allometric relationship\nbetween bone length and the overall height of mammals, we utilise the estimated\njoints to predict hip height within a real cattle dataset, extending the\nutility of our approach to offer insights into improving cattle monitoring\npractices.\n","authors":["Okour Mohammad","Falque Raphael","Alempijevic Alen"],"pdf_url":"https://arxiv.org/pdf/2410.14419v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.10547v2","updated":"2024-10-18T12:25:46Z","published":"2024-07-15T08:57:02Z","title":"Learning Social Cost Functions for Human-Aware Path Planning","summary":"  Achieving social acceptance is one of the main goals of Social Robotic\nNavigation. Despite this topic has received increasing interest in recent\nyears, most of the research has focused on driving the robotic agent along\nobstacle-free trajectories, planning around estimates of future human motion to\nrespect personal distances and optimize navigation. However, social\ninteractions in everyday life are also dictated by norms that do not strictly\ndepend on movement, such as when standing at the end of a queue rather than\ncutting it. In this paper, we propose a novel method to recognize common social\nscenarios and modify a traditional planner's cost function to adapt to them.\nThis solution enables the robot to carry out different social navigation\nbehaviors that would not arise otherwise, maintaining the robustness of\ntraditional navigation. Our approach allows the robot to learn different social\nnorms with a single learned model, rather than having different modules for\neach task. As a proof of concept, we consider the tasks of queuing and respect\ninteraction spaces of groups of people talking to one another, but the method\ncan be extended to other human activities that do not involve motion.\n","authors":["Andrea Eirale","Matteo Leonetti","Marcello Chiaberge"],"pdf_url":"https://arxiv.org/pdf/2407.10547v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.08031v2","updated":"2024-10-18T12:22:11Z","published":"2024-09-12T13:23:24Z","title":"LED: Light Enhanced Depth Estimation at Night","summary":"  Nighttime camera-based depth estimation is a highly challenging task,\nespecially for autonomous driving applications, where accurate depth perception\nis essential for ensuring safe navigation. We aim to improve the reliability of\nperception systems at night time, where models trained on daytime data often\nfail in the absence of precise but costly LiDAR sensors. In this work, we\nintroduce Light Enhanced Depth (LED), a novel cost-effective approach that\nsignificantly improves depth estimation in low-light environments by harnessing\na pattern projected by high definition headlights available in modern vehicles.\nLED leads to significant performance boosts across multiple depth-estimation\narchitectures (encoder-decoder, Adabins, DepthFormer) both on synthetic and\nreal datasets. Furthermore, increased performances beyond illuminated areas\nreveal a holistic enhancement in scene understanding. Finally, we release the\nNighttime Synthetic Drive Dataset, a new synthetic and photo-realistic\nnighttime dataset, which comprises 49,990 comprehensively annotated images.\n","authors":["Simon de Moreau","Yasser Almehio","Andrei Bursuc","Hafid El-Idrissi","Bogdan Stanciulescu","Fabien Moutarde"],"pdf_url":"https://arxiv.org/pdf/2409.08031v2.pdf","comment":"Preprint. Code and dataset available on the project page :\n  https://simondemoreau.github.io/LED/"},{"id":"http://arxiv.org/abs/2410.14407v1","updated":"2024-10-18T12:14:09Z","published":"2024-10-18T12:14:09Z","title":"Formation Control for Moving Target Enclosing and Tracking via Relative\n  Localization","summary":"  This paper proposes an integrated framework for coordinating multiple\nunmanned aerial vehicles (UAVs) in a distributed fashion to persistently\nenclose and track a moving target without external localization systems. It is\nassumed that the UAV can obtain self-displacement and the target's relative\nposition using vision-based methods within its local frame. Additionally, UAVs\ncan measure relative distances and communicate with each other, e.g. by\nultrawideband (UWB) sensors. Due to the absence of a global coordinate system,\nmeasurements from neighbors cannot be directly utilized for collaborative\nestimation of the target state. To address this, a recursive least squares\nestimator (RLSE) for estimating the relative positions between UAVs is\nintegrated into a distributed Kalman filter (DKF), enabling a persistent\nestimation of the target state. When the UAV loses direct measurements of the\ntarget due to environmental occlusion, measurements from neighbors will be\naligned into the UAV's local frame to provide indirect measurements.\nFurthermore, simultaneously ensuring the convergence of the estimators and\nmaintaining effective target tracking is a significant challenge. To tackle\nthis problem, a consensus-based formation controller with bounded inputs is\ndeveloped by integrating a coupled oscillator-based circular formation design.\nTheoretical analysis shows that the proposed framework ensures asymptotic\ntracking of a target with constant velocity. For a target with varying\nvelocity, the tracking error converges to a bounded region related to the\ntarget's maximum acceleration. Simulations and experiments validate the\neffectiveness of the proposed algorithm.\n","authors":["Xueming Liu","Dengyu Zhang","Qingrui Zhang","Tianjiang Hu"],"pdf_url":"https://arxiv.org/pdf/2410.14407v1.pdf","comment":"13 Pages"},{"id":"http://arxiv.org/abs/2410.14406v1","updated":"2024-10-18T12:12:14Z","published":"2024-10-18T12:12:14Z","title":"On the Benefits of Robot Platooning for Navigating Crowded Environments","summary":"  This paper studies how groups of robots can effectively navigate through a\ncrowd of agents. It quantifies the performance of platooning and less\nconstrained, greedy strategies, and the extent to which these strategies\ndisrupt the crowd agents. Three scenarios are considered: (i) passive crowds,\n(ii) counter-flow crowds, and (iii) perpendicular-flow crowds. Through\nsimulations consisting of up to 200 robots, we show that for navigating passive\nand counter-flow crowds, the platooning strategy is less disruptive and more\neffective in dense crowds than the greedy strategy, whereas for navigating\nperpendicular-flow crowds, the greedy strategy outperforms the platooning\nstrategy in either aspect. Moreover, we propose an adaptive strategy that can\nswitch between platooning and greedy behavioral states, and demonstrate that it\ncombines the strengths of both strategies in all the scenarios considered.\n","authors":["Jahir Argote-Gerald","Genki Miyauchi","Paul Trodden","Roderich Gross"],"pdf_url":"https://arxiv.org/pdf/2410.14406v1.pdf","comment":"14 pages, 7 figures, to be published in DARS 2024"},{"id":"http://arxiv.org/abs/2410.14383v1","updated":"2024-10-18T11:20:00Z","published":"2024-10-18T11:20:00Z","title":"MARLIN: Multi-Agent Reinforcement Learning Guided by Language-Based\n  Inter-Robot Negotiation","summary":"  Multi-agent reinforcement learning is a key method for training multi-robot\nsystems over a series of episodes in which robots are rewarded or punished\naccording to their performance; only once the system is trained to a suitable\nstandard is it deployed in the real world. If the system is not trained enough,\nthe task will likely not be completed and could pose a risk to the surrounding\nenvironment. Therefore, reaching high performance in a shorter training period\ncan lead to significant reductions in time and resource consumption. We\nintroduce Multi-Agent Reinforcement Learning guided by Language-based\nInter-Robot Negotiation (MARLIN), which makes the training process both faster\nand more transparent. We equip robots with large language models that negotiate\nand debate the task, producing a plan that is used to guide the policy during\ntraining. We dynamically switch between using reinforcement learning and the\nnegotiation-based approach throughout training. This offers an increase in\ntraining speed when compared to standard multi-agent reinforcement learning and\nallows the system to be deployed to physical hardware earlier. As robots\nnegotiate in natural language, we can better understand the behaviour of the\nrobots individually and as a collective. We compare the performance of our\napproach to multi-agent reinforcement learning and a large language model to\nshow that our hybrid method trains faster at little cost to performance.\n","authors":["Toby Godfrey","William Hunt","Mohammad D. Soorati"],"pdf_url":"https://arxiv.org/pdf/2410.14383v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14368v1","updated":"2024-10-18T10:53:44Z","published":"2024-10-18T10:53:44Z","title":"CoMAL: Collaborative Multi-Agent Large Language Models for\n  Mixed-Autonomy Traffic","summary":"  The integration of autonomous vehicles into urban traffic has great potential\nto improve efficiency by reducing congestion and optimizing traffic flow\nsystematically. In this paper, we introduce CoMAL (Collaborative Multi-Agent\nLLMs), a framework designed to address the mixed-autonomy traffic problem by\ncollaboration among autonomous vehicles to optimize traffic flow. CoMAL is\nbuilt upon large language models, operating in an interactive traffic\nsimulation environment. It utilizes a Perception Module to observe surrounding\nagents and a Memory Module to store strategies for each agent. The overall\nworkflow includes a Collaboration Module that encourages autonomous vehicles to\ndiscuss the effective strategy and allocate roles, a reasoning engine to\ndetermine optimal behaviors based on assigned roles, and an Execution Module\nthat controls vehicle actions using a hybrid approach combining rule-based\nmodels. Experimental results demonstrate that CoMAL achieves superior\nperformance on the Flow benchmark. Additionally, we evaluate the impact of\ndifferent language models and compare our framework with reinforcement learning\napproaches. It highlights the strong cooperative capability of LLM agents and\npresents a promising solution to the mixed-autonomy traffic challenge. The code\nis available at https://github.com/Hyan-Yao/CoMAL.\n","authors":["Huaiyuan Yao","Longchao Da","Vishnu Nandam","Justin Turnau","Zhiwei Liu","Linsey Pang","Hua Wei"],"pdf_url":"https://arxiv.org/pdf/2410.14368v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14367v1","updated":"2024-10-18T10:52:29Z","published":"2024-10-18T10:52:29Z","title":"Quadrotor Guidance for Window Traversal: A Bearings-Only Approach","summary":"  This paper focuses on developing a bearings-only measurement-based\nthree-dimensional window traversal guidance method for quadrotor Uninhabitated\nAerial Vehicles (UAVs). The desired flight path and heading angles of the\nquadrotor are proposed as functions of the bearing angle information of the\nfour vertices of the window. These angular guidance inputs employ a bearing\nangle bisector term and an elliptic shaping angle term, which directs the\nquadrotor towards the centroid of the window. Detailed stability analysis of\nthe resulting kinematics demonstrates that all quadrotor trajectories lead to\nthe centroid of the window along a direction which is normal to the window\nplane. A qualitative comparison with existing traversal methodologies showcases\nthe superiority of the proposed guidance approach with regard to the nature of\ninformation, computations for generating the guidance commands, and flexibility\nof replanning the traversal path. Realistic simulations considering six\ndegree-of-freedom quadrotor model and Monte Carlo studies validate the\neffectiveness, accuracy, and robustness of the proposed guidance solution.\nRepresentative flight validation trials are carried out using an indoor motion\ncapture system.\n","authors":["Midhun E K","Ashwini Ratnoo"],"pdf_url":"https://arxiv.org/pdf/2410.14367v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14337v1","updated":"2024-10-18T09:50:05Z","published":"2024-10-18T09:50:05Z","title":"Perception of Emotions in Human and Robot Faces: Is the Eye Region\n  Enough?","summary":"  The increased interest in developing next-gen social robots has raised\nquestions about the factors affecting the perception of robot emotions. This\nstudy investigates the impact of robot appearances (humanlike, mechanical) and\nface regions (full-face, eye-region) on human perception of robot emotions. A\nbetween-subjects user study (N = 305) was conducted where participants were\nasked to identify the emotions being displayed in videos of robot faces, as\nwell as a human baseline. Our findings reveal three important insights for\neffective social robot face design in Human-Robot Interaction (HRI): Firstly,\nrobots equipped with a back-projected, fully animated face - regardless of\nwhether they are more human-like or more mechanical-looking - demonstrate a\ncapacity for emotional expression comparable to that of humans. Secondly, the\nrecognition accuracy of emotional expressions in both humans and robots\ndeclines when only the eye region is visible. Lastly, within the constraint of\nonly the eye region being visible, robots with more human-like features\nsignificantly enhance emotion recognition.\n","authors":["Chinmaya Mishra","Gabriel Skantze","Peter Hagoort","Rinus Verdonschot"],"pdf_url":"https://arxiv.org/pdf/2410.14337v1.pdf","comment":"Accepted for publication at the 16th International Conference on\n  Social Robotics, Odense, Denmark (ICSR 2024)"},{"id":"http://arxiv.org/abs/2407.11478v2","updated":"2024-10-18T09:43:12Z","published":"2024-07-16T08:16:25Z","title":"Trajectory Optimization under Contact Timing Uncertainties","summary":"  Most interesting problems in robotics (e.g., locomotion and manipulation) are\nrealized through intermittent contact with the environment. Due to the\nperception and modeling errors, assuming an exact time for establishing contact\nwith the environment is unrealistic. On the other hand, handling uncertainties\nin contact timing is notoriously difficult as it gives rise to either handling\nuncertain complementarity systems or solving combinatorial optimization\nproblems at run-time. This work presents a novel optimal control formulation to\nfind robust control policies under contact timing uncertainties. Our main\nnovelty lies in casting the stochastic problem to a deterministic optimization\nover the uncertainty set that ensures robustness criterion satisfaction of\ncandidate pre-contact states and optimizes for contact-relevant objectives.\nThis way, we only need to solve a manageable standard nonlinear programming\nproblem without complementarity constraints or combinatorial explosion. Our\nsimulation results on multiple simplified locomotion and manipulation tasks\ndemonstrate the robustness of our uncertainty-aware formulation compared to the\nnominal optimal control formulation.\n","authors":["Haizhou Zhao","Majid Khadiv"],"pdf_url":"https://arxiv.org/pdf/2407.11478v2.pdf","comment":"2024 IEEE-RAS International Conference on Humanoid Robots (Humanoids)"},{"id":"http://arxiv.org/abs/2410.14310v1","updated":"2024-10-18T09:15:47Z","published":"2024-10-18T09:15:47Z","title":"Transferring Tactile Data Across Sensors","summary":"  Tactile perception is essential for human interaction with the environment\nand is becoming increasingly crucial in robotics. Tactile sensors like the\nBioTac mimic human fingertips and provide detailed interaction data. Despite\nits utility in applications like slip detection and object identification, this\nsensor is now deprecated, making many existing datasets obsolete. This article\nintroduces a novel method for translating data between tactile sensors by\nexploiting sensor deformation information rather than output signals. We\ndemonstrate the approach by translating BioTac signals into the DIGIT sensor.\nOur framework consists of three steps: first, converting signal data into\ncorresponding 3D deformation meshes; second, translating these 3D deformation\nmeshes from one sensor to another; and third, generating output images using\nthe converted meshes. Our approach enables the continued use of valuable\ndatasets.\n","authors":["Wadhah Zai El Amri","Malte Kuhlmann","Nicolás Navarro-Guerrero"],"pdf_url":"https://arxiv.org/pdf/2410.14310v1.pdf","comment":"Extended Abstract. Accepted in ICRA@40 (40th Anniversary of the IEEE\n  International Conference on Robotics and Automation) 23-26 September, 2024\n  Rotterdam, Netherlands"},{"id":"http://arxiv.org/abs/2410.14305v1","updated":"2024-10-18T09:09:35Z","published":"2024-10-18T09:09:35Z","title":"Optimizing Modeling of Continuum Robots: Integration of Lie Group\n  Kinematics and Evolutionary Algorithms","summary":"  Continuum robots, known for their high flexibility and adaptability, offer\nimmense potential for applications such as medical surgery, confined-space\ninspections, and wearable devices. However, their non-linear elastic properties\nand complex kinematics present significant challenges in digital modeling and\neffective control. This research proposes a novel computational framework that\nintegrates Lie group kinematics with an evolutionary algorithm (EA) to identify\noptimal control coefficients for specific robot models. Our method starts by\ngenerating datasets from physics-based simulations and fractional order\ncontrol, defining both ideal configurations and models to be optimized. By\nusing EA, we iteratively minimize deviations through two fitness objectives\n\\textemdash deviation mean squared error (\\(\\text{MSE}_1\\)) and TCP vector\nerror (\\(\\text{MSE}_2\\)) \\textemdash to align the robot's backbone with the\ndesired configuration. Built on the Computer-Aided Design (CAD) platform\nGrasshopper, this framework provides real-time visualization, enabling dynamic\ncontrol of robot configurations. Results show that the proposed method achieves\nprecise alignment of the robot's backbone with minimal computation. This\napproach not only simplifies the coefficient identification process but also\ndemonstrates the advantages of EA in multi-objective optimization, contributing\nto efficient modeling and control of continuum robots.\n","authors":["Po-Yu Hsieh","June-Hao Hou"],"pdf_url":"https://arxiv.org/pdf/2410.14305v1.pdf","comment":"10 pages, 20 figures"},{"id":"http://arxiv.org/abs/2410.14298v1","updated":"2024-10-18T08:58:44Z","published":"2024-10-18T08:58:44Z","title":"Optimizing Collaborative Robotics since Pre-Deployment via\n  Cyber-Physical Systems' Digital Twins","summary":"  The collaboration between humans and robots re-quires a paradigm shift not\nonly in robot perception, reasoning, and action, but also in the design of the\nrobotic cell. This paper proposes an optimization framework for designing\ncollaborative robotics cells using a digital twin during the pre-deployment\nphase. This approach mitigates the limitations of experience-based sub-optimal\ndesigns by means of Bayesian optimization to find the optimal layout after a\ncertain number of iterations. By integrating production KPIs into a black-box\noptimization frame-work, the digital twin supports data-driven decision-making,\nreduces the need for costly prototypes, and ensures continuous improvement\nthanks to the learning nature of the algorithm. The paper presents a case study\nwith preliminary results that show how this methodology can be applied to\nobtain safer, more efficient, and adaptable human-robot collaborative\nenvironments.\n","authors":["Christian Cella","Marco Faroni","Andrea Zanchettin","Paolo Rocco"],"pdf_url":"https://arxiv.org/pdf/2410.14298v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02661v2","updated":"2024-10-18T08:31:22Z","published":"2024-08-05T17:55:20Z","title":"Context-aware Mamba-based Reinforcement Learning for social robot\n  navigation","summary":"  Social robot navigation (SRN) is a relevant problem that involves navigating\na pedestrian-rich environment in a socially acceptable manner. It is an\nessential part of making social robots effective in pedestrian-rich settings.\nThe use cases of such robots could vary from companion robots to warehouse\nrobots to autonomous wheelchairs. In recent years, deep reinforcement learning\nhas been increasingly used in research on social robot navigation. Our work\nintroduces CAMRL (Context-Aware Mamba-based Reinforcement Learning). Mamba is a\nnew deep learning-based State Space Model (SSM) that has achieved results\ncomparable to transformers in sequencing tasks. CAMRL uses Mamba to determine\nthe robot's next action, which maximizes the value of the next state predicted\nby the neural network, enabling the robot to navigate effectively based on the\nrewards assigned. We evaluate CAMRL alongside existing solutions (CADRL,\nLSTM-RL, SARL) using a rigorous testing dataset which involves a variety of\ndensities and environment behaviors based on ORCA and SFM, thus, demonstrating\nthat CAMRL achieves higher success rates, minimizes collisions, and maintains\nsafer distances from pedestrians. This work introduces a new SRN planner,\nshowcasing the potential for deep-state space models for robot navigation.\n","authors":["Syed Muhammad Mustafa","Omema Rizvi","Zain Ahmed Usmani","Abdul Basit Memon","Muhammad Mobeen Movania"],"pdf_url":"https://arxiv.org/pdf/2408.02661v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.03454v2","updated":"2024-10-18T08:24:49Z","published":"2024-06-05T16:57:57Z","title":"Mission Design for Unmanned Aerial Vehicles using Hybrid Probabilistic\n  Logic Programs","summary":"  Advanced Air Mobility (AAM) is a growing field that demands a deep\nunderstanding of legal, spatial and temporal concepts in navigation. Hence, any\nimplementation of AAM is forced to deal with the inherent uncertainties of\nhuman-inhabited spaces. Enabling growth and innovation requires the creation of\na system for safe and robust mission design, i.e., the way we formalize\nintentions and decide their execution as trajectories for the Unmanned Aerial\nVehicle (UAV). Although legal frameworks have emerged to govern urban air\nspaces, their full integration into the decision process of autonomous agents\nand operators remains an open task. In this work we present ProMis, a system\narchitecture for probabilistic mission design. It links the data available from\nvarious static and dynamic data sources with legal text and operator\nrequirements by following principles of formal verification and probabilistic\nmodeling. Hereby, ProMis enables the combination of low-level perception and\nhigh-level rules in AAM to infer validity over the UAV's state-space. To this\nend, we employ Hybrid Probabilistic Logic Programs (HPLP) as a unifying,\nintermediate representation between perception and action-taking. Furthermore,\nwe present methods to connect ProMis with crowd-sourced map data by generating\nHPLP atoms that represent spatial relations in a probabilistic fashion. Our\nclaims of the utility and generality of ProMis are supported by experiments on\na diverse set of scenarios and a discussion of the computational demands\nassociated with probabilistic missions.\n","authors":["Simon Kohaut","Benedict Flade","Devendra Singh Dhami","Julian Eggert","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2406.03454v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14264v1","updated":"2024-10-18T08:19:26Z","published":"2024-10-18T08:19:26Z","title":"Error Decomposition for Hybrid Localization Systems","summary":"  Future advanced driver assistance systems and autonomous vehicles rely on\naccurate localization, which can be divided into three classes: a) viewpoint\nlocalization about local references (e.g., via vision-based localization), b)\nabsolute localization about a global reference system (e.g., via satellite\nnavigation), and c) hybrid localization, which presents a combination of the\nformer two. Hybrid localization shares characteristics and strengths of both\nabsolute and viewpoint localization. However, new sources of error, such as\ninaccurate sensor-setup calibration, complement the potential errors of the\nrespective sub-systems. Therefore, this paper introduces a general approach to\nanalyzing error sources in hybrid localization systems. More specifically, we\npropose the Kappa-Phi method, which allows for the decomposition of\nlocalization errors into individual components, i.e., into a sum of\nparameterized functions of the measured state (e.g., agent kinematics). The\nerror components can then be leveraged to, e.g., improve localization\npredictions, correct map data, or calibrate sensor setups. Theoretical\nderivations and evaluations show that the algorithm presents a promising\napproach to improve hybrid localization and counter the weaknesses of the\nsystem's individual components.\n","authors":["Benedict Flade","Simon Kohaut","Julian Eggert"],"pdf_url":"https://arxiv.org/pdf/2410.14264v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14249v1","updated":"2024-10-18T08:01:32Z","published":"2024-10-18T08:01:32Z","title":"A Tactile Feedback Approach to Path Recovery after High-Speed Impacts\n  for Collision-Resilient Drones","summary":"  Aerial robots are a well-established solution for exploration, monitoring,\nand inspection, thanks to their superior maneuverability and agility. However,\nin many environments of interest, they risk crashing and sustaining damage\nfollowing collisions. Traditional methods focus on avoiding obstacles entirely\nto prevent damage, but these approaches can be limiting, particularly in\ncomplex environments where collisions may be unavoidable, or on weight and\ncompute-constrained platforms. This paper presents a novel approach to enhance\nthe robustness and autonomy of drones in such scenarios by developing a path\nrecovery and adjustment method for a high-speed collision-resistant drone\nequipped with binary contact sensors. The proposed system employs an estimator\nthat explicitly models collisions, using pre-collision velocities and rates to\npredict post-collision dynamics, thereby improving the drone's state estimation\naccuracy. Additionally, we introduce a vector-field-based path representation\nwhich guarantees convergence to the path. Post-collision, the contact point is\nincorporated into the vector field as a repulsive potential, enabling the drone\nto avoid obstacles while naturally converging to the original path. The\neffectiveness of this method is validated through Monte Carlo simulations and\ndemonstrated on a physical prototype, showing successful path following and\nadjustment through collisions as well as recovery from collisions at speeds up\nto 3.7 m / s.\n","authors":["Anton Bredenbeck","Teaya Yang","Salua Hamaza","Mark W. Mueller"],"pdf_url":"https://arxiv.org/pdf/2410.14249v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.06790v2","updated":"2024-10-18T07:38:24Z","published":"2024-10-09T11:40:51Z","title":"Discrete time model predictive control for humanoid walking with step\n  adjustment","summary":"  This paper presents a Discrete-Time Model Predictive Controller (MPC) for\nhumanoid walking with online footstep adjustment. The proposed controller\nutilizes a hierarchical control approach. The high-level controller uses a\nlow-dimensional Linear Inverted Pendulum Model (LIPM) to determine desired foot\nplacement and Center of Mass (CoM) motion, to prevent falls while maintaining\nthe desired velocity. A Task Space Controller (TSC) then tracks the desired\nmotion obtained from the high-level controller, exploiting the whole-body\ndynamics of the humanoid. Our approach differs from existing MPC methods for\nwalking pattern generation by not relying on a predefined foot-plan or a\nreference center of pressure (CoP) trajectory. The overall approach is tested\nin simulation on a torque-controlled Humanoid Robot. Results show that proposed\ncontrol approach generates stable walking and prevents fall against push\ndisturbances.\n","authors":["Vishnu Joshi","Suraj Kumar","Nithin V","Shishir Kolathaya"],"pdf_url":"https://arxiv.org/pdf/2410.06790v2.pdf","comment":"6 pages, 17 figures, 1 table"},{"id":"http://arxiv.org/abs/2409.06959v2","updated":"2024-10-18T06:38:38Z","published":"2024-09-11T02:48:13Z","title":"Pyramid-Monozone Synergistic Grasping Policy in Dense Clutter","summary":"  Grasping a diverse range of novel objects in dense clutter poses a great\nchallenge to robotic automation mainly due to the occlusion problem. In this\nwork, we propose the Pyramid-Monozone Synergistic Grasping Policy (PMSGP) that\nenables robots to effectively handle occlusions during grasping. Specifically,\nwe initially construct the Pyramid Sequencing Policy (PSP) to sequence each\nobject in cluttered scenes into a pyramid structure. By isolating objects\nlayer-by-layer, the grasp detection model is allowed to focus on a single layer\nduring each grasp. Then, we devise the Monozone Sampling Policy (MSP) to sample\nthe grasp candidates in the top layer. Through this manner, each grasp targets\nthe topmost object, thereby effectively avoiding most occlusions. We performed\nmore than 7,000 real-world grasping in densely cluttered scenes with 300 novel\nobjects, demonstrating that PMSGP significantly outperforms seven competitive\ngrasping methods. More importantly, we tested the grasping performance of PMSGP\nin extremely cluttered scenes involving 100 different household goods, and\nfound that PMSGP pushed the grasp success rate to 84.9\\%. To the best of our\nknowledge, no previous work has demonstrated similar performance. All grasping\nvideos are available at: https://www.youtube.com/@chenghaoli4532/playlists.\n","authors":["Chenghao Li","Nak Young Chong"],"pdf_url":"https://arxiv.org/pdf/2409.06959v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14203v1","updated":"2024-10-18T06:37:46Z","published":"2024-10-18T06:37:46Z","title":"EPIC: A Lightweight LiDAR-Based UAV Exploration Framework for\n  Large-Scale Scenarios","summary":"  Autonomous exploration is a fundamental problem for various applications of\nunmanned aerial vehicles (UAVs). Recently, LiDAR-based exploration has gained\nsignificant attention due to its ability to generate high-precision point cloud\nmaps of large-scale environments. While the point clouds are inherently\ninformative for navigation, many existing exploration methods still rely on\nadditional, often expensive, environmental representations. This reliance stems\nfrom two main reasons: the need for frontier detection or information gain\ncomputation, which typically depends on memory-intensive occupancy grid maps,\nand the high computational complexity of path planning directly on point\nclouds, primarily due to costly collision checking. To address these\nlimitations, we present EPIC, a lightweight LiDAR-based UAV exploration\nframework that directly exploits point cloud data to explore large-scale\nenvironments. EPIC introduces a novel observation map derived directly from the\nquality of point clouds, eliminating the need for global occupancy grid maps\nwhile preserving comprehensive exploration capabilities. We also propose an\nincremental topological graph construction method operating directly on point\nclouds, enabling real-time path planning in large-scale environments.\nLeveraging these components, we build a hierarchical planning framework that\ngenerates agile and energy-efficient trajectories, achieving significantly\nreduced memory consumption and computation time compared to most existing\nmethods. Extensive simulations and real-world experiments demonstrate that EPIC\nachieves faster exploration while significantly reducing memory consumption\ncompared to state-of-the-art methods.\n","authors":["Shuang Geng","Zelin Ning","Fu Zhang","Boyu Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.14203v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14191v1","updated":"2024-10-18T05:55:28Z","published":"2024-10-18T05:55:28Z","title":"A Probabilistic Model for Skill Acquisition with Switching Latent\n  Feedback Controllers","summary":"  Manipulation tasks often consist of subtasks, each representing a distinct\nskill. Mastering these skills is essential for robots, as it enhances their\nautonomy, efficiency, adaptability, and ability to work in their environment.\nLearning from demonstrations allows robots to rapidly acquire new skills\nwithout starting from scratch, with demonstrations typically sequencing skills\nto achieve tasks. Behaviour cloning approaches to learning from demonstration\ncommonly rely on mixture density network output heads to predict robot actions.\nIn this work, we first reinterpret the mixture density network as a library of\nfeedback controllers (or skills) conditioned on latent states. This arises from\nthe observation that a one-layer linear network is functionally equivalent to a\nclassical feedback controller, with network weights corresponding to controller\ngains. We use this insight to derive a probabilistic graphical model that\ncombines these elements, describing the skill acquisition process as\nsegmentation in a latent space, where each skill policy functions as a feedback\ncontrol law in this latent space. Our approach significantly improves not only\ntask success rate, but also robustness to observation noise when trained with\nhuman demonstrations. Our physical robot experiments further show that the\ninduced robustness improves model deployment on robots.\n","authors":["Juyan Zhang","Dana Kulic","Michael Burke"],"pdf_url":"https://arxiv.org/pdf/2410.14191v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14177v1","updated":"2024-10-18T05:09:07Z","published":"2024-10-18T05:09:07Z","title":"Learning autonomous driving from aerial imagery","summary":"  In this work, we consider the problem of learning end to end perception to\ncontrol for ground vehicles solely from aerial imagery. Photogrammetric\nsimulators allow the synthesis of novel views through the transformation of\npre-generated assets into novel views.However, they have a large setup cost,\nrequire careful collection of data and often human effort to create usable\nsimulators. We use a Neural Radiance Field (NeRF) as an intermediate\nrepresentation to synthesize novel views from the point of view of a ground\nvehicle. These novel viewpoints can then be used for several downstream\nautonomous navigation applications. In this work, we demonstrate the utility of\nnovel view synthesis though the application of training a policy for end to end\nlearning from images and depth data. In a traditional real to sim to real\nframework, the collected data would be transformed into a visual simulator\nwhich could then be used to generate novel views. In contrast, using a NeRF\nallows a compact representation and the ability to optimize over the parameters\nof the visual simulator as more data is gathered in the environment. We\ndemonstrate the efficacy of our method in a custom built mini-city environment\nthrough the deployment of imitation policies on robotic cars. We additionally\nconsider the task of place localization and demonstrate that our method is able\nto relocalize the car in the real world.\n","authors":["Varun Murali","Guy Rosman","Sertac Karaman","Daniela Rus"],"pdf_url":"https://arxiv.org/pdf/2410.14177v1.pdf","comment":"Presented at IROS 2024"},{"id":"http://arxiv.org/abs/2410.12324v2","updated":"2024-10-18T04:32:34Z","published":"2024-10-16T07:44:56Z","title":"PAPL-SLAM: Principal Axis-Anchored Monocular Point-Line SLAM","summary":"  In point-line SLAM systems, the utilization of line structural information\nand the optimization of lines are two significant problems. The former is\nusually addressed through structural regularities, while the latter typically\ninvolves using minimal parameter representations of lines in optimization.\nHowever, separating these two steps leads to the loss of constraint information\nto each other. We anchor lines with similar directions to a principal axis and\noptimize them with $n+2$ parameters for $n$ lines, solving both problems\ntogether. Our method considers scene structural information, which can be\neasily extended to different world hypotheses while significantly reducing the\nnumber of line parameters to be optimized, enabling rapid and accurate mapping\nand tracking. To further enhance the system's robustness and avoid mismatch, we\nhave modeled the line-axis probabilistic data association and provided the\nalgorithm for axis creation, updating, and optimization. Additionally,\nconsidering that most real-world scenes conform to the Atlanta World\nhypothesis, we provide a structural line detection strategy based on vertical\npriors and vanishing points. Experimental results and ablation studies on\nvarious indoor and outdoor datasets demonstrate the effectiveness of our\nsystem.\n","authors":["Guanghao Li","Yu Cao","Qi Chen","Yifan Yang","Jian Pu"],"pdf_url":"https://arxiv.org/pdf/2410.12324v2.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2404.13346v2","updated":"2024-10-18T04:26:11Z","published":"2024-04-20T11:04:48Z","title":"EC-SLAM: Effectively Constrained Neural RGB-D SLAM with Sparse TSDF\n  Encoding and Global Bundle Adjustment","summary":"  We introduce EC-SLAM, a real-time dense RGB-D simultaneous localization and\nmapping (SLAM) system leveraging Neural Radiance Fields (NeRF). While recent\nNeRF-based SLAM systems have shown promising results, they have yet to fully\nexploit NeRF's potential to constrain pose optimization. EC-SLAM addresses this\nby using sparse parametric encodings and Truncated Signed Distance Fields\n(TSDF) to represent the map, enabling efficient fusion, reducing model\nparameters, and accelerating convergence. Our system also employs a globally\nconstrained Bundle Adjustment (BA) strategy that capitalizes on NeRF's implicit\nloop closure correction capability, improving tracking accuracy by reinforcing\nconstraints on keyframes most relevant to the current optimized frame.\nFurthermore, by integrating a feature-based and uniform sampling strategy that\nminimizes ineffective constraint points for pose optimization, we reduce the\nimpact of random sampling in NeRF. Extensive evaluations on the Replica,\nScanNet, and TUM datasets demonstrate state-of-the-art performance, with\nprecise tracking and reconstruction accuracy achieved alongside real-time\noperation at up to 21 Hz.\n","authors":["Guanghao Li","Qi Chen","YuXiang Yan","Jian Pu"],"pdf_url":"https://arxiv.org/pdf/2404.13346v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14164v1","updated":"2024-10-18T04:04:58Z","published":"2024-10-18T04:04:58Z","title":"Optimal DLT-based Solutions for the Perspective-n-Point","summary":"  We propose a modified normalized direct linear transform (DLT) algorithm for\nsolving the perspective-n-point (PnP) problem with much better behavior than\nthe conventional DLT. The modification consists of analytically weighting the\ndifferent measurements in the linear system with a negligible increase in\ncomputational load. Our approach exhibits clear improvements -- in both\nperformance and runtime -- when compared to popular methods such as EPnP, CPnP,\nRPnP, and OPnP. Our new non-iterative solution approaches that of the true\noptimal found via Gauss-Newton optimization, but at a fraction of the\ncomputational cost. Our optimal DLT (oDLT) implementation, as well as the\nexperiments, are released in open source.\n","authors":["Sébastien Henry","John A. Christian"],"pdf_url":"https://arxiv.org/pdf/2410.14164v1.pdf","comment":"8 pages, 6 figures, 2 tables"},{"id":"http://arxiv.org/abs/2406.11793v2","updated":"2024-10-18T03:56:52Z","published":"2024-06-17T17:41:42Z","title":"FetchBench: A Simulation Benchmark for Robot Fetching","summary":"  Fetching, which includes approaching, grasping, and retrieving, is a critical\nchallenge for robot manipulation tasks. Existing methods primarily focus on\ntable-top scenarios, which do not adequately capture the complexities of\nenvironments where both grasping and planning are essential. To address this\ngap, we propose a new benchmark FetchBench, featuring diverse procedural scenes\nthat integrate both grasping and motion planning challenges. Additionally,\nFetchBench includes a data generation pipeline that collects successful fetch\ntrajectories for use in imitation learning methods. We implement multiple\nbaselines from the traditional sense-plan-act pipeline to end-to-end behavior\nmodels. Our empirical analysis reveals that these methods achieve a maximum\nsuccess rate of only 20%, indicating substantial room for improvement.\nAdditionally, we identify key bottlenecks within the sense-plan-act pipeline\nand make recommendations based on the systematic analysis.\n","authors":["Beining Han","Meenal Parakh","Derek Geng","Jack A Defay","Gan Luyang","Jia Deng"],"pdf_url":"https://arxiv.org/pdf/2406.11793v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18212v2","updated":"2024-10-18T03:50:57Z","published":"2024-03-27T02:46:09Z","title":"Preference-Based Planning in Stochastic Environments: From\n  Partially-Ordered Temporal Goals to Most Preferred Policies","summary":"  Human preferences are not always represented via complete linear orders: It\nis natural to employ partially-ordered preferences for expressing incomparable\noutcomes. In this work, we consider decision-making and probabilistic planning\nin stochastic systems modeled as Markov decision processes (MDPs), given a\npartially ordered preference over a set of temporally extended goals.\nSpecifically, each temporally extended goal is expressed using a formula in\nLinear Temporal Logic on Finite Traces (LTL$_f$). To plan with the partially\nordered preference, we introduce order theory to map a preference over temporal\ngoals to a preference over policies for the MDP. Accordingly, a most preferred\npolicy under a stochastic ordering induces a stochastic nondominated\nprobability distribution over the finite paths in the MDP. To synthesize a most\npreferred policy, our technical approach includes two key steps. In the first\nstep, we develop a procedure to transform a partially ordered preference over\ntemporal goals into a computational model, called preference automaton, which\nis a semi-automaton with a partial order over acceptance conditions. In the\nsecond step, we prove that finding a most preferred policy is equivalent to\ncomputing a Pareto-optimal policy in a multi-objective MDP that is constructed\nfrom the original MDP, the preference automaton, and the chosen stochastic\nordering relation. Throughout the paper, we employ running examples to\nillustrate the proposed preference specification and solution approaches. We\ndemonstrate the efficacy of our algorithm using these examples, providing\ndetailed analysis, and then discuss several potential future directions.\n","authors":["Hazhar Rahmani","Abhishek N. Kulkarni","Jie Fu"],"pdf_url":"https://arxiv.org/pdf/2403.18212v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2209.12267"},{"id":"http://arxiv.org/abs/2410.14141v1","updated":"2024-10-18T03:26:06Z","published":"2024-10-18T03:26:06Z","title":"Coherence-Driven Multimodal Safety Dialogue with Active Learning for\n  Embodied Agents","summary":"  When assisting people in daily tasks, robots need to accurately interpret\nvisual cues and respond effectively in diverse safety-critical situations, such\nas sharp objects on the floor. In this context, we present M-CoDAL, a\nmultimodal-dialogue system specifically designed for embodied agents to better\nunderstand and communicate in safety-critical situations. The system leverages\ndiscourse coherence relations to enhance its contextual understanding and\ncommunication abilities. To train this system, we introduce a novel\nclustering-based active learning mechanism that utilizes an external Large\nLanguage Model (LLM) to identify informative instances. Our approach is\nevaluated using a newly created multimodal dataset comprising 1K safety\nviolations extracted from 2K Reddit images. These violations are annotated\nusing a Large Multimodal Model (LMM) and verified by human annotators. Results\nwith this dataset demonstrate that our approach improves resolution of safety\nsituations, user sentiment, as well as safety of the conversation. Next, we\ndeploy our dialogue system on a Hello Robot Stretch robot and conduct a\nwithin-subject user study with real-world participants. In the study,\nparticipants role-play two safety scenarios with different levels of severity\nwith the robot and receive interventions from our model and a baseline system\npowered by OpenAI's ChatGPT. The study results corroborate and extend the\nfindings from automated evaluation, showing that our proposed system is more\npersuasive and competent in a real-world embodied agent setting.\n","authors":["Sabit Hassan","Hye-Young Chung","Xiang Zhi Tan","Malihe Alikhani"],"pdf_url":"https://arxiv.org/pdf/2410.14141v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14118v1","updated":"2024-10-18T02:12:18Z","published":"2024-10-18T02:12:18Z","title":"Skill Generalization with Verbs","summary":"  It is imperative that robots can understand natural language commands issued\nby humans. Such commands typically contain verbs that signify what action\nshould be performed on a given object and that are applicable to many objects.\nWe propose a method for generalizing manipulation skills to novel objects using\nverbs. Our method learns a probabilistic classifier that determines whether a\ngiven object trajectory can be described by a specific verb. We show that this\nclassifier accurately generalizes to novel object categories with an average\naccuracy of 76.69% across 13 object categories and 14 verbs. We then perform\npolicy search over the object kinematics to find an object trajectory that\nmaximizes classifier prediction for a given verb. Our method allows a robot to\ngenerate a trajectory for a novel object based on a verb, which can then be\nused as input to a motion planner. We show that our model can generate\ntrajectories that are usable for executing five verb commands applied to novel\ninstances of two different object categories on a real robot.\n","authors":["Rachel Ma","Lyndon Lam","Benjamin A. Spiegel","Aditya Ganeshan","Roma Patel","Ben Abbatematteo","David Paulius","Stefanie Tellex","George Konidaris"],"pdf_url":"https://arxiv.org/pdf/2410.14118v1.pdf","comment":"7 pages + 2 pages (references), 6 figures. Accepted at IROS 2023.\n  Code, dataset info and demo videos can be found at:\n  https://rachelma80000.github.io/SkillGenVerbs/"},{"id":"http://arxiv.org/abs/2410.14117v1","updated":"2024-10-18T02:03:41Z","published":"2024-10-18T02:03:41Z","title":"MarineGym: Accelerated Training for Underwater Vehicles with\n  High-Fidelity RL Simulation","summary":"  Reinforcement Learning (RL) is a promising solution, allowing Unmanned\nUnderwater Vehicles (UUVs) to learn optimal behaviors through trial and error.\nHowever, existing simulators lack efficient integration with RL methods,\nlimiting training scalability and performance. This paper introduces MarineGym,\na novel simulation framework designed to enhance RL training efficiency for\nUUVs by utilizing GPU acceleration. MarineGym offers a 10,000-fold performance\nimprovement over real-time simulation on a single GPU, enabling rapid training\nof RL algorithms across multiple underwater tasks. Key features include\nrealistic dynamic modeling of UUVs, parallel environment execution, and\ncompatibility with popular RL frameworks like PyTorch and TorchRL. The\nframework is validated through four distinct tasks: station-keeping, circle\ntracking, helical tracking, and lemniscate tracking. This framework sets the\nstage for advancing RL in underwater robotics and facilitating efficient\ntraining in complex, dynamic environments.\n","authors":["Shuguang Chu","Zebin Huang","Mingwei Lin","Dejun Li","Ignacio Carlucho"],"pdf_url":"https://arxiv.org/pdf/2410.14117v1.pdf","comment":"Accepted by the 40th Anniversary of the IEEE Conference on Robotics\n  and Automation (ICRA@40)"},{"id":"http://arxiv.org/abs/2403.13783v3","updated":"2024-10-18T01:45:59Z","published":"2024-03-20T17:44:33Z","title":"A Convex Formulation of Frictional Contact for the Material Point Method\n  and Rigid Bodies","summary":"  In this paper, we introduce a novel convex formulation that seamlessly\nintegrates the Material Point Method (MPM) with articulated rigid body dynamics\nin frictional contact scenarios. We extend the linear corotational hyperelastic\nmodel into the realm of elastoplasticity and include an efficient return\nmapping algorithm. This approach is particularly effective for MPM simulations\ninvolving significant deformation and topology changes, while preserving the\nconvexity of the optimization problem. Our method ensures global convergence,\nenabling the use of large simulation time steps without compromising\nrobustness. We have validated our approach through rigorous testing and\nperformance evaluations, highlighting its superior capabilities in managing\ncomplex simulations relevant to robotics. Compared to previous MPM-based\nrobotic simulators, our method significantly improves the stability of contact\nresolution - a critical factor in robot manipulation tasks. We make our method\navailable in the open-source robotics toolkit, Drake. The supplemental video is\navailable at https://youtu.be/5jrQtF5D0DA\n","authors":["Zeshun Zong","Chenfanfu Jiang","Xuchen Han"],"pdf_url":"https://arxiv.org/pdf/2403.13783v3.pdf","comment":"The supplemental video is available at https://youtu.be/5jrQtF5D0DA"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2410.14672v1","updated":"2024-10-18T17:59:04Z","published":"2024-10-18T17:59:04Z","title":"BiGR: Harnessing Binary Latent Codes for Image Generation and Improved\n  Visual Representation Capabilities","summary":"  We introduce BiGR, a novel conditional image generation model using compact\nbinary latent codes for generative training, focusing on enhancing both\ngeneration and representation capabilities. BiGR is the first conditional\ngenerative model that unifies generation and discrimination within the same\nframework. BiGR features a binary tokenizer, a masked modeling mechanism, and a\nbinary transcoder for binary code prediction. Additionally, we introduce a\nnovel entropy-ordered sampling method to enable efficient image generation.\nExtensive experiments validate BiGR's superior performance in generation\nquality, as measured by FID-50k, and representation capabilities, as evidenced\nby linear-probe accuracy. Moreover, BiGR showcases zero-shot generalization\nacross various vision tasks, enabling applications such as image inpainting,\noutpainting, editing, interpolation, and enrichment, without the need for\nstructural modifications. Our findings suggest that BiGR unifies generative and\ndiscriminative tasks effectively, paving the way for further advancements in\nthe field.\n","authors":["Shaozhe Hao","Xuantong Liu","Xianbiao Qi","Shihao Zhao","Bojia Zi","Rong Xiao","Kai Han","Kwan-Yee K. Wong"],"pdf_url":"https://arxiv.org/pdf/2410.14672v1.pdf","comment":"Project page: https://haoosz.github.io/BiGR"},{"id":"http://arxiv.org/abs/2410.14669v1","updated":"2024-10-18T17:58:21Z","published":"2024-10-18T17:58:21Z","title":"NaturalBench: Evaluating Vision-Language Models on Natural Adversarial\n  Samples","summary":"  Vision-language models (VLMs) have made significant progress in recent\nvisual-question-answering (VQA) benchmarks that evaluate complex\nvisio-linguistic reasoning. However, are these models truly effective? In this\nwork, we show that VLMs still struggle with natural images and questions that\nhumans can easily answer, which we term natural adversarial samples. We also\nfind it surprisingly easy to generate these VQA samples from natural image-text\ncorpora using off-the-shelf models like CLIP and ChatGPT. We propose a\nsemi-automated approach to collect a new benchmark, NaturalBench, for reliably\nevaluating VLMs with 10,000 human-verified VQA samples. Crucially, we adopt a\n$\\textbf{vision-centric}$ design by pairing each question with two images that\nyield different answers, preventing blind solutions from answering without\nusing the images. This makes NaturalBench more challenging than previous\nbenchmarks that can be solved with commonsense priors. We evaluate 53\nstate-of-the-art VLMs on NaturalBench, showing that models like\nLLaVA-OneVision, Cambrian-1, Llama3.2-Vision, Molmo, Qwen2-VL, and even GPT-4o\nlag 50%-70% behind human performance (over 90%). We analyze why NaturalBench is\nhard from two angles: (1) Compositionality: Solving NaturalBench requires\ndiverse visio-linguistic skills, including understanding attribute bindings,\nobject relationships, and advanced reasoning like logic and counting. To this\nend, unlike prior work that uses a single tag per sample, we tag each\nNaturalBench sample with 1 to 8 skill tags for fine-grained evaluation. (2)\nBiases: NaturalBench exposes severe biases in VLMs, as models often choose the\nsame answer regardless of the image. Lastly, we apply our benchmark curation\nmethod to diverse data sources, including long captions (over 100 words) and\nnon-English languages like Chinese and Hindi, highlighting its potential for\ndynamic evaluations of VLMs.\n","authors":["Baiqi Li","Zhiqiu Lin","Wenxuan Peng","Jean de Dieu Nyandwi","Daniel Jiang","Zixian Ma","Simran Khanuja","Ranjay Krishna","Graham Neubig","Deva Ramanan"],"pdf_url":"https://arxiv.org/pdf/2410.14669v1.pdf","comment":"Accepted to NeurIPS 24; We open-source our dataset at:\n  https://huggingface.co/datasets/BaiqiL/NaturalBench; Project page at:\n  https://linzhiqiu.github.io/papers/naturalbench/"},{"id":"http://arxiv.org/abs/2409.06445v2","updated":"2024-10-18T17:37:51Z","published":"2024-09-10T12:00:40Z","title":"Learning Generative Interactive Environments By Trained Agent\n  Exploration","summary":"  World models are increasingly pivotal in interpreting and simulating the\nrules and actions of complex environments. Genie, a recent model, excels at\nlearning from visually diverse environments but relies on costly\nhuman-collected data. We observe that their alternative method of using random\nagents is too limited to explore the environment. We propose to improve the\nmodel by employing reinforcement learning based agents for data generation.\nThis approach produces diverse datasets that enhance the model's ability to\nadapt and perform well across various scenarios and realistic actions within\nthe environment. In this paper, we first release the model GenieRedux - an\nimplementation based on Genie. Additionally, we introduce GenieRedux-G, a\nvariant that uses the agent's readily available actions to factor out action\nprediction uncertainty during validation. Our evaluation, including a\nreplication of the Coinrun case study, shows that GenieRedux-G achieves\nsuperior visual fidelity and controllability using the trained agent\nexploration. The proposed approach is reproducable, scalable and adaptable to\nnew types of environments. Our codebase is available at\nhttps://github.com/insait-institute/GenieRedux .\n","authors":["Naser Kazemi","Nedko Savov","Danda Paudel","Luc Van Gool"],"pdf_url":"https://arxiv.org/pdf/2409.06445v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14634v1","updated":"2024-10-18T17:35:33Z","published":"2024-10-18T17:35:33Z","title":"Parallel Backpropagation for Inverse of a Convolution with Application\n  to Normalizing Flows","summary":"  Inverse of an invertible convolution is an important operation that comes up\nin Normalizing Flows, Image Deblurring, etc. The naive algorithm for\nbackpropagation of this operation using Gaussian elimination has running time\n$O(n^3)$ where $n$ is the number of pixels in the image. We give a fast\nparallel backpropagation algorithm with running time $O(\\sqrt{n})$ for a square\nimage and provide a GPU implementation of the same. Inverse Convolutions are\nusually used in Normalizing Flows in the sampling pass, making them slow. We\npropose to use Inverse Convolutions in the forward (image to latent vector)\npass of the Normalizing flow. Since the sampling pass is the inverse of the\nforward pass, it will use convolutions only, resulting in efficient sampling\ntimes. We use our parallel backpropagation algorithm for optimizing the inverse\nconvolution layer resulting in fast training times also. We implement this\napproach in various Normalizing Flow backbones, resulting in our Inverse-Flow\nmodels. We benchmark Inverse-Flow on standard datasets and show significantly\nimproved sampling times with similar bits per dimension compared to previous\nmodels.\n","authors":["Sandeep Nagar","Girish Varma"],"pdf_url":"https://arxiv.org/pdf/2410.14634v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.14633v1","updated":"2024-10-18T17:32:39Z","published":"2024-10-18T17:32:39Z","title":"Swiss Army Knife: Synergizing Biases in Knowledge from Vision Foundation\n  Models for Multi-Task Learning","summary":"  Vision Foundation Models (VFMs) have demonstrated outstanding performance on\nnumerous downstream tasks. However, due to their inherent representation biases\noriginating from different training paradigms, VFMs exhibit advantages and\ndisadvantages across distinct vision tasks. Although amalgamating the strengths\nof multiple VFMs for downstream tasks is an intuitive strategy, effectively\nexploiting these biases remains a significant challenge. In this paper, we\npropose a novel and versatile \"Swiss Army Knife\" (SAK) solution, which\nadaptively distills knowledge from a committee of VFMs to enhance multi-task\nlearning. Unlike existing methods that use a single backbone for knowledge\ntransfer, our approach preserves the unique representation bias of each teacher\nby collaborating the lightweight Teacher-Specific Adapter Path modules with the\nTeacher-Agnostic Stem. Through dynamic selection and combination of\nrepresentations with Mixture-of-Representations Routers, our SAK is capable of\nsynergizing the complementary strengths of multiple VFMs. Extensive experiments\nshow that our SAK remarkably outperforms prior state of the arts in multi-task\nlearning by 10% on the NYUD-v2 benchmark, while also providing a flexible and\nrobust framework that can readily accommodate more advanced model designs.\n","authors":["Yuxiang Lu","Shengcao Cao","Yu-Xiong Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14633v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01804v4","updated":"2024-10-18T17:20:20Z","published":"2024-10-02T17:59:09Z","title":"EVER: Exact Volumetric Ellipsoid Rendering for Real-time View Synthesis","summary":"  We present Exact Volumetric Ellipsoid Rendering (EVER), a method for\nreal-time differentiable emission-only volume rendering. Unlike recent\nrasterization based approach by 3D Gaussian Splatting (3DGS), our primitive\nbased representation allows for exact volume rendering, rather than alpha\ncompositing 3D Gaussian billboards. As such, unlike 3DGS our formulation does\nnot suffer from popping artifacts and view dependent density, but still\nachieves frame rates of $\\sim\\!30$ FPS at 720p on an NVIDIA RTX4090. Since our\napproach is built upon ray tracing it enables effects such as defocus blur and\ncamera distortion (e.g. such as from fisheye cameras), which are difficult to\nachieve by rasterization. We show that our method is more accurate with fewer\nblending issues than 3DGS and follow-up work on view-consistent rendering,\nespecially on the challenging large-scale scenes from the Zip-NeRF dataset\nwhere it achieves sharpest results among real-time techniques.\n","authors":["Alexander Mai","Peter Hedman","George Kopanas","Dor Verbin","David Futschik","Qiangeng Xu","Falko Kuester","Jonathan T. Barron","Yinda Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.01804v4.pdf","comment":"Project page: https://half-potato.gitlab.io/posts/ever"},{"id":"http://arxiv.org/abs/2410.14612v1","updated":"2024-10-18T17:05:03Z","published":"2024-10-18T17:05:03Z","title":"MultiOrg: A Multi-rater Organoid-detection Dataset","summary":"  High-throughput image analysis in the biomedical domain has gained\nsignificant attention in recent years, driving advancements in drug discovery,\ndisease prediction, and personalized medicine. Organoids, specifically, are an\nactive area of research, providing excellent models for human organs and their\nfunctions. Automating the quantification of organoids in microscopy images\nwould provide an effective solution to overcome substantial manual\nquantification bottlenecks, particularly in high-throughput image analysis.\nHowever, there is a notable lack of open biomedical datasets, in contrast to\nother domains, such as autonomous driving, and, notably, only few of them have\nattempted to quantify annotation uncertainty. In this work, we present MultiOrg\na comprehensive organoid dataset tailored for object detection tasks with\nuncertainty quantification. This dataset comprises over 400 high-resolution 2d\nmicroscopy images and curated annotations of more than 60,000 organoids. Most\nimportantly, it includes three label sets for the test data, independently\nannotated by two experts at distinct time points. We additionally provide a\nbenchmark for organoid detection, and make the best model available through an\neasily installable, interactive plugin for the popular image visualization tool\nNapari, to perform organoid quantification.\n","authors":["Christina Bukas","Harshavardhan Subramanian","Fenja See","Carina Steinchen","Ivan Ezhov","Gowtham Boosarpu","Sara Asgharpour","Gerald Burgstaller","Mareike Lehmann","Florian Kofler","Marie Piraud"],"pdf_url":"https://arxiv.org/pdf/2410.14612v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14595v1","updated":"2024-10-18T16:48:31Z","published":"2024-10-18T16:48:31Z","title":"DRACO-DehazeNet: An Efficient Image Dehazing Network Combining Detail\n  Recovery and a Novel Contrastive Learning Paradigm","summary":"  Image dehazing is crucial for clarifying images obscured by haze or fog, but\ncurrent learning-based approaches is dependent on large volumes of training\ndata and hence consumed significant computational power. Additionally, their\nperformance is often inadequate under non-uniform or heavy haze. To address\nthese challenges, we developed the Detail Recovery And Contrastive DehazeNet,\nwhich facilitates efficient and effective dehazing via a dense dilated inverted\nresidual block and an attention-based detail recovery network that tailors\nenhancements to specific dehazed scene contexts. A major innovation is its\nability to train effectively with limited data, achieved through a novel\nquadruplet loss-based contrastive dehazing paradigm. This approach distinctly\nseparates hazy and clear image features while also distinguish lower-quality\nand higher-quality dehazed images obtained from each sub-modules of our\nnetwork, thereby refining the dehazing process to a larger extent. Extensive\ntests on a variety of benchmarked haze datasets demonstrated the superiority of\nour approach. The code repository for this work will be available soon.\n","authors":["Gao Yu Lee","Tanmoy Dam","Md Meftahul Ferdaus","Daniel Puiu Poenar","Vu Duong"],"pdf_url":"https://arxiv.org/pdf/2410.14595v1.pdf","comment":"Submitted to a journal and currently under review. Once the paper is\n  accepted and published, the copyright will be transferred to the\n  corresponding journal"},{"id":"http://arxiv.org/abs/2404.13370v2","updated":"2024-10-18T16:44:05Z","published":"2024-04-20T13:15:27Z","title":"Movie101v2: Improved Movie Narration Benchmark","summary":"  Automatic movie narration aims to generate video-aligned plot descriptions to\nassist visually impaired audiences. Unlike standard video captioning, it\ninvolves not only describing key visual details but also inferring plots that\nunfold across multiple movie shots, presenting distinct and complex challenges.\nTo advance this field, we introduce Movie101v2, a large-scale, bilingual\ndataset with enhanced data quality specifically designed for movie narration.\nRevisiting the task, we propose breaking down the ultimate goal of automatic\nmovie narration into three progressive stages, offering a clear roadmap with\ncorresponding evaluation metrics. Based on our new benchmark, we baseline a\nrange of large vision-language models, including GPT-4V, and conduct an\nin-depth analysis of the challenges in narration generation. Our findings\nhighlight that achieving applicable movie narration generation is a fascinating\ngoal that requires significant research.\n","authors":["Zihao Yue","Yepeng Zhang","Ziheng Wang","Qin Jin"],"pdf_url":"https://arxiv.org/pdf/2404.13370v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17777v2","updated":"2024-10-18T16:31:49Z","published":"2024-09-26T12:15:13Z","title":"Harnessing Shared Relations via Multimodal Mixup Contrastive Learning\n  for Multimodal Classification","summary":"  Deep multimodal learning has shown remarkable success by leveraging\ncontrastive learning to capture explicit one-to-one relations across\nmodalities. However, real-world data often exhibits shared relations beyond\nsimple pairwise associations. We propose M3CoL, a Multimodal Mixup Contrastive\nLearning approach to capture nuanced shared relations inherent in multimodal\ndata. Our key contribution is a Mixup-based contrastive loss that learns robust\nrepresentations by aligning mixed samples from one modality with their\ncorresponding samples from other modalities thereby capturing shared relations\nbetween them. For multimodal classification tasks, we introduce a framework\nthat integrates a fusion module with unimodal prediction modules for auxiliary\nsupervision during training, complemented by our proposed Mixup-based\ncontrastive loss. Through extensive experiments on diverse datasets (N24News,\nROSMAP, BRCA, and Food-101), we demonstrate that M3CoL effectively captures\nshared multimodal relations and generalizes across domains. It outperforms\nstate-of-the-art methods on N24News, ROSMAP, and BRCA, while achieving\ncomparable performance on Food-101. Our work highlights the significance of\nlearning shared relations for robust multimodal learning, opening up promising\navenues for future research.\n","authors":["Raja Kumar","Raghav Singhal","Pranamya Kulkarni","Deval Mehta","Kshitij Jadhav"],"pdf_url":"https://arxiv.org/pdf/2409.17777v2.pdf","comment":"RK and RS contributed equally to this work, 20 Pages, 8 Figures, 9\n  Tables. Another version of the paper accepted at NeurIPS 2024 Workshop on\n  Unifying Representations in Neural Models (UniReps)"},{"id":"http://arxiv.org/abs/2410.08107v2","updated":"2024-10-18T16:26:30Z","published":"2024-10-10T16:54:23Z","title":"IncEventGS: Pose-Free Gaussian Splatting from a Single Event Camera","summary":"  Implicit neural representation and explicit 3D Gaussian Splatting (3D-GS) for\nnovel view synthesis have achieved remarkable progress with frame-based camera\n(e.g. RGB and RGB-D cameras) recently. Compared to frame-based camera, a novel\ntype of bio-inspired visual sensor, i.e. event camera, has demonstrated\nadvantages in high temporal resolution, high dynamic range, low power\nconsumption and low latency. Due to its unique asynchronous and irregular data\ncapturing process, limited work has been proposed to apply neural\nrepresentation or 3D Gaussian splatting for an event camera. In this work, we\npresent IncEventGS, an incremental 3D Gaussian Splatting reconstruction\nalgorithm with a single event camera. To recover the 3D scene representation\nincrementally, we exploit the tracking and mapping paradigm of conventional\nSLAM pipelines for IncEventGS. Given the incoming event stream, the tracker\nfirstly estimates an initial camera motion based on prior reconstructed 3D-GS\nscene representation. The mapper then jointly refines both the 3D scene\nrepresentation and camera motion based on the previously estimated motion\ntrajectory from the tracker. The experimental results demonstrate that\nIncEventGS delivers superior performance compared to prior NeRF-based methods\nand other related baselines, even we do not have the ground-truth camera poses.\nFurthermore, our method can also deliver better performance compared to\nstate-of-the-art event visual odometry methods in terms of camera motion\nestimation. Code is publicly available at:\nhttps://github.com/wu-cvgl/IncEventGS.\n","authors":["Jian Huang","Chengrui Dong","Peidong Liu"],"pdf_url":"https://arxiv.org/pdf/2410.08107v2.pdf","comment":"Code Page: https://github.com/wu-cvgl/IncEventGS"},{"id":"http://arxiv.org/abs/2410.13174v2","updated":"2024-10-18T16:26:30Z","published":"2024-10-17T02:57:35Z","title":"Scalable Drift Monitoring in Medical Imaging AI","summary":"  The integration of artificial intelligence (AI) into medical imaging has\nadvanced clinical diagnostics but poses challenges in managing model drift and\nensuring long-term reliability. To address these challenges, we develop MMC+,\nan enhanced framework for scalable drift monitoring, building upon the\nCheXstray framework that introduced real-time drift detection for medical\nimaging AI models using multi-modal data concordance. This work extends the\noriginal framework's methodologies, providing a more scalable and adaptable\nsolution for real-world healthcare settings and offers a reliable and\ncost-effective alternative to continuous performance monitoring addressing\nlimitations of both continuous and periodic monitoring methods. MMC+ introduces\ncritical improvements to the original framework, including more robust handling\nof diverse data streams, improved scalability with the integration of\nfoundation models like MedImageInsight for high-dimensional image embeddings\nwithout site-specific training, and the introduction of uncertainty bounds to\nbetter capture drift in dynamic clinical environments. Validated with\nreal-world data from Massachusetts General Hospital during the COVID-19\npandemic, MMC+ effectively detects significant data shifts and correlates them\nwith model performance changes. While not directly predicting performance\ndegradation, MMC+ serves as an early warning system, indicating when AI systems\nmay deviate from acceptable performance bounds and enabling timely\ninterventions. By emphasizing the importance of monitoring diverse data streams\nand evaluating data shifts alongside model performance, this work contributes\nto the broader adoption and integration of AI solutions in clinical settings.\n","authors":["Jameson Merkow","Felix J. Dorfner","Xiyu Yang","Alexander Ersoy","Giridhar Dasegowda","Mannudeep Kalra","Matthew P. Lungren","Christopher P. Bridge","Ivan Tarapov"],"pdf_url":"https://arxiv.org/pdf/2410.13174v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14574v1","updated":"2024-10-18T16:20:22Z","published":"2024-10-18T16:20:22Z","title":"MomentumSMoE: Integrating Momentum into Sparse Mixture of Experts","summary":"  Sparse Mixture of Experts (SMoE) has become the key to unlocking unparalleled\nscalability in deep learning. SMoE has the potential to exponentially increase\nparameter count while maintaining the efficiency of the model by only\nactivating a small subset of these parameters for a given sample. However, it\nhas been observed that SMoE suffers from unstable training and has difficulty\nadapting to new distributions, leading to the model's lack of robustness to\ndata contamination. To overcome these limitations, we first establish a\nconnection between the dynamics of the expert representations in SMoEs and\ngradient descent on a multi-objective optimization problem. Leveraging our\nframework, we then integrate momentum into SMoE and propose a new family of\nSMoEs named MomentumSMoE. We theoretically prove and numerically demonstrate\nthat MomentumSMoE is more stable and robust than SMoE. In particular, we verify\nthe advantages of MomentumSMoE over SMoE on a variety of practical tasks\nincluding ImageNet-1K object recognition and WikiText-103 language modeling. We\ndemonstrate the applicability of MomentumSMoE to many types of SMoE models,\nincluding those in the Sparse MoE model for vision (V-MoE) and the Generalist\nLanguage Model (GLaM). We also show that other advanced momentum-based\noptimization methods, such as Adam, can be easily incorporated into the\nMomentumSMoE framework for designing new SMoE models with even better\nperformance, almost negligible additional computation cost, and simple\nimplementations.\n","authors":["Rachel S. Y. Teo","Tan M. Nguyen"],"pdf_url":"https://arxiv.org/pdf/2410.14574v1.pdf","comment":"10 pages in the main text. Published at NeurIPS 2024. The code is\n  available at https://github.com/rachtsy/MomentumSMoE"},{"id":"http://arxiv.org/abs/2410.13242v2","updated":"2024-10-18T15:41:44Z","published":"2024-10-17T05:53:13Z","title":"Fundus to Fluorescein Angiography Video Generation as a Retinal\n  Generative Foundation Model","summary":"  Fundus fluorescein angiography (FFA) is crucial for diagnosing and monitoring\nretinal vascular issues but is limited by its invasive nature and restricted\naccessibility compared to color fundus (CF) imaging. Existing methods that\nconvert CF images to FFA are confined to static image generation, missing the\ndynamic lesional changes. We introduce Fundus2Video, an autoregressive\ngenerative adversarial network (GAN) model that generates dynamic FFA videos\nfrom single CF images. Fundus2Video excels in video generation, achieving an\nFVD of 1497.12 and a PSNR of 11.77. Clinical experts have validated the\nfidelity of the generated videos. Additionally, the model's generator\ndemonstrates remarkable downstream transferability across ten external public\ndatasets, including blood vessel segmentation, retinal disease diagnosis,\nsystemic disease prediction, and multimodal retrieval, showcasing impressive\nzero-shot and few-shot capabilities. These findings position Fundus2Video as a\npowerful, non-invasive alternative to FFA exams and a versatile retinal\ngenerative foundation model that captures both static and temporal retinal\nfeatures, enabling the representation of complex inter-modality relationships.\n","authors":["Weiyi Zhang","Jiancheng Yang","Ruoyu Chen","Siyu Huang","Pusheng Xu","Xiaolan Chen","Shanfu Lu","Hongyu Cao","Mingguang He","Danli Shi"],"pdf_url":"https://arxiv.org/pdf/2410.13242v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14540v1","updated":"2024-10-18T15:29:19Z","published":"2024-10-18T15:29:19Z","title":"Multi-modal Pose Diffuser: A Multimodal Generative Conditional Pose\n  Prior","summary":"  The Skinned Multi-Person Linear (SMPL) model plays a crucial role in 3D human\npose estimation, providing a streamlined yet effective representation of the\nhuman body. However, ensuring the validity of SMPL configurations during tasks\nsuch as human mesh regression remains a significant challenge , highlighting\nthe necessity for a robust human pose prior capable of discerning realistic\nhuman poses. To address this, we introduce MOPED:\n\\underline{M}ulti-m\\underline{O}dal \\underline{P}os\\underline{E}\n\\underline{D}iffuser. MOPED is the first method to leverage a novel multi-modal\nconditional diffusion model as a prior for SMPL pose parameters. Our method\noffers powerful unconditional pose generation with the ability to condition on\nmulti-modal inputs such as images and text. This capability enhances the\napplicability of our approach by incorporating additional context often\noverlooked in traditional pose priors. Extensive experiments across three\ndistinct tasks-pose estimation, pose denoising, and pose completion-demonstrate\nthat our multi-modal diffusion model-based prior significantly outperforms\nexisting methods. These results indicate that our model captures a broader\nspectrum of plausible human poses.\n","authors":["Calvin-Khang Ta","Arindam Dutta","Rohit Kundu","Rohit Lal","Hannah Dela Cruz","Dripta S. Raychaudhuri","Amit Roy-Chowdhury"],"pdf_url":"https://arxiv.org/pdf/2410.14540v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14536v1","updated":"2024-10-18T15:23:34Z","published":"2024-10-18T15:23:34Z","title":"A Hybrid Feature Fusion Deep Learning Framework for Leukemia Cancer\n  Detection in Microscopic Blood Sample Using Gated Recurrent Unit and\n  Uncertainty Quantification","summary":"  Acute lymphoblastic leukemia (ALL) is the most malignant form of leukemia and\nthe most common cancer in adults and children. Traditionally, leukemia is\ndiagnosed by analyzing blood and bone marrow smears under a microscope, with\nadditional cytochemical tests for confirmation. However, these methods are\nexpensive, time consuming, and highly dependent on expert knowledge. In recent\nyears, deep learning, particularly Convolutional Neural Networks (CNNs), has\nprovided advanced methods for classifying microscopic smear images, aiding in\nthe detection of leukemic cells. These approaches are quick, cost effective,\nand not subject to human bias. However, most methods lack the ability to\nquantify uncertainty, which could lead to critical misdiagnoses. In this\nresearch, hybrid deep learning models (InceptionV3-GRU, EfficientNetB3-GRU,\nMobileNetV2-GRU) were implemented to classify ALL. Bayesian optimization was\nused to fine tune the model's hyperparameters and improve its performance.\nAdditionally, Deep Ensemble uncertainty quantification was applied to address\nuncertainty during leukemia image classification. The proposed models were\ntrained on the publicly available datasets ALL-IDB1 and ALL-IDB2. Their results\nwere then aggregated at the score level using the sum rule. The parallel\narchitecture used in these models offers a high level of confidence in\ndifferentiating between ALL and non-ALL cases. The proposed method achieved a\nremarkable detection accuracy rate of 100% on the ALL-IDB1 dataset, 98.07% on\nthe ALL-IDB2 dataset, and 98.64% on the combined dataset, demonstrating its\npotential for accurate and reliable leukemia diagnosis.\n","authors":["Maksuda Akter","Rabea Khatun","Md Manowarul Islam"],"pdf_url":"https://arxiv.org/pdf/2410.14536v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14524v1","updated":"2024-10-18T15:08:05Z","published":"2024-10-18T15:08:05Z","title":"Less is More: Selective Reduction of CT Data for Self-Supervised\n  Pre-Training of Deep Learning Models with Contrastive Learning Improves\n  Downstream Classification Performance","summary":"  Self-supervised pre-training of deep learning models with contrastive\nlearning is a widely used technique in image analysis. Current findings\nindicate a strong potential for contrastive pre-training on medical images.\nHowever, further research is necessary to incorporate the particular\ncharacteristics of these images. We hypothesize that the similarity of medical\nimages hinders the success of contrastive learning in the medical imaging\ndomain. To this end, we investigate different strategies based on deep\nembedding, information theory, and hashing in order to identify and reduce\nredundancy in medical pre-training datasets. The effect of these different\nreduction strategies on contrastive learning is evaluated on two pre-training\ndatasets and several downstream classification tasks. In all of our\nexperiments, dataset reduction leads to a considerable performance gain in\ndownstream tasks, e.g., an AUC score improvement from 0.78 to 0.83 for the\nCOVID CT Classification Grand Challenge, 0.97 to 0.98 for the OrganSMNIST\nClassification Challenge and 0.73 to 0.83 for a brain hemorrhage classification\ntask. Furthermore, pre-training is up to nine times faster due to the dataset\nreduction. In conclusion, the proposed approach highlights the importance of\ndataset quality and provides a transferable approach to improve contrastive\npre-training for classification downstream tasks on medical images.\n","authors":["Daniel Wolf","Tristan Payer","Catharina Silvia Lisson","Christoph Gerhard Lisson","Meinrad Beer","Michael Götz","Timo Ropinski"],"pdf_url":"https://arxiv.org/pdf/2410.14524v1.pdf","comment":"Published in Computers in Biology and Medicine"},{"id":"http://arxiv.org/abs/2409.14485v3","updated":"2024-10-18T15:03:08Z","published":"2024-09-22T15:13:31Z","title":"Video-XL: Extra-Long Vision Language Model for Hour-Scale Video\n  Understanding","summary":"  Although current Multi-modal Large Language Models (MLLMs) demonstrate\npromising results in video understanding, processing extremely long videos\nremains an ongoing challenge. Typically, MLLMs struggle with handling thousands\nof visual tokens that exceed the maximum context length, and they suffer from\nthe information decay due to token aggregation. Another challenge is the high\ncomputational cost stemming from the large number of video tokens. To tackle\nthese issues, we propose Video-XL, an extra-long vision language model designed\nfor efficient hour-scale video understanding. Specifically, we argue that LLMs\ncan be adapted as effective visual condensers and propose Visual Context Latent\nSummarization which condenses visual contexts into highly compact forms.\nExtensive experiments demonstrate that our model achieves promising results on\npopular long video understanding benchmarks. For example, Video-XL outperforms\nthe current state-of-the-art method on VNBench by nearly 10\\% in accuracy.\nMoreover, Video-XL presents an impressive balance between efficiency and\neffectiveness, processing 2048 frames on a single 80GB GPU while achieving\nnearly 95% accuracy in the Needle-in-a-Haystack evaluation.\n","authors":["Yan Shu","Peitian Zhang","Zheng Liu","Minghao Qin","Junjie Zhou","Tiejun Huang","Bo Zhao"],"pdf_url":"https://arxiv.org/pdf/2409.14485v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14509v1","updated":"2024-10-18T14:43:34Z","published":"2024-10-18T14:43:34Z","title":"CLIP-VAD: Exploiting Vision-Language Models for Voice Activity Detection","summary":"  Voice Activity Detection (VAD) is the process of automatically determining\nwhether a person is speaking and identifying the timing of their speech in an\naudiovisual data. Traditionally, this task has been tackled by processing\neither audio signals or visual data, or by combining both modalities through\nfusion or joint learning. In our study, drawing inspiration from recent\nadvancements in visual-language models, we introduce a novel approach\nleveraging Contrastive Language-Image Pretraining (CLIP) models. The CLIP\nvisual encoder analyzes video segments composed of the upper body of an\nindividual, while the text encoder handles textual descriptions automatically\ngenerated through prompt engineering. Subsequently, embeddings from these\nencoders are fused through a deep neural network to perform VAD. Our\nexperimental analysis across three VAD benchmarks showcases the superior\nperformance of our method compared to existing visual VAD approaches. Notably,\nour approach outperforms several audio-visual methods despite its simplicity,\nand without requiring pre-training on extensive audio-visual datasets.\n","authors":["Andrea Appiani","Cigdem Beyan"],"pdf_url":"https://arxiv.org/pdf/2410.14509v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14508v1","updated":"2024-10-18T14:43:05Z","published":"2024-10-18T14:43:05Z","title":"LEAD: Latent Realignment for Human Motion Diffusion","summary":"  Our goal is to generate realistic human motion from natural language. Modern\nmethods often face a trade-off between model expressiveness and text-to-motion\nalignment. Some align text and motion latent spaces but sacrifice\nexpressiveness; others rely on diffusion models producing impressive motions,\nbut lacking semantic meaning in their latent space. This may compromise\nrealism, diversity, and applicability. Here, we address this by combining\nlatent diffusion with a realignment mechanism, producing a novel, semantically\nstructured space that encodes the semantics of language. Leveraging this\ncapability, we introduce the task of textual motion inversion to capture novel\nmotion concepts from a few examples. For motion synthesis, we evaluate LEAD on\nHumanML3D and KIT-ML and show comparable performance to the state-of-the-art in\nterms of realism, diversity, and text-motion consistency. Our qualitative\nanalysis and user study reveal that our synthesized motions are sharper, more\nhuman-like and comply better with the text compared to modern methods. For\nmotion textual inversion, our method demonstrates improved capacity in\ncapturing out-of-distribution characteristics in comparison to traditional\nVAEs.\n","authors":["Nefeli Andreou","Xi Wang","Victoria Fernández Abrevaya","Marie-Paule Cani","Yiorgos Chrysanthou","Vicky Kalogeiton"],"pdf_url":"https://arxiv.org/pdf/2410.14508v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04960v2","updated":"2024-10-18T14:42:50Z","published":"2024-10-07T11:59:54Z","title":"On Efficient Variants of Segment Anything Model: A Survey","summary":"  The Segment Anything Model (SAM) is a foundational model for image\nsegmentation tasks, known for its strong generalization across diverse\napplications. However, its impressive performance comes with significant\ncomputational and resource demands, making it challenging to deploy in\nresource-limited environments such as edge devices. To address this, a variety\nof SAM variants have been proposed to enhance efficiency while keeping\naccuracy. This survey provides the first comprehensive review of these\nefficient SAM variants. We begin by exploring the motivations driving this\nresearch. We then present core techniques used in SAM and model acceleration.\nThis is followed by a detailed exploration of SAM acceleration strategies,\ncategorized by approach, and a discussion of several future research\ndirections. Finally, we offer a unified and extensive evaluation of these\nmethods across various hardware, assessing their efficiency and accuracy on\nrepresentative benchmarks, and providing a clear comparison of their overall\nperformance.\n","authors":["Xiaorui Sun","Jun Liu","Heng Tao Shen","Xiaofeng Zhu","Ping Hu"],"pdf_url":"https://arxiv.org/pdf/2410.04960v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.07361v2","updated":"2024-10-18T14:38:03Z","published":"2024-06-11T15:28:48Z","title":"Deep Implicit Optimization for Robust and Flexible Image Registration","summary":"  Deep Learning in Image Registration (DLIR) methods have been tremendously\nsuccessful in image registration due to their speed and ability to incorporate\nweak label supervision at training time. However, DLIR methods forego many of\nthe benefits of classical optimization-based methods. The functional nature of\ndeep networks do not guarantee that the predicted transformation is a local\nminima of the registration objective, the representation of the transformation\n(displacement/velocity field/affine) is fixed, and the networks are not robust\nto domain shift. Our method aims to bridge this gap between classical and\nlearning methods by incorporating optimization as a layer in a deep network. A\ndeep network is trained to predict multi-scale dense feature images that are\nregistered using a black box iterative optimization solver. This optimal warp\nis then used to minimize image and label alignment errors. By implicitly\ndifferentiating end-to-end through an iterative optimization solver, our\nlearned features are registration and label-aware, and the warp functions are\nguaranteed to be local minima of the registration objective in the feature\nspace. Our framework shows excellent performance on in-domain datasets, and is\nagnostic to domain shift such as anisotropy and varying intensity profiles. For\nthe first time, our method allows switching between arbitrary transformation\nrepresentations (free-form to diffeomorphic) at test time with zero retraining.\nEnd-to-end feature learning also facilitates interpretability of features, and\nout-of-the-box promptability using additional label-fidelity terms at\ninference.\n","authors":["Rohit Jena","Pratik Chaudhari","James C. Gee"],"pdf_url":"https://arxiv.org/pdf/2406.07361v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14505v1","updated":"2024-10-18T14:37:37Z","published":"2024-10-18T14:37:37Z","title":"Neural Real-Time Recalibration for Infrared Multi-Camera Systems","summary":"  Currently, there are no learning-free or neural techniques for real-time\nrecalibration of infrared multi-camera systems. In this paper, we address the\nchallenge of real-time, highly-accurate calibration of multi-camera infrared\nsystems, a critical task for time-sensitive applications. Unlike traditional\ncalibration techniques that lack adaptability and struggle with on-the-fly\nrecalibrations, we propose a neural network-based method capable of dynamic\nreal-time calibration. The proposed method integrates a differentiable\nprojection model that directly correlates 3D geometries with their 2D image\nprojections and facilitates the direct optimization of both intrinsic and\nextrinsic camera parameters. Key to our approach is the dynamic camera pose\nsynthesis with perturbations in camera parameters, emulating realistic\noperational challenges to enhance model robustness. We introduce two model\nvariants: one designed for multi-camera systems with onboard processing of 2D\npoints, utilizing the direct 2D projections of 3D fiducials, and another for\nimage-based systems, employing color-coded projected points for implicitly\nestablishing correspondence. Through rigorous experimentation, we demonstrate\nour method is more accurate than traditional calibration techniques with or\nwithout perturbations while also being real-time, marking a significant leap in\nthe field of real-time multi-camera system calibration. The source code can be\nfound at https://github.com/theICTlab/neural-recalibration\n","authors":["Benyamin Mehmandar","Reza Talakoob","Charalambos Poullis"],"pdf_url":"https://arxiv.org/pdf/2410.14505v1.pdf","comment":"real-time camera calibration, infrared camera, neural calibration"},{"id":"http://arxiv.org/abs/2410.14489v1","updated":"2024-10-18T14:19:13Z","published":"2024-10-18T14:19:13Z","title":"An Integrated Deep Learning Model for Skin Cancer Detection Using Hybrid\n  Feature Fusion Technique","summary":"  Skin cancer is a serious and potentially fatal disease caused by DNA damage.\nEarly detection significantly increases survival rates, making accurate\ndiagnosis crucial. In this groundbreaking study, we present a hybrid framework\nbased on Deep Learning (DL) that achieves precise classification of benign and\nmalignant skin lesions. Our approach begins with dataset preprocessing to\nenhance classification accuracy, followed by training two separate pre-trained\nDL models, InceptionV3 and DenseNet121. By fusing the results of each model\nusing the weighted sum rule, our system achieves exceptional accuracy rates.\nSpecifically, we achieve a 92.27% detection accuracy rate, 92.33% sensitivity,\n92.22% specificity, 90.81% precision, and 91.57% F1-score, outperforming\nexisting models and demonstrating the robustness and trustworthiness of our\nhybrid approach. Our study represents a significant advance in skin cancer\ndiagnosis and provides a promising foundation for further research in the\nfield. With the potential to save countless lives through earlier detection,\nour hybrid deep-learning approach is a game-changer in the fight against skin\ncancer.\n","authors":["Maksuda Akter","Rabea Khatun","Md. Alamin Talukder","Md. Manowarul Islam","Md. Ashraf Uddin"],"pdf_url":"https://arxiv.org/pdf/2410.14489v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14470v1","updated":"2024-10-18T13:54:46Z","published":"2024-10-18T13:54:46Z","title":"How Do Training Methods Influence the Utilization of Vision Models?","summary":"  Not all learnable parameters (e.g., weights) contribute equally to a neural\nnetwork's decision function. In fact, entire layers' parameters can sometimes\nbe reset to random values with little to no impact on the model's decisions. We\nrevisit earlier studies that examined how architecture and task complexity\ninfluence this phenomenon and ask: is this phenomenon also affected by how we\ntrain the model? We conducted experimental evaluations on a diverse set of\nImageNet-1k classification models to explore this, keeping the architecture and\ntraining data constant but varying the training pipeline. Our findings reveal\nthat the training method strongly influences which layers become critical to\nthe decision function for a given task. For example, improved training regimes\nand self-supervised training increase the importance of early layers while\nsignificantly under-utilizing deeper layers. In contrast, methods such as\nadversarial training display an opposite trend. Our preliminary results extend\nprevious findings, offering a more nuanced understanding of the inner mechanics\nof neural networks.\n  Code: https://github.com/paulgavrikov/layer_criticality\n","authors":["Paul Gavrikov","Shashank Agnihotri","Margret Keuper","Janis Keuper"],"pdf_url":"https://arxiv.org/pdf/2410.14470v1.pdf","comment":"Accepted at the Interpretable AI: Past, Present and Future Workshop\n  at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2403.09939v2","updated":"2024-10-18T13:51:50Z","published":"2024-03-15T00:43:03Z","title":"Quantization Effects on Neural Networks Perception: How would\n  quantization change the perceptual field of vision models?","summary":"  Neural network quantization is a critical technique for deploying models on\nresource-limited devices. Despite its widespread use, the impact of\nquantization on model perceptual fields, particularly in relation to class\nactivation maps (CAMs), remains underexplored. This study investigates how\nquantization influences the spatial recognition abilities of vision models by\nexamining the alignment between CAMs and visual salient objects maps across\nvarious architectures. Utilizing a dataset of 10,000 images from ImageNet, we\nconduct a comprehensive evaluation of six diverse CNN architectures: VGG16,\nResNet50, EfficientNet, MobileNet, SqueezeNet, and DenseNet. Through the\nsystematic application of quantization techniques, we identify subtle changes\nin CAMs and their alignment with Salient object maps. Our results demonstrate\nthe differing sensitivities of these architectures to quantization and\nhighlight its implications for model performance and interpretability in\nreal-world applications. This work primarily contributes to a deeper\nunderstanding of neural network quantization, offering insights essential for\ndeploying efficient and interpretable models in practical settings.\n","authors":["Mohamed Amine Kerkouri","Marouane Tliba","Aladine Chetouani","Alessandro Bruno"],"pdf_url":"https://arxiv.org/pdf/2403.09939v2.pdf","comment":"Accepted & presented at IPTA 2024"},{"id":"http://arxiv.org/abs/2410.14462v1","updated":"2024-10-18T13:44:29Z","published":"2024-10-18T13:44:29Z","title":"LUDVIG: Learning-free Uplifting of 2D Visual features to Gaussian\n  Splatting scenes","summary":"  We address the task of uplifting visual features or semantic masks from 2D\nvision models to 3D scenes represented by Gaussian Splatting. Whereas common\napproaches rely on iterative optimization-based procedures, we show that a\nsimple yet effective aggregation technique yields excellent results. Applied to\nsemantic masks from Segment Anything (SAM), our uplifting approach leads to\nsegmentation quality comparable to the state of the art. We then extend this\nmethod to generic DINOv2 features, integrating 3D scene geometry through graph\ndiffusion, and achieve competitive segmentation results despite DINOv2 not\nbeing trained on millions of annotated masks like SAM.\n","authors":["Juliette Marrie","Romain Ménégaux","Michael Arbel","Diane Larlus","Julien Mairal"],"pdf_url":"https://arxiv.org/pdf/2410.14462v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.19525v3","updated":"2024-10-18T13:13:44Z","published":"2024-04-30T12:56:14Z","title":"MicroDreamer: Efficient 3D Generation in $\\sim$20 Seconds by Score-based\n  Iterative Reconstruction","summary":"  Optimization-based approaches, such as score distillation sampling (SDS),\nshow promise in zero-shot 3D generation but suffer from low efficiency,\nprimarily due to the high number of function evaluations (NFEs) required for\neach sample and the limitation of optimization confined to latent space. This\npaper introduces score-based iterative reconstruction (SIR), an efficient and\ngeneral algorithm mimicking a differentiable 3D reconstruction process to\nreduce the NFEs and enable optimization in pixel space. Given a single set of\nimages sampled from a multi-view score-based diffusion model, SIR repeatedly\noptimizes 3D parameters, unlike the single-step optimization in SDS. With other\nimprovements in training, we present an efficient approach called MicroDreamer\nthat generally applies to various 3D representations and 3D generation tasks.\nIn particular, MicroDreamer is 5-20 times faster than SDS in generating neural\nradiance field while retaining a comparable performance and takes about 20\nseconds to create meshes from 3D Gaussian splatting on a single A100 GPU,\nhalving the time of the fastest optimization-based baseline DreamGaussian with\nsignificantly superior performance compared to the measurement standard\ndeviation. Our code is available at https://github.com/ML-GSAI/MicroDreamer.\n","authors":["Luxi Chen","Zhengyi Wang","Zihan Zhou","Tingting Gao","Hang Su","Jun Zhu","Chongxuan Li"],"pdf_url":"https://arxiv.org/pdf/2404.19525v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14445v1","updated":"2024-10-18T13:04:35Z","published":"2024-10-18T13:04:35Z","title":"Toward Generalizing Visual Brain Decoding to Unseen Subjects","summary":"  Visual brain decoding aims to decode visual information from human brain\nactivities. Despite the great progress, one critical limitation of current\nbrain decoding research lies in the lack of generalization capability to unseen\nsubjects. Prior works typically focus on decoding brain activity of individuals\nbased on the observation that different subjects exhibit different brain\nactivities, while it remains unclear whether brain decoding can be generalized\nto unseen subjects. This study aims to answer this question. We first\nconsolidate an image-fMRI dataset consisting of stimulus-image and\nfMRI-response pairs, involving 177 subjects in the movie-viewing task of the\nHuman Connectome Project (HCP). This dataset allows us to investigate the brain\ndecoding performance with the increase of participants. We then present a\nlearning paradigm that applies uniform processing across all subjects, instead\nof employing different network heads or tokenizers for individuals as in\nprevious methods, which can accommodate a large number of subjects to explore\nthe generalization capability across different subjects. A series of\nexperiments are conducted and we have the following findings. First, the\nnetwork exhibits clear generalization capabilities with the increase of\ntraining subjects. Second, the generalization capability is common to popular\nnetwork architectures (MLP, CNN and Transformer). Third, the generalization\nperformance is affected by the similarity between subjects. Our findings reveal\nthe inherent similarities in brain activities across individuals. With the\nemerging of larger and more comprehensive datasets, it is possible to train a\nbrain decoding foundation model in the future.Codes and models can be found at\nhttps://github.com/Xiangtaokong/TGBD.\n","authors":["Xiangtao Kong","Kexin Huang","Ping Li","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.14445v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14429v1","updated":"2024-10-18T12:48:22Z","published":"2024-10-18T12:48:22Z","title":"FashionR2R: Texture-preserving Rendered-to-Real Image Translation with\n  Diffusion Models","summary":"  Modeling and producing lifelike clothed human images has attracted\nresearchers' attention from different areas for decades, with the complexity\nfrom highly articulated and structured content. Rendering algorithms decompose\nand simulate the imaging process of a camera, while are limited by the accuracy\nof modeled variables and the efficiency of computation. Generative models can\nproduce impressively vivid human images, however still lacking in\ncontrollability and editability. This paper studies photorealism enhancement of\nrendered images, leveraging generative power from diffusion models on the\ncontrolled basis of rendering. We introduce a novel framework to translate\nrendered images into their realistic counterparts, which consists of two\nstages: Domain Knowledge Injection (DKI) and Realistic Image Generation (RIG).\nIn DKI, we adopt positive (real) domain finetuning and negative (rendered)\ndomain embedding to inject knowledge into a pretrained Text-to-image (T2I)\ndiffusion model. In RIG, we generate the realistic image corresponding to the\ninput rendered image, with a Texture-preserving Attention Control (TAC) to\npreserve fine-grained clothing textures, exploiting the decoupled features\nencoded in the UNet structure. Additionally, we introduce SynFashion dataset,\nfeaturing high-quality digital clothing images with diverse textures. Extensive\nexperimental results demonstrate the superiority and effectiveness of our\nmethod in rendered-to-real image translation.\n","authors":["Rui Hu","Qian He","Gaofeng He","Jiedong Zhuang","Huang Chen","Huafeng Liu","Huamin Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14429v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.14423v1","updated":"2024-10-18T12:37:51Z","published":"2024-10-18T12:37:51Z","title":"Integrating Deep Learning with Fundus and Optical Coherence Tomography\n  for Cardiovascular Disease Prediction","summary":"  Early identification of patients at risk of cardiovascular diseases (CVD) is\ncrucial for effective preventive care, reducing healthcare burden, and\nimproving patients' quality of life. This study demonstrates the potential of\nretinal optical coherence tomography (OCT) imaging combined with fundus\nphotographs for identifying future adverse cardiac events. We used data from\n977 patients who experienced CVD within a 5-year interval post-image\nacquisition, alongside 1,877 control participants without CVD, totaling 2,854\nsubjects. We propose a novel binary classification network based on a\nMulti-channel Variational Autoencoder (MCVAE), which learns a latent embedding\nof patients' fundus and OCT images to classify individuals into two groups:\nthose likely to develop CVD in the future and those who are not. Our model,\ntrained on both imaging modalities, achieved promising results (AUROC 0.78 +/-\n0.02, accuracy 0.68 +/- 0.002, precision 0.74 +/- 0.02, sensitivity 0.73 +/-\n0.02, and specificity 0.68 +/- 0.01), demonstrating its efficacy in identifying\npatients at risk of future CVD events based on their retinal images. This study\nhighlights the potential of retinal OCT imaging and fundus photographs as\ncost-effective, non-invasive alternatives for predicting cardiovascular disease\nrisk. The widespread availability of these imaging techniques in optometry\npractices and hospitals further enhances their potential for large-scale CVD\nrisk screening. Our findings contribute to the development of standardized,\naccessible methods for early CVD risk identification, potentially improving\npreventive care strategies and patient outcomes.\n","authors":["Cynthia Maldonado-Garcia","Arezoo Zakeri","Alejandro F Frangi","Nishant Ravikumar"],"pdf_url":"https://arxiv.org/pdf/2410.14423v1.pdf","comment":"Part of the book series: Lecture Notes in Computer Science\n  ((LNCS,volume 15155))"},{"id":"http://arxiv.org/abs/2405.08431v4","updated":"2024-10-18T12:25:31Z","published":"2024-05-14T08:51:16Z","title":"Similarity and Quality Metrics for MR Image-To-Image Translation","summary":"  Image-to-image translation can create large impact in medical imaging, as\nimages can be synthetically transformed to other modalities, sequence types,\nhigher resolutions or lower noise levels. To ensure patient safety, these\nmethods should be validated by human readers, which requires a considerable\namount of time and costs. Quantitative metrics can effectively complement such\nstudies and provide reproducible and objective assessment of synthetic images.\nIf a reference is available, the similarity of MR images is frequently\nevaluated by SSIM and PSNR metrics, even though these metrics are not or too\nsensitive regarding specific distortions. When reference images to compare with\nare not available, non-reference quality metrics can reliably detect specific\ndistortions, such as blurriness. To provide an overview on distortion\nsensitivity, we quantitatively analyze 11 similarity (reference) and 12 quality\n(non-reference) metrics for assessing synthetic images. We additionally include\na metric on a downstream segmentation task. We investigate the sensitivity\nregarding 11 kinds of distortions and typical MR artifacts, and analyze the\ninfluence of different normalization methods on each metric and distortion.\nFinally, we derive recommendations for effective usage of the analyzed\nsimilarity and quality metrics for evaluation of image-to-image translation\nmodels.\n","authors":["Melanie Dohmen","Mark Klemens","Ivo Baltruschat","Tuan Truong","Matthias Lenga"],"pdf_url":"https://arxiv.org/pdf/2405.08431v4.pdf","comment":"21 pages, 8 figures, supplement with 16 pages, 10 figures, submitted\n  to Nature Scientific Reports"},{"id":"http://arxiv.org/abs/2409.08031v2","updated":"2024-10-18T12:22:11Z","published":"2024-09-12T13:23:24Z","title":"LED: Light Enhanced Depth Estimation at Night","summary":"  Nighttime camera-based depth estimation is a highly challenging task,\nespecially for autonomous driving applications, where accurate depth perception\nis essential for ensuring safe navigation. We aim to improve the reliability of\nperception systems at night time, where models trained on daytime data often\nfail in the absence of precise but costly LiDAR sensors. In this work, we\nintroduce Light Enhanced Depth (LED), a novel cost-effective approach that\nsignificantly improves depth estimation in low-light environments by harnessing\na pattern projected by high definition headlights available in modern vehicles.\nLED leads to significant performance boosts across multiple depth-estimation\narchitectures (encoder-decoder, Adabins, DepthFormer) both on synthetic and\nreal datasets. Furthermore, increased performances beyond illuminated areas\nreveal a holistic enhancement in scene understanding. Finally, we release the\nNighttime Synthetic Drive Dataset, a new synthetic and photo-realistic\nnighttime dataset, which comprises 49,990 comprehensively annotated images.\n","authors":["Simon de Moreau","Yasser Almehio","Andrei Bursuc","Hafid El-Idrissi","Bogdan Stanciulescu","Fabien Moutarde"],"pdf_url":"https://arxiv.org/pdf/2409.08031v2.pdf","comment":"Preprint. Code and dataset available on the project page :\n  https://simondemoreau.github.io/LED/"},{"id":"http://arxiv.org/abs/2406.08552v2","updated":"2024-10-18T12:05:21Z","published":"2024-06-12T18:00:08Z","title":"DiTFastAttn: Attention Compression for Diffusion Transformer Models","summary":"  Diffusion Transformers (DiT) excel at image and video generation but face\ncomputational challenges due to the quadratic complexity of self-attention\noperators. We propose DiTFastAttn, a post-training compression method to\nalleviate the computational bottleneck of DiT. We identify three key\nredundancies in the attention computation during DiT inference: (1) spatial\nredundancy, where many attention heads focus on local information; (2) temporal\nredundancy, with high similarity between the attention outputs of neighboring\nsteps; (3) conditional redundancy, where conditional and unconditional\ninferences exhibit significant similarity. We propose three techniques to\nreduce these redundancies: (1) Window Attention with Residual Sharing to reduce\nspatial redundancy; (2) Attention Sharing across Timesteps to exploit the\nsimilarity between steps; (3) Attention Sharing across CFG to skip redundant\ncomputations during conditional generation. We apply DiTFastAttn to DiT,\nPixArt-Sigma for image generation tasks, and OpenSora for video generation\ntasks. Our results show that for image generation, our method reduces up to 76%\nof the attention FLOPs and achieves up to 1.8x end-to-end speedup at\nhigh-resolution (2k x 2k) generation.\n","authors":["Zhihang Yuan","Hanling Zhang","Pu Lu","Xuefei Ning","Linfeng Zhang","Tianchen Zhao","Shengen Yan","Guohao Dai","Yu Wang"],"pdf_url":"https://arxiv.org/pdf/2406.08552v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14400v1","updated":"2024-10-18T12:04:23Z","published":"2024-10-18T12:04:23Z","title":"Variable Aperture Bokeh Rendering via Customized Focal Plane Guidance","summary":"  Bokeh rendering is one of the most popular techniques in photography. It can\nmake photographs visually appealing, forcing users to focus their attentions on\nparticular area of image. However, achieving satisfactory bokeh effect usually\npresents significant challenge, since mobile cameras with restricted optical\nsystems are constrained, while expensive high-end DSLR lens with large aperture\nshould be needed. Therefore, many deep learning-based computational photography\nmethods have been developed to mimic the bokeh effect in recent years.\nNevertheless, most of these methods were limited to rendering bokeh effect in\ncertain single aperture. There lacks user-friendly bokeh rendering method that\ncan provide precise focal plane control and customised bokeh generation. There\nas well lacks authentic realistic bokeh dataset that can potentially promote\nbokeh learning on variable apertures. To address these two issues, in this\npaper, we have proposed an effective controllable bokeh rendering method, and\ncontributed a Variable Aperture Bokeh Dataset (VABD). In the proposed method,\nuser can customize focal plane to accurately locate concerned subjects and\nselect target aperture information for bokeh rendering. Experimental results on\npublic EBB! benchmark dataset and our constructed dataset VABD have\ndemonstrated that the customized focal plane together aperture prompt can\nbootstrap model to simulate realistic bokeh effect. The proposed method has\nachieved competitive state-of-the-art performance with only 4.4M parameters,\nwhich is much lighter than mainstream computational bokeh models. The\ncontributed dataset and source codes will be released on github\nhttps://github.com/MoTong-AI-studio/VABM.\n","authors":["Kang Chen","Shijun Yan","Aiwen Jiang","Han Li","Zhifeng Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14400v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14398v1","updated":"2024-10-18T12:02:21Z","published":"2024-10-18T12:02:21Z","title":"Dynamic Negative Guidance of Diffusion Models","summary":"  Negative Prompting (NP) is widely utilized in diffusion models, particularly\nin text-to-image applications, to prevent the generation of undesired features.\nIn this paper, we show that conventional NP is limited by the assumption of a\nconstant guidance scale, which may lead to highly suboptimal results, or even\ncomplete failure, due to the non-stationarity and state-dependence of the\nreverse process. Based on this analysis, we derive a principled technique\ncalled Dynamic Negative Guidance, which relies on a near-optimal time and state\ndependent modulation of the guidance without requiring additional training.\nUnlike NP, negative guidance requires estimating the posterior class\nprobability during the denoising process, which is achieved with limited\nadditional computational overhead by tracking the discrete Markov Chain during\nthe generative process. We evaluate the performance of DNG class-removal on\nMNIST and CIFAR10, where we show that DNG leads to higher safety, preservation\nof class balance and image quality when compared with baseline methods.\nFurthermore, we show that it is possible to use DNG with Stable Diffusion to\nobtain more accurate and less invasive guidance than NP.\n","authors":["Felix Koulischer","Johannes Deleu","Gabriel Raya","Thomas Demeester","Luca Ambrogioni"],"pdf_url":"https://arxiv.org/pdf/2410.14398v1.pdf","comment":"Paper currently under review. Submitted to ICLR 2025"},{"id":"http://arxiv.org/abs/2410.14389v1","updated":"2024-10-18T11:49:40Z","published":"2024-10-18T11:49:40Z","title":"SurgeryV2: Bridging the Gap Between Model Merging and Multi-Task\n  Learning with Deep Representation Surgery","summary":"  Model merging-based multitask learning (MTL) offers a promising approach for\nperforming MTL by merging multiple expert models without requiring access to\nraw training data. However, in this paper, we examine the merged model's\nrepresentation distribution and uncover a critical issue of \"representation\nbias\". This bias arises from a significant distribution gap between the\nrepresentations of the merged and expert models, leading to the suboptimal\nperformance of the merged MTL model. To address this challenge, we first\npropose a representation surgery solution called Surgery. Surgery is a\nlightweight, task-specific module that aligns the final layer representations\nof the merged model with those of the expert models, effectively alleviating\nbias and improving the merged model's performance. Despite these improvements,\na performance gap remains compared to the traditional MTL method. Further\nanalysis reveals that representation bias phenomena exist at each layer of the\nmerged model, and aligning representations only in the last layer is\ninsufficient for fully reducing systemic bias because biases introduced at each\nlayer can accumulate and interact in complex ways. To tackle this, we then\npropose a more comprehensive solution, deep representation surgery (also called\nSurgeryV2), which mitigates representation bias across all layers, and thus\nbridges the performance gap between model merging-based MTL and traditional\nMTL. Finally, we design an unsupervised optimization objective to optimize both\nthe Surgery and SurgeryV2 modules. Our experimental results show that\nincorporating these modules into state-of-the-art (SOTA) model merging schemes\nleads to significant performance gains. Notably, our SurgeryV2 scheme reaches\nalmost the same level as individual expert models or the traditional MTL model.\nThe code is available at \\url{https://github.com/EnnengYang/SurgeryV2}.\n","authors":["Enneng Yang","Li Shen","Zhenyi Wang","Guibing Guo","Xingwei Wang","Xiaocun Cao","Jie Zhang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2410.14389v1.pdf","comment":"This paper is an extended version of our previous work\n  [arXiv:2402.02705] presented at ICML 2024"},{"id":"http://arxiv.org/abs/2410.14379v1","updated":"2024-10-18T11:07:12Z","published":"2024-10-18T11:07:12Z","title":"AnomalyNCD: Towards Novel Anomaly Class Discovery in Industrial\n  Scenarios","summary":"  In the industrial scenario, anomaly detection could locate but cannot\nclassify anomalies. To complete their capability, we study to automatically\ndiscover and recognize visual classes of industrial anomalies. In terms of\nmulti-class anomaly classification, previous methods cluster anomalies\nrepresented by frozen pre-trained models but often fail due to poor\ndiscrimination. Novel class discovery (NCD) has the potential to tackle this.\nHowever, it struggles with non-prominent and semantically weak anomalies that\nchallenge network learning focus. To address these, we introduce AnomalyNCD, a\nmulti-class anomaly classification framework compatible with existing anomaly\ndetection methods. This framework learns anomaly-specific features and\nclassifies anomalies in a self-supervised manner. Initially, a technique called\nMain Element Binarization (MEBin) is first designed, which segments primary\nanomaly regions into masks to alleviate the impact of incorrect detections on\nlearning. Subsequently, we employ mask-guided contrastive representation\nlearning to improve feature discrimination, which focuses network attention on\nisolated anomalous regions and reduces the confusion of erroneous inputs\nthrough re-corrected pseudo labels. Finally, to enable flexible classification\nat both region and image levels during inference, we develop a region merging\nstrategy that determines the overall image category based on the classified\nanomaly regions. Our method outperforms the state-of-the-art works on the MVTec\nAD and MTD datasets. Compared with the current methods, AnomalyNCD combined\nwith zero-shot anomaly detection method achieves a 10.8% $F_1$ gain, 8.8% NMI\ngain, and 9.5% ARI gain on MVTec AD, 12.8% $F_1$ gain, 5.7% NMI gain, and 10.8%\nARI gain on MTD. The source code is available at\nhttps://github.com/HUST-SLOW/AnomalyNCD.\n","authors":["Ziming Huang","Xurui Li","Haotian Liu","Feng Xue","Yuzhe Wang","Yu Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.14379v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14365v1","updated":"2024-10-18T10:51:10Z","published":"2024-10-18T10:51:10Z","title":"Impact of imperfect annotations on CNN training and performance for\n  instance segmentation and classification in digital pathology","summary":"  Segmentation and classification of large numbers of instances, such as cell\nnuclei, are crucial tasks in digital pathology for accurate diagnosis. However,\nthe availability of high-quality datasets for deep learning methods is often\nlimited due to the complexity of the annotation process. In this work, we\ninvestigate the impact of noisy annotations on the training and performance of\na state-of-the-art CNN model for the combined task of detecting, segmenting and\nclassifying nuclei in histopathology images. In this context, we investigate\nthe conditions for determining an appropriate number of training epochs to\nprevent overfitting to annotation noise during training. Our results indicate\nthat the utilisation of a small, correctly annotated validation set is\ninstrumental in avoiding overfitting and maintaining model performance to a\nlarge extent. Additionally, our findings underscore the beneficial role of\npre-training.\n","authors":["Laura Gálvez Jiménez","Christine Decaestecker"],"pdf_url":"https://arxiv.org/pdf/2410.14365v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.08102v2","updated":"2024-10-18T09:58:45Z","published":"2023-02-16T06:01:31Z","title":"Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech\n  Recognition","summary":"  Visual Speech Recognition (VSR) aims to infer speech into text depending on\nlip movements alone. As it focuses on visual information to model the speech,\nits performance is inherently sensitive to personal lip appearances and\nmovements, and this makes the VSR models show degraded performance when they\nare applied to unseen speakers. In this paper, to remedy the performance\ndegradation of the VSR model on unseen speakers, we propose prompt tuning\nmethods of Deep Neural Networks (DNNs) for speaker-adaptive VSR. Specifically,\nmotivated by recent advances in Natural Language Processing (NLP), we finetune\nprompts on adaptation data of target speakers instead of modifying the\npre-trained model parameters. Different from the previous prompt tuning methods\nmainly limited to Transformer variant architecture, we explore different types\nof prompts, the addition, the padding, and the concatenation form prompts that\ncan be applied to the VSR model which is composed of CNN and Transformer in\ngeneral. With the proposed prompt tuning, we show that the performance of the\npre-trained VSR model on unseen speakers can be largely improved by using a\nsmall amount of adaptation data (e.g., less than 5 minutes), even if the\npre-trained model is already developed with large speaker variations. Moreover,\nby analyzing the performance and parameters of different types of prompts, we\ninvestigate when the prompt tuning is preferred over the finetuning methods.\nThe effectiveness of the proposed method is evaluated on both word- and\nsentence-level VSR databases, LRW-ID and GRID.\n","authors":["Minsu Kim","Hyung-Il Kim","Yong Man Ro"],"pdf_url":"https://arxiv.org/pdf/2302.08102v2.pdf","comment":"IEEE TPAMI"},{"id":"http://arxiv.org/abs/2410.14343v1","updated":"2024-10-18T09:51:43Z","published":"2024-10-18T09:51:43Z","title":"2D-3D Deformable Image Registration of Histology Slide and Micro-CT with\n  ML-based Initialization","summary":"  Recent developments in the registration of histology and micro-computed\ntomography ({\\mu}CT) have broadened the perspective of pathological\napplications such as virtual histology based on {\\mu}CT. This topic remains\nchallenging because of the low image quality of soft tissue CT. Additionally,\nsoft tissue samples usually deform during the histology slide preparation,\nmaking it difficult to correlate the structures between histology slide and\n{\\mu}CT. In this work, we propose a novel 2D-3D multi-modal deformable image\nregistration method. The method uses a machine learning (ML) based\ninitialization followed by the registration. The registration is finalized by\nan analytical out-of-plane deformation refinement. The method is evaluated on\ndatasets acquired from tonsil and tumor tissues. {\\mu}CTs of both\nphase-contrast and conventional absorption modalities are investigated. The\nregistration results from the proposed method are compared with those from\nintensity- and keypoint-based methods. The comparison is conducted using both\nvisual and fiducial-based evaluations. The proposed method demonstrates\nsuperior performance compared to the other two methods.\n","authors":["Junan Chen","Matteo Ronchetti","Verena Stehl","Van Nguyen","Muhannad Al Kallaa","Mahesh Thalwaththe Gedara","Claudia Lölkes","Stefan Moser","Maximilian Seidl","Matthias Wieczorek"],"pdf_url":"https://arxiv.org/pdf/2410.14343v1.pdf","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.14340v1","updated":"2024-10-18T09:51:14Z","published":"2024-10-18T09:51:14Z","title":"Zero-shot Action Localization via the Confidence of Large\n  Vision-Language Models","summary":"  Precise action localization in untrimmed video is vital for fields such as\nprofessional sports and minimally invasive surgery, where the delineation of\nparticular motions in recordings can dramatically enhance analysis. But in many\ncases, large scale datasets with video-label pairs for localization are\nunavailable, limiting the opportunity to fine-tune video-understanding models.\nRecent developments in large vision-language models (LVLM) address this need\nwith impressive zero-shot capabilities in a variety of video understanding\ntasks. However, the adaptation of image-based LVLMs, with their powerful visual\nquestion answering capabilities, to action localization in long-form video is\nstill relatively unexplored. To this end, we introduce a true ZEro-shot Action\nLocalization method (ZEAL). Specifically, we leverage the built-in action\nknowledge of a large language model (LLM) to inflate actions into\nhighly-detailed descriptions of the archetypal start and end of the action.\nThese descriptions serve as queries to LVLM for generating frame-level\nconfidence scores which can be aggregated to produce localization outputs. The\nsimplicity and flexibility of our method lends it amenable to more capable\nLVLMs as they are developed, and we demonstrate remarkable results in zero-shot\naction localization on a challenging benchmark, without any training.\n","authors":["Josiah Aklilu","Xiaohan Wang","Serena Yeung-Levy"],"pdf_url":"https://arxiv.org/pdf/2410.14340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14334v1","updated":"2024-10-18T09:44:35Z","published":"2024-10-18T09:44:35Z","title":"Evaluating the evaluators: Towards human-aligned metrics for missing\n  markers reconstruction","summary":"  Animation data is often obtained through optical motion capture systems,\nwhich utilize a multitude of cameras to establish the position of optical\nmarkers. However, system errors or occlusions can result in missing markers,\nthe manual cleaning of which can be time-consuming. This has sparked interest\nin machine learning-based solutions for missing marker reconstruction in the\nacademic community. Most academic papers utilize a simplistic mean square error\nas the main metric. In this paper, we show that this metric does not correlate\nwith subjective perception of the fill quality. We introduce and evaluate a set\nof better-correlated metrics that can drive progress in the field.\n","authors":["Taras Kucherenko","Derek Peristy","Judith Bütepage"],"pdf_url":"https://arxiv.org/pdf/2410.14334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14332v1","updated":"2024-10-18T09:44:25Z","published":"2024-10-18T09:44:25Z","title":"Croc: Pretraining Large Multimodal Models with Cross-Modal Comprehension","summary":"  Recent advances in Large Language Models (LLMs) have catalyzed the\ndevelopment of Large Multimodal Models (LMMs). However, existing research\nprimarily focuses on tuning language and image instructions, ignoring the\ncritical pretraining phase where models learn to process textual and visual\nmodalities jointly. In this paper, we propose a new pretraining paradigm for\nLMMs to enhance the visual comprehension capabilities of LLMs by introducing a\nnovel cross-modal comprehension stage. Specifically, we design a dynamically\nlearnable prompt token pool and employ the Hungarian algorithm to replace part\nof the original visual tokens with the most relevant prompt tokens. Then, we\nconceptualize visual tokens as analogous to a \"foreign language\" for the LLMs\nand propose a mixed attention mechanism with bidirectional visual attention and\nunidirectional textual attention to comprehensively enhance the understanding\nof visual tokens. Meanwhile, we integrate a detailed caption generation task,\nleveraging rich descriptions to further facilitate LLMs in understanding visual\nsemantic information. After pretraining on 1.5 million publicly accessible\ndata, we present a new foundation model called Croc. Experimental results\ndemonstrate that Croc achieves new state-of-the-art performance on massive\nvision-language benchmarks. To support reproducibility and facilitate further\nresearch, we release the training code and pre-trained model weights at\nhttps://github.com/deepglint/Croc.\n","authors":["Yin Xie","Kaicheng Yang","Ninghua Yang","Weimo Deng","Xiangzi Dai","Tiancheng Gu","Yumeng Wang","Xiang An","Yongle Zhao","Ziyong Feng","Jiankang Deng"],"pdf_url":"https://arxiv.org/pdf/2410.14332v1.pdf","comment":"18 pages, 11 figures"},{"id":"http://arxiv.org/abs/2410.14326v1","updated":"2024-10-18T09:37:38Z","published":"2024-10-18T09:37:38Z","title":"Fast proxy centers for Jeffreys centroids: The Jeffreys-Fisher-Rao and\n  the inductive Gauss-Bregman centers","summary":"  The symmetric Kullback-Leibler centroid also called the Jeffreys centroid of\na set of mutually absolutely continuous probability distributions on a measure\nspace provides a notion of centrality which has proven useful in many tasks\nincluding information retrieval, information fusion, and clustering in image,\nvideo and sound processing. However, the Jeffreys centroid is not available in\nclosed-form for sets of categorical or normal distributions, two widely used\nstatistical models, and thus need to be approximated numerically in practice.\nIn this paper, we first propose the new Jeffreys-Fisher-Rao center defined as\nthe Fisher-Rao midpoint of the sided Kullback-Leibler centroids as a plug-in\nreplacement of the Jeffreys centroid. This Jeffreys-Fisher-Rao center admits a\ngeneric formula for uni-parameter exponential family distributions, and\nclosed-form formula for categorical and normal distributions, matches exactly\nthe Jeffreys centroid for same-mean normal distributions, and is experimentally\nobserved in practice to be close to the Jeffreys centroid. Second, we define a\nnew type of inductive centers generalizing the principle of Gauss\narithmetic-geometric double sequence mean for pairs of densities of any given\nexponential family. This center is shown experimentally to approximate very\nwell the Jeffreys centroid and is suggested to use when the Jeffreys-Fisher-Rao\ncenter is not available in closed form. Moreover, this Gauss-Bregman inductive\ncenter always converges and matches the Jeffreys centroid for sets of same-mean\nnormal distributions. We report on our experiments demonstrating the use of the\nJeffreys-Fisher-Rao and Gauss-Bregman centers instead of the Jeffreys centroid.\nFinally, we conclude this work by reinterpreting these fast proxy centers of\nJeffreys centroids under the lens of dually flat spaces in information\ngeometry.\n","authors":["Frank Nielsen"],"pdf_url":"https://arxiv.org/pdf/2410.14326v1.pdf","comment":"35 pages, 10 figures"},{"id":"http://arxiv.org/abs/2410.14324v1","updated":"2024-10-18T09:36:10Z","published":"2024-10-18T09:36:10Z","title":"HiCo: Hierarchical Controllable Diffusion Model for Layout-to-image\n  Generation","summary":"  The task of layout-to-image generation involves synthesizing images based on\nthe captions of objects and their spatial positions. Existing methods still\nstruggle in complex layout generation, where common bad cases include object\nmissing, inconsistent lighting, conflicting view angles, etc. To effectively\naddress these issues, we propose a \\textbf{Hi}erarchical \\textbf{Co}ntrollable\n(HiCo) diffusion model for layout-to-image generation, featuring object\nseperable conditioning branch structure. Our key insight is to achieve spatial\ndisentanglement through hierarchical modeling of layouts. We use a multi branch\nstructure to represent hierarchy and aggregate them in fusion module. To\nevaluate the performance of multi-objective controllable layout generation in\nnatural scenes, we introduce the HiCo-7K benchmark, derived from the GRIT-20M\ndataset and manually cleaned. https://github.com/360CVGroup/HiCo_T2I.\n","authors":["Bo Cheng","Yuhang Ma","Liebucha Wu","Shanyuan Liu","Ao Ma","Xiaoyu Wu","Dawei Leng","Yuhui Yin"],"pdf_url":"https://arxiv.org/pdf/2410.14324v1.pdf","comment":"NeurIPS2024"},{"id":"http://arxiv.org/abs/2410.13824v2","updated":"2024-10-18T09:01:01Z","published":"2024-10-17T17:48:54Z","title":"Harnessing Webpage UIs for Text-Rich Visual Understanding","summary":"  Text-rich visual understanding-the ability to process environments where\ndense textual content is integrated with visuals-is crucial for multimodal\nlarge language models (MLLMs) to interact effectively with structured\nenvironments. To enhance this capability, we propose synthesizing general\nmultimodal instructions from webpage UIs using text-based large language models\n(LLMs). Despite lacking direct visual input, text-based LLMs are able to\nprocess structured text representations from webpage accessibility trees. These\ninstructions are then paired with UI screenshots to train multimodal models. We\nintroduce MultiUI, a dataset containing 7.3 million samples from 1 million\nwebsites, covering diverse multimodal tasks and UI layouts. Models trained on\nMultiUI not only excel in web UI tasks-achieving up to a 48% improvement on\nVisualWebBench and a 19.1% boost in element accuracy on a web agent dataset\nMind2Web-but also generalize surprisingly well to non-web UI tasks and even to\nnon-UI domains, such as document understanding, OCR, and chart interpretation.\nThese results highlight the broad applicability of web UI data for advancing\ntext-rich visual understanding across various scenarios.\n","authors":["Junpeng Liu","Tianyue Ou","Yifan Song","Yuxiao Qu","Wai Lam","Chenyan Xiong","Wenhu Chen","Graham Neubig","Xiang Yue"],"pdf_url":"https://arxiv.org/pdf/2410.13824v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12013v2","updated":"2024-10-18T08:57:30Z","published":"2024-06-26T12:33:34Z","title":"Dating ancient manuscripts using radiocarbon and AI-based writing style\n  analysis","summary":"  Determining the chronology of ancient handwritten manuscripts is essential\nfor reconstructing the evolution of ideas. For the Dead Sea Scrolls, this is\nparticularly important. However, there is an almost complete lack of\ndate-bearing manuscripts evenly distributed across the timeline and written in\nsimilar scripts available for palaeographic comparison. Here, we present Enoch,\na state-of-the-art AI-based date-prediction model, trained on the basis of new\nradiocarbon-dated samples of the scrolls. Enoch uses established\nhandwriting-style descriptors and applies Bayesian ridge regression. The\nchallenge of this study is that the number of radiocarbon-dated manuscripts is\nsmall, while current machine learning requires an abundance of training data.\nWe show that by using combined angular and allographic writing style feature\nvectors and applying Bayesian ridge regression, Enoch could predict the\nradiocarbon-based dates from style, supported by leave-one-out validation, with\nvaried MAEs of 27.9 to 30.7 years relative to the radiocarbon dating. Enoch was\nthen used to estimate the dates of 135 unseen manuscripts, revealing that 79\nper cent of the samples were considered 'realistic' upon palaeographic post-hoc\nevaluation. We present a new chronology of the scrolls. The radiocarbon ranges\nand Enoch's style-based predictions are often older than the traditionally\nassumed palaeographic estimates. In the range of 300-50 BCE, Enoch's date\nprediction provides an improved granularity. The study is in line with current\ndevelopments in multimodal machine-learning techniques, and the methods can be\nused for date prediction in other partially-dated manuscript collections. This\nresearch shows how Enoch's quantitative, probability-based approach can be a\ntool for palaeographers and historians, re-dating ancient Jewish key texts and\ncontributing to current debates on Jewish and Christian origins.\n","authors":["Mladen Popović","Maruf A. Dhali","Lambert Schomaker","Johannes van der Plicht","Kaare Lund Rasmussen","Jacopo La Nasa","Ilaria Degano","Maria Perla Colombini","Eibert Tigchelaar"],"pdf_url":"https://arxiv.org/pdf/2407.12013v2.pdf","comment":"16 pages of main article, 103 pages of supplementary materials; the\n  first version of this article is originally prepared in July 2023 after the\n  completion of all the experiments"},{"id":"http://arxiv.org/abs/2410.14285v1","updated":"2024-10-18T08:40:26Z","published":"2024-10-18T08:40:26Z","title":"Advanced Underwater Image Quality Enhancement via Hybrid\n  Super-Resolution Convolutional Neural Networks and Multi-Scale Retinex-Based\n  Defogging Techniques","summary":"  The difficulties of underwater image degradation due to light scattering,\nabsorption, and fog-like particles which lead to low resolution and poor\nvisibility are discussed in this study report. We suggest a sophisticated\nhybrid strategy that combines Multi-Scale Retinex (MSR) defogging methods with\nSuper-Resolution Convolutional Neural Networks (SRCNN) to address these\nproblems. The Retinex algorithm mimics human visual perception to reduce uneven\nlighting and fogging, while the SRCNN component improves the spatial resolution\nof underwater photos.Through the combination of these methods, we are able to\nenhance the clarity, contrast, and colour restoration of underwater images,\noffering a reliable way to improve image quality in difficult underwater\nconditions. The research conducts extensive experiments on real-world\nunderwater datasets to further illustrate the efficacy of the suggested\napproach. In terms of sharpness, visibility, and feature retention,\nquantitative evaluation which use metrics like the Structural Similarity Index\nMeasure (SSIM) and Peak Signal-to-Noise Ratio (PSNR) demonstrates notable\nadvances over conventional techniques.In real-time underwater applications like\nmarine exploration, underwater robotics, and autonomous underwater vehicles,\nwhere clear and high-resolution imaging is crucial for operational success, the\ncombination of deep learning and conventional image processing techniques\noffers a computationally efficient framework with superior results.\n","authors":["Yugandhar Reddy Gogireddy","Jithendra Reddy Gogireddy"],"pdf_url":"https://arxiv.org/pdf/2410.14285v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14283v1","updated":"2024-10-18T08:39:56Z","published":"2024-10-18T08:39:56Z","title":"Takin-ADA: Emotion Controllable Audio-Driven Animation with Canonical\n  and Landmark Loss Optimization","summary":"  Existing audio-driven facial animation methods face critical challenges,\nincluding expression leakage, ineffective subtle expression transfer, and\nimprecise audio-driven synchronization. We discovered that these issues stem\nfrom limitations in motion representation and the lack of fine-grained control\nover facial expressions. To address these problems, we present Takin-ADA, a\nnovel two-stage approach for real-time audio-driven portrait animation. In the\nfirst stage, we introduce a specialized loss function that enhances subtle\nexpression transfer while reducing unwanted expression leakage. The second\nstage utilizes an advanced audio processing technique to improve lip-sync\naccuracy. Our method not only generates precise lip movements but also allows\nflexible control over facial expressions and head motions. Takin-ADA achieves\nhigh-resolution (512x512) facial animations at up to 42 FPS on an RTX 4090 GPU,\noutperforming existing commercial solutions. Extensive experiments demonstrate\nthat our model significantly surpasses previous methods in video quality,\nfacial dynamics realism, and natural head movements, setting a new benchmark in\nthe field of audio-driven facial animation.\n","authors":["Bin Lin","Yanzhen Yu","Jianhao Ye","Ruitao Lv","Yuguang Yang","Ruoye Xie","Pan Yu","Hongbin Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.14283v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2410.14282v1","updated":"2024-10-18T08:39:49Z","published":"2024-10-18T08:39:49Z","title":"You Only Look Twice! for Failure Causes Identification of Drill Bits","summary":"  Efficient identification of the root causes of drill bit failure is crucial\ndue to potential impacts such as operational losses, safety threats, and\ndelays. Early recognition of these failures enables proactive maintenance,\nreducing risks and financial losses associated with unforeseen breakdowns and\nprolonged downtime. Thus, our study investigates various causes of drill bit\nfailure using images of different blades. The process involves annotating\ncutters with their respective locations and damage types, followed by the\ndevelopment of two YOLO Location and Damage Cutter Detection models, as well as\nmulti-class multi-label Decision Tree and Random Forests models to identify the\ncauses of failure by assessing the cutters' location and damage type.\nAdditionally, RRFCI is proposed for the classification of failure causes.\nNotably, the cutter location detection model achieved a high score of 0.97 mPA,\nand the cutter damage detection model yielded a 0.49 mPA. The rule-based\napproach over-performed both DT and RF in failure cause identification,\nachieving a macro-average F1-score of 0.94 across all damage causes. The\nintegration of the complete automated pipeline successfully identified 100\\% of\nthe 24 failure causes when tested on independent sets of ten drill bits,\nshowcasing its potential to efficiently assist experts in identifying the root\ncauses of drill bit damages.\n","authors":["Asma Yamani","Nehal Al-Otaiby","Haifa Al-Shemmeri","Imane Boudellioua"],"pdf_url":"https://arxiv.org/pdf/2410.14282v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14279v1","updated":"2024-10-18T08:35:57Z","published":"2024-10-18T08:35:57Z","title":"ClearSR: Latent Low-Resolution Image Embeddings Help Diffusion-Based\n  Real-World Super Resolution Models See Clearer","summary":"  We present ClearSR, a new method that can better take advantage of latent\nlow-resolution image (LR) embeddings for diffusion-based real-world image\nsuper-resolution (Real-ISR). Previous Real-ISR models mostly focus on how to\nactivate more generative priors of text-to-image diffusion models to make the\noutput high-resolution (HR) images look better. However, since these methods\nrely too much on the generative priors, the content of the output images is\noften inconsistent with the input LR ones. To mitigate the above issue, in this\nwork, we explore using latent LR embeddings to constrain the control signals\nfrom ControlNet, and extract LR information at both detail and structure\nlevels. We show that the proper use of latent LR embeddings can produce\nhigher-quality control signals, which enables the super-resolution results to\nbe more consistent with the LR image and leads to clearer visual results. In\naddition, we also show that latent LR embeddings can be used to control the\ninference stage, allowing for the improvement of fidelity and generation\nability simultaneously. Experiments demonstrate that our model can achieve\nbetter performance across multiple metrics on several test sets and generate\nmore consistent SR results with LR images than existing methods. Our code will\nbe made publicly available.\n","authors":["Yuhao Wan","Peng-Tao Jiang","Qibin Hou","Hao Zhang","Jinwei Chen","Ming-Ming Cheng","Bo Li"],"pdf_url":"https://arxiv.org/pdf/2410.14279v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08091v2","updated":"2024-10-18T08:27:05Z","published":"2024-10-10T16:33:27Z","title":"Distribution Guidance Network for Weakly Supervised Point Cloud Semantic\n  Segmentation","summary":"  Despite alleviating the dependence on dense annotations inherent to fully\nsupervised methods, weakly supervised point cloud semantic segmentation suffers\nfrom inadequate supervision signals. In response to this challenge, we\nintroduce a novel perspective that imparts auxiliary constraints by regulating\nthe feature space under weak supervision. Our initial investigation identifies\nwhich distributions accurately characterize the feature space, subsequently\nleveraging this priori to guide the alignment of the weakly supervised\nembeddings. Specifically, we analyze the superiority of the mixture of von\nMises-Fisher distributions (moVMF) among several common distribution\ncandidates. Accordingly, we develop a Distribution Guidance Network (DGNet),\nwhich comprises a weakly supervised learning branch and a distribution\nalignment branch. Leveraging reliable clustering initialization derived from\nthe weakly supervised learning branch, the distribution alignment branch\nalternately updates the parameters of the moVMF and the network, ensuring\nalignment with the moVMF-defined latent space. Extensive experiments validate\nthe rationality and effectiveness of our distribution choice and network\ndesign. Consequently, DGNet achieves state-of-the-art performance under\nmultiple datasets and various weakly supervised settings.\n","authors":["Zhiyi Pan","Wei Gao","Shan Liu","Ge Li"],"pdf_url":"https://arxiv.org/pdf/2410.08091v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.02512v2","updated":"2024-10-18T08:25:52Z","published":"2024-05-03T22:55:56Z","title":"SatSwinMAE: Efficient Autoencoding for Multiscale Time-series Satellite\n  Imagery","summary":"  Recent advancements in foundation models have significantly impacted various\nfields, including natural language processing, computer vision, and multi-modal\ntasks. One area that stands to benefit greatly is Earth observation, where\nthese models can efficiently process large-scale, unlabeled geospatial data. In\nthis work we extend the SwinMAE model to integrate temporal information for\nsatellite time-series data. The architecture employs a hierarchical 3D Masked\nAutoencoder (MAE) with Video Swin Transformer blocks to effectively capture\nmulti-scale spatio-temporal dependencies in satellite imagery. To enhance\ntransfer learning, we incorporate both encoder and decoder pretrained weights,\nalong with skip connections to preserve scale-specific information. This forms\nan architecture similar to SwinUNet with an additional temporal component. Our\napproach shows significant performance improvements over existing\nstate-of-the-art foundation models for all the evaluated downstream tasks: land\ncover segmentation, building density prediction, flood mapping, wildfire scar\nmapping and multi-temporal crop segmentation. Particularly, in the land cover\nsegmentation task of the PhilEO Bench dataset, it outperforms other geospatial\nfoundation models with a 10.4% higher accuracy.\n","authors":["Yohei Nakayama","Jiawei Su","Luis M. Pazos-Outón"],"pdf_url":"https://arxiv.org/pdf/2405.02512v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14265v1","updated":"2024-10-18T08:20:37Z","published":"2024-10-18T08:20:37Z","title":"HYPNOS : Highly Precise Foreground-focused Diffusion Finetuning for\n  Inanimate Objects","summary":"  In recent years, personalized diffusion-based text-to-image generative tasks\nhave been a hot topic in computer vision studies. A robust diffusion model is\ndetermined by its ability to perform near-perfect reconstruction of certain\nproduct outcomes given few related input samples. Unfortunately, the current\nprominent diffusion-based finetuning technique falls short in maintaining the\nforeground object consistency while being constrained to produce diverse\nbackgrounds in the image outcome. In the worst scenario, the overfitting issue\nmay occur, meaning that the foreground object is less controllable due to the\ncondition above, for example, the input prompt information is transferred\nambiguously to both foreground and background regions, instead of the supposed\nbackground region only. To tackle the issues above, we proposed Hypnos, a\nhighly precise foreground-focused diffusion finetuning technique. On the image\nlevel, this strategy works best for inanimate object generation tasks, and to\ndo so, Hypnos implements two main approaches, namely: (i) a content-centric\nprompting strategy and (ii) the utilization of our additional\nforeground-focused discriminative module. The utilized module is connected with\nthe diffusion model and finetuned with our proposed set of supervision\nmechanism. Combining the strategies above yielded to the foreground-background\ndisentanglement capability of the diffusion model. Our experimental results\nshowed that the proposed strategy gave a more robust performance and visually\npleasing results compared to the former technique. For better elaborations, we\nalso provided extensive studies to assess the fruitful outcomes above, which\nreveal how personalization behaves in regard to several training conditions.\n","authors":["Oliverio Theophilus Nathanael","Jonathan Samuel Lumentut","Nicholas Hans Muliawan","Edbert Valencio Angky","Felix Indra Kurniadi","Alfi Yusrotis Zakiyyah","Jeklin Harefa"],"pdf_url":"https://arxiv.org/pdf/2410.14265v1.pdf","comment":"26 pages, 12 figures, to appear on the Rich Media with Generative AI\n  workshop in conjunction with Asian Conference on Computer Vision (ACCV) 2024"},{"id":"http://arxiv.org/abs/2406.00125v3","updated":"2024-10-18T08:18:36Z","published":"2024-05-31T18:32:46Z","title":"TotalVibeSegmentator: Full Body MRI Segmentation for the NAKO and UK\n  Biobank","summary":"  Objectives: To present a publicly available torso segmentation network for\nlarge epidemiology datasets on volumetric interpolated breath-hold examination\n(VIBE) images. Materials & Methods: We extracted preliminary segmentations from\nTotalSegmentator, spine, and body composition networks for VIBE images, then\nimproved them iteratively and retrained a nnUNet network. Using subsets of NAKO\n(85 subjects) and UK Biobank (16 subjects), we evaluated with Dice-score on a\nholdout set (12 subjects) and existing organ segmentation approach (1000\nsubjects), generating 71 semantic segmentation types for VIBE images. We\nprovide an additional network for the vertebra segments 22 individual vertebra\ntypes. Results: We achieved an average Dice score of 0.89 +- 0.07 overall 71\nsegmentation labels. We scored > 0.90 Dice-score on the abdominal organs except\nfor the pancreas with a Dice of 0.70. Conclusion: Our work offers a detailed\nand refined publicly available full torso segmentation on VIBE images.\n","authors":["Robert Graf","Paul-Sören Platzek","Evamaria Olga Riedel","Constanze Ramschütz","Sophie Starck","Hendrik Kristian Möller","Matan Atad","Henry Völzke","Robin Bülow","Carsten Oliver Schmidt","Julia Rüdebusch","Matthias Jung","Marco Reisert","Jakob Weiss","Maximilian Löffler","Fabian Bamberg","Bene Wiestler","Johannes C. Paetzold","Daniel Rueckert","Jan Stefan Kirschke"],"pdf_url":"https://arxiv.org/pdf/2406.00125v3.pdf","comment":"https://github.com/robert-graf/TotalVibeSegmentator"},{"id":"http://arxiv.org/abs/2410.14250v1","updated":"2024-10-18T08:01:36Z","published":"2024-10-18T08:01:36Z","title":"Vision-Language Navigation with Energy-Based Policy","summary":"  Vision-language navigation (VLN) requires an agent to execute actions\nfollowing human instructions. Existing VLN models are optimized through expert\ndemonstrations by supervised behavioural cloning or incorporating manual reward\nengineering. While straightforward, these efforts overlook the accumulation of\nerrors in the Markov decision process, and struggle to match the distribution\nof the expert policy. Going beyond this, we propose an Energy-based Navigation\nPolicy (ENP) to model the joint state-action distribution using an energy-based\nmodel. At each step, low energy values correspond to the state-action pairs\nthat the expert is most likely to perform, and vice versa. Theoretically, the\noptimization objective is equivalent to minimizing the forward divergence\nbetween the occupancy measure of the expert and ours. Consequently, ENP learns\nto globally align with the expert policy by maximizing the likelihood of the\nactions and modeling the dynamics of the navigation states in a collaborative\nmanner. With a variety of VLN architectures, ENP achieves promising\nperformances on R2R, REVERIE, RxR, and R2R-CE, unleashing the power of existing\nVLN models.\n","authors":["Rui Liu","Wenguan Wang","Yi Yang"],"pdf_url":"https://arxiv.org/pdf/2410.14250v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13621v2","updated":"2024-10-18T08:01:27Z","published":"2024-10-17T14:55:09Z","title":"Enhanced Prompt-leveraged Weakly Supervised Cancer Segmentation based on\n  Segment Anything","summary":"  This work proposes a novel approach beyond supervised learning for effective\npathological image analysis, addressing the challenge of limited robust labeled\ndata. Pathological diagnosis of diseases like cancer has conventionally relied\non the evaluation of morphological features by physicians and pathologists.\nHowever, recent advancements in compute-aided diagnosis (CAD) systems are\ngaining significant attention as diagnostic support tools. Although the\nadvancement of deep learning has improved CAD significantly, segmentation\nmodels typically require large pixel-level annotated dataset, and such labeling\nis expensive. Existing studies not based on supervised approaches still\nstruggle with limited generalization, and no practical approach has emerged\nyet. To address this issue, we present a weakly supervised semantic\nsegmentation (WSSS) model by combining class activation map and Segment\nAnything Model (SAM)-based pseudo-labeling. For effective pretraining, we adopt\nthe SAM-a foundation model that is pretrained on large datasets and operates in\nzero-shot configurations using only coarse prompts. The proposed approach\ntransfer enhanced Attention Dropout Layer's knowledge to SAM, thereby\ngenerating pseudo-labels. To demonstrate the superiority of the proposed\nmethod, experimental studies are conducted on histopathological breast cancer\ndatasets. The proposed method outperformed other WSSS methods across three\ndatasets, demonstrating its efficiency by achieving this with only 12GB of GPU\nmemory during training. Our code is available at :\nhttps://github.com/QI-NemoSong/EPLC-SAM\n","authors":["Joonhyeon Song","Seohwan Yun","Seongho Yoon","Joohyeok Kim","Sangmin Lee"],"pdf_url":"https://arxiv.org/pdf/2410.13621v2.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.14247v1","updated":"2024-10-18T07:52:03Z","published":"2024-10-18T07:52:03Z","title":"ERDDCI: Exact Reversible Diffusion via Dual-Chain Inversion for\n  High-Quality Image Editing","summary":"  Diffusion models (DMs) have been successfully applied to real image editing.\nThese models typically invert images into latent noise vectors used to\nreconstruct the original images (known as inversion), and then edit them during\nthe inference process. However, recent popular DMs often rely on the assumption\nof local linearization, where the noise injected during the inversion process\nis expected to approximate the noise removed during the inference process.\nWhile DM efficiently generates images under this assumption, it can also\naccumulate errors during the diffusion process due to the assumption,\nultimately negatively impacting the quality of real image reconstruction and\nediting. To address this issue, we propose a novel method, referred to as\nERDDCI (Exact Reversible Diffusion via Dual-Chain Inversion). ERDDCI uses the\nnew Dual-Chain Inversion (DCI) for joint inference to derive an exact\nreversible diffusion process. By using DCI, our method effectively avoids the\ncumbersome optimization process in existing inversion approaches and achieves\nhigh-quality image editing. Additionally, to accommodate image operations under\nhigh guidance scales, we introduce a dynamic control strategy that enables more\nrefined image reconstruction and editing. Our experiments demonstrate that\nERDDCI significantly outperforms state-of-the-art methods in a 50-step\ndiffusion process. It achieves rapid and precise image reconstruction with an\nSSIM of 0.999 and an LPIPS of 0.001, and also delivers competitive results in\nimage editing.\n","authors":["Jimin Dai","Yingzhen Zhang","Shuo Chen","Jian Yang","Lei Luo"],"pdf_url":"https://arxiv.org/pdf/2410.14247v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14245v1","updated":"2024-10-18T07:51:31Z","published":"2024-10-18T07:51:31Z","title":"PReP: Efficient context-based shape retrieval for missing parts","summary":"  In this paper we study the problem of shape part retrieval in the point cloud\ndomain. Shape retrieval methods in the literature rely on the presence of an\nexisting query object, but what if the part we are looking for is not\navailable? We present Part Retrieval Pipeline (PReP), a pipeline that\ncreatively utilizes metric learning techniques along with a trained\nclassification model to measure the suitability of potential replacement parts\nfrom a database, as part of an application scenario targeting circular economy.\nThrough an innovative training procedure with increasing difficulty, it is able\nto learn to recognize suitable parts relying only on shape context. Thanks to\nits low parameter size and computational requirements, it can be used to sort\nthrough a warehouse of potentially tens of thousand of spare parts in just a\nfew seconds. We also establish an alternative baseline approach to compare\nagainst, and extensively document the unique challenges associated with this\ntask, as well as identify the design choices to solve them.\n","authors":["Vlassis Fotis","Ioannis Romanelis","Georgios Mylonas","Athanasios Kalogeras","Konstantinos Moustakas"],"pdf_url":"https://arxiv.org/pdf/2410.14245v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14242v1","updated":"2024-10-18T07:47:59Z","published":"2024-10-18T07:47:59Z","title":"Pseudo-label Refinement for Improving Self-Supervised Learning Systems","summary":"  Self-supervised learning systems have gained significant attention in recent\nyears by leveraging clustering-based pseudo-labels to provide supervision\nwithout the need for human annotations. However, the noise in these\npseudo-labels caused by the clustering methods poses a challenge to the\nlearning process leading to degraded performance. In this work, we propose a\npseudo-label refinement (SLR) algorithm to address this issue. The cluster\nlabels from the previous epoch are projected to the current epoch\ncluster-labels space and a linear combination of the new label and the\nprojected label is computed as a soft refined label containing the information\nfrom the previous epoch clusters as well as from the current epoch. In contrast\nto the common practice of using the maximum value as a cluster/class indicator,\nwe employ hierarchical clustering on these soft pseudo-labels to generate\nrefined hard-labels. This approach better utilizes the information embedded in\nthe soft labels, outperforming the simple maximum value approach for hard label\ngeneration. The effectiveness of the proposed SLR algorithm is evaluated in the\ncontext of person re-identification (Re-ID) using unsupervised domain\nadaptation (UDA). Experimental results demonstrate that the modified Re-ID\nbaseline, incorporating the SLR algorithm, achieves significantly improved mean\nAverage Precision (mAP) performance in various UDA tasks, including\nreal-to-synthetic, synthetic-to-real, and different real-to-real scenarios.\nThese findings highlight the efficacy of the SLR algorithm in enhancing the\nperformance of self-supervised learning systems.\n","authors":[" Zia-ur-Rehman","Arif Mahmood","Wenxiong Kang"],"pdf_url":"https://arxiv.org/pdf/2410.14242v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14238v1","updated":"2024-10-18T07:40:41Z","published":"2024-10-18T07:40:41Z","title":"Storyboard guided Alignment for Fine-grained Video Action Recognition","summary":"  Fine-grained video action recognition can be conceptualized as a video-text\nmatching problem. Previous approaches often rely on global video semantics to\nconsolidate video embeddings, which can lead to misalignment in video-text\npairs due to a lack of understanding of action semantics at an atomic\ngranularity level. To tackle this challenge, we propose a multi-granularity\nframework based on two observations: (i) videos with different global semantics\nmay share similar atomic actions or appearances, and (ii) atomic actions within\na video can be momentary, slow, or even non-directly related to the global\nvideo semantics. Inspired by the concept of storyboarding, which disassembles a\nscript into individual shots, we enhance global video semantics by generating\nfine-grained descriptions using a pre-trained large language model. These\ndetailed descriptions capture common atomic actions depicted in videos. A\nfiltering metric is proposed to select the descriptions that correspond to the\natomic actions present in both the videos and the descriptions. By employing\nglobal semantics and fine-grained descriptions, we can identify key frames in\nvideos and utilize them to aggregate embeddings, thereby making the embedding\nmore accurate. Extensive experiments on various video action recognition\ndatasets demonstrate superior performance of our proposed method in supervised,\nfew-shot, and zero-shot settings.\n","authors":["Enqi Liu","Liyuan Pan","Yan Yang","Yiran Zhong","Zhijing Wu","Xinxiao Wu","Liu Liu"],"pdf_url":"https://arxiv.org/pdf/2410.14238v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.05822v3","updated":"2024-10-18T07:24:54Z","published":"2023-08-10T18:43:44Z","title":"Encode-Store-Retrieve: Augmenting Human Memory through Language-Encoded\n  Egocentric Perception","summary":"  We depend on our own memory to encode, store, and retrieve our experiences.\nHowever, memory lapses can occur. One promising avenue for achieving memory\naugmentation is through the use of augmented reality head-mounted displays to\ncapture and preserve egocentric videos, a practice commonly referred to as\nlifelogging. However, a significant challenge arises from the sheer volume of\nvideo data generated through lifelogging, as the current technology lacks the\ncapability to encode and store such large amounts of data efficiently. Further,\nretrieving specific information from extensive video archives requires\nsubstantial computational power, further complicating the task of quickly\naccessing desired content. To address these challenges, we propose a memory\naugmentation agent that involves leveraging natural language encoding for video\ndata and storing them in a vector database. This approach harnesses the power\nof large vision language models to perform the language encoding process.\nAdditionally, we propose using large language models to facilitate natural\nlanguage querying. Our agent underwent extensive evaluation using the QA-Ego4D\ndataset and achieved state-of-the-art results with a BLEU score of 8.3,\noutperforming conventional machine learning models that scored between 3.4 and\n5.8. Additionally, we conducted a user study in which participants interacted\nwith the human memory augmentation agent through episodic memory and open-ended\nquestions. The results of this study show that the agent results in\nsignificantly better recall performance on episodic memory tasks compared to\nhuman participants. The results also highlight the agent's practical\napplicability and user acceptance.\n","authors":["Junxiao Shen","John Dudley","Per Ola Kristensson"],"pdf_url":"https://arxiv.org/pdf/2308.05822v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18791v3","updated":"2024-10-18T07:21:56Z","published":"2024-03-27T17:35:24Z","title":"Object Pose Estimation via the Aggregation of Diffusion Features","summary":"  Estimating the pose of objects from images is a crucial task of 3D scene\nunderstanding, and recent approaches have shown promising results on very large\nbenchmarks. However, these methods experience a significant performance drop\nwhen dealing with unseen objects. We believe that it results from the limited\ngeneralizability of image features. To address this problem, we have an\nin-depth analysis on the features of diffusion models, e.g. Stable Diffusion,\nwhich hold substantial potential for modeling unseen objects. Based on this\nanalysis, we then innovatively introduce these diffusion features for object\npose estimation. To achieve this, we propose three distinct architectures that\ncan effectively capture and aggregate diffusion features of different\ngranularity, greatly improving the generalizability of object pose estimation.\nOur approach outperforms the state-of-the-art methods by a considerable margin\non three popular benchmark datasets, LM, O-LM, and T-LESS. In particular, our\nmethod achieves higher accuracy than the previous best arts on unseen objects:\n97.9% vs. 93.5% on Unseen LM, 85.9% vs. 76.3% on Unseen O-LM, showing the\nstrong generalizability of our method. Our code is released at\nhttps://github.com/Tianfu18/diff-feats-pose.\n","authors":["Tianfu Wang","Guosheng Hu","Hongguang Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18791v3.pdf","comment":"Accepted to CVPR2024, fix typo"},{"id":"http://arxiv.org/abs/2410.09421v2","updated":"2024-10-18T07:10:38Z","published":"2024-10-12T07:56:47Z","title":"VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language\n  Models Alignment","summary":"  As large vision-language models (LVLMs) evolve rapidly, the demand for\nhigh-quality and diverse data to align these models becomes increasingly\ncrucial. However, the creation of such data with human supervision proves\ncostly and time-intensive. In this paper, we investigate the efficacy of AI\nfeedback to scale supervision for aligning LVLMs. We introduce VLFeedback, the\nfirst large-scale vision-language feedback dataset, comprising over 82K\nmulti-modal instructions and comprehensive rationales generated by\noff-the-shelf models without human annotations. To evaluate the effectiveness\nof AI feedback for vision-language alignment, we train Silkie, an LVLM\nfine-tuned via direct preference optimization on VLFeedback. Silkie showcases\nexceptional performance regarding helpfulness, visual faithfulness, and safety\nmetrics. It outperforms its base model by 6.9\\% and 9.5\\% in perception and\ncognition tasks, reduces hallucination issues on MMHal-Bench, and exhibits\nenhanced resilience against red-teaming attacks. Furthermore, our analysis\nunderscores the advantage of AI feedback, particularly in fostering preference\ndiversity to deliver more comprehensive improvements. Our dataset, training\ncode and models are available at https://vlf-silkie.github.io.\n","authors":["Lei Li","Zhihui Xie","Mukai Li","Shunian Chen","Peiyi Wang","Liang Chen","Yazheng Yang","Benyou Wang","Lingpeng Kong","Qi Liu"],"pdf_url":"https://arxiv.org/pdf/2410.09421v2.pdf","comment":"EMNLP 2024 Main Conference camera-ready version (fixed small typos).\n  This article supersedes arXiv:2312.10665"},{"id":"http://arxiv.org/abs/2410.14214v1","updated":"2024-10-18T07:02:57Z","published":"2024-10-18T07:02:57Z","title":"MambaSCI: Efficient Mamba-UNet for Quad-Bayer Patterned Video Snapshot\n  Compressive Imaging","summary":"  Color video snapshot compressive imaging (SCI) employs computational imaging\ntechniques to capture multiple sequential video frames in a single\nBayer-patterned measurement. With the increasing popularity of quad-Bayer\npattern in mainstream smartphone cameras for capturing high-resolution videos,\nmobile photography has become more accessible to a wider audience. However,\nexisting color video SCI reconstruction algorithms are designed based on the\ntraditional Bayer pattern. When applied to videos captured by quad-Bayer\ncameras, these algorithms often result in color distortion and ineffective\ndemosaicing, rendering them impractical for primary equipment. To address this\nchallenge, we propose the MambaSCI method, which leverages the Mamba and UNet\narchitectures for efficient reconstruction of quad-Bayer patterned color video\nSCI. To the best of our knowledge, our work presents the first algorithm for\nquad-Bayer patterned SCI reconstruction, and also the initial application of\nthe Mamba model to this task. Specifically, we customize Residual-Mamba-Blocks,\nwhich residually connect the Spatial-Temporal Mamba (STMamba),\nEdge-Detail-Reconstruction (EDR) module, and Channel Attention (CA) module.\nRespectively, STMamba is used to model long-range spatial-temporal dependencies\nwith linear complexity, EDR is for better edge-detail reconstruction, and CA is\nused to compensate for the missing channel information interaction in Mamba\nmodel. Experiments demonstrate that MambaSCI surpasses state-of-the-art methods\nwith lower computational and memory costs. PyTorch style pseudo-code for the\ncore modules is provided in the supplementary materials.\n","authors":["Zhenghao Pan","Haijin Zeng","Jiezhang Cao","Yongyong Chen","Kai Zhang","Yong Xu"],"pdf_url":"https://arxiv.org/pdf/2410.14214v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.10167v2","updated":"2024-10-18T06:57:51Z","published":"2024-10-14T05:23:12Z","title":"X-Fi: A Modality-Invariant Foundation Model for Multimodal Human Sensing","summary":"  Human sensing, which employs various sensors and advanced deep learning\ntechnologies to accurately capture and interpret human body information, has\nsignificantly impacted fields like public security and robotics. However,\ncurrent human sensing primarily depends on modalities such as cameras and\nLiDAR, each of which has its own strengths and limitations. Furthermore,\nexisting multi-modal fusion solutions are typically designed for fixed modality\ncombinations, requiring extensive retraining when modalities are added or\nremoved for diverse scenarios. In this paper, we propose a modality-invariant\nfoundation model for all modalities, X-Fi, to address this issue. X-Fi enables\nthe independent or combinatory use of sensor modalities without additional\ntraining by utilizing a transformer structure to accommodate variable input\nsizes and incorporating a novel \"X-fusion\" mechanism to preserve\nmodality-specific features during multimodal integration. This approach not\nonly enhances adaptability but also facilitates the learning of complementary\nfeatures across modalities. Extensive experiments conducted on the MM-Fi and\nXRF55 datasets, employing six distinct modalities, demonstrate that X-Fi\nachieves state-of-the-art performance in human pose estimation (HPE) and human\nactivity recognition (HAR) tasks. The findings indicate that our proposed model\ncan efficiently support a wide range of human sensing applications, ultimately\ncontributing to the evolution of scalable, multimodal sensing technologies.\n","authors":["Xinyan Chen","Jianfei Yang"],"pdf_url":"https://arxiv.org/pdf/2410.10167v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14210v1","updated":"2024-10-18T06:52:51Z","published":"2024-10-18T06:52:51Z","title":"Shape Transformation Driven by Active Contour for Class-Imbalanced\n  Semi-Supervised Medical Image Segmentation","summary":"  Annotating 3D medical images demands expert knowledge and is time-consuming.\nAs a result, semi-supervised learning (SSL) approaches have gained significant\ninterest in 3D medical image segmentation. The significant size differences\namong various organs in the human body lead to imbalanced class distribution,\nwhich is a major challenge in the real-world application of these SSL\napproaches. To address this issue, we develop a novel Shape Transformation\ndriven by Active Contour (STAC), that enlarges smaller organs to alleviate\nimbalanced class distribution across different organs. Inspired by curve\nevolution theory in active contour methods, STAC employs a signed distance\nfunction (SDF) as the level set function, to implicitly represent the shape of\norgans, and deforms voxels in the direction of the steepest descent of SDF\n(i.e., the normal vector). To ensure that the voxels far from expansion organs\nremain unchanged, we design an SDF-based weight function to control the degree\nof deformation for each voxel. We then use STAC as a data-augmentation process\nduring the training stage. Experimental results on two benchmark datasets\ndemonstrate that the proposed method significantly outperforms some\nstate-of-the-art methods. Source code is publicly available at\nhttps://github.com/GuGuLL123/STAC.\n","authors":["Yuliang Gu","Yepeng Liu","Zhichao Sun","Jinchi Zhu","Yongchao Xu","Laurent Najman"],"pdf_url":"https://arxiv.org/pdf/2410.14210v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.06719v3","updated":"2024-10-18T06:39:27Z","published":"2024-10-09T09:43:36Z","title":"Suppress Content Shift: Better Diffusion Features via Off-the-Shelf\n  Generation Techniques","summary":"  Diffusion models are powerful generative models, and this capability can also\nbe applied to discrimination. The inner activations of a pre-trained diffusion\nmodel can serve as features for discriminative tasks, namely, diffusion\nfeature. We discover that diffusion feature has been hindered by a hidden yet\nuniversal phenomenon that we call content shift. To be specific, there are\ncontent differences between features and the input image, such as the exact\nshape of a certain object. We locate the cause of content shift as one inherent\ncharacteristic of diffusion models, which suggests the broad existence of this\nphenomenon in diffusion feature. Further empirical study also indicates that\nits negative impact is not negligible even when content shift is not visually\nperceivable. Hence, we propose to suppress content shift to enhance the overall\nquality of diffusion features. Specifically, content shift is related to the\ninformation drift during the process of recovering an image from the noisy\ninput, pointing out the possibility of turning off-the-shelf generation\ntechniques into tools for content shift suppression. We further propose a\npractical guideline named GATE to efficiently evaluate the potential benefit of\na technique and provide an implementation of our methodology. Despite the\nsimplicity, the proposed approach has achieved superior results on various\ntasks and datasets, validating its potential as a generic booster for diffusion\nfeatures. Our code is available at\nhttps://github.com/Darkbblue/diffusion-content-shift.\n","authors":["Benyuan Meng","Qianqian Xu","Zitai Wang","Zhiyong Yang","Xiaochun Cao","Qingming Huang"],"pdf_url":"https://arxiv.org/pdf/2410.06719v3.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2410.03558"},{"id":"http://arxiv.org/abs/2410.14201v1","updated":"2024-10-18T06:31:57Z","published":"2024-10-18T06:31:57Z","title":"Text-to-Image Representativity Fairness Evaluation Framework","summary":"  Text-to-Image generative systems are progressing rapidly to be a source of\nadvertisement and media and could soon serve as image searches or artists.\nHowever, there is a significant concern about the representativity bias these\nmodels embody and how these biases can propagate in the social fabric after\nfine-tuning them. Therefore, continuously monitoring and evaluating these\nmodels for fairness is important. To address this issue, we propose\nText-to-Image (TTI) Representativity Fairness Evaluation Framework. In this\nframework, we evaluate three aspects of a TTI system; diversity, inclusion, and\nquality. For each aspect, human-based and model-based approaches are proposed\nand evaluated for their ability to capture the bias and whether they can\nsubstitute each other. The framework starts by suggesting the prompts for\ngenerating the images for the evaluation based on the context and the sensitive\nattributes under study. Then the three aspects are evaluated using the proposed\napproaches. Based on the evaluation, a decision is made regarding the\nrepresentativity bias within the TTI system. The evaluation of our framework on\nStable Diffusion shows that the framework can effectively capture the bias in\nTTI systems. The results also confirm that our proposed model based-approaches\ncan substitute human-based approaches in three out of four components with high\ncorrelation, which could potentially reduce costs and automate the process. The\nstudy suggests that continual learning of the model on more inclusive data\nacross disadvantaged minorities such as Indians and Middle Easterners is\nessential to mitigate current stereotyping and lack of inclusiveness.\n","authors":["Asma Yamani","Malak Baslyman"],"pdf_url":"https://arxiv.org/pdf/2410.14201v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14200v1","updated":"2024-10-18T06:31:40Z","published":"2024-10-18T06:31:40Z","title":"E3D-GPT: Enhanced 3D Visual Foundation for Medical Vision-Language Model","summary":"  The development of 3D medical vision-language models holds significant\npotential for disease diagnosis and patient treatment. However, compared to 2D\nmedical images, 3D medical images, such as CT scans, face challenges related to\nlimited training data and high dimension, which severely restrict the progress\nof 3D medical vision-language models. To address these issues, we collect a\nlarge amount of unlabeled 3D CT data and utilize self-supervised learning to\nconstruct a 3D visual foundation model for extracting 3D visual features. Then,\nwe apply 3D spatial convolutions to aggregate and project high-level image\nfeatures, reducing computational complexity while preserving spatial\ninformation. We also construct two instruction-tuning datasets based on BIMCV-R\nand CT-RATE to fine-tune the 3D vision-language model. Our model demonstrates\nsuperior performance compared to existing methods in report generation, visual\nquestion answering, and disease diagnosis. Code and data will be made publicly\navailable soon.\n","authors":["Haoran Lai","Zihang Jiang","Qingsong Yao","Rongsheng Wang","Zhiyang He","Xiaodong Tao","Wei Wei","Weifu Lv","S. Kevin Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.14200v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03558v3","updated":"2024-10-18T06:19:45Z","published":"2024-10-04T16:05:14Z","title":"Not All Diffusion Model Activations Have Been Evaluated as\n  Discriminative Features","summary":"  Diffusion models are initially designed for image generation. Recent research\nshows that the internal signals within their backbones, named activations, can\nalso serve as dense features for various discriminative tasks such as semantic\nsegmentation. Given numerous activations, selecting a small yet effective\nsubset poses a fundamental problem. To this end, the early study of this field\nperforms a large-scale quantitative comparison of the discriminative ability of\nthe activations. However, we find that many potential activations have not been\nevaluated, such as the queries and keys used to compute attention scores.\nMoreover, recent advancements in diffusion architectures bring many new\nactivations, such as those within embedded ViT modules. Both combined,\nactivation selection remains unresolved but overlooked. To tackle this issue,\nthis paper takes a further step with a much broader range of activations\nevaluated. Considering the significant increase in activations, a full-scale\nquantitative comparison is no longer operational. Instead, we seek to\nunderstand the properties of these activations, such that the activations that\nare clearly inferior can be filtered out in advance via simple qualitative\nevaluation. After careful analysis, we discover three properties universal\namong diffusion models, enabling this study to go beyond specific models. On\ntop of this, we present effective feature selection solutions for several\npopular diffusion models. Finally, the experiments across multiple\ndiscriminative tasks validate the superiority of our method over the SOTA\ncompetitors. Our code is available at\nhttps://github.com/Darkbblue/generic-diffusion-feature.\n","authors":["Benyuan Meng","Qianqian Xu","Zitai Wang","Xiaochun Cao","Qingming Huang"],"pdf_url":"https://arxiv.org/pdf/2410.03558v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14195v1","updated":"2024-10-18T06:12:36Z","published":"2024-10-18T06:12:36Z","title":"Rethinking Transformer for Long Contextual Histopathology Whole Slide\n  Image Analysis","summary":"  Histopathology Whole Slide Image (WSI) analysis serves as the gold standard\nfor clinical cancer diagnosis in the daily routines of doctors. To develop\ncomputer-aided diagnosis model for WSIs, previous methods typically employ\nMulti-Instance Learning to enable slide-level prediction given only slide-level\nlabels. Among these models, vanilla attention mechanisms without pairwise\ninteractions have traditionally been employed but are unable to model\ncontextual information. More recently, self-attention models have been utilized\nto address this issue. To alleviate the computational complexity of long\nsequences in large WSIs, methods like HIPT use region-slicing, and TransMIL\nemploys approximation of full self-attention. Both approaches suffer from\nsuboptimal performance due to the loss of key information. Moreover, their use\nof absolute positional embedding struggles to effectively handle long\ncontextual dependencies in shape-varying WSIs. In this paper, we first analyze\nhow the low-rank nature of the long-sequence attention matrix constrains the\nrepresentation ability of WSI modelling. Then, we demonstrate that the rank of\nattention matrix can be improved by focusing on local interactions via a local\nattention mask. Our analysis shows that the local mask aligns with the\nattention patterns in the lower layers of the Transformer. Furthermore, the\nlocal attention mask can be implemented during chunked attention calculation,\nreducing the quadratic computational complexity to linear with a small local\nbandwidth. Building on this, we propose a local-global hybrid Transformer for\nboth computational acceleration and local-global information interactions\nmodelling. Our method, Long-contextual MIL (LongMIL), is evaluated through\nextensive experiments on various WSI tasks to validate its superiority. Our\ncode will be available at github.com/invoker-LL/Long-MIL.\n","authors":["Honglin Li","Yunlong Zhang","Pingyi Chen","Zhongyi Shui","Chenglu Zhu","Lin Yang"],"pdf_url":"https://arxiv.org/pdf/2410.14195v1.pdf","comment":"NeurIPS-2024. arXiv admin note: text overlap with arXiv:2311.12885"},{"id":"http://arxiv.org/abs/2410.13195v2","updated":"2024-10-18T06:02:28Z","published":"2024-10-17T03:48:02Z","title":"UniG: Modelling Unitary 3D Gaussians for View-consistent 3D\n  Reconstruction","summary":"  In this work, we present UniG, a view-consistent 3D reconstruction and novel\nview synthesis model that generates a high-fidelity representation of 3D\nGaussians from sparse images. Existing 3D Gaussians-based methods usually\nregress Gaussians per-pixel of each view, create 3D Gaussians per view\nseparately, and merge them through point concatenation. Such a view-independent\nreconstruction approach often results in a view inconsistency issue, where the\npredicted positions of the same 3D point from different views may have\ndiscrepancies. To address this problem, we develop a DETR (DEtection\nTRansformer)-like framework, which treats 3D Gaussians as decoder queries and\nupdates their parameters layer by layer by performing multi-view\ncross-attention (MVDFA) over multiple input images. In this way, multiple views\nnaturally contribute to modeling a unitary representation of 3D Gaussians,\nthereby making 3D reconstruction more view-consistent. Moreover, as the number\nof 3D Gaussians used as decoder queries is irrespective of the number of input\nviews, allow an arbitrary number of input images without causing memory\nexplosion. Extensive experiments validate the advantages of our approach,\nshowcasing superior performance over existing methods quantitatively (improving\nPSNR by 4.2 dB when trained on Objaverse and tested on the GSO benchmark) and\nqualitatively. The code will be released at https://github.com/jwubz123/UNIG.\n","authors":["Jiamin Wu","Kenkun Liu","Yukai Shi","Xiaoke Jiang","Yuan Yao","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.13195v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14189v1","updated":"2024-10-18T05:48:06Z","published":"2024-10-18T05:48:06Z","title":"Neural Signed Distance Function Inference through Splatting 3D Gaussians\n  Pulled on Zero-Level Set","summary":"  It is vital to infer a signed distance function (SDF) in multi-view based\nsurface reconstruction. 3D Gaussian splatting (3DGS) provides a novel\nperspective for volume rendering, and shows advantages in rendering efficiency\nand quality. Although 3DGS provides a promising neural rendering option, it is\nstill hard to infer SDFs for surface reconstruction with 3DGS due to the\ndiscreteness, the sparseness, and the off-surface drift of 3D Gaussians. To\nresolve these issues, we propose a method that seamlessly merge 3DGS with the\nlearning of neural SDFs. Our key idea is to more effectively constrain the SDF\ninference with the multi-view consistency. To this end, we dynamically align 3D\nGaussians on the zero-level set of the neural SDF using neural pulling, and\nthen render the aligned 3D Gaussians through the differentiable rasterization.\nMeanwhile, we update the neural SDF by pulling neighboring space to the pulled\n3D Gaussians, which progressively refine the signed distance field near the\nsurface. With both differentiable pulling and splatting, we jointly optimize 3D\nGaussians and the neural SDF with both RGB and geometry constraints, which\nrecovers more accurate, smooth, and complete surfaces with more geometry\ndetails. Our numerical and visual comparisons show our superiority over the\nstate-of-the-art results on the widely used benchmarks.\n","authors":["Wenyuan Zhang","Yu-Shen Liu","Zhizhong Han"],"pdf_url":"https://arxiv.org/pdf/2410.14189v1.pdf","comment":"Accepted by NeurIPS 2024. Project page:\n  https://wen-yuan-zhang.github.io/GS-Pull/"},{"id":"http://arxiv.org/abs/2406.13123v2","updated":"2024-10-18T05:20:34Z","published":"2024-06-19T00:38:19Z","title":"ViLCo-Bench: VIdeo Language COntinual learning Benchmark","summary":"  Video language continual learning involves continuously adapting to\ninformation from video and text inputs, enhancing a model's ability to handle\nnew tasks while retaining prior knowledge. This field is a relatively\nunder-explored area, and establishing appropriate datasets is crucial for\nfacilitating communication and research in this field. In this study, we\npresent the first dedicated benchmark, ViLCo-Bench, designed to evaluate\ncontinual learning models across a range of video-text tasks. The dataset\ncomprises ten-minute-long videos and corresponding language queries collected\nfrom publicly available datasets. Additionally, we introduce a novel\nmemory-efficient framework that incorporates self-supervised learning and\nmimics long-term and short-term memory effects. This framework addresses\nchallenges including memory complexity from long video clips, natural language\ncomplexity from open queries, and text-video misalignment. We posit that\nViLCo-Bench, with greater complexity compared to existing continual learning\nbenchmarks, would serve as a critical tool for exploring the video-language\ndomain, extending beyond conventional class-incremental tasks, and addressing\ncomplex and limited annotation issues. The curated data, evaluations, and our\nnovel method are available at https://github.com/cruiseresearchgroup/ViLCo.\n","authors":["Tianqi Tang","Shohreh Deldari","Hao Xue","Celso De Melo","Flora D. Salim"],"pdf_url":"https://arxiv.org/pdf/2406.13123v2.pdf","comment":"14 pages, 4 figures, 8 tables, Accepted at NeurIPS Dataset and\n  Benchmark Track 2024"},{"id":"http://arxiv.org/abs/2404.10210v3","updated":"2024-10-18T05:17:29Z","published":"2024-04-16T01:41:22Z","title":"MK-SGN: A Spiking Graph Convolutional Network with Multimodal Fusion and\n  Knowledge Distillation for Skeleton-based Action Recognition","summary":"  In recent years, skeleton-based action recognition, leveraging multimodal\nGraph Convolutional Networks (GCN), has achieved remarkable results. However,\ndue to their deep structure and reliance on continuous floating-point\noperations, GCN-based methods are energy-intensive. We propose an innovative\nSpiking Graph Convolutional Network with Multimodal Fusion and Knowledge\nDistillation (MK-SGN) to address this issue. By merging the energy efficiency\nof Spiking Neural Network (SNN) with the graph representation capability of\nGCN, the proposed MK-SGN reduces energy consumption while maintaining\nrecognition accuracy. Firstly, we convert Graph Convolutional Networks (GCN)\ninto Spiking Graph Convolutional Networks (SGN) establishing a new benchmark\nand paving the way for future research exploration. During this process, we\nintroduce a spiking attention mechanism and design a Spiking-Spatio Graph\nConvolution module with a Spatial Global Spiking Attention mechanism (SA-SGC),\nenhancing feature learning capability. Secondly, we propose a Spiking\nMultimodal Fusion module (SMF), leveraging mutual information to process\nmultimodal data more efficiently. Lastly, we delve into knowledge distillation\nmethods from multimodal GCN to SGN and propose a novel, integrated method that\nsimultaneously focuses on both intermediate layer distillation and soft label\ndistillation to improve the performance of SGN. MK-SGN outperforms the\nstate-of-the-art GCN-like frameworks on three challenging datasets for\nskeleton-based action recognition in reducing energy consumption. It also\noutperforms the state-of-the-art SNN frameworks in accuracy. Specifically, our\nmethod reduces energy consumption by more than 98% compared to typical\nGCN-based methods, while maintaining competitive accuracy on the NTU-RGB+D 60\ncross-subject split using 4-time steps.\n","authors":["Naichuan Zheng","Hailun Xia","Zeyu Liang","Yuanyuan Chai"],"pdf_url":"https://arxiv.org/pdf/2404.10210v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14179v1","updated":"2024-10-18T05:15:50Z","published":"2024-10-18T05:15:50Z","title":"MultiChartQA: Benchmarking Vision-Language Models on Multi-Chart\n  Problems","summary":"  Multimodal Large Language Models (MLLMs) have demonstrated impressive\nabilities across various tasks, including visual question answering and chart\ncomprehension, yet existing benchmarks for chart-related tasks fall short in\ncapturing the complexity of real-world multi-chart scenarios. Current\nbenchmarks primarily focus on single-chart tasks, neglecting the multi-hop\nreasoning required to extract and integrate information from multiple charts,\nwhich is essential in practical applications. To fill this gap, we introduce\nMultiChartQA, a benchmark that evaluates MLLMs' capabilities in four key areas:\ndirect question answering, parallel question answering, comparative reasoning,\nand sequential reasoning. Our evaluation of a wide range of MLLMs reveals\nsignificant performance gaps compared to humans. These results highlight the\nchallenges in multi-chart comprehension and the potential of MultiChartQA to\ndrive advancements in this field. Our code and data are available at\nhttps://github.com/Zivenzhu/Multi-chart-QA\n","authors":["Zifeng Zhu","Mengzhao Jia","Zhihan Zhang","Lang Li","Meng Jiang"],"pdf_url":"https://arxiv.org/pdf/2410.14179v1.pdf","comment":"18 pages, 9 figures"},{"id":"http://arxiv.org/abs/2305.19513v2","updated":"2024-10-18T05:14:57Z","published":"2023-05-31T02:52:38Z","title":"Hard Region Aware Network for Remote Sensing Change Detection","summary":"  Change detection (CD) is essential for various real-world applications, such\nas urban management and disaster assessment. Numerous CD methods have been\nproposed, and considerable results have been achieved recently. However,\ndetecting changes in hard regions, i.e., the change boundary and irrelevant\npseudo changes caused by background clutters, remains difficult for these\nmethods, since they pose equal attention for all regions in bi-temporal images.\nThis paper proposes a novel change detection network, termed as HRANet, which\nprovides accurate change maps via hard region mining. Specifically, an online\nhard region estimation branch is constructed to model the pixel-wise hard\nsamples, supervised by the error between predicted change maps and\ncorresponding ground truth during the training process. A cross-layer knowledge\nreview module is introduced to distill temporal change information from\nlow-level to high-level features, thereby enhancing the feature representation\ncapabilities. Finally, the hard region aware features extracted from the online\nhard region estimation branch and multi-level temporal difference features are\naggregated into a unified feature representation to improve the accuracy of CD.\nExperimental results on two benchmark datasets demonstrate the superior\nperformance of HRANet in the CD task.\n","authors":["Zhenglai Li","Chang Tang","Xinwang Liu","Xingchen Hu","Xianju Li","Ning Li","Changdong Li"],"pdf_url":"https://arxiv.org/pdf/2305.19513v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01701v2","updated":"2024-10-18T05:12:00Z","published":"2024-08-03T07:47:16Z","title":"Signal-SGN: A Spiking Graph Convolutional Network for Skeletal Action\n  Recognition via Learning Temporal-Frequency Dynamics","summary":"  In skeletal-based action recognition, Graph Convolutional Networks (GCNs)\nbased methods face limitations due to their complexity and high energy\nconsumption. Spiking Neural Networks (SNNs) have gained attention in recent\nyears for their low energy consumption, but existing methods combining GCNs and\nSNNs fail to fully utilize the temporal characteristics of skeletal sequences,\nleading to increased storage and computational costs. To address this issue, we\npropose a Signal-SGN(Spiking Graph Convolutional Network), which leverages the\ntemporal dimension of skeletal sequences as the spiking timestep and treats\nfeatures as discrete stochastic signals. The core of the network consists of a\n1D Spiking Graph Convolutional Network (1D-SGN) and a Frequency Spiking\nConvolutional Network (FSN). The SGN performs graph convolution on single\nframes and incorporates spiking network characteristics to capture inter-frame\ntemporal relationships, while the FSN uses Fast Fourier Transform (FFT) and\ncomplex convolution to extract temporal-frequency features. We also introduce a\nmulti-scale wavelet transform feature fusion module(MWTF) to capture spectral\nfeatures of temporal signals, enhancing the model's classification capability.\nWe propose a pluggable temporal-frequency spatial semantic feature extraction\nmodule(TFSM) to enhance the model's ability to distinguish features without\nincreasing inference-phase consumption. Our numerous experiments on the NTU\nRGB+D, NTU RGB+D 120, and NW-UCLA datasets demonstrate that the proposed models\nnot only surpass existing SNN-based methods in accuracy but also reduce\ncomputational and storage costs during training. Furthermore, they achieve\ncompetitive accuracy compared to corresponding GCN-based methods, which is\nquite remarkable.\n","authors":["Naichuan Zheng","Hailun Xia","Dapeng Liu"],"pdf_url":"https://arxiv.org/pdf/2408.01701v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14178v1","updated":"2024-10-18T05:11:07Z","published":"2024-10-18T05:11:07Z","title":"Feature Augmentation based Test-Time Adaptation","summary":"  Test-time adaptation (TTA) allows a model to be adapted to an unseen domain\nwithout accessing the source data. Due to the nature of practical environments,\nTTA has a limited amount of data for adaptation. Recent TTA methods further\nrestrict this by filtering input data for reliability, making the effective\ndata size even smaller and limiting adaptation potential. To address this\nissue, We propose Feature Augmentation based Test-time Adaptation (FATA), a\nsimple method that fully utilizes the limited amount of input data through\nfeature augmentation. FATA employs Normalization Perturbation to augment\nfeatures and adapts the model using the FATA loss, which makes the outputs of\nthe augmented and original features similar. FATA is model-agnostic and can be\nseamlessly integrated into existing models without altering the model\narchitecture. We demonstrate the effectiveness of FATA on various models and\nscenarios on ImageNet-C and Office-Home, validating its superiority in diverse\nreal-world conditions.\n","authors":["Younggeol Cho","Youngrae Kim","Junho Yoon","Seunghoon Hong","Dongman Lee"],"pdf_url":"https://arxiv.org/pdf/2410.14178v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2410.14177v1","updated":"2024-10-18T05:09:07Z","published":"2024-10-18T05:09:07Z","title":"Learning autonomous driving from aerial imagery","summary":"  In this work, we consider the problem of learning end to end perception to\ncontrol for ground vehicles solely from aerial imagery. Photogrammetric\nsimulators allow the synthesis of novel views through the transformation of\npre-generated assets into novel views.However, they have a large setup cost,\nrequire careful collection of data and often human effort to create usable\nsimulators. We use a Neural Radiance Field (NeRF) as an intermediate\nrepresentation to synthesize novel views from the point of view of a ground\nvehicle. These novel viewpoints can then be used for several downstream\nautonomous navigation applications. In this work, we demonstrate the utility of\nnovel view synthesis though the application of training a policy for end to end\nlearning from images and depth data. In a traditional real to sim to real\nframework, the collected data would be transformed into a visual simulator\nwhich could then be used to generate novel views. In contrast, using a NeRF\nallows a compact representation and the ability to optimize over the parameters\nof the visual simulator as more data is gathered in the environment. We\ndemonstrate the efficacy of our method in a custom built mini-city environment\nthrough the deployment of imitation policies on robotic cars. We additionally\nconsider the task of place localization and demonstrate that our method is able\nto relocalize the car in the real world.\n","authors":["Varun Murali","Guy Rosman","Sertac Karaman","Daniela Rus"],"pdf_url":"https://arxiv.org/pdf/2410.14177v1.pdf","comment":"Presented at IROS 2024"},{"id":"http://arxiv.org/abs/2402.13876v3","updated":"2024-10-18T05:04:40Z","published":"2024-02-21T15:35:59Z","title":"Scene Prior Filtering for Depth Super-Resolution","summary":"  Multi-modal fusion is vital to the success of super-resolution of depth maps.\nHowever, commonly used fusion strategies, such as addition and concatenation,\nfall short of effectively bridging the modal gap. As a result, guided image\nfiltering methods have been introduced to mitigate this issue. Nevertheless, it\nis observed that their filter kernels usually encounter significant texture\ninterference and edge inaccuracy. To tackle these two challenges, we introduce\na Scene Prior Filtering network, SPFNet, which utilizes the priors surface\nnormal and semantic map from large-scale models. Specifically, we design an\nAll-in-one Prior Propagation that computes the similarity between multi-modal\nscene priors, i.e., RGB, normal, semantic, and depth, to reduce the texture\ninterference. In addition, we present a One-to-one Prior Embedding that\ncontinuously embeds each single-modal prior into depth using Mutual Guided\nFiltering, further alleviating the texture interference while enhancing edges.\nOur SPFNet has been extensively evaluated on both real and synthetic datasets,\nachieving state-of-the-art performance.\n","authors":["Zhengxue Wang","Zhiqiang Yan","Ming-Hsuan Yang","Jinshan Pan","Guangwei Gao","Ying Tai","Jian Yang"],"pdf_url":"https://arxiv.org/pdf/2402.13876v3.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2406.14862v4","updated":"2024-10-18T04:39:35Z","published":"2024-06-21T04:39:03Z","title":"LatentExplainer: Explaining Latent Representations in Deep Generative\n  Models with Multi-modal Foundation Models","summary":"  Deep generative models like VAEs and diffusion models have advanced various\ngeneration tasks by leveraging latent variables to learn data distributions and\ngenerate high-quality samples. Despite the field of explainable AI making\nstrides in interpreting machine learning models, understanding latent variables\nin generative models remains challenging. This paper introduces\n\\textit{LatentExplainer}, a framework for automatically generating semantically\nmeaningful explanations of latent variables in deep generative models.\n\\textit{LatentExplainer} tackles three main challenges: inferring the meaning\nof latent variables, aligning explanations with inductive biases, and handling\nvarying degrees of explainability. Our approach perturbs latent variables,\ninterpreting changes in generated data, and uses multi-modal large language\nmodels (MLLMs) to produce human-understandable explanations. We evaluate our\nproposed method on several real-world and synthetic datasets, and the results\ndemonstrate superior performance in generating high-quality explanations for\nlatent variables. The results highlight the effectiveness of incorporating\ninductive biases and uncertainty quantification, significantly enhancing model\ninterpretability.\n","authors":["Mengdan Zhu","Raasikh Kanjiani","Jiahui Lu","Andrew Choi","Qirui Ye","Liang Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.14862v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00902v2","updated":"2024-10-18T04:37:33Z","published":"2024-07-01T01:57:21Z","title":"From Introspection to Best Practices: Principled Analysis of\n  Demonstrations in Multimodal In-Context Learning","summary":"  Motivated by in-context learning (ICL) capabilities of Large Language models\n(LLMs), multimodal LLMs with additional visual modality are also exhibited with\nsimilar ICL abilities when multiple image-text pairs are provided as\ndemonstrations. However, relatively less work has been done to investigate the\nprinciples behind how and why multimodal ICL works. We conduct a systematic and\nprincipled evaluation of multimodal ICL for models of different scales on a\nbroad spectrum of new yet critical tasks. Through perturbations over different\nmodality information, we show that modalities matter differently across tasks\nin multimodal ICL. Guided by task-specific modality impact, we recommend\nmodality-driven demonstration strategies to boost ICL performance. We also find\nthat models may follow inductive biases from multimodal ICL even if they are\nrarely seen in or contradict semantic priors from pretraining data. Our\nprincipled analysis provides a comprehensive way of understanding the role of\ndemonstrations in multimodal in-context learning, and sheds light on\neffectively improving multimodal ICL on a wide range of tasks.\n","authors":["Nan Xu","Fei Wang","Sheng Zhang","Hoifung Poon","Muhao Chen"],"pdf_url":"https://arxiv.org/pdf/2407.00902v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12324v2","updated":"2024-10-18T04:32:34Z","published":"2024-10-16T07:44:56Z","title":"PAPL-SLAM: Principal Axis-Anchored Monocular Point-Line SLAM","summary":"  In point-line SLAM systems, the utilization of line structural information\nand the optimization of lines are two significant problems. The former is\nusually addressed through structural regularities, while the latter typically\ninvolves using minimal parameter representations of lines in optimization.\nHowever, separating these two steps leads to the loss of constraint information\nto each other. We anchor lines with similar directions to a principal axis and\noptimize them with $n+2$ parameters for $n$ lines, solving both problems\ntogether. Our method considers scene structural information, which can be\neasily extended to different world hypotheses while significantly reducing the\nnumber of line parameters to be optimized, enabling rapid and accurate mapping\nand tracking. To further enhance the system's robustness and avoid mismatch, we\nhave modeled the line-axis probabilistic data association and provided the\nalgorithm for axis creation, updating, and optimization. Additionally,\nconsidering that most real-world scenes conform to the Atlanta World\nhypothesis, we provide a structural line detection strategy based on vertical\npriors and vanishing points. Experimental results and ablation studies on\nvarious indoor and outdoor datasets demonstrate the effectiveness of our\nsystem.\n","authors":["Guanghao Li","Yu Cao","Qi Chen","Yifan Yang","Jian Pu"],"pdf_url":"https://arxiv.org/pdf/2410.12324v2.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.04733v2","updated":"2024-10-18T04:28:28Z","published":"2024-10-07T03:52:06Z","title":"PredFormer: Transformers Are Effective Spatial-Temporal Predictive\n  Learners","summary":"  Spatiotemporal predictive learning methods generally fall into two\ncategories: recurrent-based approaches, which face challenges in\nparallelization and performance, and recurrent-free methods, which employ\nconvolutional neural networks (CNNs) as encoder-decoder architectures. These\nmethods benefit from strong inductive biases but often at the expense of\nscalability and generalization. This paper proposes PredFormer, a pure\ntransformer-based framework for spatiotemporal predictive learning. Motivated\nby the Vision Transformers (ViT) design, PredFormer leverages carefully\ndesigned Gated Transformer blocks, following a comprehensive analysis of 3D\nattention mechanisms, including full-, factorized-, and\ninterleaved-spatial-temporal attention. With its recurrent-free,\ntransformer-based design, PredFormer is both simple and efficient,\nsignificantly outperforming previous methods by large margins. Extensive\nexperiments on synthetic and real-world datasets demonstrate that PredFormer\nachieves state-of-the-art performance. On Moving MNIST, PredFormer achieves a\n51.3% reduction in MSE relative to SimVP. For TaxiBJ, the model decreases MSE\nby 33.1% and boosts FPS from 533 to 2364. Additionally, on WeatherBench, it\nreduces MSE by 11.1% while enhancing FPS from 196 to 404. These performance\ngains in both accuracy and efficiency demonstrate PredFormer's potential for\nreal-world applications. The source code will be released at\nhttps://github.com/yyyujintang/PredFormer .\n","authors":["Yujin Tang","Lu Qi","Fei Xie","Xiangtai Li","Chao Ma","Ming-Hsuan Yang"],"pdf_url":"https://arxiv.org/pdf/2410.04733v2.pdf","comment":"15 pages, 7 figures"},{"id":"http://arxiv.org/abs/2407.04127v2","updated":"2024-10-18T04:23:00Z","published":"2024-07-04T19:00:34Z","title":"Biometric Authentication Based on Enhanced Remote Photoplethysmography\n  Signal Morphology","summary":"  Remote photoplethysmography (rPPG) is a non-contact method for measuring\ncardiac signals from facial videos, offering a convenient alternative to\ncontact photoplethysmography (cPPG) obtained from contact sensors. Recent\nstudies have shown that each individual possesses a unique cPPG signal\nmorphology that can be utilized as a biometric identifier, which has inspired\nus to utilize the morphology of rPPG signals extracted from facial videos for\nperson authentication. Since the facial appearance and rPPG are mixed in the\nfacial videos, we first de-identify facial videos to remove facial appearance\nwhile preserving the rPPG information, which protects facial privacy and\nguarantees that only rPPG is used for authentication. The de-identified videos\nare fed into an rPPG model to get the rPPG signal morphology for\nauthentication. In the first training stage, unsupervised rPPG training is\nperformed to get coarse rPPG signals. In the second training stage, an\nrPPG-cPPG hybrid training is performed by incorporating external cPPG datasets\nto achieve rPPG biometric authentication and enhance rPPG signal morphology.\nOur approach needs only de-identified facial videos with subject IDs to train\nrPPG authentication models. The experimental results demonstrate that rPPG\nsignal morphology hidden in facial videos can be used for biometric\nauthentication. The code is available at\nhttps://github.com/zhaodongsun/rppg_biometrics.\n","authors":["Zhaodong Sun","Xiaobai Li","Jukka Komulainen","Guoying Zhao"],"pdf_url":"https://arxiv.org/pdf/2407.04127v2.pdf","comment":"accepted by IJCB 2024, Best Paper Runner-Up Award"},{"id":"http://arxiv.org/abs/2410.14169v1","updated":"2024-10-18T04:19:10Z","published":"2024-10-18T04:19:10Z","title":"DaRePlane: Direction-aware Representations for Dynamic Scene\n  Reconstruction","summary":"  Numerous recent approaches to modeling and re-rendering dynamic scenes\nleverage plane-based explicit representations, addressing slow training times\nassociated with models like neural radiance fields (NeRF) and Gaussian\nsplatting (GS). However, merely decomposing 4D dynamic scenes into multiple 2D\nplane-based representations is insufficient for high-fidelity re-rendering of\nscenes with complex motions. In response, we present DaRePlane, a novel\ndirection-aware representation approach that captures scene dynamics from six\ndifferent directions. This learned representation undergoes an inverse\ndual-tree complex wavelet transformation (DTCWT) to recover plane-based\ninformation. Within NeRF pipelines, DaRePlane computes features for each\nspace-time point by fusing vectors from these recovered planes, then passed to\na tiny MLP for color regression. When applied to Gaussian splatting, DaRePlane\ncomputes the features of Gaussian points, followed by a tiny multi-head MLP for\nspatial-time deformation prediction. Notably, to address redundancy introduced\nby the six real and six imaginary direction-aware wavelet coefficients, we\nintroduce a trainable masking approach, mitigating storage issues without\nsignificant performance decline. To demonstrate the generality and efficiency\nof DaRePlane, we test it on both regular and surgical dynamic scenes, for both\nNeRF and GS systems. Extensive experiments show that DaRePlane yields\nstate-of-the-art performance in novel view synthesis for various complex\ndynamic scenes.\n","authors":["Ange Lou","Benjamin Planche","Zhongpai Gao","Yamin Li","Tianyu Luan","Hao Ding","Meng Zheng","Terrence Chen","Ziyan Wu","Jack Noble"],"pdf_url":"https://arxiv.org/pdf/2410.14169v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2403.02265"},{"id":"http://arxiv.org/abs/2410.13726v2","updated":"2024-10-18T04:19:02Z","published":"2024-10-17T16:32:36Z","title":"DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework\n  for Talking Head Video Generation","summary":"  Talking head generation intends to produce vivid and realistic talking head\nvideos from a single portrait and speech audio clip. Although significant\nprogress has been made in diffusion-based talking head generation, almost all\nmethods rely on autoregressive strategies, which suffer from limited context\nutilization beyond the current generation step, error accumulation, and slower\ngeneration speed. To address these challenges, we present DAWN (Dynamic frame\nAvatar With Non-autoregressive diffusion), a framework that enables all-at-once\ngeneration of dynamic-length video sequences. Specifically, it consists of two\nmain components: (1) audio-driven holistic facial dynamics generation in the\nlatent motion space, and (2) audio-driven head pose and blink generation.\nExtensive experiments demonstrate that our method generates authentic and vivid\nvideos with precise lip motions, and natural pose/blink movements.\nAdditionally, with a high generation speed, DAWN possesses strong extrapolation\ncapabilities, ensuring the stable production of high-quality long videos. These\nresults highlight the considerable promise and potential impact of DAWN in the\nfield of talking head video generation. Furthermore, we hope that DAWN sparks\nfurther exploration of non-autoregressive approaches in diffusion models. Our\ncode will be publicly available at https://github.com/Hanbo-Cheng/DAWN-pytorch.\n","authors":["Hanbo Cheng","Limin Lin","Chenyu Liu","Pengcheng Xia","Pengfei Hu","Jiefeng Ma","Jun Du","Jia Pan"],"pdf_url":"https://arxiv.org/pdf/2410.13726v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14164v1","updated":"2024-10-18T04:04:58Z","published":"2024-10-18T04:04:58Z","title":"Optimal DLT-based Solutions for the Perspective-n-Point","summary":"  We propose a modified normalized direct linear transform (DLT) algorithm for\nsolving the perspective-n-point (PnP) problem with much better behavior than\nthe conventional DLT. The modification consists of analytically weighting the\ndifferent measurements in the linear system with a negligible increase in\ncomputational load. Our approach exhibits clear improvements -- in both\nperformance and runtime -- when compared to popular methods such as EPnP, CPnP,\nRPnP, and OPnP. Our new non-iterative solution approaches that of the true\noptimal found via Gauss-Newton optimization, but at a fraction of the\ncomputational cost. Our optimal DLT (oDLT) implementation, as well as the\nexperiments, are released in open source.\n","authors":["Sébastien Henry","John A. Christian"],"pdf_url":"https://arxiv.org/pdf/2410.14164v1.pdf","comment":"8 pages, 6 figures, 2 tables"},{"id":"http://arxiv.org/abs/2410.14161v1","updated":"2024-10-18T04:00:26Z","published":"2024-10-18T04:00:26Z","title":"Unlabeled Action Quality Assessment Based on Multi-dimensional Adaptive\n  Constrained Dynamic Time Warping","summary":"  The growing popularity of online sports and exercise necessitates effective\nmethods for evaluating the quality of online exercise executions. Previous\naction quality assessment methods, which relied on labeled scores from motion\nvideos, exhibited slightly lower accuracy and discriminability. This limitation\nhindered their rapid application to newly added exercises. To address this\nproblem, this paper presents an unlabeled Multi-Dimensional Exercise Distance\nAdaptive Constrained Dynamic Time Warping (MED-ACDTW) method for action quality\nassessment. Our approach uses an athletic version of DTW to compare features\nfrom template and test videos, eliminating the need for score labels during\ntraining. The result shows that utilizing both 2D and 3D spatial dimensions,\nalong with multiple human body features, improves the accuracy by 2-3% compared\nto using either 2D or 3D pose estimation alone. Additionally, employing MED for\nscore calculation enhances the precision of frame distance matching, which\nsignificantly boosts overall discriminability. The adaptive constraint scheme\nenhances the discriminability of action quality assessment by approximately\n30%. Furthermore, to address the absence of a standardized perspective in\nsports class evaluations, we introduce a new dataset called BGym.\n","authors":["Renguang Chen","Guolong Zheng","Xu Yang","Zhide Chen","Jiwu Shu","Wencheng Yang","Kexin Zhu","Chen Feng"],"pdf_url":"https://arxiv.org/pdf/2410.14161v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14159v1","updated":"2024-10-18T03:58:29Z","published":"2024-10-18T03:58:29Z","title":"Assessing Open-world Forgetting in Generative Image Model Customization","summary":"  Recent advances in diffusion models have significantly enhanced image\ngeneration capabilities. However, customizing these models with new classes\noften leads to unintended consequences that compromise their reliability. We\nintroduce the concept of open-world forgetting to emphasize the vast scope of\nthese unintended alterations, contrasting it with the well-studied closed-world\nforgetting, which is measurable by evaluating performance on a limited set of\nclasses or skills. Our research presents the first comprehensive investigation\ninto open-world forgetting in diffusion models, focusing on semantic and\nappearance drift of representations. We utilize zero-shot classification to\nanalyze semantic drift, revealing that even minor model adaptations lead to\nunpredictable shifts affecting areas far beyond newly introduced concepts, with\ndramatic drops in zero-shot classification of up to 60%. Additionally, we\nobserve significant changes in texture and color of generated content when\nanalyzing appearance drift. To address these issues, we propose a mitigation\nstrategy based on functional regularization, designed to preserve original\ncapabilities while accommodating new concepts. Our study aims to raise\nawareness of unintended changes due to model customization and advocates for\nthe analysis of open-world forgetting in future research on model customization\nand finetuning methods. Furthermore, we provide insights for developing more\nrobust adaptation methodologies.\n","authors":["Héctor Laria","Alex Gomez-Villa","Imad Eddine Marouf","Kai Wang","Bogdan Raducanu","Joost van de Weijer"],"pdf_url":"https://arxiv.org/pdf/2410.14159v1.pdf","comment":"Project page: https://hecoding.github.io/open-world-forgetting/"},{"id":"http://arxiv.org/abs/2410.14148v1","updated":"2024-10-18T03:34:32Z","published":"2024-10-18T03:34:32Z","title":"Fine-Grained Verifiers: Preference Modeling as Next-token Prediction in\n  Vision-Language Alignment","summary":"  The recent advancements in large language models (LLMs) and pre-trained\nvision models have accelerated the development of vision-language large models\n(VLLMs), enhancing the interaction between visual and linguistic modalities.\nDespite their notable success across various domains, VLLMs face challenges in\nmodality alignment, which can lead to issues like hallucinations and unsafe\ncontent generation. Current alignment techniques often rely on coarse feedback\nand external datasets, limiting scalability and performance. In this paper, we\npropose FiSAO (Fine-Grained Self-Alignment Optimization), a novel\nself-alignment method that utilizes the model's own visual encoder as a\nfine-grained verifier to improve vision-language alignment without the need for\nadditional data. By leveraging token-level feedback from the vision encoder,\nFiSAO significantly improves vision-language alignment, even surpassing\ntraditional preference tuning methods that require additional data. Through\nboth theoretical analysis and experimental validation, we demonstrate that\nFiSAO effectively addresses the misalignment problem in VLLMs, marking the\nfirst instance of token-level rewards being applied to such models.\n","authors":["Chenhang Cui","An Zhang","Yiyang Zhou","Zhaorun Chen","Gelei Deng","Huaxiu Yao","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2410.14148v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2410.14143v1","updated":"2024-10-18T03:31:00Z","published":"2024-10-18T03:31:00Z","title":"Preview-based Category Contrastive Learning for Knowledge Distillation","summary":"  Knowledge distillation is a mainstream algorithm in model compression by\ntransferring knowledge from the larger model (teacher) to the smaller model\n(student) to improve the performance of student. Despite many efforts, existing\nmethods mainly investigate the consistency between instance-level feature\nrepresentation or prediction, which neglects the category-level information and\nthe difficulty of each sample, leading to undesirable performance. To address\nthese issues, we propose a novel preview-based category contrastive learning\nmethod for knowledge distillation (PCKD). It first distills the structural\nknowledge of both instance-level feature correspondence and the relation\nbetween instance features and category centers in a contrastive learning\nfashion, which can explicitly optimize the category representation and explore\nthe distinct correlation between representations of instances and categories,\ncontributing to discriminative category centers and better classification\nresults. Besides, we introduce a novel preview strategy to dynamically\ndetermine how much the student should learn from each sample according to their\ndifficulty. Different from existing methods that treat all samples equally and\ncurriculum learning that simply filters out hard samples, our method assigns a\nsmall weight for hard instances as a preview to better guide the student\ntraining. Extensive experiments on several challenging datasets, including\nCIFAR-100 and ImageNet, demonstrate the superiority over state-of-the-art\nmethods.\n","authors":["Muhe Ding","Jianlong Wu","Xue Dong","Xiaojie Li","Pengda Qin","Tian Gan","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2410.14143v1.pdf","comment":"14 pages, 8 figures, Journal"},{"id":"http://arxiv.org/abs/2410.13674v2","updated":"2024-10-18T03:28:38Z","published":"2024-10-17T15:33:35Z","title":"Diffusion Curriculum: Synthetic-to-Real Generative Curriculum Learning\n  via Image-Guided Diffusion","summary":"  Low-quality or scarce data has posed significant challenges for training deep\nneural networks in practice. While classical data augmentation cannot\ncontribute very different new data, diffusion models opens up a new door to\nbuild self-evolving AI by generating high-quality and diverse synthetic data\nthrough text-guided prompts. However, text-only guidance cannot control\nsynthetic images' proximity to the original images, resulting in\nout-of-distribution data detrimental to the model performance. To overcome the\nlimitation, we study image guidance to achieve a spectrum of interpolations\nbetween synthetic and real images. With stronger image guidance, the generated\nimages are similar to the training data but hard to learn. While with weaker\nimage guidance, the synthetic images will be easier for model but contribute to\na larger distribution gap with the original data. The generated full spectrum\nof data enables us to build a novel \"Diffusion Curriculum (DisCL)\". DisCL\nadjusts the image guidance level of image synthesis for each training stage: It\nidentifies and focuses on hard samples for the model and assesses the most\neffective guidance level of synthetic images to improve hard data learning. We\napply DisCL to two challenging tasks: long-tail (LT) classification and\nlearning from low-quality data. It focuses on lower-guidance images of\nhigh-quality to learn prototypical features as a warm-up of learning\nhigher-guidance images that might be weak on diversity or quality. Extensive\nexperiments showcase a gain of 2.7% and 2.1% in OOD and ID macro-accuracy when\napplying DisCL to iWildCam dataset. On ImageNet-LT, DisCL improves the base\nmodel's tail-class accuracy from 4.4% to 23.64% and leads to a 4.02%\nimprovement in all-class accuracy.\n","authors":["Yijun Liang","Shweta Bhardwaj","Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.13674v2.pdf","comment":"23 pages, including references and appendix. Code is available at\n  http://github.com/tianyi-lab/DisCL"},{"id":"http://arxiv.org/abs/2410.02052v3","updated":"2024-10-18T03:27:37Z","published":"2024-10-02T21:42:35Z","title":"ExACT: Teaching AI Agents to Explore with Reflective-MCTS and\n  Exploratory Learning","summary":"  Autonomous agents have demonstrated significant potential in automating\ncomplex multistep decision-making tasks. However, even state-of-the-art\nvision-language models (VLMs), such as GPT-4o, still fall short of human-level\nperformance, particularly in intricate web environments and long-horizon tasks.\nTo address these limitations, we present ExACT, an approach to combine\ntest-time search and self-learning to build o1-like models for agentic\napplications. We first introduce Reflective Monte Carlo Tree Search (R-MCTS), a\nnovel test time algorithm designed to enhance AI agents' ability to explore\ndecision space on the fly. R-MCTS extends traditional MCTS by 1) incorporating\ncontrastive reflection, allowing agents to learn from past interactions and\ndynamically improve their search efficiency; and 2) using multi-agent debate\nfor reliable state evaluation. Next, we introduce Exploratory Learning, a novel\nlearning strategy to teach agents to search at inference time without relying\non any external search algorithms. On the challenging VisualWebArena benchmark,\nour GPT-4o based R-MCTS agent achieves a 6% to 30% relative improvement across\nvarious tasks compared to the previous state-of-the-art. Additionally, we show\nthat the knowledge and experience gained from test-time search can be\neffectively transferred back to GPT-4o via fine-tuning. After Exploratory\nLearning, GPT-4o 1) demonstrates the ability to explore the environment,\nevaluate a state, and backtrack to viable ones when it detects that the current\nstate cannot lead to success, and 2) matches 87% of R-MCTS's performance while\nusing significantly less compute. Notably, our work demonstrates the compute\nscaling properties in both training - data collection with R-MCTS - and testing\ntime. These results suggest a promising research direction to enhance VLMs'\ncapabilities for agentic applications via test-time search and self-learning.\n","authors":["Xiao Yu","Baolin Peng","Vineeth Vajipey","Hao Cheng","Michel Galley","Jianfeng Gao","Zhou Yu"],"pdf_url":"https://arxiv.org/pdf/2410.02052v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14138v1","updated":"2024-10-18T03:22:06Z","published":"2024-10-18T03:22:06Z","title":"ProReason: Multi-Modal Proactive Reasoning with Decoupled Eyesight and\n  Wisdom","summary":"  Large vision-language models (LVLMs) have witnessed significant progress on\nvisual understanding tasks. However, they often prioritize language knowledge\nover image information on visual reasoning tasks, incurring performance\ndegradation. To tackle this issue, we first identify the drawbacks of existing\nsolutions (i.e., insufficient and irrelevant visual descriptions, and limited\nmulti-modal capacities). We then decompose visual reasoning process into two\nstages: visual perception (i.e., eyesight) and textual reasoning (i.e.,\nwisdom), and introduce a novel visual reasoning framework named ProReason. This\nframework features multi-run proactive perception and decoupled\nvision-reasoning capabilities. Briefly, given a multi-modal question, ProReason\niterates proactive information collection and reasoning until the answer can be\nconcluded with necessary and sufficient visual descriptions. Notably, the\ndisassociation of capabilities allows seamless integration of existing large\nlanguage models (LLMs) to compensate for the reasoning deficits of LVLMs. Our\nextensive experiments demonstrate that ProReason outperforms both existing\nmulti-step reasoning frameworks and passive peer methods on a wide range of\nbenchmarks for both open-source and closed-source models. In addition, with the\nassistance of LLMs, ProReason achieves a performance improvement of up to 15%\non MMMU benchmark. Our insights into existing solutions and the decoupled\nperspective for feasible integration of LLMs illuminate future research on\nvisual reasoning techniques, especially LLM-assisted ones.\n","authors":["Jingqi Zhou","Sheng Wang","Jingwei Dong","Lei Li","Jiahui Gao","Lingpeng Kong","Chuan Wu"],"pdf_url":"https://arxiv.org/pdf/2410.14138v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14132v1","updated":"2024-10-18T03:00:03Z","published":"2024-10-18T03:00:03Z","title":"ViConsFormer: Constituting Meaningful Phrases of Scene Texts using\n  Transformer-based Method in Vietnamese Text-based Visual Question Answering","summary":"  Text-based VQA is a challenging task that requires machines to use scene\ntexts in given images to yield the most appropriate answer for the given\nquestion. The main challenge of text-based VQA is exploiting the meaning and\ninformation from scene texts. Recent studies tackled this challenge by\nconsidering the spatial information of scene texts in images via embedding 2D\ncoordinates of their bounding boxes. In this study, we follow the definition of\nmeaning from linguistics to introduce a novel method that effectively exploits\nthe information from scene texts written in Vietnamese. Experimental results\nshow that our proposed method obtains state-of-the-art results on two\nlarge-scale Vietnamese Text-based VQA datasets. The implementation can be found\nat this link.\n","authors":["Nghia Hieu Nguyen","Tho Thanh Quan","Ngan Luu-Thuy Nguyen"],"pdf_url":"https://arxiv.org/pdf/2410.14132v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14131v1","updated":"2024-10-18T02:57:14Z","published":"2024-10-18T02:57:14Z","title":"Deep Learning Applications in Medical Image Analysis: Advancements,\n  Challenges, and Future Directions","summary":"  Medical image analysis has emerged as an essential element of contemporary\nhealthcare, facilitating physicians in achieving expedited and precise\ndiagnosis. Recent breakthroughs in deep learning, a subset of artificial\nintelligence, have markedly revolutionized the analysis of medical pictures,\nimproving the accuracy and efficiency of clinical procedures. Deep learning\nalgorithms, especially convolutional neural networks (CNNs), have demonstrated\nremarkable proficiency in autonomously learning features from multidimensional\nmedical pictures, including MRI, CT, and X-ray scans, without the necessity for\nmanual feature extraction. These models have been utilized across multiple\nmedical disciplines, including pathology, radiology, ophthalmology, and\ncardiology, where they aid in illness detection, classification, and\nsegmentation tasks......\n","authors":["Aimina Ali Eli","Abida Ali"],"pdf_url":"https://arxiv.org/pdf/2410.14131v1.pdf","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2410.14676v1","updated":"2024-10-18T17:59:51Z","published":"2024-10-18T17:59:51Z","title":"SudoLM: Learning Access Control of Parametric Knowledge with\n  Authorization Alignment","summary":"  Existing preference alignment is a one-size-fits-all alignment mechanism,\nwhere the part of the large language model (LLM) parametric knowledge with\nnon-preferred features is uniformly blocked to all the users. However, this\npart of knowledge can be useful to advanced users whose expertise qualifies\nthem to handle these information. The one-size-fits-all alignment mechanism\nundermines LLM's utility for these qualified users. To address this problem, we\npropose SudoLM, a framework that lets LLMs learn access control over specific\nparametric knowledge for users with different credentials via authorization\nalignment. SudoLM allows authorized users to unlock their access to all the\nparametric knowledge with an assigned SUDO key while blocking access to\nnon-qualified users. Experiments on two application scenarios demonstrate that\nSudoLM effectively controls the user's access to the parametric knowledge and\nmaintains its general utility.\n","authors":["Qin Liu","Fei Wang","Chaowei Xiao","Muhao Chen"],"pdf_url":"https://arxiv.org/pdf/2410.14676v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14675v1","updated":"2024-10-18T17:59:47Z","published":"2024-10-18T17:59:47Z","title":"Enhancing Large Language Models' Situated Faithfulness to External\n  Contexts","summary":"  Large Language Models (LLMs) are often augmented with external information as\ncontexts, but this external information can sometimes be inaccurate or even\nintentionally misleading. We argue that robust LLMs should demonstrate situated\nfaithfulness, dynamically calibrating their trust in external information based\non their confidence in the internal knowledge and the external context. To\nbenchmark this capability, we evaluate LLMs across several QA datasets,\nincluding a newly created dataset called RedditQA featuring in-the-wild\nincorrect contexts sourced from Reddit posts. We show that when provided with\nboth correct and incorrect contexts, both open-source and proprietary models\ntend to overly rely on external information, regardless of its factual\naccuracy. To enhance situated faithfulness, we propose two approaches:\nSelf-Guided Confidence Reasoning (SCR) and Rule-Based Confidence Reasoning\n(RCR). SCR enables models to self-access the confidence of external information\nrelative to their own internal knowledge to produce the most accurate answer.\nRCR, in contrast, extracts explicit confidence signals from the LLM and\ndetermines the final answer using predefined rules. Our results show that for\nLLMs with strong reasoning capabilities, such as GPT-4o and GPT-4o mini, SCR\noutperforms RCR, achieving improvements of up to 24.2% over a direct input\naugmentation baseline. Conversely, for a smaller model like Llama-3-8B, RCR\noutperforms SCR. Fine-tuning SCR with our proposed Confidence Reasoning Direct\nPreference Optimization (CR-DPO) method improves performance on both seen and\nunseen datasets, yielding an average improvement of 8.9% on Llama-3-8B. In\naddition to quantitative results, we offer insights into the relative strengths\nof SCR and RCR. Our findings highlight promising avenues for improving situated\nfaithfulness in LLMs. The data and code are released.\n","authors":["Yukun Huang","Sanxing Chen","Hongyi Cai","Bhuwan Dhingra"],"pdf_url":"https://arxiv.org/pdf/2410.14675v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14672v1","updated":"2024-10-18T17:59:04Z","published":"2024-10-18T17:59:04Z","title":"BiGR: Harnessing Binary Latent Codes for Image Generation and Improved\n  Visual Representation Capabilities","summary":"  We introduce BiGR, a novel conditional image generation model using compact\nbinary latent codes for generative training, focusing on enhancing both\ngeneration and representation capabilities. BiGR is the first conditional\ngenerative model that unifies generation and discrimination within the same\nframework. BiGR features a binary tokenizer, a masked modeling mechanism, and a\nbinary transcoder for binary code prediction. Additionally, we introduce a\nnovel entropy-ordered sampling method to enable efficient image generation.\nExtensive experiments validate BiGR's superior performance in generation\nquality, as measured by FID-50k, and representation capabilities, as evidenced\nby linear-probe accuracy. Moreover, BiGR showcases zero-shot generalization\nacross various vision tasks, enabling applications such as image inpainting,\noutpainting, editing, interpolation, and enrichment, without the need for\nstructural modifications. Our findings suggest that BiGR unifies generative and\ndiscriminative tasks effectively, paving the way for further advancements in\nthe field.\n","authors":["Shaozhe Hao","Xuantong Liu","Xianbiao Qi","Shihao Zhao","Bojia Zi","Rong Xiao","Kai Han","Kwan-Yee K. Wong"],"pdf_url":"https://arxiv.org/pdf/2410.14672v1.pdf","comment":"Project page: https://haoosz.github.io/BiGR"},{"id":"http://arxiv.org/abs/2410.14666v1","updated":"2024-10-18T17:56:11Z","published":"2024-10-18T17:56:11Z","title":"DiscoGraMS: Enhancing Movie Screen-Play Summarization using Movie\n  Character-Aware Discourse Graph","summary":"  Summarizing movie screenplays presents a unique set of challenges compared to\nstandard document summarization. Screenplays are not only lengthy, but also\nfeature a complex interplay of characters, dialogues, and scenes, with numerous\ndirect and subtle relationships and contextual nuances that are difficult for\nmachine learning models to accurately capture and comprehend. Recent attempts\nat screenplay summarization focus on fine-tuning transformer-based pre-trained\nmodels, but these models often fall short in capturing long-term dependencies\nand latent relationships, and frequently encounter the \"lost in the middle\"\nissue. To address these challenges, we introduce DiscoGraMS, a novel resource\nthat represents movie scripts as a movie character-aware discourse graph (CaD\nGraph). This approach is well-suited for various downstream tasks, such as\nsummarization, question-answering, and salience detection. The model aims to\npreserve all salient information, offering a more comprehensive and faithful\nrepresentation of the screenplay's content. We further explore a baseline\nmethod that combines the CaD Graph with the corresponding movie script through\na late fusion of graph and text modalities, and we present very initial\npromising results.\n","authors":["Maitreya Prafulla Chitale","Uday Bindal","Rajakrishnan Rajkumar","Rahul Mishra"],"pdf_url":"https://arxiv.org/pdf/2410.14666v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14665v1","updated":"2024-10-18T17:55:15Z","published":"2024-10-18T17:55:15Z","title":"Online Reinforcement Learning with Passive Memory","summary":"  This paper considers an online reinforcement learning algorithm that\nleverages pre-collected data (passive memory) from the environment for online\ninteraction. We show that using passive memory improves performance and further\nprovide theoretical guarantees for regret that turns out to be near-minimax\noptimal. Results show that the quality of passive memory determines\nsub-optimality of the incurred regret. The proposed approach and results hold\nin both continuous and discrete state-action spaces.\n","authors":["Anay Pattanaik","Lav R. Varshney"],"pdf_url":"https://arxiv.org/pdf/2410.14665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.06331v2","updated":"2024-10-18T17:53:46Z","published":"2024-10-08T20:12:11Z","title":"Locate-then-edit for Multi-hop Factual Recall under Knowledge Editing","summary":"  The locate-then-edit paradigm has shown significant promise for knowledge\nediting (KE) in Large Language Models (LLMs). While previous methods perform\nwell on single-hop fact recall tasks, they consistently struggle with multi-hop\nfactual recall tasks involving newly edited knowledge. In this paper,\nleveraging tools in mechanistic interpretability, we first identify that in\nmulti-hop tasks, LLMs tend to retrieve implicit subject knowledge from deeper\nMLP layers, unlike single-hop tasks, which rely on earlier layers. This\ndistinction explains the poor performance of current methods in multi-hop\nqueries, as they primarily focus on editing shallow layers, leaving deeper\nlayers unchanged. To address this, we propose IFMET, a novel locate-then-edit\nKE approach designed to edit both shallow and deep MLP layers. IFMET employs\nmulti-hop editing prompts and supplementary sets to locate and modify knowledge\nacross different reasoning stages. Experimental results demonstrate that IFMET\nsignificantly improves performance on multi-hop factual recall tasks,\neffectively overcoming the limitations of previous locate-then-edit methods.\n","authors":["Zhuoran Zhang","Yongxiang Li","Zijian Kan","Keyuan Cheng","Lijie Hu","Di Wang"],"pdf_url":"https://arxiv.org/pdf/2410.06331v2.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2408.08821v3","updated":"2024-10-18T17:50:57Z","published":"2024-08-16T16:09:59Z","title":"EasyRec: Simple yet Effective Language Models for Recommendation","summary":"  Deep neural networks have become a powerful technique for learning\nrepresentations from user-item interaction data in collaborative filtering (CF)\nfor recommender systems. However, many existing methods heavily rely on unique\nuser and item IDs, which limits their ability to perform well in practical\nzero-shot learning scenarios where sufficient training data may be unavailable.\nInspired by the success of language models (LMs) and their strong\ngeneralization capabilities, a crucial question arises: How can we harness the\npotential of language models to empower recommender systems and elevate its\ngeneralization capabilities to new heights? In this study, we propose EasyRec -\nan effective and easy-to-use approach that seamlessly integrates text-based\nsemantic understanding with collaborative signals. EasyRec employs a\ntext-behavior alignment framework, which combines contrastive learning with\ncollaborative language model tuning, to ensure a strong alignment between the\ntext-enhanced semantic space and the collaborative behavior information.\nExtensive empirical evaluations across diverse real-world datasets demonstrate\nthe superior performance of EasyRec compared to state-of-the-art alternative\nmodels, particularly in the challenging text-based zero-shot recommendation\nscenarios. Furthermore, the study highlights the potential of seamlessly\nintegrating EasyRec as a plug-and-play component into text-enhanced\ncollaborative filtering frameworks, thereby empowering existing recommender\nsystems to elevate their recommendation performance and adapt to the evolving\nuser preferences in dynamic environments. For better result reproducibility of\nour EasyRec framework, the model implementation details, source code, and\ndatasets are available at the link: https://github.com/HKUDS/EasyRec.\n","authors":["Xubin Ren","Chao Huang"],"pdf_url":"https://arxiv.org/pdf/2408.08821v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14651v1","updated":"2024-10-18T17:47:11Z","published":"2024-10-18T17:47:11Z","title":"Real-time Fake News from Adversarial Feedback","summary":"  We show that existing evaluations for fake news detection based on\nconventional sources, such as claims on fact-checking websites, result in an\nincreasing accuracy over time for LLM-based detectors -- even after their\nknowledge cutoffs. This suggests that recent popular political claims, which\nform the majority of fake news on such sources, are easily classified using\nsurface-level shallow patterns. Instead, we argue that a proper fake news\ndetection dataset should test a model's ability to reason factually about the\ncurrent world by retrieving and reading related evidence. To this end, we\ndevelop a novel pipeline that leverages natural language feedback from a\nRAG-based detector to iteratively modify real-time news into deceptive fake\nnews that challenges LLMs. Our iterative rewrite decreases the binary\nclassification AUC by an absolute 17.5 percent for a strong RAG GPT-4o\ndetector. Our experiments reveal the important role of RAG in both detecting\nand generating fake news, as retrieval-free LLM detectors are vulnerable to\nunseen events and adversarial attacks, while feedback from RAG detection helps\ndiscover more deceitful patterns in fake news.\n","authors":["Sanxing Chen","Yukun Huang","Bhuwan Dhingra"],"pdf_url":"https://arxiv.org/pdf/2410.14651v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14641v1","updated":"2024-10-18T17:41:19Z","published":"2024-10-18T17:41:19Z","title":"Distance between Relevant Information Pieces Causes Bias in Long-Context\n  LLMs","summary":"  Positional bias in large language models (LLMs) hinders their ability to\neffectively process long inputs. A prominent example is the \"lost in the\nmiddle\" phenomenon, where LLMs struggle to utilize relevant information\nsituated in the middle of the input. While prior research primarily focuses on\nsingle pieces of relevant information, real-world applications often involve\nmultiple relevant information pieces. To bridge this gap, we present\nLongPiBench, a benchmark designed to assess positional bias involving multiple\npieces of relevant information. Thorough experiments are conducted with five\ncommercial and six open-source models. These experiments reveal that while most\ncurrent models are robust against the \"lost in the middle\" issue, there exist\nsignificant biases related to the spacing of relevant information pieces. These\nfindings highlight the importance of evaluating and reducing positional biases\nto advance LLM's capabilities.\n","authors":["Runchu Tian","Yanghao Li","Yuepeng Fu","Siyang Deng","Qinyu Luo","Cheng Qian","Shuo Wang","Xin Cong","Zhong Zhang","Yesai Wu","Yankai Lin","Huadong Wang","Xiaojiang Liu"],"pdf_url":"https://arxiv.org/pdf/2410.14641v1.pdf","comment":"work in progress"},{"id":"http://arxiv.org/abs/2409.06445v2","updated":"2024-10-18T17:37:51Z","published":"2024-09-10T12:00:40Z","title":"Learning Generative Interactive Environments By Trained Agent\n  Exploration","summary":"  World models are increasingly pivotal in interpreting and simulating the\nrules and actions of complex environments. Genie, a recent model, excels at\nlearning from visually diverse environments but relies on costly\nhuman-collected data. We observe that their alternative method of using random\nagents is too limited to explore the environment. We propose to improve the\nmodel by employing reinforcement learning based agents for data generation.\nThis approach produces diverse datasets that enhance the model's ability to\nadapt and perform well across various scenarios and realistic actions within\nthe environment. In this paper, we first release the model GenieRedux - an\nimplementation based on Genie. Additionally, we introduce GenieRedux-G, a\nvariant that uses the agent's readily available actions to factor out action\nprediction uncertainty during validation. Our evaluation, including a\nreplication of the Coinrun case study, shows that GenieRedux-G achieves\nsuperior visual fidelity and controllability using the trained agent\nexploration. The proposed approach is reproducable, scalable and adaptable to\nnew types of environments. Our codebase is available at\nhttps://github.com/insait-institute/GenieRedux .\n","authors":["Naser Kazemi","Nedko Savov","Danda Paudel","Luc Van Gool"],"pdf_url":"https://arxiv.org/pdf/2409.06445v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14635v1","updated":"2024-10-18T17:36:53Z","published":"2024-10-18T17:36:53Z","title":"GenEOL: Harnessing the Generative Power of LLMs for Training-Free\n  Sentence Embeddings","summary":"  Training-free embedding methods directly leverage pretrained large language\nmodels (LLMs) to embed text, bypassing the costly and complex procedure of\ncontrastive learning. Previous training-free embedding methods have mainly\nfocused on optimizing embedding prompts and have overlooked the benefits of\nutilizing the generative abilities of LLMs. We propose a novel method, GenEOL,\nwhich uses LLMs to generate diverse transformations of a sentence that preserve\nits meaning, and aggregates the resulting embeddings of these transformations\nto enhance the overall sentence embedding. GenEOL significantly outperforms the\nexisting training-free embedding methods by an average of 2.85 points across\nseveral LLMs on the sentence semantic text similarity (STS) benchmark. Our\nanalysis shows that GenEOL stabilizes representation quality across LLM layers\nand is robust to perturbations of embedding prompts. GenEOL also achieves\nnotable gains on multiple clustering, reranking and pair-classification tasks\nfrom the MTEB benchmark.\n","authors":["Raghuveer Thirukovalluru","Bhuwan Dhingra"],"pdf_url":"https://arxiv.org/pdf/2410.14635v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.09889v3","updated":"2024-10-18T17:32:27Z","published":"2021-09-21T00:09:03Z","title":"A Distance-based Anomaly Detection Framework for Deep Reinforcement\n  Learning","summary":"  In deep reinforcement learning (RL) systems, abnormal states pose significant\nrisks by potentially triggering unpredictable behaviors and unsafe actions,\nthus impeding the deployment of RL systems in real-world scenarios. It is\ncrucial for reliable decision-making systems to have the capability to cast an\nalert whenever they encounter unfamiliar observations that they are not\nequipped to handle. In this paper, we propose a novel Mahalanobis\ndistance-based (MD) anomaly detection framework, called \\textit{MDX}, for deep\nRL algorithms. MDX simultaneously addresses random, adversarial, and\nout-of-distribution (OOD) state outliers in both offline and online settings.\nIt utilizes Mahalanobis distance within class-conditional distributions for\neach action and operates within a statistical hypothesis testing framework\nunder the Gaussian assumption. We further extend it to robust and\ndistribution-free versions by incorporating Robust MD and conformal inference\ntechniques. Through extensive experiments on classical control environments,\nAtari games, and autonomous driving scenarios, we demonstrate the effectiveness\nof our MD-based detection framework. MDX offers a simple, unified, and\npractical anomaly detection tool for enhancing the safety and reliability of RL\nsystems in real-world applications.\n","authors":["Hongming Zhang","Ke Sun","Bo Xu","Linglong Kong","Martin Müller"],"pdf_url":"https://arxiv.org/pdf/2109.09889v3.pdf","comment":"19 pages, 21 figures"},{"id":"http://arxiv.org/abs/2410.14630v1","updated":"2024-10-18T17:30:20Z","published":"2024-10-18T17:30:20Z","title":"On the Regularization of Learnable Embeddings for Time Series Processing","summary":"  In processing multiple time series, accounting for the individual features of\neach sequence can be challenging. To address this, modern deep learning methods\nfor time series analysis combine a shared (global) model with local layers,\nspecific to each time series, often implemented as learnable embeddings.\nIdeally, these local embeddings should encode meaningful representations of the\nunique dynamics of each sequence. However, when these are learned end-to-end as\nparameters of a forecasting model, they may end up acting as mere sequence\nidentifiers. Shared processing blocks may then become reliant on such\nidentifiers, limiting their transferability to new contexts. In this paper, we\naddress this issue by investigating methods to regularize the learning of local\nlearnable embeddings for time series processing. Specifically, we perform the\nfirst extensive empirical study on the subject and show how such\nregularizations consistently improve performance in widely adopted\narchitectures. Furthermore, we show that methods preventing the co-adaptation\nof local and global parameters are particularly effective in this context. This\nhypothesis is validated by comparing several methods preventing the downstream\nmodels from relying on sequence identifiers, going as far as completely\nresetting the embeddings during training. The obtained results provide an\nimportant contribution to understanding the interplay between learnable local\nparameters and shared processing layers: a key challenge in modern time series\nprocessing models and a step toward developing effective foundation models for\ntime series.\n","authors":["Luca Butera","Giovanni De Felice","Andrea Cini","Cesare Alippi"],"pdf_url":"https://arxiv.org/pdf/2410.14630v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07114v2","updated":"2024-10-18T17:30:04Z","published":"2024-09-19T19:48:31Z","title":"System 2 thinking in OpenAI's o1-preview model: Near-perfect performance\n  on a mathematics exam","summary":"  The processes underlying human cognition are often divided into System 1,\nwhich involves fast, intuitive thinking, and System 2, which involves slow,\ndeliberate reasoning. Previously, large language models were criticized for\nlacking the deeper, more analytical capabilities of System 2. In September\n2024, OpenAI introduced the o1 model series, designed to handle System 2-like\nreasoning. While OpenAI's benchmarks are promising, independent validation is\nstill needed. In this study, we tested the o1-preview model twice on the Dutch\n'Mathematics B' final exam. It scored a near-perfect 76 and 74 out of 76\npoints. For context, only 24 out of 16,414 students in the Netherlands achieved\na perfect score. By comparison, the GPT-4o model scored 66 and 62 out of 76,\nwell above the Dutch average of 40.63 points. Neither model had access to the\nexam figures. Since there was a risk of model contamination (i.e., the\nknowledge cutoff of o1-preview and GPT-4o was after the exam was published\nonline), we repeated the procedure with a new Mathematics B exam that was\npublished after the cutoff date. The results again indicated that o1-preview\nperformed strongly (97.8th percentile), which suggests that contamination was\nnot a factor. We also show that there is some variability in the output of\no1-preview, which means that sometimes there is 'luck' (the answer is correct)\nor 'bad luck' (the output has diverged into something that is incorrect). We\ndemonstrate that a self-consistency approach, where repeated prompts are given\nand the most common answer is selected, is a useful strategy for identifying\nthe correct answer. It is concluded that while OpenAI's new model series holds\ngreat potential, certain risks must be considered.\n","authors":["Joost de Winter","Dimitra Dodou","Yke Bauke Eisma"],"pdf_url":"https://arxiv.org/pdf/2410.07114v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14627v1","updated":"2024-10-18T17:29:56Z","published":"2024-10-18T17:29:56Z","title":"CELI: Controller-Embedded Language Model Interactions","summary":"  We introduce Controller-Embedded Language Model Interactions (CELI), a\nframework that integrates control logic directly within language model (LM)\nprompts, facilitating complex, multi-stage task execution. CELI addresses\nlimitations of existing prompt engineering and workflow optimization techniques\nby embedding control logic directly within the operational context of language\nmodels, enabling dynamic adaptation to evolving task requirements. Our\nframework transfers control from the traditional programming execution\nenvironment to the LMs, allowing them to autonomously manage computational\nworkflows while maintaining seamless interaction with external systems and\nfunctions. CELI supports arbitrary function calls with variable arguments,\nbridging the gap between LMs' adaptive reasoning capabilities and conventional\nsoftware paradigms' structured control mechanisms. To evaluate CELI's\nversatility and effectiveness, we conducted case studies in two distinct\ndomains: code generation (HumanEval benchmark) and multi-stage content\ngeneration (Wikipedia-style articles). The results demonstrate notable\nperformance improvements across a range of domains. CELI achieved a 4.9\npercentage point improvement over the best reported score of the baseline GPT-4\nmodel on the HumanEval code generation benchmark. In multi-stage content\ngeneration, 94.4% of CELI-produced Wikipedia-style articles met or exceeded\nfirst draft quality when optimally configured, with 44.4% achieving high\nquality. These outcomes underscore CELI's potential for optimizing AI-driven\nworkflows across diverse computational domains.\n","authors":["Jan-Samuel Wagner","Dave DeCaprio","Abishek Chiffon Muthu Raja","Jonathan M. Holman","Lauren K. Brady","Sky C. Cheung","Hosein Barzekar","Eric Yang","Mark Anthony Martinez II","David Soong","Sriram Sridhar","Han Si","Brandon W. Higgs","Hisham Hamadeh","Scott Ogden"],"pdf_url":"https://arxiv.org/pdf/2410.14627v1.pdf","comment":"26 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.10989v2","updated":"2024-10-18T17:21:17Z","published":"2024-10-14T18:17:01Z","title":"Liger Kernel: Efficient Triton Kernels for LLM Training","summary":"  Training Large Language Models (LLMs) efficiently at scale presents a\nformidable challenge, driven by their ever-increasing computational demands and\nthe need for enhanced performance. In this work, we introduce Liger-Kernel, an\nopen-sourced set of Triton kernels developed specifically for LLM training.\nWith kernel optimization techniques like kernel operation fusing and input\nchunking, our kernels achieve on average a 20% increase in training throughput\nand a 60% reduction in GPU memory usage for popular LLMs compared to\nHuggingFace implementations. In addition, Liger-Kernel is designed with\nmodularity, accessibility, and adaptability in mind, catering to both casual\nand expert users. Comprehensive benchmarks and integration tests are built in\nto ensure compatibility, performance, correctness, and convergence across\ndiverse computing environments and model architectures.\n  The source code is available under a permissive license at:\ngithub.com/linkedin/Liger-Kernel.\n","authors":["Pin-Lun Hsu","Yun Dai","Vignesh Kothapalli","Qingquan Song","Shao Tang","Siyu Zhu","Steven Shimizu","Shivam Sahni","Haowen Ning","Yanning Chen"],"pdf_url":"https://arxiv.org/pdf/2410.10989v2.pdf","comment":"17 pages, 12 figures"},{"id":"http://arxiv.org/abs/2410.02525v3","updated":"2024-10-18T17:18:24Z","published":"2024-10-03T14:33:34Z","title":"Contextual Document Embeddings","summary":"  Dense document embeddings are central to neural retrieval. The dominant\nparadigm is to train and construct embeddings by running encoders directly on\nindividual documents. In this work, we argue that these embeddings, while\neffective, are implicitly out-of-context for targeted use cases of retrieval,\nand that a contextualized document embedding should take into account both the\ndocument and neighboring documents in context - analogous to contextualized\nword embeddings. We propose two complementary methods for contextualized\ndocument embeddings: first, an alternative contrastive learning objective that\nexplicitly incorporates the document neighbors into the intra-batch contextual\nloss; second, a new contextual architecture that explicitly encodes neighbor\ndocument information into the encoded representation. Results show that both\nmethods achieve better performance than biencoders in several settings, with\ndifferences especially pronounced out-of-domain. We achieve state-of-the-art\nresults on the MTEB benchmark with no hard negative mining, score distillation,\ndataset-specific instructions, intra-GPU example-sharing, or extremely large\nbatch sizes. Our method can be applied to improve performance on any\ncontrastive learning dataset and any biencoder.\n","authors":["John X. Morris","Alexander M. Rush"],"pdf_url":"https://arxiv.org/pdf/2410.02525v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10101v2","updated":"2024-10-18T17:15:09Z","published":"2024-10-14T02:41:01Z","title":"Learning Linear Attention in Polynomial Time","summary":"  Previous research has explored the computational expressivity of Transformer\nmodels in simulating Boolean circuits or Turing machines. However, the\nlearnability of these simulators from observational data has remained an open\nquestion. Our study addresses this gap by providing the first polynomial-time\nlearnability results (specifically strong, agnostic PAC learning) for\nsingle-layer Transformers with linear attention. We show that linear attention\nmay be viewed as a linear predictor in a suitably defined RKHS. As a\nconsequence, the problem of learning any linear transformer may be converted\ninto the problem of learning an ordinary linear predictor in an expanded\nfeature space, and any such predictor may be converted back into a multiheaded\nlinear transformer. Moving to generalization, we show how to efficiently\nidentify training datasets for which every empirical risk minimizer is\nequivalent (up to trivial symmetries) to the linear Transformer that generated\nthe data, thereby guaranteeing the learned model will correctly generalize\nacross all inputs. Finally, we provide examples of computations expressible via\nlinear attention and therefore polynomial-time learnable, including associative\nmemories, finite automata, and a class of Universal Turing Machine (UTMs) with\npolynomially bounded computation histories. We empirically validate our\ntheoretical findings on three tasks: learning random linear attention networks,\nkey--value associations, and learning to execute finite automata. Our findings\nbridge a critical gap between theoretical expressivity and learnability of\nTransformers, and show that flexible and general models of computation are\nefficiently learnable.\n","authors":["Morris Yau","Ekin Akyürek","Jiayuan Mao","Joshua B. Tenenbaum","Stefanie Jegelka","Jacob Andreas"],"pdf_url":"https://arxiv.org/pdf/2410.10101v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14616v1","updated":"2024-10-18T17:14:28Z","published":"2024-10-18T17:14:28Z","title":"Benchmarking Deep Reinforcement Learning for Navigation in Denied Sensor\n  Environments","summary":"  Deep Reinforcement learning (DRL) is used to enable autonomous navigation in\nunknown environments. Most research assume perfect sensor data, but real-world\nenvironments may contain natural and artificial sensor noise and denial. Here,\nwe present a benchmark of both well-used and emerging DRL algorithms in a\nnavigation task with configurable sensor denial effects. In particular, we are\ninterested in comparing how different DRL methods (e.g. model-free PPO vs.\nmodel-based DreamerV3) are affected by sensor denial. We show that DreamerV3\noutperforms other methods in the visual end-to-end navigation task with a\ndynamic goal - and other methods are not able to learn this. Furthermore,\nDreamerV3 generally outperforms other methods in sensor-denied environments. In\norder to improve robustness, we use adversarial training and demonstrate an\nimproved performance in denied environments, although this generally comes with\na performance cost on the vanilla environments. We anticipate this benchmark of\ndifferent DRL methods and the usage of adversarial training to be a starting\npoint for the development of more elaborate navigation strategies that are\ncapable of dealing with uncertain and denied sensor readings.\n","authors":["Mariusz Wisniewski","Paraskevas Chatzithanos","Weisi Guo","Antonios Tsourdos"],"pdf_url":"https://arxiv.org/pdf/2410.14616v1.pdf","comment":"31 pages, 19 figures. For associated code, see\n  https://github.com/mazqtpopx/cranfield-navigation-gym"},{"id":"http://arxiv.org/abs/2410.14615v1","updated":"2024-10-18T17:13:29Z","published":"2024-10-18T17:13:29Z","title":"Asymptotically Optimal Change Detection for Unnormalized Pre- and\n  Post-Change Distributions","summary":"  This paper addresses the problem of detecting changes when only unnormalized\npre- and post-change distributions are accessible. This situation happens in\nmany scenarios in physics such as in ferromagnetism, crystallography,\nmagneto-hydrodynamics, and thermodynamics, where the energy models are\ndifficult to normalize.\n  Our approach is based on the estimation of the Cumulative Sum (CUSUM)\nstatistics, which is known to produce optimal performance. We first present an\nintuitively appealing approximation method. Unfortunately, this produces a\nbiased estimator of the CUSUM statistics and may cause performance degradation.\nWe then propose the Log-Partition Approximation Cumulative Sum (LPA-CUSUM)\nalgorithm based on thermodynamic integration (TI) in order to estimate the\nlog-ratio of normalizing constants of pre- and post-change distributions. It is\nproved that this approach gives an unbiased estimate of the log-partition\nfunction and the CUSUM statistics, and leads to an asymptotically optimal\nperformance. Moreover, we derive a relationship between the required sample\nsize for thermodynamic integration and the desired detection delay performance,\noffering guidelines for practical parameter selection. Numerical studies are\nprovided demonstrating the efficacy of our approach.\n","authors":["Arman Adibi","Sanjeev Kulkarni","H. Vincent Poor","Taposh Banerjee","Vahid Tarokh"],"pdf_url":"https://arxiv.org/pdf/2410.14615v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.20601v2","updated":"2024-10-18T17:07:01Z","published":"2023-10-31T16:37:01Z","title":"Modular Boundaries in Recurrent Neural Networks","summary":"  Recent theoretical and experimental work in neuroscience has focused on the\nrepresentational and dynamical character of neural manifolds --subspaces in\nneural activity space wherein many neurons coactivate. Importantly, neural\npopulations studied under this \"neural manifold hypothesis\" are continuous and\nnot cleanly divided into separate neural populations. This perspective clashes\nwith the \"modular hypothesis\" of brain organization, wherein neural elements\nmaintain an \"all-or-nothing\" affiliation with modules. In line with this\nmodular hypothesis, recent research on recurrent neural networks suggests that\nmulti-task networks become modular across training, such that different modules\nspecialize for task-general dynamical motifs. If the modular hypothesis is\ntrue, then it would be important to use a dimensionality reduction technique\nthat captures modular structure. Here, we investigate the features of such a\nmethod. We leverage RNNs as a model system to study the character of modular\nneural populations, using a community detection method from network science\nknown as modularity maximization to partition neurons into distinct modules.\nThese partitions allow us to ask the following question: do these modular\nboundaries matter to the system? ...\n","authors":["Jacob Tanner","Sina Mansour L.","Ludovico Coletta","Alessandro Gozzi","Richard F. Betzel"],"pdf_url":"https://arxiv.org/pdf/2310.20601v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14606v1","updated":"2024-10-18T17:00:29Z","published":"2024-10-18T17:00:29Z","title":"Streaming Deep Reinforcement Learning Finally Works","summary":"  Natural intelligence processes experience as a continuous stream, sensing,\nacting, and learning moment-by-moment in real time. Streaming learning, the\nmodus operandi of classic reinforcement learning (RL) algorithms like\nQ-learning and TD, mimics natural learning by using the most recent sample\nwithout storing it. This approach is also ideal for resource-constrained,\ncommunication-limited, and privacy-sensitive applications. However, in deep RL,\nlearners almost always use batch updates and replay buffers, making them\ncomputationally expensive and incompatible with streaming learning. Although\nthe prevalence of batch deep RL is often attributed to its sample efficiency, a\nmore critical reason for the absence of streaming deep RL is its frequent\ninstability and failure to learn, which we refer to as stream barrier. This\npaper introduces the stream-x algorithms, the first class of deep RL algorithms\nto overcome stream barrier for both prediction and control and match sample\nefficiency of batch RL. Through experiments in Mujoco Gym, DM Control Suite,\nand Atari Games, we demonstrate stream barrier in existing algorithms and\nsuccessful stable learning with our stream-x algorithms: stream Q, stream AC,\nand stream TD, achieving the best model-free performance in DM Control Dog\nenvironments. A set of common techniques underlies the stream-x algorithms,\nenabling their success with a single set of hyperparameters and allowing for\neasy extension to other algorithms, thereby reviving streaming RL.\n","authors":["Mohamed Elsayed","Gautham Vasan","A. Rupam Mahmood"],"pdf_url":"https://arxiv.org/pdf/2410.14606v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14602v1","updated":"2024-10-18T16:57:05Z","published":"2024-10-18T16:57:05Z","title":"How Does Data Diversity Shape the Weight Landscape of Neural Networks?","summary":"  To enhance the generalization of machine learning models to unseen data,\ntechniques such as dropout, weight decay ($L_2$ regularization), and noise\naugmentation are commonly employed. While regularization methods (i.e., dropout\nand weight decay) are geared toward adjusting model parameters to prevent\noverfitting, data augmentation increases the diversity of the input training\nset, a method purported to improve accuracy and calibration error. In this\npaper, we investigate the impact of each of these techniques on the parameter\nspace of neural networks, with the goal of understanding how they alter the\nweight landscape in transfer learning scenarios. To accomplish this, we employ\nRandom Matrix Theory to analyze the eigenvalue distributions of pre-trained\nmodels, fine-tuned using these techniques but using different levels of data\ndiversity, for the same downstream tasks. We observe that diverse data\ninfluences the weight landscape in a similar fashion as dropout. Additionally,\nwe compare commonly used data augmentation methods with synthetic data created\nby generative models. We conclude that synthetic data can bring more diversity\ninto real input data, resulting in a better performance on out-of-distribution\ntest instances.\n","authors":["Yang Ba","Michelle V. Mancenido","Rong Pan"],"pdf_url":"https://arxiv.org/pdf/2410.14602v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14596v1","updated":"2024-10-18T16:49:36Z","published":"2024-10-18T16:49:36Z","title":"Teaching Models to Balance Resisting and Accepting Persuasion","summary":"  Large language models (LLMs) are susceptible to persuasion, which can pose\nrisks when models are faced with an adversarial interlocutor. We take a first\nstep towards defending models against persuasion while also arguing that\ndefense against adversarial (i.e. negative) persuasion is only half of the\nequation: models should also be able to accept beneficial (i.e. positive)\npersuasion to improve their answers. We show that optimizing models for only\none side results in poor performance on the other. In order to balance positive\nand negative persuasion, we introduce Persuasion-Balanced Training (or PBT),\nwhich leverages multi-agent recursive dialogue trees to create data and trains\nmodels via preference optimization to accept persuasion when appropriate. PBT\nconsistently improves resistance to misinformation and resilience to being\nchallenged while also resulting in the best overall performance on holistic\ndata containing both positive and negative persuasion. Crucially, we show that\nPBT models are better teammates in multi-agent debates. We find that without\nPBT, pairs of stronger and weaker models have unstable performance, with the\norder in which the models present their answers determining whether the team\nobtains the stronger or weaker model's performance. PBT leads to better and\nmore stable results and less order dependence, with the stronger model\nconsistently pulling the weaker one up.\n","authors":["Elias Stengel-Eskin","Peter Hase","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2410.14596v1.pdf","comment":"Code: https://github.com/esteng/persuasion_balanced_training"},{"id":"http://arxiv.org/abs/2410.14593v1","updated":"2024-10-18T16:43:36Z","published":"2024-10-18T16:43:36Z","title":"Temporal Fair Division of Indivisible Items","summary":"  We study a fair division model where indivisible items arrive sequentially,\nand must be allocated immediately and irrevocably. Previous work on online fair\ndivision has shown impossibility results in achieving approximate envy-freeness\nunder these constraints. In contrast, we consider an informed setting where the\nalgorithm has complete knowledge of future items, and aim to ensure that the\ncumulative allocation at each round satisfies approximate envy-freeness --\nwhich we define as temporal envy-freeness up to one item (TEF1). We focus on\nsettings where items can be exclusively goods or exclusively chores. For goods,\nwhile TEF1 allocations may not always exist, we identify several special cases\nwhere they do -- two agents, two item types, generalized binary valuations,\nunimodal preferences -- and provide polynomial-time algorithms for these cases.\nWe also prove that determining the existence of a TEF1 allocation is NP-hard.\nFor chores, we establish analogous results for the special cases, but present a\nslightly weaker intractability result. We also establish the incompatibility\nbetween TEF1 and Pareto-optimality, with the implication that it is intractable\nto find a TEF1 allocation that maximizes any $p$-mean welfare, even for two\nagents.\n","authors":["Edith Elkind","Alexander Lam","Mohamad Latifian","Tzeh Yuan Neoh","Nicholas Teh"],"pdf_url":"https://arxiv.org/pdf/2410.14593v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13191v2","updated":"2024-10-18T16:42:01Z","published":"2024-10-17T03:38:29Z","title":"MCQG-SRefine: Multiple Choice Question Generation and Evaluation with\n  Iterative Self-Critique, Correction, and Comparison Feedback","summary":"  Automatic question generation (QG) is essential for AI and NLP, particularly\nin intelligent tutoring, dialogue systems, and fact verification. Generating\nmultiple-choice questions (MCQG) for professional exams, like the United States\nMedical Licensing Examination (USMLE), is particularly challenging, requiring\ndomain expertise and complex multi-hop reasoning for high-quality questions.\nHowever, current large language models (LLMs) like GPT-4 struggle with\nprofessional MCQG due to outdated knowledge, hallucination issues, and prompt\nsensitivity, resulting in unsatisfactory quality and difficulty. To address\nthese challenges, we propose MCQG-SRefine, an LLM self-refine-based (Critique\nand Correction) framework for converting medical cases into high-quality\nUSMLE-style questions. By integrating expert-driven prompt engineering with\niterative self-critique and self-correction feedback, MCQG-SRefine\nsignificantly enhances human expert satisfaction regarding both the quality and\ndifficulty of the questions. Furthermore, we introduce an LLM-as-Judge-based\nautomatic metric to replace the complex and costly expert evaluation process,\nensuring reliable and expert-aligned assessments.\n","authors":["Zonghai Yao","Aditya Parashar","Huixue Zhou","Won Seok Jang","Feiyun Ouyang","Zhichao Yang","Hong Yu"],"pdf_url":"https://arxiv.org/pdf/2410.13191v2.pdf","comment":"Equal contribution for the first two authors"},{"id":"http://arxiv.org/abs/2410.14586v1","updated":"2024-10-18T16:37:28Z","published":"2024-10-18T16:37:28Z","title":"Neural Combinatorial Clustered Bandits for Recommendation Systems","summary":"  We consider the contextual combinatorial bandit setting where in each round,\nthe learning agent, e.g., a recommender system, selects a subset of \"arms,\"\ne.g., products, and observes rewards for both the individual base arms, which\nare a function of known features (called \"context\"), and the super arm (the\nsubset of arms), which is a function of the base arm rewards. The agent's goal\nis to simultaneously learn the unknown reward functions and choose the\nhighest-reward arms. For example, the \"reward\" may represent a user's\nprobability of clicking on one of the recommended products. Conventional bandit\nmodels, however, employ restrictive reward function models in order to obtain\nperformance guarantees. We make use of deep neural networks to estimate and\nlearn the unknown reward functions and propose Neural UCB Clustering\n(NeUClust), which adopts a clustering approach to select the super arm in every\nround by exploiting underlying structure in the context space. Unlike prior\nneural bandit works, NeUClust uses a neural network to estimate the super arm\nreward and select the super arm, thus eliminating the need for a known\noptimization oracle. We non-trivially extend prior neural combinatorial bandit\nworks to prove that NeUClust achieves\n$\\widetilde{O}\\left(\\widetilde{d}\\sqrt{T}\\right)$ regret, where $\\widetilde{d}$\nis the effective dimension of a neural tangent kernel matrix, $T$ the number of\nrounds. Experiments on real world recommendation datasets show that NeUClust\nachieves better regret and reward than other contextual combinatorial and\nneural bandit algorithms.\n","authors":["Baran Atalar","Carlee Joe-Wong"],"pdf_url":"https://arxiv.org/pdf/2410.14586v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14584v1","updated":"2024-10-18T16:35:25Z","published":"2024-10-18T16:35:25Z","title":"MCSFF: Multi-modal Consistency and Specificity Fusion Framework for\n  Entity Alignment","summary":"  Multi-modal entity alignment (MMEA) is essential for enhancing knowledge\ngraphs and improving information retrieval and question-answering systems.\nExisting methods often focus on integrating modalities through their\ncomplementarity but overlook the specificity of each modality, which can\nobscure crucial features and reduce alignment accuracy. To solve this, we\npropose the Multi-modal Consistency and Specificity Fusion Framework (MCSFF),\nwhich innovatively integrates both complementary and specific aspects of\nmodalities. We utilize Scale Computing's hyper-converged infrastructure to\noptimize IT management and resource allocation in large-scale data processing.\nOur framework first computes similarity matrices for each modality using\nmodality embeddings to preserve their unique characteristics. Then, an\niterative update method denoises and enhances modality features to fully\nexpress critical information. Finally, we integrate the updated information\nfrom all modalities to create enriched and precise entity representations.\nExperiments show our method outperforms current state-of-the-art MMEA baselines\non the MMKG dataset, demonstrating its effectiveness and practical potential.\n","authors":["Wei Ai","Wen Deng","Hongyi Chen","Jiayi Du","Tao Meng","Yuntao Shou"],"pdf_url":"https://arxiv.org/pdf/2410.14584v1.pdf","comment":"6 pages, 1 figures"},{"id":"http://arxiv.org/abs/2410.13752v2","updated":"2024-10-18T16:33:05Z","published":"2024-10-17T16:50:48Z","title":"Privacy-Preserving Decentralized AI with Confidential Computing","summary":"  This paper addresses privacy protection in decentralized Artificial\nIntelligence (AI) using Confidential Computing (CC) within the Atoma Network, a\ndecentralized AI platform designed for the Web3 domain. Decentralized AI\ndistributes AI services among multiple entities without centralized oversight,\nfostering transparency and robustness. However, this structure introduces\nsignificant privacy challenges, as sensitive assets such as proprietary models\nand personal data may be exposed to untrusted participants. Cryptography-based\nprivacy protection techniques such as zero-knowledge machine learning (zkML)\nsuffers prohibitive computational overhead. To address the limitation, we\npropose leveraging Confidential Computing (CC). Confidential Computing\nleverages hardware-based Trusted Execution Environments (TEEs) to provide\nisolation for processing sensitive data, ensuring that both model parameters\nand user data remain secure, even in decentralized, potentially untrusted\nenvironments. While TEEs face a few limitations, we believe they can bridge the\nprivacy gap in decentralized AI. We explore how we can integrate TEEs into\nAtoma's decentralized framework.\n","authors":["Dayeol Lee","Jorge António","Hisham Khan"],"pdf_url":"https://arxiv.org/pdf/2410.13752v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14582v1","updated":"2024-10-18T16:32:10Z","published":"2024-10-18T16:32:10Z","title":"Do LLMs estimate uncertainty well in instruction-following?","summary":"  Large language models (LLMs) could be valuable personal AI agents across\nvarious domains, provided they can precisely follow user instructions. However,\nrecent studies have shown significant limitations in LLMs'\ninstruction-following capabilities, raising concerns about their reliability in\nhigh-stakes applications. Accurately estimating LLMs' uncertainty in adhering\nto instructions is critical to mitigating deployment risks. We present, to our\nknowledge, the first systematic evaluation of the uncertainty estimation\nabilities of LLMs in the context of instruction-following. Our study identifies\nkey challenges with existing instruction-following benchmarks, where multiple\nfactors are entangled with uncertainty stems from instruction-following,\ncomplicating the isolation and comparison across methods and models. To address\nthese issues, we introduce a controlled evaluation setup with two benchmark\nversions of data, enabling a comprehensive comparison of uncertainty estimation\nmethods under various conditions. Our findings show that existing uncertainty\nmethods struggle, particularly when models make subtle errors in instruction\nfollowing. While internal model states provide some improvement, they remain\ninadequate in more complex scenarios. The insights from our controlled\nevaluation setups provide a crucial understanding of LLMs' limitations and\npotential for uncertainty estimation in instruction-following tasks, paving the\nway for more trustworthy AI agents.\n","authors":["Juyeon Heo","Miao Xiong","Christina Heinze-Deml","Jaya Narain"],"pdf_url":"https://arxiv.org/pdf/2410.14582v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14581v1","updated":"2024-10-18T16:32:06Z","published":"2024-10-18T16:32:06Z","title":"Optimizing Attention with Mirror Descent: Generalized Max-Margin Token\n  Selection","summary":"  Attention mechanisms have revolutionized several domains of artificial\nintelligence, such as natural language processing and computer vision, by\nenabling models to selectively focus on relevant parts of the input data. While\nrecent work has characterized the optimization dynamics of gradient descent\n(GD) in attention-based models and the structural properties of its preferred\nsolutions, less is known about more general optimization algorithms such as\nmirror descent (MD). In this paper, we investigate the convergence properties\nand implicit biases of a family of MD algorithms tailored for softmax attention\nmechanisms, with the potential function chosen as the $p$-th power of the\n$\\ell_p$-norm. Specifically, we show that these algorithms converge in\ndirection to a generalized hard-margin SVM with an $\\ell_p$-norm objective when\napplied to a classification problem using a softmax attention model. Notably,\nour theoretical results reveal that the convergence rate is comparable to that\nof traditional GD in simpler models, despite the highly nonlinear and nonconvex\nnature of the present problem. Additionally, we delve into the joint\noptimization dynamics of the key-query matrix and the decoder, establishing\nconditions under which this complex joint optimization converges to their\nrespective hard-margin SVM solutions. Lastly, our numerical experiments on real\ndata demonstrate that MD algorithms improve generalization over standard GD and\nexcel in optimal token selection.\n","authors":["Aaron Alvarado Kristanto Julistiono","Davoud Ataee Tarzanagh","Navid Azizan"],"pdf_url":"https://arxiv.org/pdf/2410.14581v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17777v2","updated":"2024-10-18T16:31:49Z","published":"2024-09-26T12:15:13Z","title":"Harnessing Shared Relations via Multimodal Mixup Contrastive Learning\n  for Multimodal Classification","summary":"  Deep multimodal learning has shown remarkable success by leveraging\ncontrastive learning to capture explicit one-to-one relations across\nmodalities. However, real-world data often exhibits shared relations beyond\nsimple pairwise associations. We propose M3CoL, a Multimodal Mixup Contrastive\nLearning approach to capture nuanced shared relations inherent in multimodal\ndata. Our key contribution is a Mixup-based contrastive loss that learns robust\nrepresentations by aligning mixed samples from one modality with their\ncorresponding samples from other modalities thereby capturing shared relations\nbetween them. For multimodal classification tasks, we introduce a framework\nthat integrates a fusion module with unimodal prediction modules for auxiliary\nsupervision during training, complemented by our proposed Mixup-based\ncontrastive loss. Through extensive experiments on diverse datasets (N24News,\nROSMAP, BRCA, and Food-101), we demonstrate that M3CoL effectively captures\nshared multimodal relations and generalizes across domains. It outperforms\nstate-of-the-art methods on N24News, ROSMAP, and BRCA, while achieving\ncomparable performance on Food-101. Our work highlights the significance of\nlearning shared relations for robust multimodal learning, opening up promising\navenues for future research.\n","authors":["Raja Kumar","Raghav Singhal","Pranamya Kulkarni","Deval Mehta","Kshitij Jadhav"],"pdf_url":"https://arxiv.org/pdf/2409.17777v2.pdf","comment":"RK and RS contributed equally to this work, 20 Pages, 8 Figures, 9\n  Tables. Another version of the paper accepted at NeurIPS 2024 Workshop on\n  Unifying Representations in Neural Models (UniReps)"},{"id":"http://arxiv.org/abs/2410.14579v1","updated":"2024-10-18T16:27:04Z","published":"2024-10-18T16:27:04Z","title":"Towards Unsupervised Validation of Anomaly-Detection Models","summary":"  Unsupervised validation of anomaly-detection models is a highly challenging\ntask. While the common practices for model validation involve a labeled\nvalidation set, such validation sets cannot be constructed when the underlying\ndatasets are unlabeled. The lack of robust and efficient unsupervised\nmodel-validation techniques presents an acute challenge in the implementation\nof automated anomaly-detection pipelines, especially when there exists no prior\nknowledge of the model's performance on similar datasets. This work presents a\nnew paradigm to automated validation of anomaly-detection models, inspired by\nreal-world, collaborative decision-making mechanisms. We focus on two\ncommonly-used, unsupervised model-validation tasks -- model selection and model\nevaluation -- and provide extensive experimental results that demonstrate the\naccuracy and robustness of our approach on both tasks.\n","authors":["Lihi Idan"],"pdf_url":"https://arxiv.org/pdf/2410.14579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14578v1","updated":"2024-10-18T16:26:45Z","published":"2024-10-18T16:26:45Z","title":"Large Language Models Are Overparameterized Text Encoders","summary":"  Large language models (LLMs) demonstrate strong performance as text embedding\nmodels when finetuned with supervised contrastive training. However, their\nlarge size balloons inference time and memory requirements. In this paper, we\nshow that by pruning the last $p\\%$ layers of an LLM before supervised training\nfor only 1000 steps, we can achieve a proportional reduction in memory and\ninference time. We evaluate four different state-of-the-art LLMs on text\nembedding tasks and find that our method can prune up to 30\\% of layers with\nnegligible impact on performance and up to 80\\% with only a modest drop. With\nonly three lines of code, our method is easily implemented in any pipeline for\ntransforming LLMs to text encoders. We also propose $\\text{L}^3 \\text{Prune}$,\na novel layer-pruning strategy based on the model's initial loss that provides\ntwo optimal pruning configurations: a large variant with negligible performance\nloss and a small variant for resource-constrained settings. On average, the\nlarge variant prunes 21\\% of the parameters with a $-0.3$ performance drop, and\nthe small variant only suffers from a $-5.1$ decrease while pruning 74\\% of the\nmodel. We consider these results strong evidence that LLMs are\noverparameterized for text embedding tasks, and can be easily pruned.\n","authors":["Thennal D K","Tim Fischer","Chris Biemann"],"pdf_url":"https://arxiv.org/pdf/2410.14578v1.pdf","comment":"8 pages of content + 1 for limitations and ethical considerations, 14\n  pages in total including references and appendix, 5+1 figures"},{"id":"http://arxiv.org/abs/2410.14574v1","updated":"2024-10-18T16:20:22Z","published":"2024-10-18T16:20:22Z","title":"MomentumSMoE: Integrating Momentum into Sparse Mixture of Experts","summary":"  Sparse Mixture of Experts (SMoE) has become the key to unlocking unparalleled\nscalability in deep learning. SMoE has the potential to exponentially increase\nparameter count while maintaining the efficiency of the model by only\nactivating a small subset of these parameters for a given sample. However, it\nhas been observed that SMoE suffers from unstable training and has difficulty\nadapting to new distributions, leading to the model's lack of robustness to\ndata contamination. To overcome these limitations, we first establish a\nconnection between the dynamics of the expert representations in SMoEs and\ngradient descent on a multi-objective optimization problem. Leveraging our\nframework, we then integrate momentum into SMoE and propose a new family of\nSMoEs named MomentumSMoE. We theoretically prove and numerically demonstrate\nthat MomentumSMoE is more stable and robust than SMoE. In particular, we verify\nthe advantages of MomentumSMoE over SMoE on a variety of practical tasks\nincluding ImageNet-1K object recognition and WikiText-103 language modeling. We\ndemonstrate the applicability of MomentumSMoE to many types of SMoE models,\nincluding those in the Sparse MoE model for vision (V-MoE) and the Generalist\nLanguage Model (GLaM). We also show that other advanced momentum-based\noptimization methods, such as Adam, can be easily incorporated into the\nMomentumSMoE framework for designing new SMoE models with even better\nperformance, almost negligible additional computation cost, and simple\nimplementations.\n","authors":["Rachel S. Y. Teo","Tan M. Nguyen"],"pdf_url":"https://arxiv.org/pdf/2410.14574v1.pdf","comment":"10 pages in the main text. Published at NeurIPS 2024. The code is\n  available at https://github.com/rachtsy/MomentumSMoE"},{"id":"http://arxiv.org/abs/2410.14573v1","updated":"2024-10-18T16:20:17Z","published":"2024-10-18T16:20:17Z","title":"Building Trust in Black-box Optimization: A Comprehensive Framework for\n  Explainability","summary":"  Optimizing costly black-box functions within a constrained evaluation budget\npresents significant challenges in many real-world applications. Surrogate\nOptimization (SO) is a common resolution, yet its proprietary nature introduced\nby the complexity of surrogate models and the sampling core (e.g., acquisition\nfunctions) often leads to a lack of explainability and transparency. While\nexisting literature has primarily concentrated on enhancing convergence to\nglobal optima, the practical interpretation of newly proposed strategies\nremains underexplored, especially in batch evaluation settings. In this paper,\nwe propose \\emph{Inclusive} Explainability Metrics for Surrogate Optimization\n(IEMSO), a comprehensive set of model-agnostic metrics designed to enhance the\ntransparency, trustworthiness, and explainability of the SO approaches. Through\nthese metrics, we provide both intermediate and post-hoc explanations to\npractitioners before and after performing expensive evaluations to gain trust.\nWe consider four primary categories of metrics, each targeting a specific\naspect of the SO process: Sampling Core Metrics, Batch Properties Metrics,\nOptimization Process Metrics, and Feature Importance. Our experimental\nevaluations demonstrate the significant potential of the proposed metrics\nacross different benchmarks.\n","authors":["Nazanin Nezami","Hadis Anahideh"],"pdf_url":"https://arxiv.org/pdf/2410.14573v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14571v1","updated":"2024-10-18T16:17:10Z","published":"2024-10-18T16:17:10Z","title":"TransBox: EL++-closed Ontology Embedding","summary":"  OWL (Web Ontology Language) ontologies, which are able to represent both\nrelational and type facts as standard knowledge graphs and complex domain\nknowledge in Description Logic (DL) axioms, are widely adopted in domains such\nas healthcare and bioinformatics. Inspired by the success of knowledge graph\nembeddings, embedding OWL ontologies has gained significant attention in recent\nyears. Current methods primarily focus on learning embeddings for atomic\nconcepts and roles, enabling the evaluation based on normalized axioms through\nspecially designed score functions. However, they often neglect the embedding\nof complex concepts, making it difficult to infer with more intricate axioms.\nThis limitation reduces their effectiveness in advanced reasoning tasks, such\nas Ontology Learning and ontology-mediated Query Answering. In this paper, we\npropose EL++-closed ontology embeddings which are able to represent any logical\nexpressions in DL via composition. Furthermore, we develop TransBox, an\neffective EL++-closed ontology embedding method that can handle many-to-one,\none-to-many and many-to-many relations. Our extensive experiments demonstrate\nthat TransBox often achieves state-of-the-art performance across various\nreal-world datasets for predicting complex axioms.\n","authors":["Hui Yang","Jiaoyan Chen","Uli Sattler"],"pdf_url":"https://arxiv.org/pdf/2410.14571v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14569v1","updated":"2024-10-18T16:16:34Z","published":"2024-10-18T16:16:34Z","title":"When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs","summary":"  Recent advancements in Large Language Models (LLMs) have established them as\nagentic systems capable of planning and interacting with various tools. These\nLLM agents are often paired with web-based tools, enabling access to diverse\nsources and real-time information. Although these advancements offer\nsignificant benefits across various applications, they also increase the risk\nof malicious use, particularly in cyberattacks involving personal information.\nIn this work, we investigate the risks associated with misuse of LLM agents in\ncyberattacks involving personal data. Specifically, we aim to understand: 1)\nhow potent LLM agents can be when directed to conduct cyberattacks, 2) how\ncyberattacks are enhanced by web-based tools, and 3) how affordable and easy it\nbecomes to launch cyberattacks using LLM agents. We examine three attack\nscenarios: the collection of Personally Identifiable Information (PII), the\ngeneration of impersonation posts, and the creation of spear-phishing emails.\nOur experiments reveal the effectiveness of LLM agents in these attacks: LLM\nagents achieved a precision of up to 95.9% in collecting PII, up to 93.9% of\nimpersonation posts created by LLM agents were evaluated as authentic, and the\nclick rate for links in spear phishing emails created by LLM agents reached up\nto 46.67%. Additionally, our findings underscore the limitations of existing\nsafeguards in contemporary commercial LLMs, emphasizing the urgent need for\nmore robust security measures to prevent the misuse of LLM agents.\n","authors":["Hanna Kim","Minkyoo Song","Seung Ho Na","Seungwon Shin","Kimin Lee"],"pdf_url":"https://arxiv.org/pdf/2410.14569v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14567v1","updated":"2024-10-18T16:11:29Z","published":"2024-10-18T16:11:29Z","title":"RAG-ConfusionQA: A Benchmark for Evaluating LLMs on Confusing Questions","summary":"  Conversational AI agents use Retrieval Augmented Generation (RAG) to provide\nverifiable document-grounded responses to user inquiries. However, many natural\nquestions do not have good answers: about 25\\% contain false\nassumptions~\\cite{Yu2023:CREPE}, and over 50\\% are\nambiguous~\\cite{Min2020:AmbigQA}. RAG agents need high-quality data to improve\ntheir responses to confusing questions. This paper presents a novel synthetic\ndata generation method to efficiently create a diverse set of context-grounded\nconfusing questions from a given document corpus. We conduct an empirical\ncomparative evaluation of several large language models as RAG agents to\nmeasure the accuracy of confusion detection and appropriate response\ngeneration. We contribute a benchmark dataset to the public domain.\n","authors":["Zhiyuan Peng","Jinming Nian","Alexandre Evfimievski","Yi Fang"],"pdf_url":"https://arxiv.org/pdf/2410.14567v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2410.14548v1","updated":"2024-10-18T15:43:34Z","published":"2024-10-18T15:43:34Z","title":"Boosting K-means for Big Data by Fusing Data Streaming with Global\n  Optimization","summary":"  K-means clustering is a cornerstone of data mining, but its efficiency\ndeteriorates when confronted with massive datasets. To address this limitation,\nwe propose a novel heuristic algorithm that leverages the Variable Neighborhood\nSearch (VNS) metaheuristic to optimize K-means clustering for big data. Our\napproach is based on the sequential optimization of the partial objective\nfunction landscapes obtained by restricting the Minimum Sum-of-Squares\nClustering (MSSC) formulation to random samples from the original big dataset.\nWithin each landscape, systematically expanding neighborhoods of the currently\nbest (incumbent) solution are explored by reinitializing all degenerate and a\nvarying number of additional centroids. Extensive and rigorous experimentation\non a large number of real-world datasets reveals that by transforming the\ntraditional local search into a global one, our algorithm significantly\nenhances the accuracy and efficiency of K-means clustering in big data\nenvironments, becoming the new state of the art in the field.\n","authors":["Ravil Mussabayev","Rustam Mussabayev"],"pdf_url":"https://arxiv.org/pdf/2410.14548v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14545v1","updated":"2024-10-18T15:40:48Z","published":"2024-10-18T15:40:48Z","title":"Tell me what I need to know: Exploring LLM-based (Personalized)\n  Abstractive Multi-Source Meeting Summarization","summary":"  Meeting summarization is crucial in digital communication, but existing\nsolutions struggle with salience identification to generate personalized,\nworkable summaries, and context understanding to fully comprehend the meetings'\ncontent. Previous attempts to address these issues by considering related\nsupplementary resources (e.g., presentation slides) alongside transcripts are\nhindered by models' limited context sizes and handling the additional\ncomplexities of the multi-source tasks, such as identifying relevant\ninformation in additional files and seamlessly aligning it with the meeting\ncontent. This work explores multi-source meeting summarization considering\nsupplementary materials through a three-stage large language model approach:\nidentifying transcript passages needing additional context, inferring relevant\ndetails from supplementary materials and inserting them into the transcript,\nand generating a summary from this enriched transcript. Our multi-source\napproach enhances model understanding, increasing summary relevance by ~9% and\nproducing more content-rich outputs. We introduce a personalization protocol\nthat extracts participant characteristics and tailors summaries accordingly,\nimproving informativeness by ~10%. This work further provides insights on\nperformance-cost trade-offs across four leading model families, including\nedge-device capable options. Our approach can be extended to similar complex\ngenerative tasks benefitting from additional resources and personalization,\nsuch as dialogue systems and action planning.\n","authors":["Frederic Kirstein","Terry Ruas","Robert Kratel","Bela Gipp"],"pdf_url":"https://arxiv.org/pdf/2410.14545v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14544v1","updated":"2024-10-18T15:38:33Z","published":"2024-10-18T15:38:33Z","title":"Computational Grounding of Responsibility Attribution and Anticipation\n  in LTLf","summary":"  Responsibility is one of the key notions in machine ethics and in the area of\nautonomous systems. It is a multi-faceted notion involving counterfactual\nreasoning about actions and strategies. In this paper, we study different\nvariants of responsibility in a strategic setting based on LTLf. We show a\nconnection with notions in reactive synthesis, including synthesis of winning,\ndominant, and best-effort strategies. This connection provides the building\nblocks for a computational grounding of responsibility including complexity\ncharacterizations and sound, complete, and optimal algorithms for attributing\nand anticipating responsibility.\n","authors":["Giuseppe De Giacomo","Emiliano Lorini","Timothy Parker","Gianmarco Parretti"],"pdf_url":"https://arxiv.org/pdf/2410.14544v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.15379v2","updated":"2024-10-18T15:38:16Z","published":"2024-04-23T07:16:13Z","title":"Clustering of timed sequences -- Application to the analysis of care\n  pathways","summary":"  Improving the future of healthcare starts by better understanding the current\nactual practices in hospital settings. This motivates the objective of\ndiscovering typical care pathways from patient data. Revealing typical care\npathways can be achieved through clustering. The difficulty in clustering care\npathways, represented by sequences of timestamped events, lies in defining a\nsemantically appropriate metric and clustering algorithms. In this article, we\nadapt two methods developed for time series to the clustering of timed\nsequences: the drop-DTW metric and the DBA approach for the construction of\naveraged time sequences. These methods are then applied in clustering\nalgorithms to propose original and sound clustering algorithms for timed\nsequences. This approach is experimented with and evaluated on synthetic and\nreal-world data.\n","authors":["Thomas Guyet","Pierre Pinson","Enoal Gesny"],"pdf_url":"https://arxiv.org/pdf/2404.15379v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.11124v2","updated":"2024-10-18T15:34:41Z","published":"2024-04-17T07:15:07Z","title":"What's under the hood: Investigating Automatic Metrics on Meeting\n  Summarization","summary":"  Meeting summarization has become a critical task considering the increase in\nonline interactions. While new techniques are introduced regularly, their\nevaluation uses metrics not designed to capture meeting-specific errors,\nundermining effective evaluation. This paper investigates what the frequently\nused automatic metrics capture and which errors they mask by correlating\nautomatic metric scores with human evaluations across a broad error taxonomy.\nWe commence with a comprehensive literature review on English meeting\nsummarization to define key challenges like speaker dynamics and contextual\nturn-taking and error types such as missing information and linguistic\ninaccuracy, concepts previously loosely defined in the field. We examine the\nrelationship between characteristic challenges and errors by using annotated\ntranscripts and summaries from Transformer-based sequence-to-sequence and\nautoregressive models from the general summary QMSum dataset. Through\nexperimental validation, we find that different model architectures respond\nvariably to challenges in meeting transcripts, resulting in different\npronounced links between challenges and errors. Current default-used metrics\nstruggle to capture observable errors, showing weak to mid-correlations, while\na third of the correlations show trends of error masking. Only a subset reacts\naccurately to specific errors, while most correlations show either\nunresponsiveness or failure to reflect the error's impact on summary quality.\n","authors":["Frederic Kirstein","Jan Philip Wahle","Terry Ruas","Bela Gipp"],"pdf_url":"https://arxiv.org/pdf/2404.11124v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14524v1","updated":"2024-10-18T15:08:05Z","published":"2024-10-18T15:08:05Z","title":"Less is More: Selective Reduction of CT Data for Self-Supervised\n  Pre-Training of Deep Learning Models with Contrastive Learning Improves\n  Downstream Classification Performance","summary":"  Self-supervised pre-training of deep learning models with contrastive\nlearning is a widely used technique in image analysis. Current findings\nindicate a strong potential for contrastive pre-training on medical images.\nHowever, further research is necessary to incorporate the particular\ncharacteristics of these images. We hypothesize that the similarity of medical\nimages hinders the success of contrastive learning in the medical imaging\ndomain. To this end, we investigate different strategies based on deep\nembedding, information theory, and hashing in order to identify and reduce\nredundancy in medical pre-training datasets. The effect of these different\nreduction strategies on contrastive learning is evaluated on two pre-training\ndatasets and several downstream classification tasks. In all of our\nexperiments, dataset reduction leads to a considerable performance gain in\ndownstream tasks, e.g., an AUC score improvement from 0.78 to 0.83 for the\nCOVID CT Classification Grand Challenge, 0.97 to 0.98 for the OrganSMNIST\nClassification Challenge and 0.73 to 0.83 for a brain hemorrhage classification\ntask. Furthermore, pre-training is up to nine times faster due to the dataset\nreduction. In conclusion, the proposed approach highlights the importance of\ndataset quality and provides a transferable approach to improve contrastive\npre-training for classification downstream tasks on medical images.\n","authors":["Daniel Wolf","Tristan Payer","Catharina Silvia Lisson","Christoph Gerhard Lisson","Meinrad Beer","Michael Götz","Timo Ropinski"],"pdf_url":"https://arxiv.org/pdf/2410.14524v1.pdf","comment":"Published in Computers in Biology and Medicine"},{"id":"http://arxiv.org/abs/2410.14516v1","updated":"2024-10-18T14:55:14Z","published":"2024-10-18T14:55:14Z","title":"Do LLMs \"know\" internally when they follow instructions?","summary":"  Instruction-following is crucial for building AI agents with large language\nmodels (LLMs), as these models must adhere strictly to user-provided\nconstraints and guidelines. However, LLMs often fail to follow even simple and\nclear instructions. To improve instruction-following behavior and prevent\nundesirable outputs, a deeper understanding of how LLMs' internal states relate\nto these outcomes is required. Our analysis of LLM internal states reveal a\ndimension in the input embedding space linked to successful\ninstruction-following. We demonstrate that modifying representations along this\ndimension improves instruction-following success rates compared to random\nchanges, without compromising response quality. Further investigation reveals\nthat this dimension is more closely related to the phrasing of prompts rather\nthan the inherent difficulty of the task or instructions. This discovery also\nsuggests explanations for why LLMs sometimes fail to follow clear instructions\nand why prompt engineering is often effective, even when the content remains\nlargely unchanged. This work provides insight into the internal workings of\nLLMs' instruction-following, paving the way for reliable LLM agents.\n","authors":["Juyeon Heo","Christina Heinze-Deml","Oussama Elachqar","Shirley Ren","Udhay Nallasamy","Andy Miller","Kwan Ho Ryan Chan","Jaya Narain"],"pdf_url":"https://arxiv.org/pdf/2410.14516v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14515v1","updated":"2024-10-18T14:54:40Z","published":"2024-10-18T14:54:40Z","title":"Efficient Annotator Reliability Assessment and Sample Weighting for\n  Knowledge-Based Misinformation Detection on Social Media","summary":"  Misinformation spreads rapidly on social media, confusing the truth and\ntargetting potentially vulnerable people. To effectively mitigate the negative\nimpact of misinformation, it must first be accurately detected before applying\na mitigation strategy, such as X's community notes, which is currently a manual\nprocess. This study takes a knowledge-based approach to misinformation\ndetection, modelling the problem similarly to one of natural language\ninference. The EffiARA annotation framework is introduced, aiming to utilise\ninter- and intra-annotator agreement to understand the reliability of each\nannotator and influence the training of large language models for\nclassification based on annotator reliability. In assessing the EffiARA\nannotation framework, the Russo-Ukrainian Conflict Knowledge-Based\nMisinformation Classification Dataset (RUC-MCD) was developed and made publicly\navailable. This study finds that sample weighting using annotator reliability\nperforms the best, utilising both inter- and intra-annotator agreement and\nsoft-label training. The highest classification performance achieved using\nLlama-3.2-1B was a macro-F1 of 0.757 and 0.740 using TwHIN-BERT-large.\n","authors":["Owen Cook","Charlie Grimshaw","Ben Wu","Sophie Dillon","Jack Hicks","Luke Jones","Thomas Smith","Matyas Szert","Xingyi Song"],"pdf_url":"https://arxiv.org/pdf/2410.14515v1.pdf","comment":"8 pages, 3 figures, 3 tables. Code available here:\n  https://github.com/MiniEggz/ruc-misinfo"},{"id":"http://arxiv.org/abs/2410.14508v1","updated":"2024-10-18T14:43:05Z","published":"2024-10-18T14:43:05Z","title":"LEAD: Latent Realignment for Human Motion Diffusion","summary":"  Our goal is to generate realistic human motion from natural language. Modern\nmethods often face a trade-off between model expressiveness and text-to-motion\nalignment. Some align text and motion latent spaces but sacrifice\nexpressiveness; others rely on diffusion models producing impressive motions,\nbut lacking semantic meaning in their latent space. This may compromise\nrealism, diversity, and applicability. Here, we address this by combining\nlatent diffusion with a realignment mechanism, producing a novel, semantically\nstructured space that encodes the semantics of language. Leveraging this\ncapability, we introduce the task of textual motion inversion to capture novel\nmotion concepts from a few examples. For motion synthesis, we evaluate LEAD on\nHumanML3D and KIT-ML and show comparable performance to the state-of-the-art in\nterms of realism, diversity, and text-motion consistency. Our qualitative\nanalysis and user study reveal that our synthesized motions are sharper, more\nhuman-like and comply better with the text compared to modern methods. For\nmotion textual inversion, our method demonstrates improved capacity in\ncapturing out-of-distribution characteristics in comparison to traditional\nVAEs.\n","authors":["Nefeli Andreou","Xi Wang","Victoria Fernández Abrevaya","Marie-Paule Cani","Yiorgos Chrysanthou","Vicky Kalogeiton"],"pdf_url":"https://arxiv.org/pdf/2410.14508v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14506v1","updated":"2024-10-18T14:38:37Z","published":"2024-10-18T14:38:37Z","title":"SignAttention: On the Interpretability of Transformer Models for Sign\n  Language Translation","summary":"  This paper presents the first comprehensive interpretability analysis of a\nTransformer-based Sign Language Translation (SLT) model, focusing on the\ntranslation from video-based Greek Sign Language to glosses and text.\nLeveraging the Greek Sign Language Dataset, we examine the attention mechanisms\nwithin the model to understand how it processes and aligns visual input with\nsequential glosses. Our analysis reveals that the model pays attention to\nclusters of frames rather than individual ones, with a diagonal alignment\npattern emerging between poses and glosses, which becomes less distinct as the\nnumber of glosses increases. We also explore the relative contributions of\ncross-attention and self-attention at each decoding step, finding that the\nmodel initially relies on video frames but shifts its focus to previously\npredicted tokens as the translation progresses. This work contributes to a\ndeeper understanding of SLT models, paving the way for the development of more\ntransparent and reliable translation systems essential for real-world\napplications.\n","authors":["Pedro Alejandro Dal Bianco","Oscar Agustín Stanchi","Facundo Manuel Quiroga","Franco Ronchetti","Enzo Ferrante"],"pdf_url":"https://arxiv.org/pdf/2410.14506v1.pdf","comment":"Accepted at IAI Workshop @ NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.08979v2","updated":"2024-10-18T14:35:53Z","published":"2024-10-11T16:54:07Z","title":"Overcoming Slow Decision Frequencies in Continuous Control: Model-Based\n  Sequence Reinforcement Learning for Model-Free Control","summary":"  Reinforcement learning (RL) is rapidly reaching and surpassing human-level\ncontrol capabilities. However, state-of-the-art RL algorithms often require\ntimesteps and reaction times significantly faster than human capabilities,\nwhich is impractical in real-world settings and typically necessitates\nspecialized hardware. Such speeds are difficult to achieve in the real world\nand often requires specialized hardware. We introduce Sequence Reinforcement\nLearning (SRL), an RL algorithm designed to produce a sequence of actions for a\ngiven input state, enabling effective control at lower decision frequencies.\nSRL addresses the challenges of learning action sequences by employing both a\nmodel and an actor-critic architecture operating at different temporal scales.\nWe propose a \"temporal recall\" mechanism, where the critic uses the model to\nestimate intermediate states between primitive actions, providing a learning\nsignal for each individual action within the sequence. Once training is\ncomplete, the actor can generate action sequences independently of the model,\nachieving model-free control at a slower frequency. We evaluate SRL on a suite\nof continuous control tasks, demonstrating that it achieves performance\ncomparable to state-of-the-art algorithms while significantly reducing actor\nsample complexity. To better assess performance across varying decision\nfrequencies, we introduce the Frequency-Averaged Score (FAS) metric. Our\nresults show that SRL significantly outperforms traditional RL algorithms in\nterms of FAS, making it particularly suitable for applications requiring\nvariable decision frequencies. Additionally, we compare SRL with model-based\nonline planning, showing that SRL achieves superior FAS while leveraging the\nsame model during training that online planners use for planning.\n","authors":["Devdhar Patel","Hava Siegelmann"],"pdf_url":"https://arxiv.org/pdf/2410.08979v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14488v1","updated":"2024-10-18T14:16:54Z","published":"2024-10-18T14:16:54Z","title":"ANT: Adaptive Noise Schedule for Time Series Diffusion Models","summary":"  Advances in diffusion models for generative artificial intelligence have\nrecently propagated to the time series (TS) domain, demonstrating\nstate-of-the-art performance on various tasks. However, prior works on TS\ndiffusion models often borrow the framework of existing works proposed in other\ndomains without considering the characteristics of TS data, leading to\nsuboptimal performance. In this work, we propose Adaptive Noise schedule for\nTime series diffusion models (ANT), which automatically predetermines proper\nnoise schedules for given TS datasets based on their statistics representing\nnon-stationarity. Our intuition is that an optimal noise schedule should\nsatisfy the following desiderata: 1) It linearly reduces the non-stationarity\nof TS data so that all diffusion steps are equally meaningful, 2) the data is\ncorrupted to the random noise at the final step, and 3) the number of steps is\nsufficiently large. The proposed method is practical for use in that it\neliminates the necessity of finding the optimal noise schedule with a small\nadditional cost to compute the statistics for given datasets, which can be done\noffline before training. We validate the effectiveness of our method across\nvarious tasks, including TS forecasting, refinement, and generation, on\ndatasets from diverse domains. Code is available at this repository:\nhttps://github.com/seunghan96/ANT.\n","authors":["Seunghan Lee","Kibok Lee","Taeyoung Park"],"pdf_url":"https://arxiv.org/pdf/2410.14488v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.14484v1","updated":"2024-10-18T14:08:41Z","published":"2024-10-18T14:08:41Z","title":"Transfer Reinforcement Learning in Heterogeneous Action Spaces using\n  Subgoal Mapping","summary":"  In this paper, we consider a transfer reinforcement learning problem\ninvolving agents with different action spaces. Specifically, for any new unseen\ntask, the goal is to use a successful demonstration of this task by an expert\nagent in its action space to enable a learner agent learn an optimal policy in\nits own different action space with fewer samples than those required if the\nlearner was learning on its own. Existing transfer learning methods across\ndifferent action spaces either require handcrafted mappings between those\naction spaces provided by human experts, which can induce bias in the learning\nprocedure, or require the expert agent to share its policy parameters with the\nlearner agent, which does not generalize well to unseen tasks. In this work, we\npropose a method that learns a subgoal mapping between the expert agent policy\nand the learner agent policy. Since the expert agent and the learner agent have\ndifferent action spaces, their optimal policies can have different subgoal\ntrajectories. We learn this subgoal mapping by training a Long Short Term\nMemory (LSTM) network for a distribution of tasks and then use this mapping to\npredict the learner subgoal sequence for unseen tasks, thereby improving the\nspeed of learning by biasing the agent's policy towards the predicted learner\nsubgoal sequence. Through numerical experiments, we demonstrate that the\nproposed learning scheme can effectively find the subgoal mapping underlying\nthe given distribution of tasks. Moreover, letting the learner agent imitate\nthe expert agent's policy with the learnt subgoal mapping can significantly\nimprove the sample efficiency and training time of the learner agent in unseen\nnew tasks.\n","authors":["Kavinayan P. Sivakumar","Yan Zhang","Zachary Bell","Scott Nivison","Michael M. Zavlanos"],"pdf_url":"https://arxiv.org/pdf/2410.14484v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14481v1","updated":"2024-10-18T14:04:38Z","published":"2024-10-18T14:04:38Z","title":"DRL Optimization Trajectory Generation via Wireless Network\n  Intent-Guided Diffusion Models for Optimizing Resource Allocation","summary":"  With the rapid advancements in wireless communication fields, including\nlow-altitude economies, 6G, and Wi-Fi, the scale of wireless networks continues\nto expand, accompanied by increasing service quality demands. Traditional deep\nreinforcement learning (DRL)-based optimization models can improve network\nperformance by solving non-convex optimization problems intelligently. However,\nthey heavily rely on online deployment and often require extensive initial\ntraining. Online DRL optimization models typically make accurate decisions\nbased on current channel state distributions. When these distributions change,\ntheir generalization capability diminishes, which hinders the responsiveness\nessential for real-time and high-reliability wireless communication networks.\nFurthermore, different users have varying quality of service (QoS) requirements\nacross diverse scenarios, and conventional online DRL methods struggle to\naccommodate this variability. Consequently, exploring flexible and customized\nAI strategies is critical. We propose a wireless network intent (WNI)-guided\ntrajectory generation model based on a generative diffusion model (GDM). This\nmodel can be generated and fine-tuned in real time to achieve the objective and\nmeet the constraints of target intent networks, significantly reducing state\ninformation exposure during wireless communication. Moreover, The WNI-guided\noptimization trajectory generation can be customized to address differentiated\nQoS requirements, enhancing the overall quality of communication in future\nintelligent networks. Extensive simulation results demonstrate that our\napproach achieves greater stability in spectral efficiency variations and\noutperforms traditional DRL optimization models in dynamic communication\nsystems.\n","authors":["Junjie Wu","Xuming Fang","Dusit Niyato","Jiacheng Wang","Jingyu Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14481v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09804v2","updated":"2024-10-18T14:03:05Z","published":"2024-10-13T11:15:38Z","title":"BlackDAN: A Black-Box Multi-Objective Approach for Effective and\n  Contextual Jailbreaking of Large Language Models","summary":"  While large language models (LLMs) exhibit remarkable capabilities across\nvarious tasks, they encounter potential security risks such as jailbreak\nattacks, which exploit vulnerabilities to bypass security measures and generate\nharmful outputs. Existing jailbreak strategies mainly focus on maximizing\nattack success rate (ASR), frequently neglecting other critical factors,\nincluding the relevance of the jailbreak response to the query and the level of\nstealthiness. This narrow focus on single objectives can result in ineffective\nattacks that either lack contextual relevance or are easily recognizable. In\nthis work, we introduce BlackDAN, an innovative black-box attack framework with\nmulti-objective optimization, aiming to generate high-quality prompts that\neffectively facilitate jailbreaking while maintaining contextual relevance and\nminimizing detectability. BlackDAN leverages Multiobjective Evolutionary\nAlgorithms (MOEAs), specifically the NSGA-II algorithm, to optimize jailbreaks\nacross multiple objectives including ASR, stealthiness, and semantic relevance.\nBy integrating mechanisms like mutation, crossover, and Pareto-dominance,\nBlackDAN provides a transparent and interpretable process for generating\njailbreaks. Furthermore, the framework allows customization based on user\npreferences, enabling the selection of prompts that balance harmfulness,\nrelevance, and other factors. Experimental results demonstrate that BlackDAN\noutperforms traditional single-objective methods, yielding higher success rates\nand improved robustness across various LLMs and multimodal LLMs, while ensuring\njailbreak responses are both relevant and less detectable.\n","authors":["Xinyuan Wang","Victor Shea-Jay Huang","Renmiao Chen","Hao Wang","Chengwei Pan","Lei Sha","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2410.09804v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14470v1","updated":"2024-10-18T13:54:46Z","published":"2024-10-18T13:54:46Z","title":"How Do Training Methods Influence the Utilization of Vision Models?","summary":"  Not all learnable parameters (e.g., weights) contribute equally to a neural\nnetwork's decision function. In fact, entire layers' parameters can sometimes\nbe reset to random values with little to no impact on the model's decisions. We\nrevisit earlier studies that examined how architecture and task complexity\ninfluence this phenomenon and ask: is this phenomenon also affected by how we\ntrain the model? We conducted experimental evaluations on a diverse set of\nImageNet-1k classification models to explore this, keeping the architecture and\ntraining data constant but varying the training pipeline. Our findings reveal\nthat the training method strongly influences which layers become critical to\nthe decision function for a given task. For example, improved training regimes\nand self-supervised training increase the importance of early layers while\nsignificantly under-utilizing deeper layers. In contrast, methods such as\nadversarial training display an opposite trend. Our preliminary results extend\nprevious findings, offering a more nuanced understanding of the inner mechanics\nof neural networks.\n  Code: https://github.com/paulgavrikov/layer_criticality\n","authors":["Paul Gavrikov","Shashank Agnihotri","Margret Keuper","Janis Keuper"],"pdf_url":"https://arxiv.org/pdf/2410.14470v1.pdf","comment":"Accepted at the Interpretable AI: Past, Present and Future Workshop\n  at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.14461v1","updated":"2024-10-18T13:40:44Z","published":"2024-10-18T13:40:44Z","title":"The Propensity for Density in Feed-forward Models","summary":"  Does the process of training a neural network to solve a task tend to use all\nof the available weights even when the task could be solved with fewer weights?\nTo address this question we study the effects of pruning fully connected,\nconvolutional and residual models while varying their widths. We find that the\nproportion of weights that can be pruned without degrading performance is\nlargely invariant to model size. Increasing the width of a model has little\neffect on the density of the pruned model relative to the increase in absolute\nsize of the pruned network. In particular, we find substantial prunability\nacross a large range of model sizes, where our biggest model is 50 times as\nwide as our smallest model. We explore three hypotheses that could explain\nthese findings.\n","authors":["Nandi Schoots","Alex Jackson","Ali Kholmovaia","Peter McBurney","Murray Shanahan"],"pdf_url":"https://arxiv.org/pdf/2410.14461v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13852v4","updated":"2024-10-18T13:21:49Z","published":"2023-11-23T08:42:18Z","title":"A Cross Attention Approach to Diagnostic Explainability using Clinical\n  Practice Guidelines for Depression","summary":"  The lack of explainability using relevant clinical knowledge hinders the\nadoption of Artificial Intelligence-powered analysis of unstructured clinical\ndialogue. A wealth of relevant, untapped Mental Health (MH) data is available\nin online communities, providing the opportunity to address the explainability\nproblem with substantial potential impact as a screening tool for both online\nand offline applications. We develop a method to enhance attention in popular\ntransformer models and generate clinician-understandable explanations for\nclassification by incorporating external clinical knowledge. Inspired by how\nclinicians rely on their expertise when interacting with patients, we leverage\nrelevant clinical knowledge to model patient inputs, providing meaningful\nexplanations for classification. This will save manual review time and engender\ntrust. We develop such a system in the context of MH using clinical practice\nguidelines (CPG) for diagnosing depression, a mental health disorder of global\nconcern. We propose an application-specific language model called ProcesS\nknowledge-infused cross ATtention (PSAT), which incorporates CPGs when\ncomputing attention. Through rigorous evaluation on three expert-curated\ndatasets related to depression, we demonstrate application-relevant\nexplainability of PSAT. PSAT also surpasses the performance of nine baseline\nmodels and can provide explanations where other baselines fall short. We\ntransform a CPG resource focused on depression, such as the Patient Health\nQuestionnaire (e.g. PHQ-9) and related questions, into a machine-readable\nontology using SNOMED-CT. With this resource, PSAT enhances the ability of\nmodels like GPT-3.5 to generate application-relevant explanations.\n","authors":["Sumit Dalal","Deepa Tilwani","Kaushik Roy","Manas Gaur","Sarika Jain","Valerie Shalin","Amit Sheth"],"pdf_url":"https://arxiv.org/pdf/2311.13852v4.pdf","comment":"This paper has been accepted for publication in IEEE Journal of\n  Biomedical and Health Informatics"},{"id":"http://arxiv.org/abs/2406.13663v4","updated":"2024-10-18T13:16:57Z","published":"2024-06-19T16:10:26Z","title":"Model Internals-based Answer Attribution for Trustworthy\n  Retrieval-Augmented Generation","summary":"  Ensuring the verifiability of model answers is a fundamental challenge for\nretrieval-augmented generation (RAG) in the question answering (QA) domain.\nRecently, self-citation prompting was proposed to make large language models\n(LLMs) generate citations to supporting documents along with their answers.\nHowever, self-citing LLMs often struggle to match the required format, refer to\nnon-existent sources, and fail to faithfully reflect LLMs' context usage\nthroughout the generation. In this work, we present MIRAGE --Model\nInternals-based RAG Explanations -- a plug-and-play approach using model\ninternals for faithful answer attribution in RAG applications. MIRAGE detects\ncontext-sensitive answer tokens and pairs them with retrieved documents\ncontributing to their prediction via saliency methods. We evaluate our proposed\napproach on a multilingual extractive QA dataset, finding high agreement with\nhuman answer attribution. On open-ended QA, MIRAGE achieves citation quality\nand efficiency comparable to self-citation while also allowing for a\nfiner-grained control of attribution parameters. Our qualitative evaluation\nhighlights the faithfulness of MIRAGE's attributions and underscores the\npromising application of model internals for RAG answer attribution.\n","authors":["Jirui Qi","Gabriele Sarti","Raquel Fernández","Arianna Bisazza"],"pdf_url":"https://arxiv.org/pdf/2406.13663v4.pdf","comment":"Accepted by EMNLP 2024 Main Conference. Code and data released at\n  https://github.com/Betswish/MIRAGE"},{"id":"http://arxiv.org/abs/2410.14445v1","updated":"2024-10-18T13:04:35Z","published":"2024-10-18T13:04:35Z","title":"Toward Generalizing Visual Brain Decoding to Unseen Subjects","summary":"  Visual brain decoding aims to decode visual information from human brain\nactivities. Despite the great progress, one critical limitation of current\nbrain decoding research lies in the lack of generalization capability to unseen\nsubjects. Prior works typically focus on decoding brain activity of individuals\nbased on the observation that different subjects exhibit different brain\nactivities, while it remains unclear whether brain decoding can be generalized\nto unseen subjects. This study aims to answer this question. We first\nconsolidate an image-fMRI dataset consisting of stimulus-image and\nfMRI-response pairs, involving 177 subjects in the movie-viewing task of the\nHuman Connectome Project (HCP). This dataset allows us to investigate the brain\ndecoding performance with the increase of participants. We then present a\nlearning paradigm that applies uniform processing across all subjects, instead\nof employing different network heads or tokenizers for individuals as in\nprevious methods, which can accommodate a large number of subjects to explore\nthe generalization capability across different subjects. A series of\nexperiments are conducted and we have the following findings. First, the\nnetwork exhibits clear generalization capabilities with the increase of\ntraining subjects. Second, the generalization capability is common to popular\nnetwork architectures (MLP, CNN and Transformer). Third, the generalization\nperformance is affected by the similarity between subjects. Our findings reveal\nthe inherent similarities in brain activities across individuals. With the\nemerging of larger and more comprehensive datasets, it is possible to train a\nbrain decoding foundation model in the future.Codes and models can be found at\nhttps://github.com/Xiangtaokong/TGBD.\n","authors":["Xiangtao Kong","Kexin Huang","Ping Li","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.14445v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.11877v5","updated":"2024-10-18T13:03:05Z","published":"2024-05-20T08:41:15Z","title":"A Novel Cartography-Based Curriculum Learning Method Applied on RoNLI:\n  The First Romanian Natural Language Inference Corpus","summary":"  Natural language inference (NLI), the task of recognizing the entailment\nrelationship in sentence pairs, is an actively studied topic serving as a proxy\nfor natural language understanding. Despite the relevance of the task in\nbuilding conversational agents and improving text classification, machine\ntranslation and other NLP tasks, to the best of our knowledge, there is no\npublicly available NLI corpus for the Romanian language. To this end, we\nintroduce the first Romanian NLI corpus (RoNLI) comprising 58K training\nsentence pairs, which are obtained via distant supervision, and 6K validation\nand test sentence pairs, which are manually annotated with the correct labels.\nWe conduct experiments with multiple machine learning methods based on distant\nlearning, ranging from shallow models based on word embeddings to\ntransformer-based neural networks, to establish a set of competitive baselines.\nFurthermore, we improve on the best model by employing a new curriculum\nlearning strategy based on data cartography. Our dataset and code to reproduce\nthe baselines are available at https://github.com/Eduard6421/RONLI.\n","authors":["Eduard Poesina","Cornelia Caragea","Radu Tudor Ionescu"],"pdf_url":"https://arxiv.org/pdf/2405.11877v5.pdf","comment":"Accepted at ACL 2024 (Main)"},{"id":"http://arxiv.org/abs/2410.14436v1","updated":"2024-10-18T12:53:23Z","published":"2024-10-18T12:53:23Z","title":"Learning to refine domain knowledge for biological network inference","summary":"  Perturbation experiments allow biologists to discover causal relationships\nbetween variables of interest, but the sparsity and high dimensionality of\nthese data pose significant challenges for causal structure learning\nalgorithms. Biological knowledge graphs can bootstrap the inference of causal\nstructures in these situations, but since they compile vastly diverse\ninformation, they can bias predictions towards well-studied systems.\nAlternatively, amortized causal structure learning algorithms encode inductive\nbiases through data simulation and train supervised models to recapitulate\nthese synthetic graphs. However, realistically simulating biology is arguably\neven harder than understanding a specific system. In this work, we take\ninspiration from both strategies and propose an amortized algorithm for\nrefining domain knowledge, based on data observations. On real and synthetic\ndatasets, we show that our approach outperforms baselines in recovering ground\ntruth causal graphs and identifying errors in the prior knowledge with limited\ninterventional data.\n","authors":["Peiwen Li","Menghua Wu"],"pdf_url":"https://arxiv.org/pdf/2410.14436v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.17819v3","updated":"2024-10-18T12:49:35Z","published":"2023-05-28T22:46:21Z","title":"Large Language Models, scientific knowledge and factuality: A framework\n  to streamline human expert evaluation","summary":"  The paper introduces a framework for the evaluation of the encoding of\nfactual scientific knowledge, designed to streamline the manual evaluation\nprocess typically conducted by domain experts. Inferring over and extracting\ninformation from Large Language Models (LLMs) trained on a large corpus of\nscientific literature can potentially define a step change in biomedical\ndiscovery, reducing the barriers for accessing and integrating existing medical\nevidence. This work explores the potential of LLMs for dialoguing with\nbiomedical background knowledge, using the context of antibiotic discovery. The\nframework involves of three evaluation steps, each assessing different aspects\nsequentially: fluency, prompt alignment, semantic coherence, factual knowledge,\nand specificity of the generated responses. By splitting these tasks between\nnon-experts and experts, the framework reduces the effort required from the\nlatter. The work provides a systematic assessment on the ability of eleven\nstate-of-the-art models LLMs, including ChatGPT, GPT-4 and Llama 2, in two\nprompting-based tasks: chemical compound definition generation and chemical\ncompound-fungus relation determination. Although recent models have improved in\nfluency, factual accuracy is still low and models are biased towards\nover-represented entities. The ability of LLMs to serve as biomedical knowledge\nbases is questioned, and the need for additional systematic evaluation\nframeworks is highlighted. While LLMs are currently not fit for purpose to be\nused as biomedical factual knowledge bases in a zero-shot setting, there is a\npromising emerging property in the direction of factuality as the models become\ndomain specialised, scale-up in size and level of human feedback.\n","authors":["Magdalena Wysocka","Oskar Wysocki","Maxime Delmas","Vincent Mutel","Andre Freitas"],"pdf_url":"https://arxiv.org/pdf/2305.17819v3.pdf","comment":"Accepted at the Journal of Biomedical Informatics, Volume 158,\n  October 2024, 104724"},{"id":"http://arxiv.org/abs/2410.14429v1","updated":"2024-10-18T12:48:22Z","published":"2024-10-18T12:48:22Z","title":"FashionR2R: Texture-preserving Rendered-to-Real Image Translation with\n  Diffusion Models","summary":"  Modeling and producing lifelike clothed human images has attracted\nresearchers' attention from different areas for decades, with the complexity\nfrom highly articulated and structured content. Rendering algorithms decompose\nand simulate the imaging process of a camera, while are limited by the accuracy\nof modeled variables and the efficiency of computation. Generative models can\nproduce impressively vivid human images, however still lacking in\ncontrollability and editability. This paper studies photorealism enhancement of\nrendered images, leveraging generative power from diffusion models on the\ncontrolled basis of rendering. We introduce a novel framework to translate\nrendered images into their realistic counterparts, which consists of two\nstages: Domain Knowledge Injection (DKI) and Realistic Image Generation (RIG).\nIn DKI, we adopt positive (real) domain finetuning and negative (rendered)\ndomain embedding to inject knowledge into a pretrained Text-to-image (T2I)\ndiffusion model. In RIG, we generate the realistic image corresponding to the\ninput rendered image, with a Texture-preserving Attention Control (TAC) to\npreserve fine-grained clothing textures, exploiting the decoupled features\nencoded in the UNet structure. Additionally, we introduce SynFashion dataset,\nfeaturing high-quality digital clothing images with diverse textures. Extensive\nexperimental results demonstrate the superiority and effectiveness of our\nmethod in rendered-to-real image translation.\n","authors":["Rui Hu","Qian He","Gaofeng He","Jiedong Zhuang","Huang Chen","Huafeng Liu","Huamin Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14429v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.14425v1","updated":"2024-10-18T12:39:32Z","published":"2024-10-18T12:39:32Z","title":"Unlearning Backdoor Attacks for LLMs with Weak-to-Strong Knowledge\n  Distillation","summary":"  Parameter-efficient fine-tuning (PEFT) can bridge the gap between large\nlanguage models (LLMs) and downstream tasks. However, PEFT has been proven\nvulnerable to malicious attacks. Research indicates that poisoned LLMs, even\nafter PEFT, retain the capability to activate internalized backdoors when input\nsamples contain predefined triggers. In this paper, we introduce a novel\nweak-to-strong unlearning algorithm to defend against backdoor attacks based on\nfeature alignment knowledge distillation, named W2SDefense. Specifically, we\nfirst train a small-scale language model through full-parameter fine-tuning to\nserve as the clean teacher model. Then, this teacher model guides the\nlarge-scale poisoned student model in unlearning the backdoor, leveraging PEFT.\nTheoretical analysis suggests that W2SDefense has the potential to enhance the\nstudent model's ability to unlearn backdoor features, preventing the activation\nof the backdoor. We conduct experiments on text classification tasks involving\nthree state-of-the-art language models and three different backdoor attack\nalgorithms. Our empirical results demonstrate the outstanding performance of\nW2SDefense in defending against backdoor attacks without compromising model\nperformance.\n","authors":["Shuai Zhao","Xiaobao Wu","Cong-Duy Nguyen","Meihuizi Jia","Yichao Feng","Luu Anh Tuan"],"pdf_url":"https://arxiv.org/pdf/2410.14425v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14416v1","updated":"2024-10-18T12:29:10Z","published":"2024-10-18T12:29:10Z","title":"An explainable machine learning approach for energy forecasting at the\n  household level","summary":"  Electricity forecasting has been a recurring research topic, as it is key to\nfinding the right balance between production and consumption. While most papers\nare focused on the national or regional scale, few are interested in the\nhousehold level. Desegregated forecast is a common topic in Machine Learning\n(ML) literature but lacks explainability that household energy forecasts\nrequire. This paper specifically targets the challenges of forecasting\nelectricity use at the household level. This paper confronts common Machine\nLearning algorithms to electricity household forecasts, weighing the pros and\ncons, including accuracy and explainability with well-known key metrics.\nFurthermore, we also confront them in this paper with the business challenges\nspecific to this sector such as explainability or outliers resistance. We\nintroduce a custom decision tree, aiming at providing a fair estimate of the\nenergy consumption, while being explainable and consistent with human\nintuition. We show that this novel method allows greater explainability without\nsacrificing much accuracy. The custom tree methodology can be used in various\nbusiness use cases but is subject to limitations, such as a lack of resilience\nwith outliers.\n","authors":["Pauline Béraud","Margaux Rioux","Michel Babany","Philippe de La Chevasnerie","Damien Theis","Giacomo Teodori","Chloé Pinguet","Romane Rigaud","François Leclerc"],"pdf_url":"https://arxiv.org/pdf/2410.14416v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10918v5","updated":"2024-10-18T12:27:07Z","published":"2024-06-16T12:46:40Z","title":"Multi-LLM QA with Embodied Exploration","summary":"  Large language models (LLMs) have grown in popularity due to their natural\nlanguage interface and pre trained knowledge, leading to rapidly increasing\nsuccess in question-answering (QA) tasks. More recently, multi-agent systems\nwith LLM-based agents (Multi-LLM) have been utilized increasingly more for QA.\nIn these scenarios, the models may each answer the question and reach a\nconsensus or each model is specialized to answer different domain questions.\nHowever, most prior work dealing with Multi-LLM QA has focused on scenarios\nwhere the models are asked in a zero-shot manner or are given information\nsources to extract the answer. For question answering of an unknown\nenvironment, embodied exploration of the environment is first needed to answer\nthe question. This skill is necessary for personalizing embodied AI to\nenvironments such as households. There is a lack of insight into whether a\nMulti-LLM system can handle question-answering based on observations from\nembodied exploration. In this work, we address this gap by investigating the\nuse of Multi-Embodied LLM Explorers (MELE) for QA in an unknown environment.\nMultiple LLM-based agents independently explore and then answer queries about a\nhousehold environment. We analyze different aggregation methods to generate a\nsingle, final answer for each query: debating, majority voting, and training a\ncentral answer module (CAM). Using CAM, we observe a $46\\%$ higher accuracy\ncompared against the other non-learning-based aggregation methods. We provide\ncode and the query dataset for further research.\n","authors":["Bhrij Patel","Vishnu Sashank Dorbala","Amrit Singh Bedi","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2406.10918v5.pdf","comment":"16 pages, 9 Figures, 5 Tables"},{"id":"http://arxiv.org/abs/2407.10547v2","updated":"2024-10-18T12:25:46Z","published":"2024-07-15T08:57:02Z","title":"Learning Social Cost Functions for Human-Aware Path Planning","summary":"  Achieving social acceptance is one of the main goals of Social Robotic\nNavigation. Despite this topic has received increasing interest in recent\nyears, most of the research has focused on driving the robotic agent along\nobstacle-free trajectories, planning around estimates of future human motion to\nrespect personal distances and optimize navigation. However, social\ninteractions in everyday life are also dictated by norms that do not strictly\ndepend on movement, such as when standing at the end of a queue rather than\ncutting it. In this paper, we propose a novel method to recognize common social\nscenarios and modify a traditional planner's cost function to adapt to them.\nThis solution enables the robot to carry out different social navigation\nbehaviors that would not arise otherwise, maintaining the robustness of\ntraditional navigation. Our approach allows the robot to learn different social\nnorms with a single learned model, rather than having different modules for\neach task. As a proof of concept, we consider the tasks of queuing and respect\ninteraction spaces of groups of people talking to one another, but the method\ncan be extended to other human activities that do not involve motion.\n","authors":["Andrea Eirale","Matteo Leonetti","Marcello Chiaberge"],"pdf_url":"https://arxiv.org/pdf/2407.10547v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12950v2","updated":"2024-10-18T12:19:41Z","published":"2024-06-18T12:54:47Z","title":"MolecularGPT: Open Large Language Model (LLM) for Few-Shot Molecular\n  Property Prediction","summary":"  Molecular property prediction (MPP) is a fundamental and crucial task in drug\ndiscovery. However, prior methods are limited by the requirement for a large\nnumber of labeled molecules and their restricted ability to generalize for\nunseen and new tasks, both of which are essential for real-world applications.\nTo address these challenges, we present MolecularGPT for few-shot MPP. From a\nperspective on instruction tuning, we fine-tune large language models (LLMs)\nbased on curated molecular instructions spanning over 1000 property prediction\ntasks. This enables building a versatile and specialized LLM that can be\nadapted to novel MPP tasks without any fine-tuning through zero- and few-shot\nin-context learning (ICL). MolecularGPT exhibits competitive in-context\nreasoning capabilities across 10 downstream evaluation datasets, setting new\nbenchmarks for few-shot molecular prediction tasks. More importantly, with just\ntwo-shot examples, MolecularGPT can outperform standard supervised graph neural\nnetwork methods on 4 out of 7 datasets. It also excels state-of-the-art LLM\nbaselines by up to 15.7% increase on classification accuracy and decrease of\n17.9 on regression metrics (e.g., RMSE) under zero-shot. This study\ndemonstrates the potential of LLMs as effective few-shot molecular property\npredictors. The code is available at https://github.com/NYUSHCS/MolecularGPT.\n","authors":["Yuyan Liu","Sirui Ding","Sheng Zhou","Wenqi Fan","Qiaoyu Tan"],"pdf_url":"https://arxiv.org/pdf/2406.12950v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14395v1","updated":"2024-10-18T11:58:03Z","published":"2024-10-18T11:58:03Z","title":"Generative AI, Pragmatics, and Authenticity in Second Language Learning","summary":"  There are obvious benefits to integrating generative AI (artificial\nintelligence) into language learning and teaching. Those include using AI as a\nlanguage tutor, creating learning materials, or assessing learner output.\nHowever, due to how AI systems under-stand human language, based on a\nmathematical model using statistical probability, they lack the lived\nexperience to be able to use language with the same social aware-ness as\nhumans. Additionally, there are built-in linguistic and cultural biases based\non their training data which is mostly in English and predominantly from\nWestern sources. Those facts limit AI suitability for some language learning\ninteractions. Stud-ies have clearly shown that systems such as ChatGPT often do\nnot produce language that is pragmatically appropriate. The lack of linguistic\nand cultural authenticity has important implications for how AI is integrated\ninto second language acquisition as well as in instruction targeting\ndevelopment of intercultural communication compe-tence.\n","authors":["Robert Godwin-Jones`"],"pdf_url":"https://arxiv.org/pdf/2410.14395v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14393v1","updated":"2024-10-18T11:55:34Z","published":"2024-10-18T11:55:34Z","title":"Debug Smarter, Not Harder: AI Agents for Error Resolution in\n  Computational Notebooks","summary":"  Computational notebooks became indispensable tools for research-related\ndevelopment, offering unprecedented interactivity and flexibility in the\ndevelopment process. However, these benefits come at the cost of\nreproducibility and an increased potential for bugs. With the rise of\ncode-fluent Large Language Models empowered with agentic techniques, smart\nbug-fixing tools with a high level of autonomy have emerged. However, those\ntools are tuned for classical script programming and still struggle with\nnon-linear computational notebooks. In this paper, we present an AI agent\ndesigned specifically for error resolution in a computational notebook. We have\ndeveloped an agentic system capable of exploring a notebook environment by\ninteracting with it -- similar to how a user would -- and integrated the system\ninto the JetBrains service for collaborative data science called Datalore. We\nevaluate our approach against the pre-existing single-action solution by\ncomparing costs and conducting a user study. Users rate the error resolution\ncapabilities of the agentic system higher but experience difficulties with UI.\nWe share the results of the study and consider them valuable for further\nimproving user-agent collaboration.\n","authors":["Konstantin Grotov","Artem Borzilov","Maksim Krivobok","Timofey Bryksin","Yaroslav Zharov"],"pdf_url":"https://arxiv.org/pdf/2410.14393v1.pdf","comment":"Accepted to EMNLP 2024 System Demonstrations"},{"id":"http://arxiv.org/abs/2410.14389v1","updated":"2024-10-18T11:49:40Z","published":"2024-10-18T11:49:40Z","title":"SurgeryV2: Bridging the Gap Between Model Merging and Multi-Task\n  Learning with Deep Representation Surgery","summary":"  Model merging-based multitask learning (MTL) offers a promising approach for\nperforming MTL by merging multiple expert models without requiring access to\nraw training data. However, in this paper, we examine the merged model's\nrepresentation distribution and uncover a critical issue of \"representation\nbias\". This bias arises from a significant distribution gap between the\nrepresentations of the merged and expert models, leading to the suboptimal\nperformance of the merged MTL model. To address this challenge, we first\npropose a representation surgery solution called Surgery. Surgery is a\nlightweight, task-specific module that aligns the final layer representations\nof the merged model with those of the expert models, effectively alleviating\nbias and improving the merged model's performance. Despite these improvements,\na performance gap remains compared to the traditional MTL method. Further\nanalysis reveals that representation bias phenomena exist at each layer of the\nmerged model, and aligning representations only in the last layer is\ninsufficient for fully reducing systemic bias because biases introduced at each\nlayer can accumulate and interact in complex ways. To tackle this, we then\npropose a more comprehensive solution, deep representation surgery (also called\nSurgeryV2), which mitigates representation bias across all layers, and thus\nbridges the performance gap between model merging-based MTL and traditional\nMTL. Finally, we design an unsupervised optimization objective to optimize both\nthe Surgery and SurgeryV2 modules. Our experimental results show that\nincorporating these modules into state-of-the-art (SOTA) model merging schemes\nleads to significant performance gains. Notably, our SurgeryV2 scheme reaches\nalmost the same level as individual expert models or the traditional MTL model.\nThe code is available at \\url{https://github.com/EnnengYang/SurgeryV2}.\n","authors":["Enneng Yang","Li Shen","Zhenyi Wang","Guibing Guo","Xingwei Wang","Xiaocun Cao","Jie Zhang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2410.14389v1.pdf","comment":"This paper is an extended version of our previous work\n  [arXiv:2402.02705] presented at ICML 2024"},{"id":"http://arxiv.org/abs/2407.01511v2","updated":"2024-10-18T11:29:39Z","published":"2024-07-01T17:55:04Z","title":"CRAB: Cross-environment Agent Benchmark for Multimodal Language Model\n  Agents","summary":"  The development of autonomous agents increasingly relies on Multimodal\nLanguage Models (MLMs) to perform tasks described in natural language with GUI\nenvironments, such as websites, desktop computers, or mobile phones. Existing\nbenchmarks for MLM agents in interactive environments are limited by their\nfocus on a single environment, lack of detailed and generalized evaluation\nmethods, and the complexities of constructing tasks and evaluators. To overcome\nthese limitations, we introduce Crab, the first agent benchmark framework\ndesigned to support cross-environment tasks, incorporating a graph-based\nfine-grained evaluation method and an efficient mechanism for task and\nevaluator construction. Our framework supports multiple devices and can be\neasily extended to any environment with a Python interface. Leveraging Crab, we\ndeveloped a cross-platform Crab Benchmark-v0 comprising 120 tasks in computer\ndesktop and mobile phone environments. We evaluated four advanced MLMs using\ndifferent single and multi-agent system configurations on this benchmark. The\nexperimental results demonstrate that the single agent with GPT-4o achieves the\nbest completion ratio of 38.01%. All framework code, agent code, and task\ndatasets are publicly available at https://github.com/camel-ai/crab.\n","authors":["Tianqi Xu","Linyao Chen","Dai-Jie Wu","Yanjun Chen","Zecheng Zhang","Xiang Yao","Zhiqiang Xie","Yongchao Chen","Shilong Liu","Bochen Qian","Anjie Yang","Zhaoxuan Jin","Jianbo Deng","Philip Torr","Bernard Ghanem","Guohao Li"],"pdf_url":"https://arxiv.org/pdf/2407.01511v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09388v2","updated":"2024-10-18T11:23:18Z","published":"2024-10-12T06:39:31Z","title":"3-D Magnetotelluric Deep Learning Inversion Guided by Pseudo-Physical\n  Information","summary":"  Magnetotelluric deep learning (DL) inversion methods based on joint\ndata-driven and physics-driven have become a hot topic in recent years. When\nmapping observation data (or forward modeling data) to the resistivity model\nusing neural networks (NNs), incorporating the error (loss) term of the\ninversion resistivity's forward modeling response--which introduces physical\ninformation about electromagnetic field propagation--can significantly enhance\nthe inversion accuracy. To efficiently achieve data-physical dual-driven MT\ndeep learning inversion for large-scale 3-D MT data, we propose using DL\nforward modeling networks to compute this portion of the loss. This approach\nintroduces pseudo-physical information through the forward modeling of NN\nsimulation, further guiding the inversion network fitting. Specifically, we\nfirst pre-train the forward modeling networks as fixed forward modeling\noperators, then transfer and integrate them into the inversion network\ntraining, and finally optimize the inversion network by minimizing the\nmultinomial loss. Theoretical experimental results indicate that despite some\nsimulation errors in DL forward modeling, the introduced pseudo-physical\ninformation still enhances inversion accuracy and significantly mitigates the\noverfitting problem during training. Additionally, we propose a new input mode\nthat involves masking and adding noise to the data, simulating the field data\nenvironment of 3-D MT inversion, thereby making the method more flexible and\neffective for practical applications.\n","authors":["Peifan Jiang","Xuben Wang","Shuang Wang","Fei Deng","Kunpeng Wang","Bin Wang","Yuhan Yang","Islam Fadel"],"pdf_url":"https://arxiv.org/pdf/2410.09388v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.15840v3","updated":"2024-10-18T11:22:32Z","published":"2024-04-24T12:28:27Z","title":"Constructive Interpolation and Concept-Based Beth Definability for\n  Description Logics via Sequents","summary":"  We introduce a constructive method applicable to a large number of\ndescription logics (DLs) for establishing the concept-based Beth definability\nproperty (CBP) based on sequent systems. Using the highly expressive DL RIQ as\na case study, we introduce novel sequent calculi for RIQ-ontologies and show\nhow certain interpolants can be computed from sequent calculus proofs, which\npermit the extraction of explicit definitions of implicitly definable concepts.\nTo the best of our knowledge, this is the first sequent-based approach to\ncomputing interpolants and definitions within the context of DLs, as well as\nthe first proof that RIQ enjoys the CBP. Moreover, due to the modularity of our\nsequent systems, our results hold for restrictions of RIQ, and are applicable\nto other DLs by suitable modifications.\n","authors":["Tim S. Lyon","Jonas Karge"],"pdf_url":"https://arxiv.org/pdf/2404.15840v3.pdf","comment":"Accepted to IJCAI 2024"},{"id":"http://arxiv.org/abs/2410.14371v1","updated":"2024-10-18T10:59:13Z","published":"2024-10-18T10:59:13Z","title":"Interpretable end-to-end Neurosymbolic Reinforcement Learning agents","summary":"  Deep reinforcement learning (RL) agents rely on shortcut learning, preventing\nthem from generalizing to slightly different environments. To address this\nproblem, symbolic method, that use object-centric states, have been developed.\nHowever, comparing these methods to deep agents is not fair, as these last\noperate from raw pixel-based states. In this work, we instantiate the symbolic\nSCoBots framework. SCoBots decompose RL tasks into intermediate, interpretable\nrepresentations, culminating in action decisions based on a comprehensible set\nof object-centric relational concepts. This architecture aids in demystifying\nagent decisions. By explicitly learning to extract object-centric\nrepresentations from raw states, object-centric RL, and policy distillation via\nrule extraction, this work places itself within the neurosymbolic AI paradigm,\nblending the strengths of neural networks with symbolic AI. We present the\nfirst implementation of an end-to-end trained SCoBot, separately evaluate of\nits components, on different Atari games. The results demonstrate the\nframework's potential to create interpretable and performing RL systems, and\npave the way for future research directions in obtaining end-to-end\ninterpretable RL agents.\n","authors":["Nils Grandien","Quentin Delfosse","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2410.14371v1.pdf","comment":"19 pages; 5 figures; 3 tables"},{"id":"http://arxiv.org/abs/2410.14368v1","updated":"2024-10-18T10:53:44Z","published":"2024-10-18T10:53:44Z","title":"CoMAL: Collaborative Multi-Agent Large Language Models for\n  Mixed-Autonomy Traffic","summary":"  The integration of autonomous vehicles into urban traffic has great potential\nto improve efficiency by reducing congestion and optimizing traffic flow\nsystematically. In this paper, we introduce CoMAL (Collaborative Multi-Agent\nLLMs), a framework designed to address the mixed-autonomy traffic problem by\ncollaboration among autonomous vehicles to optimize traffic flow. CoMAL is\nbuilt upon large language models, operating in an interactive traffic\nsimulation environment. It utilizes a Perception Module to observe surrounding\nagents and a Memory Module to store strategies for each agent. The overall\nworkflow includes a Collaboration Module that encourages autonomous vehicles to\ndiscuss the effective strategy and allocate roles, a reasoning engine to\ndetermine optimal behaviors based on assigned roles, and an Execution Module\nthat controls vehicle actions using a hybrid approach combining rule-based\nmodels. Experimental results demonstrate that CoMAL achieves superior\nperformance on the Flow benchmark. Additionally, we evaluate the impact of\ndifferent language models and compare our framework with reinforcement learning\napproaches. It highlights the strong cooperative capability of LLM agents and\npresents a promising solution to the mixed-autonomy traffic challenge. The code\nis available at https://github.com/Hyan-Yao/CoMAL.\n","authors":["Huaiyuan Yao","Longchao Da","Vishnu Nandam","Justin Turnau","Zhiwei Liu","Linsey Pang","Hua Wei"],"pdf_url":"https://arxiv.org/pdf/2410.14368v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01129v4","updated":"2024-10-18T10:46:43Z","published":"2024-08-02T09:18:41Z","title":"A Survey of Mamba","summary":"  As one of the most representative DL techniques, Transformer architecture has\nempowered numerous advanced models, especially the large language models (LLMs)\nthat comprise billions of parameters, becoming a cornerstone in deep learning.\nDespite the impressive achievements, Transformers still face inherent\nlimitations, particularly the time-consuming inference resulting from the\nquadratic computation complexity of attention calculation. Recently, a novel\narchitecture named Mamba, drawing inspiration from classical state space models\n(SSMs), has emerged as a promising alternative for building foundation models,\ndelivering comparable modeling abilities to Transformers while preserving\nnear-linear scalability concerning sequence length. This has sparked an\nincreasing number of studies actively exploring Mamba's potential to achieve\nimpressive performance across diverse domains. Given such rapid evolution,\nthere is a critical need for a systematic review that consolidates existing\nMamba-empowered models, offering a comprehensive understanding of this emerging\nmodel architecture. In this survey, we therefore conduct an in-depth\ninvestigation of recent Mamba-associated studies, covering three main aspects:\nthe advancements of Mamba-based models, the techniques of adapting Mamba to\ndiverse data, and the applications where Mamba can excel. Specifically, we\nfirst review the foundational knowledge of various representative deep learning\nmodels and the details of Mamba-1&2 as preliminaries. Then, to showcase the\nsignificance of Mamba for AI, we comprehensively review the related studies\nfocusing on Mamba models' architecture design, data adaptability, and\napplications. Finally, we present a discussion of current limitations and\nexplore various promising research directions to provide deeper insights for\nfuture investigations.\n","authors":["Haohao Qu","Liangbo Ning","Rui An","Wenqi Fan","Tyler Derr","Hui Liu","Xin Xu","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2408.01129v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14353v1","updated":"2024-10-18T10:16:07Z","published":"2024-10-18T10:16:07Z","title":"Assistive AI for Augmenting Human Decision-making","summary":"  Regulatory frameworks for the use of AI are emerging. However, they trail\nbehind the fast-evolving malicious AI technologies that can quickly cause\nlasting societal damage. In response, we introduce a pioneering Assistive AI\nframework designed to enhance human decision-making capabilities. This\nframework aims to establish a trust network across various fields, especially\nwithin legal contexts, serving as a proactive complement to ongoing regulatory\nefforts. Central to our framework are the principles of privacy,\naccountability, and credibility. In our methodology, the foundation of\nreliability of information and information sources is built upon the ability to\nuphold accountability, enhance security, and protect privacy. This approach\nsupports, filters, and potentially guides communication, thereby empowering\nindividuals and communities to make well-informed decisions based on\ncutting-edge advancements in AI. Our framework uses the concept of Boards as\nproxies to collectively ensure that AI-assisted decisions are reliable,\naccountable, and in alignment with societal values and legal standards. Through\na detailed exploration of our framework, including its main components,\noperations, and sample use cases, the paper shows how AI can assist in the\ncomplex process of decision-making while maintaining human oversight. The\nproposed framework not only extends regulatory landscapes but also highlights\nthe synergy between AI technology and human judgement, underscoring the\npotential of AI to serve as a vital instrument in discerning reality from\nfiction and thus enhancing the decision-making process. Furthermore, we provide\ndomain-specific use cases to highlight the applicability of our framework.\n","authors":["Natabara Máté Gyöngyössy","Bernát Török","Csilla Farkas","Laura Lucaj","Attila Menyhárd","Krisztina Menyhárd-Balázs","András Simonyi","Patrick van der Smagt","Zsolt Ződi","András Lőrincz"],"pdf_url":"https://arxiv.org/pdf/2410.14353v1.pdf","comment":"37 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.10859v2","updated":"2024-10-18T10:02:03Z","published":"2024-10-07T13:46:06Z","title":"FAME: Towards Factual Multi-Task Model Editing","summary":"  Large language models (LLMs) embed extensive knowledge and utilize it to\nperform exceptionally well across various tasks. Nevertheless, outdated\nknowledge or factual errors within LLMs can lead to misleading or incorrect\nresponses, causing significant issues in practical applications. To rectify the\nfatal flaw without the necessity for costly model retraining, various model\nediting approaches have been proposed to correct inaccurate knowledge within\nLLMs in a cost-efficient way. To evaluate these model editing methods, previous\nwork introduced a series of datasets. However, most of the previous datasets\nonly contain fabricated data in a single format, which diverges from real-world\nmodel editing scenarios, raising doubts about their usability in practice. To\nfacilitate the application of model editing in real-world scenarios, we propose\nthe challenge of practicality. To resolve such challenges and effectively\nenhance the capabilities of LLMs, we present FAME, an factual, comprehensive,\nand multi-task dataset, which is designed to enhance the practicality of model\nediting. We then propose SKEME, a model editing method that uses a novel\ncaching mechanism to ensure synchronization with the real world. The\nexperiments demonstrate that SKEME performs excellently across various tasks\nand scenarios, confirming its practicality.\n","authors":["Li Zeng","Yingyu Shan","Zeming Liu","Jiashu Yao","Yuhang Guo"],"pdf_url":"https://arxiv.org/pdf/2410.10859v2.pdf","comment":"9 pages, 3 figures. This paper has been accepted by EMNLP 2024"},{"id":"http://arxiv.org/abs/2302.08102v2","updated":"2024-10-18T09:58:45Z","published":"2023-02-16T06:01:31Z","title":"Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech\n  Recognition","summary":"  Visual Speech Recognition (VSR) aims to infer speech into text depending on\nlip movements alone. As it focuses on visual information to model the speech,\nits performance is inherently sensitive to personal lip appearances and\nmovements, and this makes the VSR models show degraded performance when they\nare applied to unseen speakers. In this paper, to remedy the performance\ndegradation of the VSR model on unseen speakers, we propose prompt tuning\nmethods of Deep Neural Networks (DNNs) for speaker-adaptive VSR. Specifically,\nmotivated by recent advances in Natural Language Processing (NLP), we finetune\nprompts on adaptation data of target speakers instead of modifying the\npre-trained model parameters. Different from the previous prompt tuning methods\nmainly limited to Transformer variant architecture, we explore different types\nof prompts, the addition, the padding, and the concatenation form prompts that\ncan be applied to the VSR model which is composed of CNN and Transformer in\ngeneral. With the proposed prompt tuning, we show that the performance of the\npre-trained VSR model on unseen speakers can be largely improved by using a\nsmall amount of adaptation data (e.g., less than 5 minutes), even if the\npre-trained model is already developed with large speaker variations. Moreover,\nby analyzing the performance and parameters of different types of prompts, we\ninvestigate when the prompt tuning is preferred over the finetuning methods.\nThe effectiveness of the proposed method is evaluated on both word- and\nsentence-level VSR databases, LRW-ID and GRID.\n","authors":["Minsu Kim","Hyung-Il Kim","Yong Man Ro"],"pdf_url":"https://arxiv.org/pdf/2302.08102v2.pdf","comment":"IEEE TPAMI"},{"id":"http://arxiv.org/abs/2410.14347v1","updated":"2024-10-18T09:57:59Z","published":"2024-10-18T09:57:59Z","title":"A Scientific Machine Learning Approach for Predicting and Forecasting\n  Battery Degradation in Electric Vehicles","summary":"  Carbon emissions are rising at an alarming rate, posing a significant threat\nto global efforts to mitigate climate change. Electric vehicles have emerged as\na promising solution, but their reliance on lithium-ion batteries introduces\nthe critical challenge of battery degradation. Accurate prediction and\nforecasting of battery degradation over both short and long time spans are\nessential for optimizing performance, extending battery life, and ensuring\neffective long-term energy management. This directly influences the\nreliability, safety, and sustainability of EVs, supporting their widespread\nadoption and aligning with key UN SDGs. In this paper, we present a novel\napproach to the prediction and long-term forecasting of battery degradation\nusing Scientific Machine Learning framework which integrates domain knowledge\nwith neural networks, offering more interpretable and scientifically grounded\nsolutions for both predicting short-term battery health and forecasting\ndegradation over extended periods. This hybrid approach captures both known and\nunknown degradation dynamics, improving predictive accuracy while reducing data\nrequirements. We incorporate ground-truth data to inform our models, ensuring\nthat both the predictions and forecasts reflect practical conditions. The model\nachieved MSE of 9.90 with the UDE and 11.55 with the NeuralODE, in experimental\ndata, a loss of 1.6986 with the UDE, and a MSE of 2.49 in the NeuralODE,\ndemonstrating the enhanced precision of our approach. This integration of\ndata-driven insights with SciML's strengths in interpretability and scalability\nallows for robust battery management. By enhancing battery longevity and\nminimizing waste, our approach contributes to the sustainability of energy\nsystems and accelerates the global transition toward cleaner, more responsible\nenergy solutions, aligning with the UN's SDG agenda.\n","authors":["Sharv Murgai","Hrishikesh Bhagwat","Raj Abhijit Dandekar","Rajat Dandekar","Sreedath Panat"],"pdf_url":"https://arxiv.org/pdf/2410.14347v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.06750v2","updated":"2024-10-18T09:43:09Z","published":"2024-04-10T05:34:07Z","title":"Frontier AI Ethics: Anticipating and Evaluating the Societal Impacts of\n  Language Model Agents","summary":"  Some have criticised Generative AI Systems for replicating the familiar\npathologies of already widely-deployed AI systems. Other critics highlight how\nthey foreshadow vastly more powerful future systems, which might threaten\nhumanity's survival. The first group says there is nothing new here; the other\nlooks through the present to a perhaps distant horizon. In this paper, I\ninstead pay attention to what makes these particular systems distinctive: both\ntheir remarkable scientific achievement, and the most likely and consequential\nways in which they will change society over the next five to ten years. In\nparticular, I explore the potential societal impacts and normative questions\nraised by the looming prospect of 'Language Model Agents', in which multimodal\nlarge language models (LLMs) form the executive centre of complex, tool-using\nAI systems that can take unsupervised sequences of actions towards some goal.\n","authors":["Seth Lazar"],"pdf_url":"https://arxiv.org/pdf/2404.06750v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11677v2","updated":"2024-10-18T09:41:53Z","published":"2024-10-15T15:14:22Z","title":"Understanding Likelihood Over-optimisation in Direct Alignment\n  Algorithms","summary":"  Direct Alignment Algorithms (DAAs), such as Direct Preference Optimisation\n(DPO) and Identity Preference Optimisation (IPO), have emerged as alternatives\nto online Reinforcement Learning from Human Feedback (RLHF) algorithms such as\nProximal Policy Optimisation (PPO) for aligning language models to human\npreferences, without the need for explicit reward modelling. These methods\ngenerally aim to increase the likelihood of generating better (preferred)\ncompletions while discouraging worse (non-preferred) ones, while staying close\nto the original model's behaviour. In this work, we explore the relationship\nbetween completion likelihood and model performance in state-of-the-art DAAs,\nand identify a critical issue of likelihood over-optimisation. Contrary to\nexpectations, we find that higher likelihood of better completions and larger\nmargins between better and worse completion likelihoods do not necessarily lead\nto better performance, and may even degrade it. Our analysis reveals that while\nhigher likelihood correlates with better memorisation of factual knowledge\npatterns, a slightly lower completion likelihood tends to improve output\ndiversity, thus leading to better generalisation to unseen scenarios. Moreover,\nwe identify two key indicators that signal when over-optimised output diversity\nbegins to harm performance: Decreasing Entropy over Top-k Tokens and\nDiminishing Top-k Probability Mass. Our experimental results validate that\nthese indicators are reliable signs of declining performance under different\nregularisations, helping prevent over-optimisation and improve alignment with\nhuman preferences.\n","authors":["Zhengyan Shi","Sander Land","Acyr Locatelli","Matthieu Geist","Max Bartolo"],"pdf_url":"https://arxiv.org/pdf/2410.11677v2.pdf","comment":"Preprint Version"},{"id":"http://arxiv.org/abs/2410.10291v2","updated":"2024-10-18T09:26:46Z","published":"2024-10-14T08:45:35Z","title":"Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal\n  Perspective","summary":"  Accurate interpretation and visualization of human instructions are crucial\nfor text-to-image (T2I) synthesis. However, current models struggle to capture\nsemantic variations from word order changes, and existing evaluations, relying\non indirect metrics like text-image similarity, fail to reliably assess these\nchallenges. This often obscures poor performance on complex or uncommon\nlinguistic patterns by the focus on frequent word combinations. To address\nthese deficiencies, we propose a novel metric called SemVarEffect and a\nbenchmark named SemVarBench, designed to evaluate the causality between\nsemantic variations in inputs and outputs in T2I synthesis. Semantic variations\nare achieved through two types of linguistic permutations, while avoiding\neasily predictable literal variations. Experiments reveal that the\nCogView-3-Plus and Ideogram 2 performed the best, achieving a score of 0.2/1.\nSemantic variations in object relations are less understood than attributes,\nscoring 0.07/1 compared to 0.17-0.19/1. We found that cross-modal alignment in\nUNet or Transformers plays a crucial role in handling semantic variations, a\nfactor previously overlooked by a focus on textual encoders. Our work\nestablishes an effective evaluation framework that advances the T2I synthesis\ncommunity's exploration of human instruction understanding. Our benchmark and\ncode are available at https://github.com/zhuxiangru/SemVarBench .\n","authors":["Xiangru Zhu","Penglei Sun","Yaoxian Song","Yanghua Xiao","Zhixu Li","Chengyu Wang","Jun Huang","Bei Yang","Xiaoxiao Xu"],"pdf_url":"https://arxiv.org/pdf/2410.10291v2.pdf","comment":"The only change in the current version update is the replacement of\n  the template with a more precise one"},{"id":"http://arxiv.org/abs/2410.14311v1","updated":"2024-10-18T09:17:18Z","published":"2024-10-18T09:17:18Z","title":"Game Theory with Simulation in the Presence of Unpredictable\n  Randomisation","summary":"  AI agents will be predictable in certain ways that traditional agents are\nnot. Where and how can we leverage this predictability in order to improve\nsocial welfare? We study this question in a game-theoretic setting where one\nagent can pay a fixed cost to simulate the other in order to learn its mixed\nstrategy. As a negative result, we prove that, in contrast to prior work on\npure-strategy simulation, enabling mixed-strategy simulation may no longer lead\nto improved outcomes for both players in all so-called \"generalised trust\ngames\". In fact, mixed-strategy simulation does not help in any game where the\nsimulatee's action can depend on that of the simulator. We also show that, in\ngeneral, deciding whether simulation introduces Pareto-improving Nash\nequilibria in a given game is NP-hard. As positive results, we establish that\nmixed-strategy simulation can improve social welfare if the simulator has the\noption to scale their level of trust, if the players face challenges with both\ntrust and coordination, or if maintaining some level of privacy is essential\nfor enabling cooperation.\n","authors":["Vojtech Kovarik","Nathaniel Sauerberg","Lewis Hammond","Vincent Conitzer"],"pdf_url":"https://arxiv.org/pdf/2410.14311v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14310v1","updated":"2024-10-18T09:15:47Z","published":"2024-10-18T09:15:47Z","title":"Transferring Tactile Data Across Sensors","summary":"  Tactile perception is essential for human interaction with the environment\nand is becoming increasingly crucial in robotics. Tactile sensors like the\nBioTac mimic human fingertips and provide detailed interaction data. Despite\nits utility in applications like slip detection and object identification, this\nsensor is now deprecated, making many existing datasets obsolete. This article\nintroduces a novel method for translating data between tactile sensors by\nexploiting sensor deformation information rather than output signals. We\ndemonstrate the approach by translating BioTac signals into the DIGIT sensor.\nOur framework consists of three steps: first, converting signal data into\ncorresponding 3D deformation meshes; second, translating these 3D deformation\nmeshes from one sensor to another; and third, generating output images using\nthe converted meshes. Our approach enables the continued use of valuable\ndatasets.\n","authors":["Wadhah Zai El Amri","Malte Kuhlmann","Nicolás Navarro-Guerrero"],"pdf_url":"https://arxiv.org/pdf/2410.14310v1.pdf","comment":"Extended Abstract. Accepted in ICRA@40 (40th Anniversary of the IEEE\n  International Conference on Robotics and Automation) 23-26 September, 2024\n  Rotterdam, Netherlands"},{"id":"http://arxiv.org/abs/2410.14309v1","updated":"2024-10-18T09:15:35Z","published":"2024-10-18T09:15:35Z","title":"LoGU: Long-form Generation with Uncertainty Expressions","summary":"  While Large Language Models (LLMs) demonstrate impressive capabilities, they\nstill struggle with generating factually incorrect content (i.e.,\nhallucinations). A promising approach to mitigate this issue is enabling models\nto express uncertainty when unsure. Previous research on uncertainty modeling\nhas primarily focused on short-form QA, but realworld applications often\nrequire much longer responses. In this work, we introduce the task of Long-form\nGeneration with Uncertainty(LoGU). We identify two key challenges: Uncertainty\nSuppression, where models hesitate to express uncertainty, and Uncertainty\nMisalignment, where models convey uncertainty inaccurately. To tackle these\nchallenges, we propose a refinement-based data collection framework and a\ntwo-stage training pipeline. Our framework adopts a divide-and-conquer\nstrategy, refining uncertainty based on atomic claims. The collected data are\nthen used in training through supervised fine-tuning (SFT) and direct\npreference optimization (DPO) to enhance uncertainty expression. Extensive\nexperiments on three long-form instruction following datasets show that our\nmethod significantly improves accuracy, reduces hallucinations, and maintains\nthe comprehensiveness of responses.\n","authors":["Ruihan Yang","Caiqi Zhang","Zhisong Zhang","Xinting Huang","Sen Yang","Nigel Collier","Dong Yu","Deqing Yang"],"pdf_url":"https://arxiv.org/pdf/2410.14309v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12013v2","updated":"2024-10-18T08:57:30Z","published":"2024-06-26T12:33:34Z","title":"Dating ancient manuscripts using radiocarbon and AI-based writing style\n  analysis","summary":"  Determining the chronology of ancient handwritten manuscripts is essential\nfor reconstructing the evolution of ideas. For the Dead Sea Scrolls, this is\nparticularly important. However, there is an almost complete lack of\ndate-bearing manuscripts evenly distributed across the timeline and written in\nsimilar scripts available for palaeographic comparison. Here, we present Enoch,\na state-of-the-art AI-based date-prediction model, trained on the basis of new\nradiocarbon-dated samples of the scrolls. Enoch uses established\nhandwriting-style descriptors and applies Bayesian ridge regression. The\nchallenge of this study is that the number of radiocarbon-dated manuscripts is\nsmall, while current machine learning requires an abundance of training data.\nWe show that by using combined angular and allographic writing style feature\nvectors and applying Bayesian ridge regression, Enoch could predict the\nradiocarbon-based dates from style, supported by leave-one-out validation, with\nvaried MAEs of 27.9 to 30.7 years relative to the radiocarbon dating. Enoch was\nthen used to estimate the dates of 135 unseen manuscripts, revealing that 79\nper cent of the samples were considered 'realistic' upon palaeographic post-hoc\nevaluation. We present a new chronology of the scrolls. The radiocarbon ranges\nand Enoch's style-based predictions are often older than the traditionally\nassumed palaeographic estimates. In the range of 300-50 BCE, Enoch's date\nprediction provides an improved granularity. The study is in line with current\ndevelopments in multimodal machine-learning techniques, and the methods can be\nused for date prediction in other partially-dated manuscript collections. This\nresearch shows how Enoch's quantitative, probability-based approach can be a\ntool for palaeographers and historians, re-dating ancient Jewish key texts and\ncontributing to current debates on Jewish and Christian origins.\n","authors":["Mladen Popović","Maruf A. Dhali","Lambert Schomaker","Johannes van der Plicht","Kaare Lund Rasmussen","Jacopo La Nasa","Ilaria Degano","Maria Perla Colombini","Eibert Tigchelaar"],"pdf_url":"https://arxiv.org/pdf/2407.12013v2.pdf","comment":"16 pages of main article, 103 pages of supplementary materials; the\n  first version of this article is originally prepared in July 2023 after the\n  completion of all the experiments"},{"id":"http://arxiv.org/abs/2410.13754v2","updated":"2024-10-18T08:56:52Z","published":"2024-10-17T16:52:28Z","title":"MixEval-X: Any-to-Any Evaluations from Real-World Data Mixtures","summary":"  Perceiving and generating diverse modalities are crucial for AI models to\neffectively learn from and engage with real-world signals, necessitating\nreliable evaluations for their development. We identify two major issues in\ncurrent evaluations: (1) inconsistent standards, shaped by different\ncommunities with varying protocols and maturity levels; and (2) significant\nquery, grading, and generalization biases. To address these, we introduce\nMixEval-X, the first any-to-any, real-world benchmark designed to optimize and\nstandardize evaluations across diverse input and output modalities. We propose\nmulti-modal benchmark mixture and adaptation-rectification pipelines to\nreconstruct real-world task distributions, ensuring evaluations generalize\neffectively to real-world use cases. Extensive meta-evaluations show our\napproach effectively aligns benchmark samples with real-world task\ndistributions. Meanwhile, MixEval-X's model rankings correlate strongly with\nthat of crowd-sourced real-world evaluations (up to 0.98) while being much more\nefficient. We provide comprehensive leaderboards to rerank existing models and\norganizations and offer insights to enhance understanding of multi-modal\nevaluations and inform future research.\n","authors":["Jinjie Ni","Yifan Song","Deepanway Ghosal","Bo Li","David Junhao Zhang","Xiang Yue","Fuzhao Xue","Zian Zheng","Kaichen Zhang","Mahir Shah","Kabir Jain","Yang You","Michael Shieh"],"pdf_url":"https://arxiv.org/pdf/2410.13754v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.20680v4","updated":"2024-10-18T08:54:37Z","published":"2024-05-31T08:22:49Z","title":"Unraveling and Mitigating Retriever Inconsistencies in\n  Retrieval-Augmented Large Language Models","summary":"  Although Retrieval-Augmented Large Language Models (RALMs) demonstrate their\nsuperiority in terms of factuality, they do not consistently outperform the\noriginal retrieval-free Language Models (LMs). Our experiments reveal that this\nexample-level performance inconsistency exists not only between\nretrieval-augmented and retrieval-free LM but also among different retrievers.\nTo understand this phenomenon, we investigate the degeneration behavior of\nRALMs and theoretically decompose it into four categories. Further analysis\nbased on our decomposition reveals that the innate difference in knowledge\nsources and the unpredictable degeneration of the reader model contribute most\nto the inconsistency. Drawing from our analysis, we introduce Ensemble of\nRetrievers (EoR), a trainable framework that can adaptively retrieve from\ndifferent knowledge sources and effectively decrease unpredictable reader\nerrors. Our experiments on Open Domain Question Answering show that EoR\nsubstantially improves performance over the RALM with a single retriever by\nconsiderably reducing inconsistent behaviors.\n","authors":["Mingda Li","Xinyu Li","Yifan Chen","Wenfeng Xuan","Weinan Zhang"],"pdf_url":"https://arxiv.org/pdf/2405.20680v4.pdf","comment":"ACL 2024 (findings)"},{"id":"http://arxiv.org/abs/2410.14289v1","updated":"2024-10-18T08:49:24Z","published":"2024-10-18T08:49:24Z","title":"SwaQuAD-24: QA Benchmark Dataset in Swahili","summary":"  This paper proposes the creation of a Swahili Question Answering (QA)\nbenchmark dataset, aimed at addressing the underrepresentation of Swahili in\nnatural language processing (NLP). Drawing from established benchmarks like\nSQuAD, GLUE, KenSwQuAD, and KLUE, the dataset will focus on providing\nhigh-quality, annotated question-answer pairs that capture the linguistic\ndiversity and complexity of Swahili. The dataset is designed to support a\nvariety of applications, including machine translation, information retrieval,\nand social services like healthcare chatbots. Ethical considerations, such as\ndata privacy, bias mitigation, and inclusivity, are central to the dataset\ndevelopment. Additionally, the paper outlines future expansion plans to include\ndomain-specific content, multimodal integration, and broader crowdsourcing\nefforts. The Swahili QA dataset aims to foster technological innovation in East\nAfrica and provide an essential resource for NLP research and applications in\nlow-resource languages.\n","authors":["Alfred Malengo Kondoro"],"pdf_url":"https://arxiv.org/pdf/2410.14289v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14285v1","updated":"2024-10-18T08:40:26Z","published":"2024-10-18T08:40:26Z","title":"Advanced Underwater Image Quality Enhancement via Hybrid\n  Super-Resolution Convolutional Neural Networks and Multi-Scale Retinex-Based\n  Defogging Techniques","summary":"  The difficulties of underwater image degradation due to light scattering,\nabsorption, and fog-like particles which lead to low resolution and poor\nvisibility are discussed in this study report. We suggest a sophisticated\nhybrid strategy that combines Multi-Scale Retinex (MSR) defogging methods with\nSuper-Resolution Convolutional Neural Networks (SRCNN) to address these\nproblems. The Retinex algorithm mimics human visual perception to reduce uneven\nlighting and fogging, while the SRCNN component improves the spatial resolution\nof underwater photos.Through the combination of these methods, we are able to\nenhance the clarity, contrast, and colour restoration of underwater images,\noffering a reliable way to improve image quality in difficult underwater\nconditions. The research conducts extensive experiments on real-world\nunderwater datasets to further illustrate the efficacy of the suggested\napproach. In terms of sharpness, visibility, and feature retention,\nquantitative evaluation which use metrics like the Structural Similarity Index\nMeasure (SSIM) and Peak Signal-to-Noise Ratio (PSNR) demonstrates notable\nadvances over conventional techniques.In real-time underwater applications like\nmarine exploration, underwater robotics, and autonomous underwater vehicles,\nwhere clear and high-resolution imaging is crucial for operational success, the\ncombination of deep learning and conventional image processing techniques\noffers a computationally efficient framework with superior results.\n","authors":["Yugandhar Reddy Gogireddy","Jithendra Reddy Gogireddy"],"pdf_url":"https://arxiv.org/pdf/2410.14285v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13196v2","updated":"2024-10-18T08:33:19Z","published":"2024-10-17T03:56:12Z","title":"Context-Enhanced Multi-View Trajectory Representation Learning: Bridging\n  the Gap through Self-Supervised Models","summary":"  Modeling trajectory data with generic-purpose dense representations has\nbecome a prevalent paradigm for various downstream applications, such as\ntrajectory classification, travel time estimation and similarity computation.\nHowever, existing methods typically rely on trajectories from a single spatial\nview, limiting their ability to capture the rich contextual information that is\ncrucial for gaining deeper insights into movement patterns across different\ngeospatial contexts. To this end, we propose MVTraj, a novel multi-view\nmodeling method for trajectory representation learning. MVTraj integrates\ndiverse contextual knowledge, from GPS to road network and points-of-interest\nto provide a more comprehensive understanding of trajectory data. To align the\nlearning process across multiple views, we utilize GPS trajectories as a bridge\nand employ self-supervised pretext tasks to capture and distinguish movement\npatterns across different spatial views. Following this, we treat trajectories\nfrom different views as distinct modalities and apply a hierarchical\ncross-modal interaction module to fuse the representations, thereby enriching\nthe knowledge derived from multiple sources. Extensive experiments on\nreal-world datasets demonstrate that MVTraj significantly outperforms existing\nbaselines in tasks associated with various spatial views, validating its\neffectiveness and practical utility in spatio-temporal modeling.\n","authors":["Tangwen Qian","Junhe Li","Yile Chen","Gao Cong","Tao Sun","Fei Wang","Yongjun Xu"],"pdf_url":"https://arxiv.org/pdf/2410.13196v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14273v1","updated":"2024-10-18T08:27:02Z","published":"2024-10-18T08:27:02Z","title":"REEF: Representation Encoding Fingerprints for Large Language Models","summary":"  Protecting the intellectual property of open-source Large Language Models\n(LLMs) is very important, because training LLMs costs extensive computational\nresources and data. Therefore, model owners and third parties need to identify\nwhether a suspect model is a subsequent development of the victim model. To\nthis end, we propose a training-free REEF to identify the relationship between\nthe suspect and victim models from the perspective of LLMs' feature\nrepresentations. Specifically, REEF computes and compares the centered kernel\nalignment similarity between the representations of a suspect model and a\nvictim model on the same samples. This training-free REEF does not impair the\nmodel's general capabilities and is robust to sequential fine-tuning, pruning,\nmodel merging, and permutations. In this way, REEF provides a simple and\neffective way for third parties and models' owners to protect LLMs'\nintellectual property together. The code is available at\nhttps://github.com/tmylla/REEF.\n","authors":["Jie Zhang","Dongrui Liu","Chen Qian","Linfeng Zhang","Yong Liu","Yu Qiao","Jing Shao"],"pdf_url":"https://arxiv.org/pdf/2410.14273v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.02512v2","updated":"2024-10-18T08:25:52Z","published":"2024-05-03T22:55:56Z","title":"SatSwinMAE: Efficient Autoencoding for Multiscale Time-series Satellite\n  Imagery","summary":"  Recent advancements in foundation models have significantly impacted various\nfields, including natural language processing, computer vision, and multi-modal\ntasks. One area that stands to benefit greatly is Earth observation, where\nthese models can efficiently process large-scale, unlabeled geospatial data. In\nthis work we extend the SwinMAE model to integrate temporal information for\nsatellite time-series data. The architecture employs a hierarchical 3D Masked\nAutoencoder (MAE) with Video Swin Transformer blocks to effectively capture\nmulti-scale spatio-temporal dependencies in satellite imagery. To enhance\ntransfer learning, we incorporate both encoder and decoder pretrained weights,\nalong with skip connections to preserve scale-specific information. This forms\nan architecture similar to SwinUNet with an additional temporal component. Our\napproach shows significant performance improvements over existing\nstate-of-the-art foundation models for all the evaluated downstream tasks: land\ncover segmentation, building density prediction, flood mapping, wildfire scar\nmapping and multi-temporal crop segmentation. Particularly, in the land cover\nsegmentation task of the PhilEO Bench dataset, it outperforms other geospatial\nfoundation models with a 10.4% higher accuracy.\n","authors":["Yohei Nakayama","Jiawei Su","Luis M. Pazos-Outón"],"pdf_url":"https://arxiv.org/pdf/2405.02512v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.06572v2","updated":"2024-10-18T08:20:38Z","published":"2024-06-03T17:07:46Z","title":"Graph Neural Network Enhanced Retrieval for Question Answering of LLMs","summary":"  Retrieval augmented generation has revolutionized large language model (LLM)\noutputs by providing factual supports. Nevertheless, it struggles to capture\nall the necessary knowledge for complex reasoning questions. Existing retrieval\nmethods typically divide reference documents into passages, treating them in\nisolation. These passages, however, are often interrelated, such as passages\nthat are contiguous or share the same keywords. Therefore, it is crucial to\nrecognize such relatedness for enhancing the retrieval process. In this paper,\nwe propose a novel retrieval method, called GNN-Ret, which leverages graph\nneural networks (GNNs) to enhance retrieval by exploiting the relatedness\nbetween passages. Specifically, we first construct a graph of passages by\nconnecting passages that are structure-related or keyword-related. A graph\nneural network (GNN) is then leveraged to exploit the relationships between\npassages and improve the retrieval of supporting passages. Furthermore, we\nextend our method to handle multi-hop reasoning questions using a recurrent\ngraph neural network (RGNN), named RGNN-Ret. At each step, RGNN-Ret integrates\nthe graphs of passages from previous steps, thereby enhancing the retrieval of\nsupporting passages. Extensive experiments on benchmark datasets demonstrate\nthat GNN-Ret achieves higher accuracy for question answering with a single\nquery of LLMs than strong baselines that require multiple queries, and RGNN-Ret\nfurther improves accuracy and achieves state-of-the-art performance, with up to\n10.4% accuracy improvement on the 2WikiMQA dataset.\n","authors":["Zijian Li","Qingyan Guo","Jiawei Shao","Lei Song","Jiang Bian","Jun Zhang","Rui Wang"],"pdf_url":"https://arxiv.org/pdf/2406.06572v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2403.13784v6","updated":"2024-10-18T08:20:22Z","published":"2024-03-20T17:47:08Z","title":"The Model Openness Framework: Promoting Completeness and Openness for\n  Reproducibility, Transparency, and Usability in Artificial Intelligence","summary":"  Generative artificial intelligence (AI) offers numerous opportunities for\nresearch and innovation, but its commercialization has raised concerns about\nthe transparency and safety of frontier AI models. Most models lack the\nnecessary components for full understanding, auditing, and reproducibility, and\nsome model producers use restrictive licenses whilst claiming that their models\nare \"open source\". To address these concerns, we introduce the Model Openness\nFramework (MOF), a three-tiered ranked classification system that rates machine\nlearning models based on their completeness and openness, following open\nscience principles. For each MOF class, we specify code, data, and\ndocumentation components of the model development lifecycle that must be\nreleased and under which open licenses. In addition, the Model Openness Tool\n(MOT) provides a user-friendly reference implementation to evaluate the\nopenness and completeness of models against the MOF classification system.\nTogether, the MOF and MOT provide timely practical guidance for (i) model\nproducers to enhance the openness and completeness of their publicly-released\nmodels, and (ii) model consumers to identify open models and their constituent\ncomponents that can be permissively used, studied, modified, and redistributed.\nThrough the MOF, we seek to establish completeness and openness as core tenets\nof responsible AI research and development, and to promote best practices in\nthe burgeoning open AI ecosystem.\n","authors":["Matt White","Ibrahim Haddad","Cailean Osborne","Xiao-Yang Yanglet Liu","Ahmed Abdelmonsef","Sachin Varghese","Arnaud Le Hors"],"pdf_url":"https://arxiv.org/pdf/2403.13784v6.pdf","comment":"28 pages, 4 figures, 2 tables"},{"id":"http://arxiv.org/abs/2410.14257v1","updated":"2024-10-18T08:05:37Z","published":"2024-10-18T08:05:37Z","title":"Revisiting SLO and Goodput Metrics in LLM Serving","summary":"  Large language models (LLMs) have achieved remarkable performance and are\nwidely deployed in various applications, while the serving of LLM inference has\nraised concerns about user experience and serving throughput. Accordingly,\nservice level objectives (SLOs) and goodput-the number of requests that meet\nSLOs per second-are introduced to evaluate the performance of LLM serving.\nHowever, existing metrics fail to capture the nature of user experience. We\nobserve two ridiculous phenomena in existing metrics: 1) delaying token\ndelivery can smooth the tail time between tokens (tail TBT) of a request and 2)\ndropping the request that fails to meet the SLOs midway can improve goodput.\n  In this paper, we revisit SLO and goodput metrics in LLM serving and propose\na unified metric framework smooth goodput including SLOs and goodput to reflect\nthe nature of user experience in LLM serving. The framework can adapt to\nspecific goals of different tasks by setting parameters. We re-evaluate the\nperformance of different LLM serving systems under multiple workloads based on\nthis unified framework and provide possible directions for future optimization\nof existing strategies. We hope that this framework can provide a unified\nstandard for evaluating LLM serving and foster researches in the field of LLM\nserving optimization to move in a cohesive direction.\n","authors":["Zhibin Wang","Shipeng Li","Yuhang Zhou","Xue Li","Rong Gu","Nguyen Cam-Tu","Chen Tian","Sheng Zhong"],"pdf_url":"https://arxiv.org/pdf/2410.14257v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14255v1","updated":"2024-10-18T08:04:36Z","published":"2024-10-18T08:04:36Z","title":"Nova: An Iterative Planning and Search Approach to Enhance Novelty and\n  Diversity of LLM Generated Ideas","summary":"  Scientific innovation is pivotal for humanity, and harnessing large language\nmodels (LLMs) to generate research ideas could transform discovery. However,\nexisting LLMs often produce simplistic and repetitive suggestions due to their\nlimited ability in acquiring external knowledge for innovation. To address this\nproblem, we introduce an enhanced planning and search methodology designed to\nboost the creative potential of LLM-based systems. Our approach involves an\niterative process to purposely plan the retrieval of external knowledge,\nprogressively enriching the idea generation with broader and deeper insights.\nValidation through automated and human assessments indicates that our framework\nsubstantially elevates the quality of generated ideas, particularly in novelty\nand diversity. The number of unique novel ideas produced by our framework is\n3.4 times higher than without it. Moreover, our method outperforms the current\nstate-of-the-art, generating at least 2.5 times more top-rated ideas based on\n170 seed papers in a Swiss Tournament evaluation.\n","authors":["Xiang Hu","Hongyu Fu","Jinge Wang","Yifeng Wang","Zhikun Li","Renjun Xu","Yu Lu","Yaochu Jin","Lili Pan","Zhenzhong Lan"],"pdf_url":"https://arxiv.org/pdf/2410.14255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.17524v4","updated":"2024-10-18T08:03:02Z","published":"2024-04-26T16:41:00Z","title":"On the Use of Large Language Models to Generate Capability Ontologies","summary":"  Capability ontologies are increasingly used to model functionalities of\nsystems or machines. The creation of such ontological models with all\nproperties and constraints of capabilities is very complex and can only be done\nby ontology experts. However, Large Language Models (LLMs) have shown that they\ncan generate machine-interpretable models from natural language text input and\nthus support engineers / ontology experts. Therefore, this paper investigates\nhow LLMs can be used to create capability ontologies. We present a study with a\nseries of experiments in which capabilities with varying complexities are\ngenerated using different prompting techniques and with different LLMs. Errors\nin the generated ontologies are recorded and compared. To analyze the quality\nof the generated ontologies, a semi-automated approach based on RDF syntax\nchecking, OWL reasoning, and SHACL constraints is used. The results of this\nstudy are very promising because even for complex capabilities, the generated\nontologies are almost free of errors.\n","authors":["Luis Miguel Vieira da Silva","Aljosha Köcher","Felix Gehlhoff","Alexander Fay"],"pdf_url":"https://arxiv.org/pdf/2404.17524v4.pdf","comment":"\\c{opyright} 2024 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2410.14673v1","updated":"2024-10-18T17:59:25Z","published":"2024-10-18T17:59:25Z","title":"Self-supervised contrastive learning performs non-linear system\n  identification","summary":"  Self-supervised learning (SSL) approaches have brought tremendous success\nacross many tasks and domains. It has been argued that these successes can be\nattributed to a link between SSL and identifiable representation learning:\nTemporal structure and auxiliary variables ensure that latent representations\nare related to the true underlying generative factors of the data. Here, we\ndeepen this connection and show that SSL can perform system identification in\nlatent space. We propose DynCL, a framework to uncover linear, switching linear\nand non-linear dynamics under a non-linear observation model, give theoretical\nguarantees and validate them empirically.\n","authors":["Rodrigo González Laiz","Tobias Schmidt","Steffen Schneider"],"pdf_url":"https://arxiv.org/pdf/2410.14673v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14670v1","updated":"2024-10-18T17:58:53Z","published":"2024-10-18T17:58:53Z","title":"Decomposing The Dark Matter of Sparse Autoencoders","summary":"  Sparse autoencoders (SAEs) are a promising technique for decomposing language\nmodel activations into interpretable linear features. However, current SAEs\nfall short of completely explaining model performance, resulting in \"dark\nmatter\": unexplained variance in activations. This work investigates dark\nmatter as an object of study in its own right. Surprisingly, we find that much\nof SAE dark matter--about half of the error vector itself and >90% of its\nnorm--can be linearly predicted from the initial activation vector.\nAdditionally, we find that the scaling behavior of SAE error norms at a per\ntoken level is remarkably predictable: larger SAEs mostly struggle to\nreconstruct the same contexts as smaller SAEs. We build on the linear\nrepresentation hypothesis to propose models of activations that might lead to\nthese observations, including postulating a new type of \"introduced error\";\nthese insights imply that the part of the SAE error vector that cannot be\nlinearly predicted (\"nonlinear\" error) might be fundamentally different from\nthe linearly predictable component. To validate this hypothesis, we empirically\nanalyze nonlinear SAE error and show that 1) it contains fewer not yet learned\nfeatures, 2) SAEs trained on it are quantitatively worse, 3) it helps predict\nSAE per-token scaling behavior, and 4) it is responsible for a proportional\namount of the downstream increase in cross entropy loss when SAE activations\nare inserted into the model. Finally, we examine two methods to reduce\nnonlinear SAE error at a fixed sparsity: inference time gradient pursuit, which\nleads to a very slight decrease in nonlinear error, and linear transformations\nfrom earlier layer SAE outputs, which leads to a larger reduction.\n","authors":["Joshua Engels","Logan Riggs","Max Tegmark"],"pdf_url":"https://arxiv.org/pdf/2410.14670v1.pdf","comment":"Code at https://github.com/JoshEngels/SAE-Dark-Matter"},{"id":"http://arxiv.org/abs/2410.14667v1","updated":"2024-10-18T17:57:01Z","published":"2024-10-18T17:57:01Z","title":"Stochastic Gradient Descent Jittering for Inverse Problems: Alleviating\n  the Accuracy-Robustness Tradeoff","summary":"  Inverse problems aim to reconstruct unseen data from corrupted or perturbed\nmeasurements. While most work focuses on improving reconstruction quality,\ngeneralization accuracy and robustness are equally important, especially for\nsafety-critical applications. Model-based architectures (MBAs), such as loop\nunrolling methods, are considered more interpretable and achieve better\nreconstructions. Empirical evidence suggests that MBAs are more robust to\nperturbations than black-box solvers, but the accuracy-robustness tradeoff in\nMBAs remains underexplored. In this work, we propose a simple yet effective\ntraining scheme for MBAs, called SGD jittering, which injects noise\niteration-wise during reconstruction. We theoretically demonstrate that SGD\njittering not only generalizes better than the standard mean squared error\ntraining but is also more robust to average-case attacks. We validate SGD\njittering using denoising toy examples, seismic deconvolution, and single-coil\nMRI reconstruction. The proposed method achieves cleaner reconstructions for\nout-of-distribution data and demonstrates enhanced robustness to adversarial\nattacks.\n","authors":["Peimeng Guan","Mark A. Davenport"],"pdf_url":"https://arxiv.org/pdf/2410.14667v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14666v1","updated":"2024-10-18T17:56:11Z","published":"2024-10-18T17:56:11Z","title":"DiscoGraMS: Enhancing Movie Screen-Play Summarization using Movie\n  Character-Aware Discourse Graph","summary":"  Summarizing movie screenplays presents a unique set of challenges compared to\nstandard document summarization. Screenplays are not only lengthy, but also\nfeature a complex interplay of characters, dialogues, and scenes, with numerous\ndirect and subtle relationships and contextual nuances that are difficult for\nmachine learning models to accurately capture and comprehend. Recent attempts\nat screenplay summarization focus on fine-tuning transformer-based pre-trained\nmodels, but these models often fall short in capturing long-term dependencies\nand latent relationships, and frequently encounter the \"lost in the middle\"\nissue. To address these challenges, we introduce DiscoGraMS, a novel resource\nthat represents movie scripts as a movie character-aware discourse graph (CaD\nGraph). This approach is well-suited for various downstream tasks, such as\nsummarization, question-answering, and salience detection. The model aims to\npreserve all salient information, offering a more comprehensive and faithful\nrepresentation of the screenplay's content. We further explore a baseline\nmethod that combines the CaD Graph with the corresponding movie script through\na late fusion of graph and text modalities, and we present very initial\npromising results.\n","authors":["Maitreya Prafulla Chitale","Uday Bindal","Rajakrishnan Rajkumar","Rahul Mishra"],"pdf_url":"https://arxiv.org/pdf/2410.14666v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14665v1","updated":"2024-10-18T17:55:15Z","published":"2024-10-18T17:55:15Z","title":"Online Reinforcement Learning with Passive Memory","summary":"  This paper considers an online reinforcement learning algorithm that\nleverages pre-collected data (passive memory) from the environment for online\ninteraction. We show that using passive memory improves performance and further\nprovide theoretical guarantees for regret that turns out to be near-minimax\noptimal. Results show that the quality of passive memory determines\nsub-optimality of the incurred regret. The proposed approach and results hold\nin both continuous and discrete state-action spaces.\n","authors":["Anay Pattanaik","Lav R. Varshney"],"pdf_url":"https://arxiv.org/pdf/2410.14665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.06331v2","updated":"2024-10-18T17:53:46Z","published":"2024-10-08T20:12:11Z","title":"Locate-then-edit for Multi-hop Factual Recall under Knowledge Editing","summary":"  The locate-then-edit paradigm has shown significant promise for knowledge\nediting (KE) in Large Language Models (LLMs). While previous methods perform\nwell on single-hop fact recall tasks, they consistently struggle with multi-hop\nfactual recall tasks involving newly edited knowledge. In this paper,\nleveraging tools in mechanistic interpretability, we first identify that in\nmulti-hop tasks, LLMs tend to retrieve implicit subject knowledge from deeper\nMLP layers, unlike single-hop tasks, which rely on earlier layers. This\ndistinction explains the poor performance of current methods in multi-hop\nqueries, as they primarily focus on editing shallow layers, leaving deeper\nlayers unchanged. To address this, we propose IFMET, a novel locate-then-edit\nKE approach designed to edit both shallow and deep MLP layers. IFMET employs\nmulti-hop editing prompts and supplementary sets to locate and modify knowledge\nacross different reasoning stages. Experimental results demonstrate that IFMET\nsignificantly improves performance on multi-hop factual recall tasks,\neffectively overcoming the limitations of previous locate-then-edit methods.\n","authors":["Zhuoran Zhang","Yongxiang Li","Zijian Kan","Keyuan Cheng","Lijie Hu","Di Wang"],"pdf_url":"https://arxiv.org/pdf/2410.06331v2.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2410.14660v1","updated":"2024-10-18T17:51:51Z","published":"2024-10-18T17:51:51Z","title":"A Large Language Model-Driven Reward Design Framework via Dynamic\n  Feedback for Reinforcement Learning","summary":"  Large Language Models (LLMs) have shown significant potential in designing\nreward functions for Reinforcement Learning (RL) tasks. However, obtaining\nhigh-quality reward code often involves human intervention, numerous LLM\nqueries, or repetitive RL training. To address these issues, we propose CARD, a\nLLM-driven Reward Design framework that iteratively generates and improves\nreward function code. Specifically, CARD includes a Coder that generates and\nverifies the code, while a Evaluator provides dynamic feedback to guide the\nCoder in improving the code, eliminating the need for human feedback. In\naddition to process feedback and trajectory feedback, we introduce Trajectory\nPreference Evaluation (TPE), which evaluates the current reward function based\non trajectory preferences. If the code fails the TPE, the Evaluator provides\npreference feedback, avoiding RL training at every iteration and making the\nreward function better aligned with the task objective. Empirical results on\nMeta-World and ManiSkill2 demonstrate that our method achieves an effective\nbalance between task performance and token efficiency, outperforming or\nmatching the baselines across all tasks. On 10 out of 12 tasks, CARD shows\nbetter or comparable performance to policies trained with expert-designed\nrewards, and our method even surpasses the oracle on 3 tasks.\n","authors":["Shengjie Sun","Runze Liu","Jiafei Lyu","Jing-Wen Yang","Liangpeng Zhang","Xiu Li"],"pdf_url":"https://arxiv.org/pdf/2410.14660v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14659v1","updated":"2024-10-18T17:51:37Z","published":"2024-10-18T17:51:37Z","title":"Harnessing Causality in Reinforcement Learning With Bagged Decision\n  Times","summary":"  We consider reinforcement learning (RL) for a class of problems with bagged\ndecision times. A bag contains a finite sequence of consecutive decision times.\nThe transition dynamics are non-Markovian and non-stationary within a bag.\nFurther, all actions within a bag jointly impact a single reward, observed at\nthe end of the bag. Our goal is to construct an online RL algorithm to maximize\nthe discounted sum of the bag-specific rewards. To handle non-Markovian\ntransitions within a bag, we utilize an expert-provided causal directed acyclic\ngraph (DAG). Based on the DAG, we construct the states as a dynamical Bayesian\nsufficient statistic of the observed history, which results in Markovian state\ntransitions within and across bags. We then frame this problem as a periodic\nMarkov decision process (MDP) that allows non-stationarity within a period. An\nonline RL algorithm based on Bellman-equations for stationary MDPs is\ngeneralized to handle periodic MDPs. To justify the proposed RL algorithm, we\nshow that our constructed state achieves the maximal optimal value function\namong all state constructions for a periodic MDP. Further we prove the Bellman\noptimality equations for periodic MDPs. We evaluate the proposed method on\ntestbed variants, constructed with real data from a mobile health clinical\ntrial.\n","authors":["Daiqi Gao","Hsin-Yu Lai","Predrag Klasnja","Susan A. Murphy"],"pdf_url":"https://arxiv.org/pdf/2410.14659v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14655v1","updated":"2024-10-18T17:48:27Z","published":"2024-10-18T17:48:27Z","title":"Bridging the Training-Inference Gap in LLMs by Leveraging Self-Generated\n  Tokens","summary":"  Language models are often trained to maximize the likelihood of the next\ntoken given past tokens in the training dataset. However, during inference\ntime, they are utilized differently, generating text sequentially and\nauto-regressively by using previously generated tokens as input to predict the\nnext one. Marginal differences in predictions at each step can cascade over\nsuccessive steps, resulting in different distributions from what the models\nwere trained for and potentially leading to unpredictable behavior. This paper\nproposes two simple approaches based on model own generation to address this\ndiscrepancy between the training and inference time. Our first approach is\nBatch-Scheduled Sampling, where, during training, we stochastically choose\nbetween the ground-truth token from the dataset and the model's own generated\ntoken as input to predict the next token. This is done in an offline manner,\nmodifying the context window by interleaving ground-truth tokens with those\ngenerated by the model. Our second approach is Reference-Answer-based\nCorrection, where we explicitly incorporate a self-correction capability into\nthe model during training. This enables the model to effectively self-correct\nthe gaps between the generated sequences and the ground truth data without\nrelying on an external oracle model. By incorporating our proposed strategies\nduring training, we have observed an overall improvement in performance\ncompared to baseline methods, as demonstrated by our extensive experiments\nusing summarization, general question-answering, and math question-answering\ntasks.\n","authors":["Zhepeng Cen","Yao Liu","Siliang Zeng","Pratik Chaudhar","Huzefa Rangwala","George Karypis","Rasool Fakoor"],"pdf_url":"https://arxiv.org/pdf/2410.14655v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14649v1","updated":"2024-10-18T17:46:37Z","published":"2024-10-18T17:46:37Z","title":"EvoPress: Towards Optimal Dynamic Model Compression via Evolutionary\n  Search","summary":"  The high computational costs of large language models (LLMs) have led to a\nflurry of research on LLM compression, via methods such as quantization,\nsparsification, or structured pruning. A new frontier in this area is given by\n\\emph{dynamic, non-uniform} compression methods, which adjust the compression\nlevels (e.g., sparsity) per-block or even per-layer in order to minimize\naccuracy loss, while guaranteeing a global compression threshold. Yet, current\nmethods rely on heuristics for identifying the \"importance\" of a given layer\ntowards the loss, based on assumptions such as \\emph{error monotonicity}, i.e.\nthat the end-to-end model compression error is proportional to the sum of\nlayer-wise errors. In this paper, we revisit this area, and propose a new and\ngeneral approach for dynamic compression that is provably optimal in a given\ninput range. We begin from the motivating observation that, in general,\n\\emph{error monotonicity does not hold for LLMs}: compressed models with lower\nsum of per-layer errors can perform \\emph{worse} than models with higher error\nsums. To address this, we propose a new general evolutionary framework for\ndynamic LLM compression called EvoPress, which has provable convergence, and\nlow sample and evaluation complexity. We show that these theoretical guarantees\nlead to highly competitive practical performance for dynamic compression of\nLlama, Mistral and Phi models. Via EvoPress, we set new state-of-the-art\nresults across all compression approaches: structural pruning (block/layer\ndropping), unstructured sparsity, as well as quantization with dynamic\nbitwidths. Our code is available at https://github.com/IST-DASLab/EvoPress.\n","authors":["Oliver Sieberling","Denis Kuznedelev","Eldar Kurtic","Dan Alistarh"],"pdf_url":"https://arxiv.org/pdf/2410.14649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14640v1","updated":"2024-10-18T17:41:19Z","published":"2024-10-18T17:41:19Z","title":"HR-Bandit: Human-AI Collaborated Linear Recourse Bandit","summary":"  Human doctors frequently recommend actionable recourses that allow patients\nto modify their conditions to access more effective treatments. Inspired by\nsuch healthcare scenarios, we propose the Recourse Linear UCB\n($\\textsf{RLinUCB}$) algorithm, which optimizes both action selection and\nfeature modifications by balancing exploration and exploitation. We further\nextend this to the Human-AI Linear Recourse Bandit ($\\textsf{HR-Bandit}$),\nwhich integrates human expertise to enhance performance. $\\textsf{HR-Bandit}$\noffers three key guarantees: (i) a warm-start guarantee for improved initial\nperformance, (ii) a human-effort guarantee to minimize required human\ninteractions, and (iii) a robustness guarantee that ensures sublinear regret\neven when human decisions are suboptimal. Empirical results, including a\nhealthcare case study, validate its superior performance against existing\nbenchmarks.\n","authors":["Junyu Cao","Ruijiang Gao","Esmaeil Keyvanshokooh"],"pdf_url":"https://arxiv.org/pdf/2410.14640v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2410.14639v1","updated":"2024-10-18T17:40:58Z","published":"2024-10-18T17:40:58Z","title":"Convergence of Manifold Filter-Combine Networks","summary":"  In order to better understand manifold neural networks (MNNs), we introduce\nManifold Filter-Combine Networks (MFCNs). The filter-combine framework\nparallels the popular aggregate-combine paradigm for graph neural networks\n(GNNs) and naturally suggests many interesting families of MNNs which can be\ninterpreted as the manifold analog of various popular GNNs. We then propose a\nmethod for implementing MFCNs on high-dimensional point clouds that relies on\napproximating the manifold by a sparse graph. We prove that our method is\nconsistent in the sense that it converges to a continuum limit as the number of\ndata points tends to infinity.\n","authors":["David R. Johnson","Joyce Chew","Siddharth Viswanath","Edward De Brouwer","Deanna Needell","Smita Krishnaswamy","Michael Perlmutter"],"pdf_url":"https://arxiv.org/pdf/2410.14639v1.pdf","comment":"Accepted to NeurIPS Workshop on Symmetry and Geometry in Neural\n  Representations (Extended Abstract Track)"},{"id":"http://arxiv.org/abs/2410.14634v1","updated":"2024-10-18T17:35:33Z","published":"2024-10-18T17:35:33Z","title":"Parallel Backpropagation for Inverse of a Convolution with Application\n  to Normalizing Flows","summary":"  Inverse of an invertible convolution is an important operation that comes up\nin Normalizing Flows, Image Deblurring, etc. The naive algorithm for\nbackpropagation of this operation using Gaussian elimination has running time\n$O(n^3)$ where $n$ is the number of pixels in the image. We give a fast\nparallel backpropagation algorithm with running time $O(\\sqrt{n})$ for a square\nimage and provide a GPU implementation of the same. Inverse Convolutions are\nusually used in Normalizing Flows in the sampling pass, making them slow. We\npropose to use Inverse Convolutions in the forward (image to latent vector)\npass of the Normalizing flow. Since the sampling pass is the inverse of the\nforward pass, it will use convolutions only, resulting in efficient sampling\ntimes. We use our parallel backpropagation algorithm for optimizing the inverse\nconvolution layer resulting in fast training times also. We implement this\napproach in various Normalizing Flow backbones, resulting in our Inverse-Flow\nmodels. We benchmark Inverse-Flow on standard datasets and show significantly\nimproved sampling times with similar bits per dimension compared to previous\nmodels.\n","authors":["Sandeep Nagar","Girish Varma"],"pdf_url":"https://arxiv.org/pdf/2410.14634v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2109.09889v3","updated":"2024-10-18T17:32:27Z","published":"2021-09-21T00:09:03Z","title":"A Distance-based Anomaly Detection Framework for Deep Reinforcement\n  Learning","summary":"  In deep reinforcement learning (RL) systems, abnormal states pose significant\nrisks by potentially triggering unpredictable behaviors and unsafe actions,\nthus impeding the deployment of RL systems in real-world scenarios. It is\ncrucial for reliable decision-making systems to have the capability to cast an\nalert whenever they encounter unfamiliar observations that they are not\nequipped to handle. In this paper, we propose a novel Mahalanobis\ndistance-based (MD) anomaly detection framework, called \\textit{MDX}, for deep\nRL algorithms. MDX simultaneously addresses random, adversarial, and\nout-of-distribution (OOD) state outliers in both offline and online settings.\nIt utilizes Mahalanobis distance within class-conditional distributions for\neach action and operates within a statistical hypothesis testing framework\nunder the Gaussian assumption. We further extend it to robust and\ndistribution-free versions by incorporating Robust MD and conformal inference\ntechniques. Through extensive experiments on classical control environments,\nAtari games, and autonomous driving scenarios, we demonstrate the effectiveness\nof our MD-based detection framework. MDX offers a simple, unified, and\npractical anomaly detection tool for enhancing the safety and reliability of RL\nsystems in real-world applications.\n","authors":["Hongming Zhang","Ke Sun","Bo Xu","Linglong Kong","Martin Müller"],"pdf_url":"https://arxiv.org/pdf/2109.09889v3.pdf","comment":"19 pages, 21 figures"},{"id":"http://arxiv.org/abs/2410.14630v1","updated":"2024-10-18T17:30:20Z","published":"2024-10-18T17:30:20Z","title":"On the Regularization of Learnable Embeddings for Time Series Processing","summary":"  In processing multiple time series, accounting for the individual features of\neach sequence can be challenging. To address this, modern deep learning methods\nfor time series analysis combine a shared (global) model with local layers,\nspecific to each time series, often implemented as learnable embeddings.\nIdeally, these local embeddings should encode meaningful representations of the\nunique dynamics of each sequence. However, when these are learned end-to-end as\nparameters of a forecasting model, they may end up acting as mere sequence\nidentifiers. Shared processing blocks may then become reliant on such\nidentifiers, limiting their transferability to new contexts. In this paper, we\naddress this issue by investigating methods to regularize the learning of local\nlearnable embeddings for time series processing. Specifically, we perform the\nfirst extensive empirical study on the subject and show how such\nregularizations consistently improve performance in widely adopted\narchitectures. Furthermore, we show that methods preventing the co-adaptation\nof local and global parameters are particularly effective in this context. This\nhypothesis is validated by comparing several methods preventing the downstream\nmodels from relying on sequence identifiers, going as far as completely\nresetting the embeddings during training. The obtained results provide an\nimportant contribution to understanding the interplay between learnable local\nparameters and shared processing layers: a key challenge in modern time series\nprocessing models and a step toward developing effective foundation models for\ntime series.\n","authors":["Luca Butera","Giovanni De Felice","Andrea Cini","Cesare Alippi"],"pdf_url":"https://arxiv.org/pdf/2410.14630v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14629v1","updated":"2024-10-18T17:30:17Z","published":"2024-10-18T17:30:17Z","title":"SIMformer: Single-Layer Vanilla Transformer Can Learn Free-Space\n  Trajectory Similarity","summary":"  Free-space trajectory similarity calculation, e.g., DTW, Hausdorff, and\nFrechet, often incur quadratic time complexity, thus learning-based methods\nhave been proposed to accelerate the computation. The core idea is to train an\nencoder to transform trajectories into representation vectors and then compute\nvector similarity to approximate the ground truth. However, existing methods\nface dual challenges of effectiveness and efficiency: 1) they all utilize\nEuclidean distance to compute representation similarity, which leads to the\nsevere curse of dimensionality issue -- reducing the distinguishability among\nrepresentations and significantly affecting the accuracy of subsequent\nsimilarity search tasks; 2) most of them are trained in triplets manner and\noften necessitate additional information which downgrades the efficiency; 3)\nprevious studies, while emphasizing the scalability in terms of efficiency,\noverlooked the deterioration of effectiveness when the dataset size grows. To\ncope with these issues, we propose a simple, yet accurate, fast, scalable model\nthat only uses a single-layer vanilla transformer encoder as the feature\nextractor and employs tailored representation similarity functions to\napproximate various ground truth similarity measures. Extensive experiments\ndemonstrate our model significantly mitigates the curse of dimensionality issue\nand outperforms the state-of-the-arts in effectiveness, efficiency, and\nscalability.\n","authors":["Chuang Yang","Renhe Jiang","Xiaohang Xu","Chuan Xiao","Kaoru Sezaki"],"pdf_url":"https://arxiv.org/pdf/2410.14629v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14625v1","updated":"2024-10-18T17:27:07Z","published":"2024-10-18T17:27:07Z","title":"Enhancing AI Accessibility in Veterinary Medicine: Linking Classifiers\n  and Electronic Health Records","summary":"  In the rapidly evolving landscape of veterinary healthcare, integrating\nmachine learning (ML) clinical decision-making tools with electronic health\nrecords (EHRs) promises to improve diagnostic accuracy and patient care.\nHowever, the seamless integration of ML classifiers into existing EHRs in\nveterinary medicine is frequently hindered by the rigidity of EHR systems or\nthe limited availability of IT resources. To address this shortcoming, we\npresent Anna, a freely-available software solution that provides ML classifier\nresults for EHR laboratory data in real-time.\n","authors":["Chun Yin Kong","Picasso Vasquez","Makan Farhoodimoghadam","Chris Brandt","Titus C. Brown","Krystle L. Reagan","Allison Zwingenberger","Stefan M. Keller"],"pdf_url":"https://arxiv.org/pdf/2410.14625v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14623v1","updated":"2024-10-18T17:22:38Z","published":"2024-10-18T17:22:38Z","title":"syren-new: Precise formulae for the linear and nonlinear matter power\n  spectra with massive neutrinos and dynamical dark energy","summary":"  Current and future large scale structure surveys aim to constrain the\nneutrino mass and the equation of state of dark energy. We aim to construct\naccurate and interpretable symbolic approximations to the linear and nonlinear\nmatter power spectra as a function of cosmological parameters in extended\n$\\Lambda$CDM models which contain massive neutrinos and non-constant equations\nof state for dark energy. This constitutes an extension of the syren-halofit\nemulators to incorporate these two effects, which we call syren-new\n(SYmbolic-Regression-ENhanced power spectrum emulator with NEutrinos and\n$W_0-w_a$). We also obtain a simple approximation to the derived parameter\n$\\sigma_8$ as a function of the cosmological parameters for these models. Our\nresults for the linear power spectrum are designed to emulate CLASS, whereas\nfor the nonlinear case we aim to match the results of EuclidEmulator2. We\ncompare our results to existing emulators and $N$-body simulations. Our\nanalytic emulators for $\\sigma_8$, the linear and nonlinear power spectra\nachieve root mean squared errors of 0.1%, 0.3% and 1.3%, respectively, across a\nwide range of cosmological parameters, redshifts and wavenumbers. We verify\nthat emulator-related discrepancies are subdominant compared to observational\nerrors and other modelling uncertainties when computing shear power spectra for\nLSST-like surveys. Our expressions have similar accuracy to existing\n(numerical) emulators, but are at least an order of magnitude faster, both on a\nCPU and GPU. Our work greatly improves the accuracy, speed and range of\napplicability of current symbolic approximations to the linear and nonlinear\nmatter power spectra. We provide publicly available code for all symbolic\napproximations found.\n","authors":["Ce Sui","Deaglan J. Bartlett","Shivam Pandey","Harry Desmond","Pedro G. Ferreira","Benjamin D. Wandelt"],"pdf_url":"https://arxiv.org/pdf/2410.14623v1.pdf","comment":"18 pages, 15 figures"},{"id":"http://arxiv.org/abs/2410.14621v1","updated":"2024-10-18T17:21:25Z","published":"2024-10-18T17:21:25Z","title":"JAMUN: Transferable Molecular Conformational Ensemble Generation with\n  Walk-Jump Sampling","summary":"  Conformational ensembles of protein structures are immensely important both\nto understanding protein function, and for drug discovery in novel modalities\nsuch as cryptic pockets. Current techniques for sampling ensembles are\ncomputationally inefficient, or do not transfer to systems outside their\ntraining data. We present walk-Jump Accelerated Molecular ensembles with\nUniversal Noise (JAMUN), a step towards the goal of efficiently sampling the\nBoltzmann distribution of arbitrary proteins. By extending Walk-Jump Sampling\nto point clouds, JAMUN enables ensemble generation at orders of magnitude\nfaster rates than traditional molecular dynamics or state-of-the-art ML\nmethods. Further, JAMUN is able to predict the stable basins of small peptides\nthat were not seen during training.\n","authors":["Ameya Daigavane","Bodhi P. Vani","Saeed Saremi","Joseph Kleinhenz","Joshua Rackers"],"pdf_url":"https://arxiv.org/pdf/2410.14621v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10989v2","updated":"2024-10-18T17:21:17Z","published":"2024-10-14T18:17:01Z","title":"Liger Kernel: Efficient Triton Kernels for LLM Training","summary":"  Training Large Language Models (LLMs) efficiently at scale presents a\nformidable challenge, driven by their ever-increasing computational demands and\nthe need for enhanced performance. In this work, we introduce Liger-Kernel, an\nopen-sourced set of Triton kernels developed specifically for LLM training.\nWith kernel optimization techniques like kernel operation fusing and input\nchunking, our kernels achieve on average a 20% increase in training throughput\nand a 60% reduction in GPU memory usage for popular LLMs compared to\nHuggingFace implementations. In addition, Liger-Kernel is designed with\nmodularity, accessibility, and adaptability in mind, catering to both casual\nand expert users. Comprehensive benchmarks and integration tests are built in\nto ensure compatibility, performance, correctness, and convergence across\ndiverse computing environments and model architectures.\n  The source code is available under a permissive license at:\ngithub.com/linkedin/Liger-Kernel.\n","authors":["Pin-Lun Hsu","Yun Dai","Vignesh Kothapalli","Qingquan Song","Shao Tang","Siyu Zhu","Steven Shimizu","Shivam Sahni","Haowen Ning","Yanning Chen"],"pdf_url":"https://arxiv.org/pdf/2410.10989v2.pdf","comment":"17 pages, 12 figures"},{"id":"http://arxiv.org/abs/2410.10101v2","updated":"2024-10-18T17:15:09Z","published":"2024-10-14T02:41:01Z","title":"Learning Linear Attention in Polynomial Time","summary":"  Previous research has explored the computational expressivity of Transformer\nmodels in simulating Boolean circuits or Turing machines. However, the\nlearnability of these simulators from observational data has remained an open\nquestion. Our study addresses this gap by providing the first polynomial-time\nlearnability results (specifically strong, agnostic PAC learning) for\nsingle-layer Transformers with linear attention. We show that linear attention\nmay be viewed as a linear predictor in a suitably defined RKHS. As a\nconsequence, the problem of learning any linear transformer may be converted\ninto the problem of learning an ordinary linear predictor in an expanded\nfeature space, and any such predictor may be converted back into a multiheaded\nlinear transformer. Moving to generalization, we show how to efficiently\nidentify training datasets for which every empirical risk minimizer is\nequivalent (up to trivial symmetries) to the linear Transformer that generated\nthe data, thereby guaranteeing the learned model will correctly generalize\nacross all inputs. Finally, we provide examples of computations expressible via\nlinear attention and therefore polynomial-time learnable, including associative\nmemories, finite automata, and a class of Universal Turing Machine (UTMs) with\npolynomially bounded computation histories. We empirically validate our\ntheoretical findings on three tasks: learning random linear attention networks,\nkey--value associations, and learning to execute finite automata. Our findings\nbridge a critical gap between theoretical expressivity and learnability of\nTransformers, and show that flexible and general models of computation are\nefficiently learnable.\n","authors":["Morris Yau","Ekin Akyürek","Jiayuan Mao","Joshua B. Tenenbaum","Stefanie Jegelka","Jacob Andreas"],"pdf_url":"https://arxiv.org/pdf/2410.10101v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14616v1","updated":"2024-10-18T17:14:28Z","published":"2024-10-18T17:14:28Z","title":"Benchmarking Deep Reinforcement Learning for Navigation in Denied Sensor\n  Environments","summary":"  Deep Reinforcement learning (DRL) is used to enable autonomous navigation in\nunknown environments. Most research assume perfect sensor data, but real-world\nenvironments may contain natural and artificial sensor noise and denial. Here,\nwe present a benchmark of both well-used and emerging DRL algorithms in a\nnavigation task with configurable sensor denial effects. In particular, we are\ninterested in comparing how different DRL methods (e.g. model-free PPO vs.\nmodel-based DreamerV3) are affected by sensor denial. We show that DreamerV3\noutperforms other methods in the visual end-to-end navigation task with a\ndynamic goal - and other methods are not able to learn this. Furthermore,\nDreamerV3 generally outperforms other methods in sensor-denied environments. In\norder to improve robustness, we use adversarial training and demonstrate an\nimproved performance in denied environments, although this generally comes with\na performance cost on the vanilla environments. We anticipate this benchmark of\ndifferent DRL methods and the usage of adversarial training to be a starting\npoint for the development of more elaborate navigation strategies that are\ncapable of dealing with uncertain and denied sensor readings.\n","authors":["Mariusz Wisniewski","Paraskevas Chatzithanos","Weisi Guo","Antonios Tsourdos"],"pdf_url":"https://arxiv.org/pdf/2410.14616v1.pdf","comment":"31 pages, 19 figures. For associated code, see\n  https://github.com/mazqtpopx/cranfield-navigation-gym"},{"id":"http://arxiv.org/abs/2410.14615v1","updated":"2024-10-18T17:13:29Z","published":"2024-10-18T17:13:29Z","title":"Asymptotically Optimal Change Detection for Unnormalized Pre- and\n  Post-Change Distributions","summary":"  This paper addresses the problem of detecting changes when only unnormalized\npre- and post-change distributions are accessible. This situation happens in\nmany scenarios in physics such as in ferromagnetism, crystallography,\nmagneto-hydrodynamics, and thermodynamics, where the energy models are\ndifficult to normalize.\n  Our approach is based on the estimation of the Cumulative Sum (CUSUM)\nstatistics, which is known to produce optimal performance. We first present an\nintuitively appealing approximation method. Unfortunately, this produces a\nbiased estimator of the CUSUM statistics and may cause performance degradation.\nWe then propose the Log-Partition Approximation Cumulative Sum (LPA-CUSUM)\nalgorithm based on thermodynamic integration (TI) in order to estimate the\nlog-ratio of normalizing constants of pre- and post-change distributions. It is\nproved that this approach gives an unbiased estimate of the log-partition\nfunction and the CUSUM statistics, and leads to an asymptotically optimal\nperformance. Moreover, we derive a relationship between the required sample\nsize for thermodynamic integration and the desired detection delay performance,\noffering guidelines for practical parameter selection. Numerical studies are\nprovided demonstrating the efficacy of our approach.\n","authors":["Arman Adibi","Sanjeev Kulkarni","H. Vincent Poor","Taposh Banerjee","Vahid Tarokh"],"pdf_url":"https://arxiv.org/pdf/2410.14615v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.06402v2","updated":"2024-10-18T17:10:05Z","published":"2024-03-11T03:28:13Z","title":"One size doesn't fit all: Predicting the Number of Examples for\n  In-Context Learning","summary":"  In-context learning (ICL) refers to the process of adding a small number of\nlocalized examples (ones that are semantically similar to the input) from a\ntraining set of labelled data to an LLM's prompt with an objective to\neffectively control the generative process seeking to improve the downstream\ntask performance. Existing ICL approaches use an identical number of examples\n(a pre-configured hyper-parameter) for each data instance. Our work alleviates\nthe limitations of this 'one fits all' approach by dynamically predicting the\nnumber of examples for each data instance to be used in few-shot inference with\nLLMs. In particular, we employ a multi-label classifier, the parameters of\nwhich are fitted using a training set, where the label for each instance in the\ntraining set indicates if using a specific value of k (number of most similar\nexamples from 0 up to a maximum value) leads to correct k-shot downstream\npredictions. Our experiments on a number of text classification benchmarks show\nthat AICL substantially outperforms standard ICL by up to 17%.\n","authors":["Manish Chandra","Debasis Ganguly","Iadh Ounis"],"pdf_url":"https://arxiv.org/pdf/2403.06402v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.20601v2","updated":"2024-10-18T17:07:01Z","published":"2023-10-31T16:37:01Z","title":"Modular Boundaries in Recurrent Neural Networks","summary":"  Recent theoretical and experimental work in neuroscience has focused on the\nrepresentational and dynamical character of neural manifolds --subspaces in\nneural activity space wherein many neurons coactivate. Importantly, neural\npopulations studied under this \"neural manifold hypothesis\" are continuous and\nnot cleanly divided into separate neural populations. This perspective clashes\nwith the \"modular hypothesis\" of brain organization, wherein neural elements\nmaintain an \"all-or-nothing\" affiliation with modules. In line with this\nmodular hypothesis, recent research on recurrent neural networks suggests that\nmulti-task networks become modular across training, such that different modules\nspecialize for task-general dynamical motifs. If the modular hypothesis is\ntrue, then it would be important to use a dimensionality reduction technique\nthat captures modular structure. Here, we investigate the features of such a\nmethod. We leverage RNNs as a model system to study the character of modular\nneural populations, using a community detection method from network science\nknown as modularity maximization to partition neurons into distinct modules.\nThese partitions allow us to ask the following question: do these modular\nboundaries matter to the system? ...\n","authors":["Jacob Tanner","Sina Mansour L.","Ludovico Coletta","Alessandro Gozzi","Richard F. Betzel"],"pdf_url":"https://arxiv.org/pdf/2310.20601v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14606v1","updated":"2024-10-18T17:00:29Z","published":"2024-10-18T17:00:29Z","title":"Streaming Deep Reinforcement Learning Finally Works","summary":"  Natural intelligence processes experience as a continuous stream, sensing,\nacting, and learning moment-by-moment in real time. Streaming learning, the\nmodus operandi of classic reinforcement learning (RL) algorithms like\nQ-learning and TD, mimics natural learning by using the most recent sample\nwithout storing it. This approach is also ideal for resource-constrained,\ncommunication-limited, and privacy-sensitive applications. However, in deep RL,\nlearners almost always use batch updates and replay buffers, making them\ncomputationally expensive and incompatible with streaming learning. Although\nthe prevalence of batch deep RL is often attributed to its sample efficiency, a\nmore critical reason for the absence of streaming deep RL is its frequent\ninstability and failure to learn, which we refer to as stream barrier. This\npaper introduces the stream-x algorithms, the first class of deep RL algorithms\nto overcome stream barrier for both prediction and control and match sample\nefficiency of batch RL. Through experiments in Mujoco Gym, DM Control Suite,\nand Atari Games, we demonstrate stream barrier in existing algorithms and\nsuccessful stable learning with our stream-x algorithms: stream Q, stream AC,\nand stream TD, achieving the best model-free performance in DM Control Dog\nenvironments. A set of common techniques underlies the stream-x algorithms,\nenabling their success with a single set of hyperparameters and allowing for\neasy extension to other algorithms, thereby reviving streaming RL.\n","authors":["Mohamed Elsayed","Gautham Vasan","A. Rupam Mahmood"],"pdf_url":"https://arxiv.org/pdf/2410.14606v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14604v1","updated":"2024-10-18T16:57:27Z","published":"2024-10-18T16:57:27Z","title":"Learning to Control the Smoothness of Graph Convolutional Network\n  Features","summary":"  The pioneering work of Oono and Suzuki [ICLR, 2020] and Cai and Wang\n[arXiv:2006.13318] initializes the analysis of the smoothness of graph\nconvolutional network (GCN) features. Their results reveal an intricate\nempirical correlation between node classification accuracy and the ratio of\nsmooth to non-smooth feature components. However, the optimal ratio that favors\nnode classification is unknown, and the non-smooth features of deep GCN with\nReLU or leaky ReLU activation function diminish. In this paper, we propose a\nnew strategy to let GCN learn node features with a desired smoothness --\nadapting to data and tasks -- to enhance node classification. Our approach has\nthree key steps: (1) We establish a geometric relationship between the input\nand output of ReLU or leaky ReLU. (2) Building on our geometric insights, we\naugment the message-passing process of graph convolutional layers (GCLs) with a\nlearnable term to modulate the smoothness of node features with computational\nefficiency. (3) We investigate the achievable ratio between smooth and\nnon-smooth feature components for GCNs with the augmented message-passing\nscheme. Our extensive numerical results show that the augmented message-passing\nschemes significantly improve node classification for GCN and some related\nmodels.\n","authors":["Shih-Hsin Wang","Justin Baker","Cory Hauck","Bao Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14604v1.pdf","comment":"48 pages"},{"id":"http://arxiv.org/abs/2410.14602v1","updated":"2024-10-18T16:57:05Z","published":"2024-10-18T16:57:05Z","title":"How Does Data Diversity Shape the Weight Landscape of Neural Networks?","summary":"  To enhance the generalization of machine learning models to unseen data,\ntechniques such as dropout, weight decay ($L_2$ regularization), and noise\naugmentation are commonly employed. While regularization methods (i.e., dropout\nand weight decay) are geared toward adjusting model parameters to prevent\noverfitting, data augmentation increases the diversity of the input training\nset, a method purported to improve accuracy and calibration error. In this\npaper, we investigate the impact of each of these techniques on the parameter\nspace of neural networks, with the goal of understanding how they alter the\nweight landscape in transfer learning scenarios. To accomplish this, we employ\nRandom Matrix Theory to analyze the eigenvalue distributions of pre-trained\nmodels, fine-tuned using these techniques but using different levels of data\ndiversity, for the same downstream tasks. We observe that diverse data\ninfluences the weight landscape in a similar fashion as dropout. Additionally,\nwe compare commonly used data augmentation methods with synthetic data created\nby generative models. We conclude that synthetic data can bring more diversity\ninto real input data, resulting in a better performance on out-of-distribution\ntest instances.\n","authors":["Yang Ba","Michelle V. Mancenido","Rong Pan"],"pdf_url":"https://arxiv.org/pdf/2410.14602v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.09639v2","updated":"2024-10-18T16:50:56Z","published":"2024-06-14T00:08:04Z","title":"TGB 2.0: A Benchmark for Learning on Temporal Knowledge Graphs and\n  Heterogeneous Graphs","summary":"  Multi-relational temporal graphs are powerful tools for modeling real-world\ndata, capturing the evolving and interconnected nature of entities over time.\nRecently, many novel models are proposed for ML on such graphs intensifying the\nneed for robust evaluation and standardized benchmark datasets. However, the\navailability of such resources remains scarce and evaluation faces added\ncomplexity due to reproducibility issues in experimental protocols. To address\nthese challenges, we introduce Temporal Graph Benchmark 2.0 (TGB 2.0), a novel\nbenchmarking framework tailored for evaluating methods for predicting future\nlinks on Temporal Knowledge Graphs and Temporal Heterogeneous Graphs with a\nfocus on large-scale datasets, extending the Temporal Graph Benchmark. TGB 2.0\nfacilitates comprehensive evaluations by presenting eight novel datasets\nspanning five domains with up to 53 million edges. TGB 2.0 datasets are\nsignificantly larger than existing datasets in terms of number of nodes, edges,\nor timestamps. In addition, TGB 2.0 provides a reproducible and realistic\nevaluation pipeline for multi-relational temporal graphs. Through extensive\nexperimentation, we observe that 1) leveraging edge-type information is crucial\nto obtain high performance, 2) simple heuristic baselines are often competitive\nwith more complex methods, 3) most methods fail to run on our largest datasets,\nhighlighting the need for research on more scalable methods.\n","authors":["Julia Gastinger","Shenyang Huang","Mikhail Galkin","Erfan Loghmani","Ali Parviz","Farimah Poursafaei","Jacob Danovitch","Emanuele Rossi","Ioannis Koutis","Heiner Stuckenschmidt","Reihaneh Rabbany","Guillaume Rabusseau"],"pdf_url":"https://arxiv.org/pdf/2406.09639v2.pdf","comment":"29 pages, 8 figures, 11 tables, accepted at NeurIPS 2024 Track on\n  Datasets and Benchmarks"},{"id":"http://arxiv.org/abs/2410.14592v1","updated":"2024-10-18T16:43:10Z","published":"2024-10-18T16:43:10Z","title":"Contractivity and linear convergence in bilinear saddle-point problems:\n  An operator-theoretic approach","summary":"  We study the convex-concave bilinear saddle-point problem $\\min_x \\max_y f(x)\n+ y^\\top Ax - g(y)$, where both, only one, or none of the functions $f$ and $g$\nare strongly convex, and suitable rank conditions on the matrix $A$ hold. The\nsolution of this problem is at the core of many machine learning tasks. By\nemploying tools from operator theory, we systematically prove the contractivity\n(in turn, the linear convergence) of several first-order primal-dual\nalgorithms, including the Chambolle-Pock method. Our approach results in\nconcise and elegant proofs, and it yields new convergence guarantees and\ntighter bounds compared to known results.\n","authors":["Colin Dirren","Mattia Bianchi","Panagiotis D. Grontas","John Lygeros","Florian Dörfler"],"pdf_url":"https://arxiv.org/pdf/2410.14592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14591v1","updated":"2024-10-18T16:41:37Z","published":"2024-10-18T16:41:37Z","title":"A Lipschitz spaces view of infinitely wide shallow neural networks","summary":"  We revisit the mean field parametrization of shallow neural networks, using\nsigned measures on unbounded parameter spaces and duality pairings that take\ninto account the regularity and growth of activation functions. This setting\ndirectly leads to the use of unbalanced Kantorovich-Rubinstein norms defined by\nduality with Lipschitz functions, and of spaces of measures dual to those of\ncontinuous functions with controlled growth. These allow to make transparent\nthe need for total variation and moment bounds or penalization to obtain\nexistence of minimizers of variational formulations, under which we prove a\ncompactness result in strong Kantorovich-Rubinstein norm, and in the absence of\nwhich we show several examples demonstrating undesirable behavior. Further, the\nKantorovich-Rubinstein setting enables us to combine the advantages of a\ncompletely linear parametrization and ensuing reproducing kernel Banach space\nframework with optimal transport insights. We showcase this synergy with\nrepresenter theorems and uniform large data limits for empirical risk\nminimization, and in proposed formulations for distillation and fusion\napplications.\n","authors":["Francesca Bartolucci","Marcello Carioni","José A. Iglesias","Yury Korolev","Emanuele Naldi","Stefano Vigogna"],"pdf_url":"https://arxiv.org/pdf/2410.14591v1.pdf","comment":"39 pages, 1 table"},{"id":"http://arxiv.org/abs/2410.14588v1","updated":"2024-10-18T16:38:55Z","published":"2024-10-18T16:38:55Z","title":"Learning With Multi-Group Guarantees For Clusterable Subpopulations","summary":"  A canonical desideratum for prediction problems is that performance\nguarantees should hold not just on average over the population, but also for\nmeaningful subpopulations within the overall population. But what constitutes a\nmeaningful subpopulation? In this work, we take the perspective that relevant\nsubpopulations should be defined with respect to the clusters that naturally\nemerge from the distribution of individuals for which predictions are being\nmade. In this view, a population refers to a mixture model whose components\nconstitute the relevant subpopulations. We suggest two formalisms for capturing\nper-subgroup guarantees: first, by attributing each individual to the component\nfrom which they were most likely drawn, given their features; and second, by\nattributing each individual to all components in proportion to their relative\nlikelihood of having been drawn from each component. Using online calibration\nas a case study, we study a \\variational algorithm that provides guarantees for\neach of these formalisms by handling all plausible underlying subpopulation\nstructures simultaneously, and achieve an $O(T^{1/2})$ rate even when the\nsubpopulations are not well-separated. In comparison, the more natural\ncluster-then-predict approach that first recovers the structure of the\nsubpopulations and then makes predictions suffers from a $O(T^{2/3})$ rate and\nrequires the subpopulations to be separable. Along the way, we prove that\nproviding per-subgroup calibration guarantees for underlying clusters can be\neasier than learning the clusters: separation between median subgroup features\nis required for the latter but not the former.\n","authors":["Jessica Dai","Nika Haghtalab","Eric Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.14588v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14587v1","updated":"2024-10-18T16:37:52Z","published":"2024-10-18T16:37:52Z","title":"Neuro-Symbolic Traders: Assessing the Wisdom of AI Crowds in Markets","summary":"  Deep generative models are becoming increasingly used as tools for financial\nanalysis. However, it is unclear how these models will influence financial\nmarkets, especially when they infer financial value in a semi-autonomous way.\nIn this work, we explore the interplay between deep generative models and\nmarket dynamics. We develop a form of virtual traders that use deep generative\nmodels to make buy/sell decisions, which we term neuro-symbolic traders, and\nexpose them to a virtual market. Under our framework, neuro-symbolic traders\nare agents that use vision-language models to discover a model of the\nfundamental value of an asset. Agents develop this model as a stochastic\ndifferential equation, calibrated to market data using gradient descent. We\ntest our neuro-symbolic traders on both synthetic data and real financial time\nseries, including an equity stock, commodity, and a foreign exchange pair. We\nthen expose several groups of neuro-symbolic traders to a virtual market\nenvironment. This market environment allows for feedback between the traders\nbelief of the underlying value to the observed price dynamics. We find that\nthis leads to price suppression compared to the historical data, highlighting a\nfuture risk to market stability. Our work is a first step towards quantifying\nthe effect of deep generative agents on markets dynamics and sets out some of\nthe potential risks and benefits of this approach in the future.\n","authors":["Namid R. Stillman","Rory Baggott"],"pdf_url":"https://arxiv.org/pdf/2410.14587v1.pdf","comment":"8 pages, 4 figures, ACM format"},{"id":"http://arxiv.org/abs/2410.14586v1","updated":"2024-10-18T16:37:28Z","published":"2024-10-18T16:37:28Z","title":"Neural Combinatorial Clustered Bandits for Recommendation Systems","summary":"  We consider the contextual combinatorial bandit setting where in each round,\nthe learning agent, e.g., a recommender system, selects a subset of \"arms,\"\ne.g., products, and observes rewards for both the individual base arms, which\nare a function of known features (called \"context\"), and the super arm (the\nsubset of arms), which is a function of the base arm rewards. The agent's goal\nis to simultaneously learn the unknown reward functions and choose the\nhighest-reward arms. For example, the \"reward\" may represent a user's\nprobability of clicking on one of the recommended products. Conventional bandit\nmodels, however, employ restrictive reward function models in order to obtain\nperformance guarantees. We make use of deep neural networks to estimate and\nlearn the unknown reward functions and propose Neural UCB Clustering\n(NeUClust), which adopts a clustering approach to select the super arm in every\nround by exploiting underlying structure in the context space. Unlike prior\nneural bandit works, NeUClust uses a neural network to estimate the super arm\nreward and select the super arm, thus eliminating the need for a known\noptimization oracle. We non-trivially extend prior neural combinatorial bandit\nworks to prove that NeUClust achieves\n$\\widetilde{O}\\left(\\widetilde{d}\\sqrt{T}\\right)$ regret, where $\\widetilde{d}$\nis the effective dimension of a neural tangent kernel matrix, $T$ the number of\nrounds. Experiments on real world recommendation datasets show that NeUClust\nachieves better regret and reward than other contextual combinatorial and\nneural bandit algorithms.\n","authors":["Baran Atalar","Carlee Joe-Wong"],"pdf_url":"https://arxiv.org/pdf/2410.14586v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14581v1","updated":"2024-10-18T16:32:06Z","published":"2024-10-18T16:32:06Z","title":"Optimizing Attention with Mirror Descent: Generalized Max-Margin Token\n  Selection","summary":"  Attention mechanisms have revolutionized several domains of artificial\nintelligence, such as natural language processing and computer vision, by\nenabling models to selectively focus on relevant parts of the input data. While\nrecent work has characterized the optimization dynamics of gradient descent\n(GD) in attention-based models and the structural properties of its preferred\nsolutions, less is known about more general optimization algorithms such as\nmirror descent (MD). In this paper, we investigate the convergence properties\nand implicit biases of a family of MD algorithms tailored for softmax attention\nmechanisms, with the potential function chosen as the $p$-th power of the\n$\\ell_p$-norm. Specifically, we show that these algorithms converge in\ndirection to a generalized hard-margin SVM with an $\\ell_p$-norm objective when\napplied to a classification problem using a softmax attention model. Notably,\nour theoretical results reveal that the convergence rate is comparable to that\nof traditional GD in simpler models, despite the highly nonlinear and nonconvex\nnature of the present problem. Additionally, we delve into the joint\noptimization dynamics of the key-query matrix and the decoder, establishing\nconditions under which this complex joint optimization converges to their\nrespective hard-margin SVM solutions. Lastly, our numerical experiments on real\ndata demonstrate that MD algorithms improve generalization over standard GD and\nexcel in optimal token selection.\n","authors":["Aaron Alvarado Kristanto Julistiono","Davoud Ataee Tarzanagh","Navid Azizan"],"pdf_url":"https://arxiv.org/pdf/2410.14581v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14579v1","updated":"2024-10-18T16:27:04Z","published":"2024-10-18T16:27:04Z","title":"Towards Unsupervised Validation of Anomaly-Detection Models","summary":"  Unsupervised validation of anomaly-detection models is a highly challenging\ntask. While the common practices for model validation involve a labeled\nvalidation set, such validation sets cannot be constructed when the underlying\ndatasets are unlabeled. The lack of robust and efficient unsupervised\nmodel-validation techniques presents an acute challenge in the implementation\nof automated anomaly-detection pipelines, especially when there exists no prior\nknowledge of the model's performance on similar datasets. This work presents a\nnew paradigm to automated validation of anomaly-detection models, inspired by\nreal-world, collaborative decision-making mechanisms. We focus on two\ncommonly-used, unsupervised model-validation tasks -- model selection and model\nevaluation -- and provide extensive experimental results that demonstrate the\naccuracy and robustness of our approach on both tasks.\n","authors":["Lihi Idan"],"pdf_url":"https://arxiv.org/pdf/2410.14579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14578v1","updated":"2024-10-18T16:26:45Z","published":"2024-10-18T16:26:45Z","title":"Large Language Models Are Overparameterized Text Encoders","summary":"  Large language models (LLMs) demonstrate strong performance as text embedding\nmodels when finetuned with supervised contrastive training. However, their\nlarge size balloons inference time and memory requirements. In this paper, we\nshow that by pruning the last $p\\%$ layers of an LLM before supervised training\nfor only 1000 steps, we can achieve a proportional reduction in memory and\ninference time. We evaluate four different state-of-the-art LLMs on text\nembedding tasks and find that our method can prune up to 30\\% of layers with\nnegligible impact on performance and up to 80\\% with only a modest drop. With\nonly three lines of code, our method is easily implemented in any pipeline for\ntransforming LLMs to text encoders. We also propose $\\text{L}^3 \\text{Prune}$,\na novel layer-pruning strategy based on the model's initial loss that provides\ntwo optimal pruning configurations: a large variant with negligible performance\nloss and a small variant for resource-constrained settings. On average, the\nlarge variant prunes 21\\% of the parameters with a $-0.3$ performance drop, and\nthe small variant only suffers from a $-5.1$ decrease while pruning 74\\% of the\nmodel. We consider these results strong evidence that LLMs are\noverparameterized for text embedding tasks, and can be easily pruned.\n","authors":["Thennal D K","Tim Fischer","Chris Biemann"],"pdf_url":"https://arxiv.org/pdf/2410.14578v1.pdf","comment":"8 pages of content + 1 for limitations and ethical considerations, 14\n  pages in total including references and appendix, 5+1 figures"},{"id":"http://arxiv.org/abs/2410.13174v2","updated":"2024-10-18T16:26:30Z","published":"2024-10-17T02:57:35Z","title":"Scalable Drift Monitoring in Medical Imaging AI","summary":"  The integration of artificial intelligence (AI) into medical imaging has\nadvanced clinical diagnostics but poses challenges in managing model drift and\nensuring long-term reliability. To address these challenges, we develop MMC+,\nan enhanced framework for scalable drift monitoring, building upon the\nCheXstray framework that introduced real-time drift detection for medical\nimaging AI models using multi-modal data concordance. This work extends the\noriginal framework's methodologies, providing a more scalable and adaptable\nsolution for real-world healthcare settings and offers a reliable and\ncost-effective alternative to continuous performance monitoring addressing\nlimitations of both continuous and periodic monitoring methods. MMC+ introduces\ncritical improvements to the original framework, including more robust handling\nof diverse data streams, improved scalability with the integration of\nfoundation models like MedImageInsight for high-dimensional image embeddings\nwithout site-specific training, and the introduction of uncertainty bounds to\nbetter capture drift in dynamic clinical environments. Validated with\nreal-world data from Massachusetts General Hospital during the COVID-19\npandemic, MMC+ effectively detects significant data shifts and correlates them\nwith model performance changes. While not directly predicting performance\ndegradation, MMC+ serves as an early warning system, indicating when AI systems\nmay deviate from acceptable performance bounds and enabling timely\ninterventions. By emphasizing the importance of monitoring diverse data streams\nand evaluating data shifts alongside model performance, this work contributes\nto the broader adoption and integration of AI solutions in clinical settings.\n","authors":["Jameson Merkow","Felix J. Dorfner","Xiyu Yang","Alexander Ersoy","Giridhar Dasegowda","Mannudeep Kalra","Matthew P. Lungren","Christopher P. Bridge","Ivan Tarapov"],"pdf_url":"https://arxiv.org/pdf/2410.13174v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14574v1","updated":"2024-10-18T16:20:22Z","published":"2024-10-18T16:20:22Z","title":"MomentumSMoE: Integrating Momentum into Sparse Mixture of Experts","summary":"  Sparse Mixture of Experts (SMoE) has become the key to unlocking unparalleled\nscalability in deep learning. SMoE has the potential to exponentially increase\nparameter count while maintaining the efficiency of the model by only\nactivating a small subset of these parameters for a given sample. However, it\nhas been observed that SMoE suffers from unstable training and has difficulty\nadapting to new distributions, leading to the model's lack of robustness to\ndata contamination. To overcome these limitations, we first establish a\nconnection between the dynamics of the expert representations in SMoEs and\ngradient descent on a multi-objective optimization problem. Leveraging our\nframework, we then integrate momentum into SMoE and propose a new family of\nSMoEs named MomentumSMoE. We theoretically prove and numerically demonstrate\nthat MomentumSMoE is more stable and robust than SMoE. In particular, we verify\nthe advantages of MomentumSMoE over SMoE on a variety of practical tasks\nincluding ImageNet-1K object recognition and WikiText-103 language modeling. We\ndemonstrate the applicability of MomentumSMoE to many types of SMoE models,\nincluding those in the Sparse MoE model for vision (V-MoE) and the Generalist\nLanguage Model (GLaM). We also show that other advanced momentum-based\noptimization methods, such as Adam, can be easily incorporated into the\nMomentumSMoE framework for designing new SMoE models with even better\nperformance, almost negligible additional computation cost, and simple\nimplementations.\n","authors":["Rachel S. Y. Teo","Tan M. Nguyen"],"pdf_url":"https://arxiv.org/pdf/2410.14574v1.pdf","comment":"10 pages in the main text. Published at NeurIPS 2024. The code is\n  available at https://github.com/rachtsy/MomentumSMoE"},{"id":"http://arxiv.org/abs/2410.14573v1","updated":"2024-10-18T16:20:17Z","published":"2024-10-18T16:20:17Z","title":"Building Trust in Black-box Optimization: A Comprehensive Framework for\n  Explainability","summary":"  Optimizing costly black-box functions within a constrained evaluation budget\npresents significant challenges in many real-world applications. Surrogate\nOptimization (SO) is a common resolution, yet its proprietary nature introduced\nby the complexity of surrogate models and the sampling core (e.g., acquisition\nfunctions) often leads to a lack of explainability and transparency. While\nexisting literature has primarily concentrated on enhancing convergence to\nglobal optima, the practical interpretation of newly proposed strategies\nremains underexplored, especially in batch evaluation settings. In this paper,\nwe propose \\emph{Inclusive} Explainability Metrics for Surrogate Optimization\n(IEMSO), a comprehensive set of model-agnostic metrics designed to enhance the\ntransparency, trustworthiness, and explainability of the SO approaches. Through\nthese metrics, we provide both intermediate and post-hoc explanations to\npractitioners before and after performing expensive evaluations to gain trust.\nWe consider four primary categories of metrics, each targeting a specific\naspect of the SO process: Sampling Core Metrics, Batch Properties Metrics,\nOptimization Process Metrics, and Feature Importance. Our experimental\nevaluations demonstrate the significant potential of the proposed metrics\nacross different benchmarks.\n","authors":["Nazanin Nezami","Hadis Anahideh"],"pdf_url":"https://arxiv.org/pdf/2410.14573v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14570v1","updated":"2024-10-18T16:16:52Z","published":"2024-10-18T16:16:52Z","title":"Understanding the difficulty of low-precision post-training quantization\n  of large language models","summary":"  Large language models of high parameter counts are computationally expensive,\nyet can be made much more efficient by compressing their weights to very low\nnumerical precision. This can be achieved either through post-training\nquantization by minimizing local, layer-wise quantization errors, or through\nquantization-aware fine-tuning by minimizing the global loss function. In this\nstudy, we discovered that, under the same data constraint, the former approach\nnearly always fared worse than the latter, a phenomenon particularly prominent\nwhen the numerical precision is very low. We further showed that this\ndifficulty of post-training quantization arose from stark misalignment between\noptimization of the local and global objective functions. Our findings explains\nlimited utility in minimization of local quantization error and the importance\nof direct quantization-aware fine-tuning, in the regime of large models at very\nlow precision.\n","authors":["Zifei Xu","Sayeh Sharify","Wanzin Yazar","Tristan Webb","Xin Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14570v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12616v2","updated":"2024-10-18T16:09:52Z","published":"2024-06-18T13:44:07Z","title":"Learning diffusion at lightspeed","summary":"  Diffusion regulates numerous natural processes and the dynamics of many\nsuccessful generative models. Existing models to learn the diffusion terms from\nobservational data rely on complex bilevel optimization problems and model only\nthe drift of the system. We propose a new simple model, JKOnet*, which bypasses\nthe complexity of existing architectures while presenting significantly\nenhanced representational capabilities: JKOnet* recovers the potential,\ninteraction, and internal energy components of the underlying diffusion\nprocess. JKOnet* minimizes a simple quadratic loss and outperforms other\nbaselines in terms of sample efficiency, computational complexity, and\naccuracy. Additionally, JKOnet* provides a closed-form optimal solution for\nlinearly parametrized functionals, and, when applied to predict the evolution\nof cellular processes from real-world data, it achieves state-of-the-art\naccuracy at a fraction of the computational cost of all existing methods. Our\nmethodology is based on the interpretation of diffusion processes as\nenergy-minimizing trajectories in the probability space via the so-called JKO\nscheme, which we study via its first-order optimality conditions.\n","authors":["Antonio Terpin","Nicolas Lanzetti","Martin Gadea","Florian Dörfler"],"pdf_url":"https://arxiv.org/pdf/2406.12616v2.pdf","comment":"Accepted for presentation at, and publication in the proceedings of,\n  the 38th Conference on Neural Information Processing Systems (NeurIPS 2024,\n  oral)"},{"id":"http://arxiv.org/abs/2410.14556v1","updated":"2024-10-18T15:59:54Z","published":"2024-10-18T15:59:54Z","title":"Measuring Diversity: Axioms and Challenges","summary":"  The concept of diversity is widely used in various applications: from image\nor molecule generation to recommender systems. Thus, being able to properly\nmeasure diversity is important. This paper addresses the problem of quantifying\ndiversity for a set of objects. First, we make a systematic review of existing\ndiversity measures and explore their undesirable behavior in some cases. Based\non this review, we formulate three desirable properties (axioms) of a reliable\ndiversity measure: monotonicity, uniqueness, and continuity. We show that none\nof the existing measures has all three properties and thus these measures are\nnot suitable for quantifying diversity. Then, we construct two examples of\nmeasures that have all the desirable properties, thus proving that the list of\naxioms is not self-contradicting. Unfortunately, the constructed examples are\ntoo computationally complex for practical use, thus we pose an open problem of\nconstructing a diversity measure that has all the listed properties and can be\ncomputed in practice.\n","authors":["Mikhail Mironov","Liudmila Prokhorenkova"],"pdf_url":"https://arxiv.org/pdf/2410.14556v1.pdf","comment":"17 pages, 7 figures"},{"id":"http://arxiv.org/abs/2409.15652v3","updated":"2024-10-18T15:45:39Z","published":"2024-09-24T01:29:24Z","title":"English offensive text detection using CNN based Bi-GRU model","summary":"  Over the years, the number of users of social media has increased\ndrastically. People frequently share their thoughts through social platforms,\nand this leads to an increase in hate content. In this virtual community,\nindividuals share their views, express their feelings, and post photos, videos,\nblogs, and more. Social networking sites like Facebook and Twitter provide\nplatforms to share vast amounts of content with a single click. However, these\nplatforms do not impose restrictions on the uploaded content, which may include\nabusive language and explicit images unsuitable for social media. To resolve\nthis issue, a new idea must be implemented to divide the inappropriate content.\nNumerous studies have been done to automate the process. In this paper, we\npropose a new Bi-GRU-CNN model to classify whether the text is offensive or\nnot. The combination of the Bi-GRU and CNN models outperforms the existing\nmodel.\n","authors":["Tonmoy Roy","Md Robiul Islam","Asif Ahammad Miazee","Anika Antara","Al Amin","Sunjim Hossain"],"pdf_url":"https://arxiv.org/pdf/2409.15652v3.pdf","comment":"5 pages and 6 figures"},{"id":"http://arxiv.org/abs/2410.14548v1","updated":"2024-10-18T15:43:34Z","published":"2024-10-18T15:43:34Z","title":"Boosting K-means for Big Data by Fusing Data Streaming with Global\n  Optimization","summary":"  K-means clustering is a cornerstone of data mining, but its efficiency\ndeteriorates when confronted with massive datasets. To address this limitation,\nwe propose a novel heuristic algorithm that leverages the Variable Neighborhood\nSearch (VNS) metaheuristic to optimize K-means clustering for big data. Our\napproach is based on the sequential optimization of the partial objective\nfunction landscapes obtained by restricting the Minimum Sum-of-Squares\nClustering (MSSC) formulation to random samples from the original big dataset.\nWithin each landscape, systematically expanding neighborhoods of the currently\nbest (incumbent) solution are explored by reinitializing all degenerate and a\nvarying number of additional centroids. Extensive and rigorous experimentation\non a large number of real-world datasets reveals that by transforming the\ntraditional local search into a global one, our algorithm significantly\nenhances the accuracy and efficiency of K-means clustering in big data\nenvironments, becoming the new state of the art in the field.\n","authors":["Ravil Mussabayev","Rustam Mussabayev"],"pdf_url":"https://arxiv.org/pdf/2410.14548v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.11206v2","updated":"2024-10-18T15:43:02Z","published":"2024-06-17T04:53:47Z","title":"Retraining with Predicted Hard Labels Provably Increases Model Accuracy","summary":"  The performance of a model trained with \\textit{noisy labels} is often\nimproved by simply \\textit{retraining} the model with its own predicted\n\\textit{hard} labels (i.e., $1$/$0$ labels). Yet, a detailed theoretical\ncharacterization of this phenomenon is lacking. In this paper, we theoretically\nanalyze retraining in a linearly separable setting with randomly corrupted\nlabels given to us and prove that retraining can improve the population\naccuracy obtained by initially training with the given (noisy) labels. To the\nbest of our knowledge, this is the first such theoretical result. Retraining\nfinds application in improving training with local label differential privacy\n(DP) which involves training with noisy labels. We empirically show that\nretraining selectively on the samples for which the predicted label matches the\ngiven label significantly improves label DP training at \\textit{no extra\nprivacy cost}; we call this \\textit{consensus-based retraining}. As an example,\nwhen training ResNet-18 on CIFAR-100 with $\\epsilon=3$ label DP, we obtain\n$6.4\\%$ improvement in accuracy with consensus-based retraining.\n","authors":["Rudrajit Das","Inderjit S. Dhillon","Alessandro Epasto","Adel Javanmard","Jieming Mao","Vahab Mirrokni","Sujay Sanghavi","Peilin Zhong"],"pdf_url":"https://arxiv.org/pdf/2406.11206v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.15379v2","updated":"2024-10-18T15:38:16Z","published":"2024-04-23T07:16:13Z","title":"Clustering of timed sequences -- Application to the analysis of care\n  pathways","summary":"  Improving the future of healthcare starts by better understanding the current\nactual practices in hospital settings. This motivates the objective of\ndiscovering typical care pathways from patient data. Revealing typical care\npathways can be achieved through clustering. The difficulty in clustering care\npathways, represented by sequences of timestamped events, lies in defining a\nsemantically appropriate metric and clustering algorithms. In this article, we\nadapt two methods developed for time series to the clustering of timed\nsequences: the drop-DTW metric and the DBA approach for the construction of\naveraged time sequences. These methods are then applied in clustering\nalgorithms to propose original and sound clustering algorithms for timed\nsequences. This approach is experimented with and evaluated on synthetic and\nreal-world data.\n","authors":["Thomas Guyet","Pierre Pinson","Enoal Gesny"],"pdf_url":"https://arxiv.org/pdf/2404.15379v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14539v1","updated":"2024-10-18T15:29:04Z","published":"2024-10-18T15:29:04Z","title":"Diffusion-based Semi-supervised Spectral Algorithm for Regression on\n  Manifolds","summary":"  We introduce a novel diffusion-based spectral algorithm to tackle regression\nanalysis on high-dimensional data, particularly data embedded within\nlower-dimensional manifolds. Traditional spectral algorithms often fall short\nin such contexts, primarily due to the reliance on predetermined kernel\nfunctions, which inadequately address the complex structures inherent in\nmanifold-based data. By employing graph Laplacian approximation, our method\nuses the local estimation property of heat kernel, offering an adaptive,\ndata-driven approach to overcome this obstacle. Another distinct advantage of\nour algorithm lies in its semi-supervised learning framework, enabling it to\nfully use the additional unlabeled data. This ability enhances the performance\nby allowing the algorithm to dig the spectrum and curvature of the data\nmanifold, providing a more comprehensive understanding of the dataset.\nMoreover, our algorithm performs in an entirely data-driven manner, operating\ndirectly within the intrinsic manifold structure of the data, without requiring\nany predefined manifold information. We provide a convergence analysis of our\nalgorithm. Our findings reveal that the algorithm achieves a convergence rate\nthat depends solely on the intrinsic dimension of the underlying manifold,\nthereby avoiding the curse of dimensionality associated with the higher ambient\ndimension.\n","authors":["Weichun Xia","Jiaxin Jiang","Lei Shi"],"pdf_url":"https://arxiv.org/pdf/2410.14539v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12874v2","updated":"2024-10-18T15:26:55Z","published":"2024-10-14T18:11:53Z","title":"On Debiasing Text Embeddings Through Context Injection","summary":"  Current advances in Natural Language Processing (NLP) have made it\nincreasingly feasible to build applications leveraging textual data. Generally,\nthe core of these applications rely on having a good semantic representation of\ntext into vectors, via embedding models. However, it has been shown that these\nembeddings capture and perpetuate biases already present in text. While a few\ntechniques have been proposed to debias embeddings, they do not take advantage\nof the recent advances in context understanding of modern embedding models. In\nthis paper, we fill this gap by conducting a review of 19 embedding models by\nquantifying their biases and how well they respond to context injection as a\nmean of debiasing. We show that higher performing models are more prone to\ncapturing biases, but are also better at incorporating context. Surprisingly,\nwe find that while models can easily embed affirmative semantics, they fail at\nembedding neutral semantics. Finally, in a retrieval task, we show that biases\nin embeddings can lead to non-desirable outcomes. We use our new-found insights\nto design a simple algorithm for top $k$ retrieval, where $k$ is dynamically\nselected. We show that our algorithm is able to retrieve all relevant gendered\nand neutral chunks.\n","authors":["Thomas Uriot"],"pdf_url":"https://arxiv.org/pdf/2410.12874v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14535v1","updated":"2024-10-18T15:23:29Z","published":"2024-10-18T15:23:29Z","title":"Comparing Differentiable and Dynamic Ray Tracing: Introducing the\n  Multipath Lifetime Map","summary":"  With the increasing presence of dynamic scenarios, such as Vehicle-to-Vehicle\ncommunications, radio propagation modeling tools must adapt to the rapidly\nchanging nature of the radio channel. Recently, both Differentiable and Dynamic\nRay Tracing frameworks have emerged to address these challenges. However, there\nis often confusion about how these approaches differ and which one should be\nused in specific contexts. In this paper, we provide an overview of these two\ntechniques and a comparative analysis against two state-of-the-art tools:\n3DSCAT from UniBo and Sionna from NVIDIA. To provide a more precise\ncharacterization of the scope of these methods, we introduce a novel\nsimulation-based metric, the Multipath Lifetime Map, which enables the\nevaluation of spatial and temporal coherence in radio channels only based on\nthe geometrical description of the environment. Finally, our metrics are\nevaluated on a classic urban street canyon scenario, yielding similar results\nto those obtained from measurement campaigns.\n","authors":["Jérome Eertmans","Enrico Maria Vittuci","Vittorio Degli Esposti","Laurent Jacques","Claude Oestges"],"pdf_url":"https://arxiv.org/pdf/2410.14535v1.pdf","comment":"5 pages, 5 figures, 1 table, submitted to EuCAP 2025"},{"id":"http://arxiv.org/abs/2404.07864v2","updated":"2024-10-18T15:23:26Z","published":"2024-04-11T15:57:12Z","title":"Inferring Change Points in High-Dimensional Regression via Approximate\n  Message Passing","summary":"  We consider the problem of localizing change points in a generalized linear\nmodel (GLM), a model that covers many widely studied problems in statistical\nlearning including linear, logistic, and rectified linear regression. We\npropose a novel and computationally efficient Approximate Message Passing (AMP)\nalgorithm for estimating both the signals and the change point locations, and\nrigorously characterize its performance in the high-dimensional limit where the\nnumber of parameters $p$ is proportional to the number of samples $n$. This\ncharacterization is in terms of a state evolution recursion, which allows us to\nprecisely compute performance measures such as the asymptotic Hausdorff error\nof our change point estimates, and allows us to tailor the algorithm to take\nadvantage of any prior structural information on the signals and change points.\nMoreover, we show how our AMP iterates can be used to efficiently compute a\nBayesian posterior distribution over the change point locations in the\nhigh-dimensional limit. We validate our theory via numerical experiments, and\ndemonstrate the favorable performance of our estimators on both synthetic and\nreal data in the settings of linear, logistic, and rectified linear regression.\n","authors":["Gabriel Arpino","Xiaoqi Liu","Julia Gontarek","Ramji Venkataramanan"],"pdf_url":"https://arxiv.org/pdf/2404.07864v2.pdf","comment":"43 pages, 9 figures. A preliminary version of this paper appeared in\n  ICML 2024"},{"id":"http://arxiv.org/abs/2408.05807v3","updated":"2024-10-18T15:19:04Z","published":"2024-08-11T15:56:44Z","title":"Kernel Density Estimators in Large Dimensions","summary":"  This paper studies Kernel Density Estimation for a high-dimensional\ndistribution $\\rho(x)$. Traditional approaches have focused on the limit of\nlarge number of data points $n$ and fixed dimension $d$. We analyze instead the\nregime where both the number $n$ of data points $y_i$ and their dimensionality\n$d$ grow with a fixed ratio $\\alpha=(\\log n)/d$. Our study reveals three\ndistinct statistical regimes for the kernel-based estimate of the density $\\hat\n\\rho_h^{\\mathcal {D}}(x)=\\frac{1}{n h^d}\\sum_{i=1}^n\nK\\left(\\frac{x-y_i}{h}\\right)$, depending on the bandwidth $h$: a classical\nregime for large bandwidth where the Central Limit Theorem (CLT) holds, which\nis akin to the one found in traditional approaches. Below a certain value of\nthe bandwidth, $h_{CLT}(\\alpha)$, we find that the CLT breaks down. The\nstatistics of $\\hat\\rho_h^{\\mathcal {D}}(x)$ for a fixed $x$ drawn from\n$\\rho(x)$ is given by a heavy-tailed distribution (an alpha-stable\ndistribution). In particular below a value $h_G(\\alpha)$, we find that\n$\\hat\\rho_h^{\\mathcal {D}}(x)$ is governed by extreme value statistics: only a\nfew points in the database matter and give the dominant contribution to the\ndensity estimator. We provide a detailed analysis for high-dimensional\nmultivariate Gaussian data. We show that the optimal bandwidth threshold based\non Kullback-Leibler divergence lies in the new statistical regime identified in\nthis paper. As known by practitioners, when decreasing the bandwidth a\nKernel-estimated estimated changes from a smooth curve to a collections of\npeaks centred on the data points. Our findings reveal that this general\nphenomenon is related to sharp transitions between phases characterized by\ndifferent statistical properties, and offer new insights for Kernel density\nestimation in high-dimensional settings.\n","authors":["Giulio Biroli","Marc Mézard"],"pdf_url":"https://arxiv.org/pdf/2408.05807v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14533v1","updated":"2024-10-18T15:14:25Z","published":"2024-10-18T15:14:25Z","title":"The Traveling Bandit: A Framework for Bayesian Optimization with\n  Movement Costs","summary":"  This paper introduces a framework for Bayesian Optimization (BO) with metric\nmovement costs, addressing a critical challenge in practical applications where\ninput alterations incur varying costs. Our approach is a convenient plug-in\nthat seamlessly integrates with the existing literature on batched algorithms,\nwhere designs within batches are observed following the solution of a Traveling\nSalesman Problem. The proposed method provides a theoretical guarantee of\nconvergence in terms of movement costs for BO. Empirically, our method\neffectively reduces average movement costs over time while maintaining\ncomparable regret performance to conventional BO methods. This framework also\nshows promise for broader applications in various bandit settings with movement\ncosts.\n","authors":["Qiyuan Chen","Raed Al Kontar"],"pdf_url":"https://arxiv.org/pdf/2410.14533v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14532v1","updated":"2024-10-18T15:13:07Z","published":"2024-10-18T15:13:07Z","title":"Using Sentiment and Technical Analysis to Predict Bitcoin with Machine\n  Learning","summary":"  Cryptocurrencies have gained significant attention in recent years due to\ntheir decentralized nature and potential for financial innovation. Thus, the\nability to accurately predict its price has become a subject of great interest\nfor investors, traders, and researchers. Some works in the literature show how\nBitcoin's market sentiment correlates with its price fluctuations in the\nmarket. However, papers that consider the sentiment of the market associated\nwith financial Technical Analysis indicators in order to predict Bitcoin's\nprice are still scarce. In this paper, we present a novel approach for\npredicting Bitcoin price movements by combining the Fear & Greedy Index, a\nmeasure of market sentiment, Technical Analysis indicators, and the potential\nof Machine Learning algorithms. This work represents a preliminary study on the\nimportance of sentiment metrics in cryptocurrency forecasting. Our initial\nexperiments demonstrate promising results considering investment returns,\nsurpassing the Buy & Hold baseline, and offering valuable insights about the\ncombination of indicators of sentiment and market in a cryptocurrency\nprediction model.\n","authors":["Arthur Emanuel de Oliveira Carosia"],"pdf_url":"https://arxiv.org/pdf/2410.14532v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14528v1","updated":"2024-10-18T15:10:55Z","published":"2024-10-18T15:10:55Z","title":"Domain Adaptive Safety Filters via Deep Operator Learning","summary":"  Learning-based approaches for constructing Control Barrier Functions (CBFs)\nare increasingly being explored for safety-critical control systems. However,\nthese methods typically require complete retraining when applied to unseen\nenvironments, limiting their adaptability. To address this, we propose a\nself-supervised deep operator learning framework that learns the mapping from\nenvironmental parameters to the corresponding CBF, rather than learning the CBF\ndirectly. Our approach leverages the residual of a parametric Partial\nDifferential Equation (PDE), where the solution defines a parametric CBF\napproximating the maximal control invariant set. This framework accommodates\ncomplex safety constraints, higher relative degrees, and actuation limits. We\ndemonstrate the effectiveness of the method through numerical experiments on\nnavigation tasks involving dynamic obstacles.\n","authors":["Lakshmideepakreddy Manda","Shaoru Chen","Mahyar Fazlyab"],"pdf_url":"https://arxiv.org/pdf/2410.14528v1.pdf","comment":"63rd IEEE Conference on Decision and Control (CDC)"},{"id":"http://arxiv.org/abs/2410.14522v1","updated":"2024-10-18T15:06:50Z","published":"2024-10-18T15:06:50Z","title":"Rethinking Distance Metrics for Counterfactual Explainability","summary":"  Counterfactual explanations have been a popular method of post-hoc\nexplainability for a variety of settings in Machine Learning. Such methods\nfocus on explaining classifiers by generating new data points that are similar\nto a given reference, while receiving a more desirable prediction. In this\nwork, we investigate a framing for counterfactual generation methods that\nconsiders counterfactuals not as independent draws from a region around the\nreference, but as jointly sampled with the reference from the underlying data\ndistribution. Through this framing, we derive a distance metric, tailored for\ncounterfactual similarity that can be applied to a broad range of settings.\nThrough both quantitative and qualitative analyses of counterfactual generation\nmethods, we show that this framing allows us to express more nuanced\ndependencies among the covariates.\n","authors":["Joshua Nathaniel Williams","Anurag Katakkar","Hoda Heidari","J. Zico Kolter"],"pdf_url":"https://arxiv.org/pdf/2410.14522v1.pdf","comment":"13 pages, 3 figures, 1 table"},{"id":"http://arxiv.org/abs/2410.14515v1","updated":"2024-10-18T14:54:40Z","published":"2024-10-18T14:54:40Z","title":"Efficient Annotator Reliability Assessment and Sample Weighting for\n  Knowledge-Based Misinformation Detection on Social Media","summary":"  Misinformation spreads rapidly on social media, confusing the truth and\ntargetting potentially vulnerable people. To effectively mitigate the negative\nimpact of misinformation, it must first be accurately detected before applying\na mitigation strategy, such as X's community notes, which is currently a manual\nprocess. This study takes a knowledge-based approach to misinformation\ndetection, modelling the problem similarly to one of natural language\ninference. The EffiARA annotation framework is introduced, aiming to utilise\ninter- and intra-annotator agreement to understand the reliability of each\nannotator and influence the training of large language models for\nclassification based on annotator reliability. In assessing the EffiARA\nannotation framework, the Russo-Ukrainian Conflict Knowledge-Based\nMisinformation Classification Dataset (RUC-MCD) was developed and made publicly\navailable. This study finds that sample weighting using annotator reliability\nperforms the best, utilising both inter- and intra-annotator agreement and\nsoft-label training. The highest classification performance achieved using\nLlama-3.2-1B was a macro-F1 of 0.757 and 0.740 using TwHIN-BERT-large.\n","authors":["Owen Cook","Charlie Grimshaw","Ben Wu","Sophie Dillon","Jack Hicks","Luke Jones","Thomas Smith","Matyas Szert","Xingyi Song"],"pdf_url":"https://arxiv.org/pdf/2410.14515v1.pdf","comment":"8 pages, 3 figures, 3 tables. Code available here:\n  https://github.com/MiniEggz/ruc-misinfo"},{"id":"http://arxiv.org/abs/2406.07361v2","updated":"2024-10-18T14:38:03Z","published":"2024-06-11T15:28:48Z","title":"Deep Implicit Optimization for Robust and Flexible Image Registration","summary":"  Deep Learning in Image Registration (DLIR) methods have been tremendously\nsuccessful in image registration due to their speed and ability to incorporate\nweak label supervision at training time. However, DLIR methods forego many of\nthe benefits of classical optimization-based methods. The functional nature of\ndeep networks do not guarantee that the predicted transformation is a local\nminima of the registration objective, the representation of the transformation\n(displacement/velocity field/affine) is fixed, and the networks are not robust\nto domain shift. Our method aims to bridge this gap between classical and\nlearning methods by incorporating optimization as a layer in a deep network. A\ndeep network is trained to predict multi-scale dense feature images that are\nregistered using a black box iterative optimization solver. This optimal warp\nis then used to minimize image and label alignment errors. By implicitly\ndifferentiating end-to-end through an iterative optimization solver, our\nlearned features are registration and label-aware, and the warp functions are\nguaranteed to be local minima of the registration objective in the feature\nspace. Our framework shows excellent performance on in-domain datasets, and is\nagnostic to domain shift such as anisotropy and varying intensity profiles. For\nthe first time, our method allows switching between arbitrary transformation\nrepresentations (free-form to diffeomorphic) at test time with zero retraining.\nEnd-to-end feature learning also facilitates interpretability of features, and\nout-of-the-box promptability using additional label-fidelity terms at\ninference.\n","authors":["Rohit Jena","Pratik Chaudhari","James C. Gee"],"pdf_url":"https://arxiv.org/pdf/2406.07361v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08979v2","updated":"2024-10-18T14:35:53Z","published":"2024-10-11T16:54:07Z","title":"Overcoming Slow Decision Frequencies in Continuous Control: Model-Based\n  Sequence Reinforcement Learning for Model-Free Control","summary":"  Reinforcement learning (RL) is rapidly reaching and surpassing human-level\ncontrol capabilities. However, state-of-the-art RL algorithms often require\ntimesteps and reaction times significantly faster than human capabilities,\nwhich is impractical in real-world settings and typically necessitates\nspecialized hardware. Such speeds are difficult to achieve in the real world\nand often requires specialized hardware. We introduce Sequence Reinforcement\nLearning (SRL), an RL algorithm designed to produce a sequence of actions for a\ngiven input state, enabling effective control at lower decision frequencies.\nSRL addresses the challenges of learning action sequences by employing both a\nmodel and an actor-critic architecture operating at different temporal scales.\nWe propose a \"temporal recall\" mechanism, where the critic uses the model to\nestimate intermediate states between primitive actions, providing a learning\nsignal for each individual action within the sequence. Once training is\ncomplete, the actor can generate action sequences independently of the model,\nachieving model-free control at a slower frequency. We evaluate SRL on a suite\nof continuous control tasks, demonstrating that it achieves performance\ncomparable to state-of-the-art algorithms while significantly reducing actor\nsample complexity. To better assess performance across varying decision\nfrequencies, we introduce the Frequency-Averaged Score (FAS) metric. Our\nresults show that SRL significantly outperforms traditional RL algorithms in\nterms of FAS, making it particularly suitable for applications requiring\nvariable decision frequencies. Additionally, we compare SRL with model-based\nonline planning, showing that SRL achieves superior FAS while leveraging the\nsame model during training that online planners use for planning.\n","authors":["Devdhar Patel","Hava Siegelmann"],"pdf_url":"https://arxiv.org/pdf/2410.08979v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13012v2","updated":"2024-10-18T14:32:21Z","published":"2024-10-16T20:14:02Z","title":"Sample Compression Scheme Reductions","summary":"  We present novel reductions from sample compression schemes in multiclass\nclassification, regression, and adversarially robust learning settings to\nbinary sample compression schemes. Assuming we have a compression scheme for\nbinary classes of size $f(d_\\mathrm{VC})$, where $d_\\mathrm{VC}$ is the VC\ndimension, then we have the following results: (1) If the binary compression\nscheme is a majority-vote or a stable compression scheme, then there exists a\nmulticlass compression scheme of size $O(f(d_\\mathrm{G}))$, where\n$d_\\mathrm{G}$ is the graph dimension. Moreover, for general binary compression\nschemes, we obtain a compression of size $O(f(d_\\mathrm{G})\\log|Y|)$, where $Y$\nis the label space. (2) If the binary compression scheme is a majority-vote or\na stable compression scheme, then there exists an $\\epsilon$-approximate\ncompression scheme for regression over $[0,1]$-valued functions of size\n$O(f(d_\\mathrm{P}))$, where $d_\\mathrm{P}$ is the pseudo-dimension. For general\nbinary compression schemes, we obtain a compression of size\n$O(f(d_\\mathrm{P})\\log(1/\\epsilon))$. These results would have significant\nimplications if the sample compression conjecture, which posits that any binary\nconcept class with a finite VC dimension admits a binary compression scheme of\nsize $O(d_\\mathrm{VC})$, is resolved (Littlestone and Warmuth, 1986; Floyd and\nWarmuth, 1995; Warmuth, 2003). Our results would then extend the proof of the\nconjecture immediately to other settings. We establish similar results for\nadversarially robust learning and also provide an example of a concept class\nthat is robustly learnable but has no bounded-size compression scheme,\ndemonstrating that learnability is not equivalent to having a compression\nscheme independent of the sample size, unlike in binary classification, where\ncompression of size $2^{O(d_\\mathrm{VC})}$ is attainable (Moran and Yehudayoff,\n2016).\n","authors":["Idan Attias","Steve Hanneke","Arvind Ramaswami"],"pdf_url":"https://arxiv.org/pdf/2410.13012v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14489v1","updated":"2024-10-18T14:19:13Z","published":"2024-10-18T14:19:13Z","title":"An Integrated Deep Learning Model for Skin Cancer Detection Using Hybrid\n  Feature Fusion Technique","summary":"  Skin cancer is a serious and potentially fatal disease caused by DNA damage.\nEarly detection significantly increases survival rates, making accurate\ndiagnosis crucial. In this groundbreaking study, we present a hybrid framework\nbased on Deep Learning (DL) that achieves precise classification of benign and\nmalignant skin lesions. Our approach begins with dataset preprocessing to\nenhance classification accuracy, followed by training two separate pre-trained\nDL models, InceptionV3 and DenseNet121. By fusing the results of each model\nusing the weighted sum rule, our system achieves exceptional accuracy rates.\nSpecifically, we achieve a 92.27% detection accuracy rate, 92.33% sensitivity,\n92.22% specificity, 90.81% precision, and 91.57% F1-score, outperforming\nexisting models and demonstrating the robustness and trustworthiness of our\nhybrid approach. Our study represents a significant advance in skin cancer\ndiagnosis and provides a promising foundation for further research in the\nfield. With the potential to save countless lives through earlier detection,\nour hybrid deep-learning approach is a game-changer in the fight against skin\ncancer.\n","authors":["Maksuda Akter","Rabea Khatun","Md. Alamin Talukder","Md. Manowarul Islam","Md. Ashraf Uddin"],"pdf_url":"https://arxiv.org/pdf/2410.14489v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14488v1","updated":"2024-10-18T14:16:54Z","published":"2024-10-18T14:16:54Z","title":"ANT: Adaptive Noise Schedule for Time Series Diffusion Models","summary":"  Advances in diffusion models for generative artificial intelligence have\nrecently propagated to the time series (TS) domain, demonstrating\nstate-of-the-art performance on various tasks. However, prior works on TS\ndiffusion models often borrow the framework of existing works proposed in other\ndomains without considering the characteristics of TS data, leading to\nsuboptimal performance. In this work, we propose Adaptive Noise schedule for\nTime series diffusion models (ANT), which automatically predetermines proper\nnoise schedules for given TS datasets based on their statistics representing\nnon-stationarity. Our intuition is that an optimal noise schedule should\nsatisfy the following desiderata: 1) It linearly reduces the non-stationarity\nof TS data so that all diffusion steps are equally meaningful, 2) the data is\ncorrupted to the random noise at the final step, and 3) the number of steps is\nsufficiently large. The proposed method is practical for use in that it\neliminates the necessity of finding the optimal noise schedule with a small\nadditional cost to compute the statistics for given datasets, which can be done\noffline before training. We validate the effectiveness of our method across\nvarious tasks, including TS forecasting, refinement, and generation, on\ndatasets from diverse domains. Code is available at this repository:\nhttps://github.com/seunghan96/ANT.\n","authors":["Seunghan Lee","Kibok Lee","Taeyoung Park"],"pdf_url":"https://arxiv.org/pdf/2410.14488v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.14485v1","updated":"2024-10-18T14:10:16Z","published":"2024-10-18T14:10:16Z","title":"CaTs and DAGs: Integrating Directed Acyclic Graphs with Transformers and\n  Fully-Connected Neural Networks for Causally Constrained Predictions","summary":"  Artificial Neural Networks (ANNs), including fully-connected networks and\ntransformers, are highly flexible and powerful function approximators, widely\napplied in fields like computer vision and natural language processing.\nHowever, their inability to inherently respect causal structures can limit\ntheir robustness, making them vulnerable to covariate shift and difficult to\ninterpret/explain. This poses significant challenges for their reliability in\nreal-world applications. In this paper, we introduce Causal Fully-Connected\nNeural Networks (CFCNs) and Causal Transformers (CaTs), two general model\nfamilies designed to operate under predefined causal constraints, as specified\nby a Directed Acyclic Graph (DAG). These models retain the powerful function\napproximation abilities of traditional neural networks while adhering to the\nunderlying structural constraints, improving robustness, reliability, and\ninterpretability at inference time. This approach opens new avenues for\ndeploying neural networks in more demanding, real-world scenarios where\nrobustness and explainability is critical.\n","authors":["Matthew J. Vowels","Mathieu Rochat","Sina Akbari"],"pdf_url":"https://arxiv.org/pdf/2410.14485v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14484v1","updated":"2024-10-18T14:08:41Z","published":"2024-10-18T14:08:41Z","title":"Transfer Reinforcement Learning in Heterogeneous Action Spaces using\n  Subgoal Mapping","summary":"  In this paper, we consider a transfer reinforcement learning problem\ninvolving agents with different action spaces. Specifically, for any new unseen\ntask, the goal is to use a successful demonstration of this task by an expert\nagent in its action space to enable a learner agent learn an optimal policy in\nits own different action space with fewer samples than those required if the\nlearner was learning on its own. Existing transfer learning methods across\ndifferent action spaces either require handcrafted mappings between those\naction spaces provided by human experts, which can induce bias in the learning\nprocedure, or require the expert agent to share its policy parameters with the\nlearner agent, which does not generalize well to unseen tasks. In this work, we\npropose a method that learns a subgoal mapping between the expert agent policy\nand the learner agent policy. Since the expert agent and the learner agent have\ndifferent action spaces, their optimal policies can have different subgoal\ntrajectories. We learn this subgoal mapping by training a Long Short Term\nMemory (LSTM) network for a distribution of tasks and then use this mapping to\npredict the learner subgoal sequence for unseen tasks, thereby improving the\nspeed of learning by biasing the agent's policy towards the predicted learner\nsubgoal sequence. Through numerical experiments, we demonstrate that the\nproposed learning scheme can effectively find the subgoal mapping underlying\nthe given distribution of tasks. Moreover, letting the learner agent imitate\nthe expert agent's policy with the learnt subgoal mapping can significantly\nimprove the sample efficiency and training time of the learner agent in unseen\nnew tasks.\n","authors":["Kavinayan P. Sivakumar","Yan Zhang","Zachary Bell","Scott Nivison","Michael M. Zavlanos"],"pdf_url":"https://arxiv.org/pdf/2410.14484v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14483v1","updated":"2024-10-18T14:06:49Z","published":"2024-10-18T14:06:49Z","title":"Spectral Representations for Accurate Causal Uncertainty Quantification\n  with Gaussian Processes","summary":"  Accurate uncertainty quantification for causal effects is essential for\nrobust decision making in complex systems, but remains challenging in\nnon-parametric settings. One promising framework represents conditional\ndistributions in a reproducing kernel Hilbert space and places Gaussian process\npriors on them to infer posteriors on causal effects, but requires restrictive\nnuclear dominant kernels and approximations that lead to unreliable uncertainty\nestimates. In this work, we introduce a method, IMPspec, that addresses these\nlimitations via a spectral representation of the Hilbert space. We show that\nposteriors in this model can be obtained explicitly, by extending a result in\nHilbert space regression theory. We also learn the spectral representation to\noptimise posterior calibration. Our method achieves state-of-the-art\nperformance in uncertainty quantification and causal Bayesian optimisation\nacross simulations and a healthcare application.\n","authors":["Hugh Dance","Peter Orbanz","Arthur Gretton"],"pdf_url":"https://arxiv.org/pdf/2410.14483v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09804v2","updated":"2024-10-18T14:03:05Z","published":"2024-10-13T11:15:38Z","title":"BlackDAN: A Black-Box Multi-Objective Approach for Effective and\n  Contextual Jailbreaking of Large Language Models","summary":"  While large language models (LLMs) exhibit remarkable capabilities across\nvarious tasks, they encounter potential security risks such as jailbreak\nattacks, which exploit vulnerabilities to bypass security measures and generate\nharmful outputs. Existing jailbreak strategies mainly focus on maximizing\nattack success rate (ASR), frequently neglecting other critical factors,\nincluding the relevance of the jailbreak response to the query and the level of\nstealthiness. This narrow focus on single objectives can result in ineffective\nattacks that either lack contextual relevance or are easily recognizable. In\nthis work, we introduce BlackDAN, an innovative black-box attack framework with\nmulti-objective optimization, aiming to generate high-quality prompts that\neffectively facilitate jailbreaking while maintaining contextual relevance and\nminimizing detectability. BlackDAN leverages Multiobjective Evolutionary\nAlgorithms (MOEAs), specifically the NSGA-II algorithm, to optimize jailbreaks\nacross multiple objectives including ASR, stealthiness, and semantic relevance.\nBy integrating mechanisms like mutation, crossover, and Pareto-dominance,\nBlackDAN provides a transparent and interpretable process for generating\njailbreaks. Furthermore, the framework allows customization based on user\npreferences, enabling the selection of prompts that balance harmfulness,\nrelevance, and other factors. Experimental results demonstrate that BlackDAN\noutperforms traditional single-objective methods, yielding higher success rates\nand improved robustness across various LLMs and multimodal LLMs, while ensuring\njailbreak responses are both relevant and less detectable.\n","authors":["Xinyuan Wang","Victor Shea-Jay Huang","Renmiao Chen","Hao Wang","Chengwei Pan","Lei Sha","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2410.09804v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14479v1","updated":"2024-10-18T14:02:34Z","published":"2024-10-18T14:02:34Z","title":"Backdoored Retrievers for Prompt Injection Attacks on Retrieval\n  Augmented Generation of Large Language Models","summary":"  Large Language Models (LLMs) have demonstrated remarkable capabilities in\ngenerating coherent text but remain limited by the static nature of their\ntraining data. Retrieval Augmented Generation (RAG) addresses this issue by\ncombining LLMs with up-to-date information retrieval, but also expand the\nattack surface of the system. This paper investigates prompt injection attacks\non RAG, focusing on malicious objectives beyond misinformation, such as\ninserting harmful links, promoting unauthorized services, and initiating\ndenial-of-service behaviors. We build upon existing corpus poisoning techniques\nand propose a novel backdoor attack aimed at the fine-tuning process of the\ndense retriever component. Our experiments reveal that corpus poisoning can\nachieve significant attack success rates through the injection of a small\nnumber of compromised documents into the retriever corpus. In contrast,\nbackdoor attacks demonstrate even higher success rates but necessitate a more\ncomplex setup, as the victim must fine-tune the retriever using the attacker\npoisoned dataset.\n","authors":["Cody Clop","Yannick Teglia"],"pdf_url":"https://arxiv.org/pdf/2410.14479v1.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2410.14477v1","updated":"2024-10-18T14:02:06Z","published":"2024-10-18T14:02:06Z","title":"Laplace Transform Based Low-Complexity Learning of Continuous Markov\n  Semigroups","summary":"  Markov processes serve as a universal model for many real-world random\nprocesses. This paper presents a data-driven approach for learning these models\nthrough the spectral decomposition of the infinitesimal generator (IG) of the\nMarkov semigroup. The unbounded nature of IGs complicates traditional methods\nsuch as vector-valued regression and Hilbert-Schmidt operator analysis.\nExisting techniques, including physics-informed kernel regression, are\ncomputationally expensive and limited in scope, with no recovery guarantees for\ntransfer operator methods when the time-lag is small. We propose a novel method\nthat leverages the IG's resolvent, characterized by the Laplace transform of\ntransfer operators. This approach is robust to time-lag variations, ensuring\naccurate eigenvalue learning even for small time-lags. Our statistical analysis\napplies to a broader class of Markov processes than current methods while\nreducing computational complexity from quadratic to linear in the state\ndimension. Finally, we illustrate the behaviour of our method in two\nexperiments.\n","authors":["Vladimir R. Kostic","Karim Lounici","Hélène Halconruy","Timothée Devergne","Pietro Novelli","Massimiliano Pontil"],"pdf_url":"https://arxiv.org/pdf/2410.14477v1.pdf","comment":"35 pages"},{"id":"http://arxiv.org/abs/2410.14475v1","updated":"2024-10-18T14:00:44Z","published":"2024-10-18T14:00:44Z","title":"Enhancing Cryptocurrency Market Forecasting: Advanced Machine Learning\n  Techniques and Industrial Engineering Contributions","summary":"  Cryptocurrencies, as decentralized digital assets, have experienced rapid\ngrowth and adoption, with over 23,000 cryptocurrencies and a market\ncapitalization nearing \\$1.1 trillion (about \\$3,400 per person in the US) as\nof 2023. This dynamic market presents significant opportunities and risks,\nhighlighting the need for accurate price prediction models to manage\nvolatility. This chapter comprehensively reviews machine learning (ML)\ntechniques applied to cryptocurrency price prediction from 2014 to 2024. We\nexplore various ML algorithms, including linear models, tree-based approaches,\nand advanced deep learning architectures such as transformers and large\nlanguage models. Additionally, we examine the role of sentiment analysis in\ncapturing market sentiment from textual data like social media posts and news\narticles to anticipate price fluctuations. With expertise in optimizing complex\nsystems and processes, industrial engineers are pivotal in enhancing these\nmodels. They contribute by applying principles of process optimization,\nefficiency, and risk mitigation to improve computational performance and data\nmanagement. This chapter highlights the evolving landscape of cryptocurrency\nprice prediction, the integration of emerging technologies, and the significant\nrole of industrial engineers in refining predictive models. By addressing\ncurrent limitations and exploring future research directions, this chapter aims\nto advance the development of more accurate and robust prediction systems,\nsupporting better-informed investment decisions and more stable market\nbehavior.\n","authors":["Jannatun Nayeem Pinky","Ramya Akula"],"pdf_url":"https://arxiv.org/pdf/2410.14475v1.pdf","comment":"63 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.14470v1","updated":"2024-10-18T13:54:46Z","published":"2024-10-18T13:54:46Z","title":"How Do Training Methods Influence the Utilization of Vision Models?","summary":"  Not all learnable parameters (e.g., weights) contribute equally to a neural\nnetwork's decision function. In fact, entire layers' parameters can sometimes\nbe reset to random values with little to no impact on the model's decisions. We\nrevisit earlier studies that examined how architecture and task complexity\ninfluence this phenomenon and ask: is this phenomenon also affected by how we\ntrain the model? We conducted experimental evaluations on a diverse set of\nImageNet-1k classification models to explore this, keeping the architecture and\ntraining data constant but varying the training pipeline. Our findings reveal\nthat the training method strongly influences which layers become critical to\nthe decision function for a given task. For example, improved training regimes\nand self-supervised training increase the importance of early layers while\nsignificantly under-utilizing deeper layers. In contrast, methods such as\nadversarial training display an opposite trend. Our preliminary results extend\nprevious findings, offering a more nuanced understanding of the inner mechanics\nof neural networks.\n  Code: https://github.com/paulgavrikov/layer_criticality\n","authors":["Paul Gavrikov","Shashank Agnihotri","Margret Keuper","Janis Keuper"],"pdf_url":"https://arxiv.org/pdf/2410.14470v1.pdf","comment":"Accepted at the Interpretable AI: Past, Present and Future Workshop\n  at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.14466v1","updated":"2024-10-18T13:51:25Z","published":"2024-10-18T13:51:25Z","title":"Flow-based Sampling for Entanglement Entropy and the Machine Learning of\n  Defects","summary":"  We introduce a novel technique to numerically calculate R\\'enyi entanglement\nentropies in lattice quantum field theory using generative models. We describe\nhow flow-based approaches can be combined with the replica trick using a custom\nneural-network architecture around a lattice defect connecting two replicas.\nNumerical tests for the $\\phi^4$ scalar field theory in two and three\ndimensions demonstrate that our technique outperforms state-of-the-art Monte\nCarlo calculations, and exhibit a promising scaling with the defect size.\n","authors":["Andrea Bulgarelli","Elia Cellini","Karl Jansen","Stefan Kühn","Alessandro Nada","Shinichi Nakajima","Kim A. Nicoli","Marco Panero"],"pdf_url":"https://arxiv.org/pdf/2410.14466v1.pdf","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2404.18550v4","updated":"2024-10-18T13:50:10Z","published":"2024-04-29T09:45:46Z","title":"IncidentResponseGPT: Generating Traffic Incident Response Plans with\n  Generative Artificial Intelligence","summary":"  The proposed IncidentResponseGPT framework - a novel system that applies\ngenerative artificial intelligence (AI) to potentially enhance the efficiency\nand effectiveness of traffic incident response. This model allows for synthesis\nof region-specific incident response guidelines and generates incident response\nplans adapted to specific area, aiming to expedite decision-making for traffic\nmanagement authorities. This approach aims to accelerate incident resolution\ntimes by suggesting various recommendations (e.g. optimal rerouting strategies,\nestimating resource needs) to minimize the overall impact on the urban traffic\nnetwork. The system suggests specific actions, including dynamic lane closures,\noptimized rerouting and dispatching appropriate emergency resources. We utilize\nthe Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) to\nrank generated response plans based on criteria like impact minimization and\nresource efficiency based on their proximity to an human-proposed solution.\n","authors":["Artur Grigorev","Adriana-Simona Mihaita Khaled Saleh","Yuming Ou"],"pdf_url":"https://arxiv.org/pdf/2404.18550v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14464v1","updated":"2024-10-18T13:48:01Z","published":"2024-10-18T13:48:01Z","title":"Electrocardiogram-Language Model for Few-Shot Question Answering with\n  Meta Learning","summary":"  Electrocardiogram (ECG) interpretation requires specialized expertise, often\ninvolving synthesizing insights from ECG signals with complex clinical queries\nposed in natural language. The scarcity of labeled ECG data coupled with the\ndiverse nature of clinical inquiries presents a significant challenge for\ndeveloping robust and adaptable ECG diagnostic systems. This work introduces a\nnovel multimodal meta-learning method for few-shot ECG question answering,\naddressing the challenge of limited labeled data while leveraging the rich\nknowledge encoded within large language models (LLMs). Our LLM-agnostic\napproach integrates a pre-trained ECG encoder with a frozen LLM (e.g., LLaMA\nand Gemma) via a trainable fusion module, enabling the language model to reason\nabout ECG data and generate clinically meaningful answers. Extensive\nexperiments demonstrate superior generalization to unseen diagnostic tasks\ncompared to supervised baselines, achieving notable performance even with\nlimited ECG leads. For instance, in a 5-way 5-shot setting, our method using\nLLaMA-3.1-8B achieves accuracy of 84.6%, 77.3%, and 69.6% on single verify,\nchoose and query question types, respectively. These results highlight the\npotential of our method to enhance clinical ECG interpretation by combining\nsignal processing with the nuanced language understanding capabilities of LLMs,\nparticularly in data-constrained scenarios.\n","authors":["Jialu Tang","Tong Xia","Yuan Lu","Cecilia Mascolo","Aaqib Saeed"],"pdf_url":"https://arxiv.org/pdf/2410.14464v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14461v1","updated":"2024-10-18T13:40:44Z","published":"2024-10-18T13:40:44Z","title":"The Propensity for Density in Feed-forward Models","summary":"  Does the process of training a neural network to solve a task tend to use all\nof the available weights even when the task could be solved with fewer weights?\nTo address this question we study the effects of pruning fully connected,\nconvolutional and residual models while varying their widths. We find that the\nproportion of weights that can be pruned without degrading performance is\nlargely invariant to model size. Increasing the width of a model has little\neffect on the density of the pruned model relative to the increase in absolute\nsize of the pruned network. In particular, we find substantial prunability\nacross a large range of model sizes, where our biggest model is 50 times as\nwide as our smallest model. We explore three hypotheses that could explain\nthese findings.\n","authors":["Nandi Schoots","Alex Jackson","Ali Kholmovaia","Peter McBurney","Murray Shanahan"],"pdf_url":"https://arxiv.org/pdf/2410.14461v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.13663v4","updated":"2024-10-18T13:16:57Z","published":"2024-06-19T16:10:26Z","title":"Model Internals-based Answer Attribution for Trustworthy\n  Retrieval-Augmented Generation","summary":"  Ensuring the verifiability of model answers is a fundamental challenge for\nretrieval-augmented generation (RAG) in the question answering (QA) domain.\nRecently, self-citation prompting was proposed to make large language models\n(LLMs) generate citations to supporting documents along with their answers.\nHowever, self-citing LLMs often struggle to match the required format, refer to\nnon-existent sources, and fail to faithfully reflect LLMs' context usage\nthroughout the generation. In this work, we present MIRAGE --Model\nInternals-based RAG Explanations -- a plug-and-play approach using model\ninternals for faithful answer attribution in RAG applications. MIRAGE detects\ncontext-sensitive answer tokens and pairs them with retrieved documents\ncontributing to their prediction via saliency methods. We evaluate our proposed\napproach on a multilingual extractive QA dataset, finding high agreement with\nhuman answer attribution. On open-ended QA, MIRAGE achieves citation quality\nand efficiency comparable to self-citation while also allowing for a\nfiner-grained control of attribution parameters. Our qualitative evaluation\nhighlights the faithfulness of MIRAGE's attributions and underscores the\npromising application of model internals for RAG answer attribution.\n","authors":["Jirui Qi","Gabriele Sarti","Raquel Fernández","Arianna Bisazza"],"pdf_url":"https://arxiv.org/pdf/2406.13663v4.pdf","comment":"Accepted by EMNLP 2024 Main Conference. Code and data released at\n  https://github.com/Betswish/MIRAGE"},{"id":"http://arxiv.org/abs/2410.12804v2","updated":"2024-10-18T13:15:50Z","published":"2024-09-30T12:05:07Z","title":"Hip Fracture Patient Pathways and Agent-based Modelling","summary":"  Increased healthcare demand is significantly straining European services.\nDigital solutions including advanced modelling techniques offer a promising\nsolution to optimising patient flow without impacting day-to-day healthcare\nprovision. In this work we outline an ongoing project that aims to optimise\nhealthcare resources using agent-based simulations.\n","authors":["Alison N. O'Connor","Stephen E. Ryan","Gauri Vaidya","Paul Harford","Meghana Kshirsagar"],"pdf_url":"https://arxiv.org/pdf/2410.12804v2.pdf","comment":"6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.11443v2","updated":"2024-10-18T13:09:00Z","published":"2024-10-15T09:47:49Z","title":"Are High-Degree Representations Really Unnecessary in Equivariant Graph\n  Neural Networks?","summary":"  Equivariant Graph Neural Networks (GNNs) that incorporate E(3) symmetry have\nachieved significant success in various scientific applications. As one of the\nmost successful models, EGNN leverages a simple scalarization technique to\nperform equivariant message passing over only Cartesian vectors (i.e.,\n1st-degree steerable vectors), enjoying greater efficiency and efficacy\ncompared to equivariant GNNs using higher-degree steerable vectors. This\nsuccess suggests that higher-degree representations might be unnecessary. In\nthis paper, we disprove this hypothesis by exploring the expressivity of\nequivariant GNNs on symmetric structures, including $k$-fold rotations and\nregular polyhedra. We theoretically demonstrate that equivariant GNNs will\nalways degenerate to a zero function if the degree of the output\nrepresentations is fixed to 1 or other specific values. Based on this\ntheoretical insight, we propose HEGNN, a high-degree version of EGNN to\nincrease the expressivity by incorporating high-degree steerable vectors while\nmaintaining EGNN's efficiency through the scalarization trick. Our extensive\nexperiments demonstrate that HEGNN not only aligns with our theoretical\nanalyses on toy datasets consisting of symmetric structures, but also shows\nsubstantial improvements on more complicated datasets such as $N$-body and\nMD17. Our theoretical findings and empirical results potentially open up new\npossibilities for the research of equivariant GNNs.\n","authors":["Jiacheng Cen","Anyi Li","Ning Lin","Yuxiang Ren","Zihe Wang","Wenbing Huang"],"pdf_url":"https://arxiv.org/pdf/2410.11443v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.11877v5","updated":"2024-10-18T13:03:05Z","published":"2024-05-20T08:41:15Z","title":"A Novel Cartography-Based Curriculum Learning Method Applied on RoNLI:\n  The First Romanian Natural Language Inference Corpus","summary":"  Natural language inference (NLI), the task of recognizing the entailment\nrelationship in sentence pairs, is an actively studied topic serving as a proxy\nfor natural language understanding. Despite the relevance of the task in\nbuilding conversational agents and improving text classification, machine\ntranslation and other NLP tasks, to the best of our knowledge, there is no\npublicly available NLI corpus for the Romanian language. To this end, we\nintroduce the first Romanian NLI corpus (RoNLI) comprising 58K training\nsentence pairs, which are obtained via distant supervision, and 6K validation\nand test sentence pairs, which are manually annotated with the correct labels.\nWe conduct experiments with multiple machine learning methods based on distant\nlearning, ranging from shallow models based on word embeddings to\ntransformer-based neural networks, to establish a set of competitive baselines.\nFurthermore, we improve on the best model by employing a new curriculum\nlearning strategy based on data cartography. Our dataset and code to reproduce\nthe baselines are available at https://github.com/Eduard6421/RONLI.\n","authors":["Eduard Poesina","Cornelia Caragea","Radu Tudor Ionescu"],"pdf_url":"https://arxiv.org/pdf/2405.11877v5.pdf","comment":"Accepted at ACL 2024 (Main)"},{"id":"http://arxiv.org/abs/2410.14436v1","updated":"2024-10-18T12:53:23Z","published":"2024-10-18T12:53:23Z","title":"Learning to refine domain knowledge for biological network inference","summary":"  Perturbation experiments allow biologists to discover causal relationships\nbetween variables of interest, but the sparsity and high dimensionality of\nthese data pose significant challenges for causal structure learning\nalgorithms. Biological knowledge graphs can bootstrap the inference of causal\nstructures in these situations, but since they compile vastly diverse\ninformation, they can bias predictions towards well-studied systems.\nAlternatively, amortized causal structure learning algorithms encode inductive\nbiases through data simulation and train supervised models to recapitulate\nthese synthetic graphs. However, realistically simulating biology is arguably\neven harder than understanding a specific system. In this work, we take\ninspiration from both strategies and propose an amortized algorithm for\nrefining domain knowledge, based on data observations. On real and synthetic\ndatasets, we show that our approach outperforms baselines in recovering ground\ntruth causal graphs and identifying errors in the prior knowledge with limited\ninterventional data.\n","authors":["Peiwen Li","Menghua Wu"],"pdf_url":"https://arxiv.org/pdf/2410.14436v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14433v1","updated":"2024-10-18T12:51:19Z","published":"2024-10-18T12:51:19Z","title":"A Bioinformatic Approach Validated Utilizing Machine Learning Algorithms\n  to Identify Relevant Biomarkers and Crucial Pathways in Gallbladder Cancer","summary":"  Gallbladder cancer (GBC) is the most frequent cause of disease among biliary\ntract neoplasms. Identifying the molecular mechanisms and biomarkers linked to\nGBC progression has been a significant challenge in scientific research. Few\nrecent studies have explored the roles of biomarkers in GBC. Our study aimed to\nidentify biomarkers in GBC using machine learning (ML) and bioinformatics\ntechniques. We compared GBC tumor samples with normal samples to identify\ndifferentially expressed genes (DEGs) from two microarray datasets (GSE100363,\nGSE139682) obtained from the NCBI GEO database. A total of 146 DEGs were found,\nwith 39 up-regulated and 107 down-regulated genes. Functional enrichment\nanalysis of these DEGs was performed using Gene Ontology (GO) terms and\nREACTOME pathways through DAVID. The protein-protein interaction network was\nconstructed using the STRING database. To identify hub genes, we applied three\nranking algorithms: Degree, MNC, and Closeness Centrality. The intersection of\nhub genes from these algorithms yielded 11 hub genes. Simultaneously, two\nfeature selection methods (Pearson correlation and recursive feature\nelimination) were used to identify significant gene subsets. We then developed\nML models using SVM and RF on the GSE100363 dataset, with validation on\nGSE139682, to determine the gene subset that best distinguishes GBC samples.\nThe hub genes outperformed the other gene subsets. Finally, NTRK2, COL14A1,\nSCN4B, ATP1A2, SLC17A7, SLIT3, COL7A1, CLDN4, CLEC3B, ADCYAP1R1, and MFAP4 were\nidentified as crucial genes, with SLIT3, COL7A1, and CLDN4 being strongly\nlinked to GBC development and prediction.\n","authors":["Rabea Khatun","Wahia Tasnim","Maksuda Akter","Md Manowarul Islam","Md. Ashraf Uddin","Md. Zulfiker Mahmud","Saurav Chandra Das"],"pdf_url":"https://arxiv.org/pdf/2410.14433v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14429v1","updated":"2024-10-18T12:48:22Z","published":"2024-10-18T12:48:22Z","title":"FashionR2R: Texture-preserving Rendered-to-Real Image Translation with\n  Diffusion Models","summary":"  Modeling and producing lifelike clothed human images has attracted\nresearchers' attention from different areas for decades, with the complexity\nfrom highly articulated and structured content. Rendering algorithms decompose\nand simulate the imaging process of a camera, while are limited by the accuracy\nof modeled variables and the efficiency of computation. Generative models can\nproduce impressively vivid human images, however still lacking in\ncontrollability and editability. This paper studies photorealism enhancement of\nrendered images, leveraging generative power from diffusion models on the\ncontrolled basis of rendering. We introduce a novel framework to translate\nrendered images into their realistic counterparts, which consists of two\nstages: Domain Knowledge Injection (DKI) and Realistic Image Generation (RIG).\nIn DKI, we adopt positive (real) domain finetuning and negative (rendered)\ndomain embedding to inject knowledge into a pretrained Text-to-image (T2I)\ndiffusion model. In RIG, we generate the realistic image corresponding to the\ninput rendered image, with a Texture-preserving Attention Control (TAC) to\npreserve fine-grained clothing textures, exploiting the decoupled features\nencoded in the UNet structure. Additionally, we introduce SynFashion dataset,\nfeaturing high-quality digital clothing images with diverse textures. Extensive\nexperimental results demonstrate the superiority and effectiveness of our\nmethod in rendered-to-real image translation.\n","authors":["Rui Hu","Qian He","Gaofeng He","Jiedong Zhuang","Huang Chen","Huafeng Liu","Huamin Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14429v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.14426v1","updated":"2024-10-18T12:41:41Z","published":"2024-10-18T12:41:41Z","title":"Predicting time-varying flux and balance in metabolic systems using\n  structured neural-ODE processes","summary":"  We develop a novel data-driven framework as an alternative to dynamic flux\nbalance analysis, bypassing the demand for deep domain knowledge and manual\nefforts to formulate the optimization problem. The proposed framework is\nend-to-end, which trains a structured neural ODE process (SNODEP) model to\nestimate flux and balance samples using gene-expression time-series data.\nSNODEP is designed to circumvent the limitations of the standard neural ODE\nprocess model, including restricting the latent and decoder sampling\ndistributions to be normal and lacking structure between context points for\ncalculating the latent, thus more suitable for modeling the underlying dynamics\nof a metabolic system. Through comprehensive experiments ($156$ in total), we\ndemonstrate that SNODEP not only predicts the unseen time points of real-world\ngene-expression data and the flux and balance estimates well but can even\ngeneralize to more challenging unseen knockout configurations and irregular\ndata sampling scenarios, all essential for metabolic pathway analysis. We hope\nour work can serve as a catalyst for building more scalable and powerful models\nfor genome-scale metabolic analysis. Our code is available at:\n\\url{https://github.com/TrustMLRG/SNODEP}.\n","authors":["Santanu Rathod","Pietro Lio","Xiao Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.14426v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.03546v2","updated":"2024-10-18T12:41:23Z","published":"2023-10-05T13:57:53Z","title":"Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior\n  Models","summary":"  Posterior sampling has been shown to be a powerful Bayesian approach for\nsolving imaging inverse problems. The recent plug-and-play unadjusted Langevin\nalgorithm (PnP-ULA) has emerged as a promising method for Monte Carlo sampling\nand minimum mean squared error (MMSE) estimation by combining physical\nmeasurement models with deep-learning priors specified using image denoisers.\nHowever, the intricate relationship between the sampling distribution of\nPnP-ULA and the mismatched data-fidelity and denoiser has not been\ntheoretically analyzed. We address this gap by proposing a posterior-L2\npseudometric and using it to quantify an explicit error bound for PnP-ULA under\nmismatched posterior distribution. We numerically validate our theory on\nseveral inverse problems such as sampling from Gaussian mixture models and\nimage deblurring. Our results suggest that the sensitivity of the sampling\ndistribution of PnP-ULA to a mismatch in the measurement model and the denoiser\ncan be precisely characterized.\n","authors":["Marien Renaud","Jiaming Liu","Valentin de Bortoli","Andrés Almansa","Ulugbek S. Kamilov"],"pdf_url":"https://arxiv.org/pdf/2310.03546v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14423v1","updated":"2024-10-18T12:37:51Z","published":"2024-10-18T12:37:51Z","title":"Integrating Deep Learning with Fundus and Optical Coherence Tomography\n  for Cardiovascular Disease Prediction","summary":"  Early identification of patients at risk of cardiovascular diseases (CVD) is\ncrucial for effective preventive care, reducing healthcare burden, and\nimproving patients' quality of life. This study demonstrates the potential of\nretinal optical coherence tomography (OCT) imaging combined with fundus\nphotographs for identifying future adverse cardiac events. We used data from\n977 patients who experienced CVD within a 5-year interval post-image\nacquisition, alongside 1,877 control participants without CVD, totaling 2,854\nsubjects. We propose a novel binary classification network based on a\nMulti-channel Variational Autoencoder (MCVAE), which learns a latent embedding\nof patients' fundus and OCT images to classify individuals into two groups:\nthose likely to develop CVD in the future and those who are not. Our model,\ntrained on both imaging modalities, achieved promising results (AUROC 0.78 +/-\n0.02, accuracy 0.68 +/- 0.002, precision 0.74 +/- 0.02, sensitivity 0.73 +/-\n0.02, and specificity 0.68 +/- 0.01), demonstrating its efficacy in identifying\npatients at risk of future CVD events based on their retinal images. This study\nhighlights the potential of retinal OCT imaging and fundus photographs as\ncost-effective, non-invasive alternatives for predicting cardiovascular disease\nrisk. The widespread availability of these imaging techniques in optometry\npractices and hospitals further enhances their potential for large-scale CVD\nrisk screening. Our findings contribute to the development of standardized,\naccessible methods for early CVD risk identification, potentially improving\npreventive care strategies and patient outcomes.\n","authors":["Cynthia Maldonado-Garcia","Arezoo Zakeri","Alejandro F Frangi","Nishant Ravikumar"],"pdf_url":"https://arxiv.org/pdf/2410.14423v1.pdf","comment":"Part of the book series: Lecture Notes in Computer Science\n  ((LNCS,volume 15155))"},{"id":"http://arxiv.org/abs/2410.14420v1","updated":"2024-10-18T12:33:10Z","published":"2024-10-18T12:33:10Z","title":"Asymptotic non-linear shrinkage formulas for weighted sample covariance","summary":"  We compute asymptotic non-linear shrinkage formulas for covariance and\nprecision matrix estimators for weighted sample covariances, in the spirit of\nLedoit and P\\'ech\\'e. We detail explicitly the formulas for\nexponentially-weighted sample covariances. Those new tools pave a way for\napplying non-linear shrinkage methods on weighted sample covariance. We show\nexperimentally the performance of the asymptotic shrinkage formulas. Finally,\nwe test the robustness of the theory to a heavy-tailed distributions.\n","authors":["Benoit Oriol"],"pdf_url":"https://arxiv.org/pdf/2410.14420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14416v1","updated":"2024-10-18T12:29:10Z","published":"2024-10-18T12:29:10Z","title":"An explainable machine learning approach for energy forecasting at the\n  household level","summary":"  Electricity forecasting has been a recurring research topic, as it is key to\nfinding the right balance between production and consumption. While most papers\nare focused on the national or regional scale, few are interested in the\nhousehold level. Desegregated forecast is a common topic in Machine Learning\n(ML) literature but lacks explainability that household energy forecasts\nrequire. This paper specifically targets the challenges of forecasting\nelectricity use at the household level. This paper confronts common Machine\nLearning algorithms to electricity household forecasts, weighing the pros and\ncons, including accuracy and explainability with well-known key metrics.\nFurthermore, we also confront them in this paper with the business challenges\nspecific to this sector such as explainability or outliers resistance. We\nintroduce a custom decision tree, aiming at providing a fair estimate of the\nenergy consumption, while being explainable and consistent with human\nintuition. We show that this novel method allows greater explainability without\nsacrificing much accuracy. The custom tree methodology can be used in various\nbusiness use cases but is subject to limitations, such as a lack of resilience\nwith outliers.\n","authors":["Pauline Béraud","Margaux Rioux","Michel Babany","Philippe de La Chevasnerie","Damien Theis","Giacomo Teodori","Chloé Pinguet","Romane Rigaud","François Leclerc"],"pdf_url":"https://arxiv.org/pdf/2410.14416v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10918v5","updated":"2024-10-18T12:27:07Z","published":"2024-06-16T12:46:40Z","title":"Multi-LLM QA with Embodied Exploration","summary":"  Large language models (LLMs) have grown in popularity due to their natural\nlanguage interface and pre trained knowledge, leading to rapidly increasing\nsuccess in question-answering (QA) tasks. More recently, multi-agent systems\nwith LLM-based agents (Multi-LLM) have been utilized increasingly more for QA.\nIn these scenarios, the models may each answer the question and reach a\nconsensus or each model is specialized to answer different domain questions.\nHowever, most prior work dealing with Multi-LLM QA has focused on scenarios\nwhere the models are asked in a zero-shot manner or are given information\nsources to extract the answer. For question answering of an unknown\nenvironment, embodied exploration of the environment is first needed to answer\nthe question. This skill is necessary for personalizing embodied AI to\nenvironments such as households. There is a lack of insight into whether a\nMulti-LLM system can handle question-answering based on observations from\nembodied exploration. In this work, we address this gap by investigating the\nuse of Multi-Embodied LLM Explorers (MELE) for QA in an unknown environment.\nMultiple LLM-based agents independently explore and then answer queries about a\nhousehold environment. We analyze different aggregation methods to generate a\nsingle, final answer for each query: debating, majority voting, and training a\ncentral answer module (CAM). Using CAM, we observe a $46\\%$ higher accuracy\ncompared against the other non-learning-based aggregation methods. We provide\ncode and the query dataset for further research.\n","authors":["Bhrij Patel","Vishnu Sashank Dorbala","Amrit Singh Bedi","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2406.10918v5.pdf","comment":"16 pages, 9 Figures, 5 Tables"},{"id":"http://arxiv.org/abs/2410.14413v1","updated":"2024-10-18T12:26:51Z","published":"2024-10-18T12:26:51Z","title":"WeSpeR: Population spectrum retrieval and spectral density estimation of\n  weighted sample covariance","summary":"  The spectrum of the weighted sample covariance shows a asymptotic non random\nbehavior when the dimension grows with the number of samples. In this setting,\nwe prove that the asymptotic spectral distribution $F$ of the weighted sample\ncovariance has a continuous density on $\\mathbb{R}^*$. We address then the\npractical problem of numerically finding this density. We propose a procedure\nto compute it, to determine the support of $F$ and define an efficient grid on\nit. We use this procedure to design the $\\textit{WeSpeR}$ algorithm, which\nestimates the spectral density and retrieves the true spectral covariance\nspectrum. Empirical tests confirm the good properties of the $\\textit{WeSpeR}$\nalgorithm.\n","authors":["Benoit Oriol"],"pdf_url":"https://arxiv.org/pdf/2410.14413v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.10547v2","updated":"2024-10-18T12:25:46Z","published":"2024-07-15T08:57:02Z","title":"Learning Social Cost Functions for Human-Aware Path Planning","summary":"  Achieving social acceptance is one of the main goals of Social Robotic\nNavigation. Despite this topic has received increasing interest in recent\nyears, most of the research has focused on driving the robotic agent along\nobstacle-free trajectories, planning around estimates of future human motion to\nrespect personal distances and optimize navigation. However, social\ninteractions in everyday life are also dictated by norms that do not strictly\ndepend on movement, such as when standing at the end of a queue rather than\ncutting it. In this paper, we propose a novel method to recognize common social\nscenarios and modify a traditional planner's cost function to adapt to them.\nThis solution enables the robot to carry out different social navigation\nbehaviors that would not arise otherwise, maintaining the robustness of\ntraditional navigation. Our approach allows the robot to learn different social\nnorms with a single learned model, rather than having different modules for\neach task. As a proof of concept, we consider the tasks of queuing and respect\ninteraction spaces of groups of people talking to one another, but the method\ncan be extended to other human activities that do not involve motion.\n","authors":["Andrea Eirale","Matteo Leonetti","Marcello Chiaberge"],"pdf_url":"https://arxiv.org/pdf/2407.10547v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14411v1","updated":"2024-10-18T12:24:05Z","published":"2024-10-18T12:24:05Z","title":"SNAC: Multi-Scale Neural Audio Codec","summary":"  Neural audio codecs have recently gained popularity because they can\nrepresent audio signals with high fidelity at very low bitrates, making it\nfeasible to use language modeling approaches for audio generation and\nunderstanding. Residual Vector Quantization (RVQ) has become the standard\ntechnique for neural audio compression using a cascade of VQ codebooks. This\npaper proposes the Multi-Scale Neural Audio Codec, a simple extension of RVQ\nwhere the quantizers can operate at different temporal resolutions. By applying\na hierarchy of quantizers at variable frame rates, the codec adapts to the\naudio structure across multiple timescales. This leads to more efficient\ncompression, as demonstrated by extensive objective and subjective evaluations.\nThe code and model weights are open-sourced at\nhttps://github.com/hubertsiuzdak/snac.\n","authors":["Hubert Siuzdak","Florian Grötschla","Luca A. Lanzendörfer"],"pdf_url":"https://arxiv.org/pdf/2410.14411v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.14437v3","updated":"2024-10-18T12:20:54Z","published":"2022-12-29T19:21:33Z","title":"An algorithm for clustering with confidence-based must-link and\n  cannot-link constraints","summary":"  We study here the semi-supervised $k$-clustering problem where information is\navailable on whether pairs of objects are in the same or in different clusters.\nThis information is either available with certainty or with a limited level of\nconfidence. We introduce the PCCC (Pairwise-Confidence-Constraints-Clustering)\nalgorithm, which iteratively assigns objects to clusters while accounting for\nthe information provided on the pairs of objects. Our algorithm uses integer\nprogramming for the assignment of objects which allows to include relationships\nas hard constraints that are guaranteed to be satisfied or as soft constraints\nthat can be violated subject to a penalty. This flexibility distinguishes our\nalgorithm from the state-of-the-art in which all pairwise constraints are\neither considered hard, or all are considered soft. We developed an enhanced\nmulti-start approach and a model-size reduction technique for the integer\nprogram that contributes to the effectiveness and the efficiency of the\nalgorithm. Unlike existing algorithms, our algorithm scales to large-scale\ninstances with up to 60,000 objects, 100 clusters, and millions of cannot-link\nconstraints (which are the most challenging constraints to incorporate). We\ncompare the PCCC algorithm with state-of-the-art approaches in an extensive\ncomputational study. Even though the PCCC algorithm is more general than the\nstate-of-the-art approaches in its applicability, it outperforms the\nstate-of-the-art approaches on instances with all hard or all soft constraints\nboth in terms of runtime and various metrics of solution quality. The code of\nthe PCCC algorithm is publicly available on GitHub.\n","authors":["Philipp Baumann","Dorit S. Hochbaum"],"pdf_url":"https://arxiv.org/pdf/2212.14437v3.pdf","comment":"To appear in INFORMS Journal on Computing"},{"id":"http://arxiv.org/abs/2405.16504v2","updated":"2024-10-18T12:20:11Z","published":"2024-05-26T09:57:45Z","title":"Explaining Modern Gated-Linear RNNs via a Unified Implicit Attention\n  Formulation","summary":"  Recent advances in efficient sequence modeling have led to attention-free\nlayers, such as Mamba, RWKV, and various gated RNNs, all featuring\nsub-quadratic complexity in sequence length and excellent scaling properties,\nenabling the construction of a new type of foundation models. In this paper, we\npresent a unified view of these models, formulating such layers as implicit\ncausal self-attention layers. The formulation includes most of their\nsub-components and is not limited to a specific part of the architecture. The\nframework compares the underlying mechanisms on similar grounds for different\nlayers and provides a direct means for applying explainability methods. Our\nexperiments show that our attention matrices and attribution method outperform\nan alternative and a more limited formulation that was recently proposed for\nMamba. For the other architectures for which our method is the first to provide\nsuch a view, our method is effective and competitive in the relevant metrics\ncompared to the results obtained by state-of-the-art Transformer explainability\nmethods. Our code is publicly available.\n","authors":["Itamar Zimerman","Ameen Ali","Lior Wolf"],"pdf_url":"https://arxiv.org/pdf/2405.16504v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12950v2","updated":"2024-10-18T12:19:41Z","published":"2024-06-18T12:54:47Z","title":"MolecularGPT: Open Large Language Model (LLM) for Few-Shot Molecular\n  Property Prediction","summary":"  Molecular property prediction (MPP) is a fundamental and crucial task in drug\ndiscovery. However, prior methods are limited by the requirement for a large\nnumber of labeled molecules and their restricted ability to generalize for\nunseen and new tasks, both of which are essential for real-world applications.\nTo address these challenges, we present MolecularGPT for few-shot MPP. From a\nperspective on instruction tuning, we fine-tune large language models (LLMs)\nbased on curated molecular instructions spanning over 1000 property prediction\ntasks. This enables building a versatile and specialized LLM that can be\nadapted to novel MPP tasks without any fine-tuning through zero- and few-shot\nin-context learning (ICL). MolecularGPT exhibits competitive in-context\nreasoning capabilities across 10 downstream evaluation datasets, setting new\nbenchmarks for few-shot molecular prediction tasks. More importantly, with just\ntwo-shot examples, MolecularGPT can outperform standard supervised graph neural\nnetwork methods on 4 out of 7 datasets. It also excels state-of-the-art LLM\nbaselines by up to 15.7% increase on classification accuracy and decrease of\n17.9 on regression metrics (e.g., RMSE) under zero-shot. This study\ndemonstrates the potential of LLMs as effective few-shot molecular property\npredictors. The code is available at https://github.com/NYUSHCS/MolecularGPT.\n","authors":["Yuyan Liu","Sirui Ding","Sheng Zhou","Wenqi Fan","Qiaoyu Tan"],"pdf_url":"https://arxiv.org/pdf/2406.12950v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09567v2","updated":"2024-10-18T12:18:01Z","published":"2024-10-12T15:29:18Z","title":"Timeseria: an object-oriented time series processing library","summary":"  Timeseria is an object-oriented time series processing library implemented in\nPython, which aims at making it easier to manipulate time series data and to\nbuild statistical and machine learning models on top of it. Unlike common data\nanalysis frameworks, it builds up from well defined and reusable logical units\n(objects), which can be easily combined together in order to ensure a high\nlevel of consistency. Thanks to this approach, Timeseria can address by design\nseveral non-trivial issues often underestimated, such as handling data losses,\nnon-uniform sampling rates, differences between aggregated data and punctual\nobservations, time zones, daylight saving times, and more. Timeseria comes with\na comprehensive set of base data structures, common data manipulation\noperations, and extensible models for data reconstruction, forecasting and\nanomaly detection. It also integrates a powerful plotting engine capable of\nhandling even millions of data points.\n","authors":["Stefano Alberto Russo","Giuliano Taffoni","Luca Bortolussi"],"pdf_url":"https://arxiv.org/pdf/2410.09567v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14393v1","updated":"2024-10-18T11:55:34Z","published":"2024-10-18T11:55:34Z","title":"Debug Smarter, Not Harder: AI Agents for Error Resolution in\n  Computational Notebooks","summary":"  Computational notebooks became indispensable tools for research-related\ndevelopment, offering unprecedented interactivity and flexibility in the\ndevelopment process. However, these benefits come at the cost of\nreproducibility and an increased potential for bugs. With the rise of\ncode-fluent Large Language Models empowered with agentic techniques, smart\nbug-fixing tools with a high level of autonomy have emerged. However, those\ntools are tuned for classical script programming and still struggle with\nnon-linear computational notebooks. In this paper, we present an AI agent\ndesigned specifically for error resolution in a computational notebook. We have\ndeveloped an agentic system capable of exploring a notebook environment by\ninteracting with it -- similar to how a user would -- and integrated the system\ninto the JetBrains service for collaborative data science called Datalore. We\nevaluate our approach against the pre-existing single-action solution by\ncomparing costs and conducting a user study. Users rate the error resolution\ncapabilities of the agentic system higher but experience difficulties with UI.\nWe share the results of the study and consider them valuable for further\nimproving user-agent collaboration.\n","authors":["Konstantin Grotov","Artem Borzilov","Maksim Krivobok","Timofey Bryksin","Yaroslav Zharov"],"pdf_url":"https://arxiv.org/pdf/2410.14393v1.pdf","comment":"Accepted to EMNLP 2024 System Demonstrations"},{"id":"http://arxiv.org/abs/2410.14390v1","updated":"2024-10-18T11:50:54Z","published":"2024-10-18T11:50:54Z","title":"Personalizing Low-Rank Bayesian Neural Networks Via Federated Learning","summary":"  To support real-world decision-making, it is crucial for models to be\nwell-calibrated, i.e., to assign reliable confidence estimates to their\npredictions. Uncertainty quantification is particularly important in\npersonalized federated learning (PFL), as participating clients typically have\nsmall local datasets, making it difficult to unambiguously determine optimal\nmodel parameters. Bayesian PFL (BPFL) methods can potentially enhance\ncalibration, but they often come with considerable computational and memory\nrequirements due to the need to track the variances of all the individual model\nparameters. Furthermore, different clients may exhibit heterogeneous\nuncertainty levels owing to varying local dataset sizes and distributions. To\naddress these challenges, we propose LR-BPFL, a novel BPFL method that learns a\nglobal deterministic model along with personalized low-rank Bayesian\ncorrections. To tailor the local model to each client's inherent uncertainty\nlevel, LR-BPFL incorporates an adaptive rank selection mechanism. We evaluate\nLR-BPFL across a variety of datasets, demonstrating its advantages in terms of\ncalibration, accuracy, as well as computational and memory requirements.\n","authors":["Boning Zhang","Dongzhu Liu","Osvaldo Simeone","Guanchu Wang","Dimitrios Pezaros","Guangxu Zhu"],"pdf_url":"https://arxiv.org/pdf/2410.14390v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14389v1","updated":"2024-10-18T11:49:40Z","published":"2024-10-18T11:49:40Z","title":"SurgeryV2: Bridging the Gap Between Model Merging and Multi-Task\n  Learning with Deep Representation Surgery","summary":"  Model merging-based multitask learning (MTL) offers a promising approach for\nperforming MTL by merging multiple expert models without requiring access to\nraw training data. However, in this paper, we examine the merged model's\nrepresentation distribution and uncover a critical issue of \"representation\nbias\". This bias arises from a significant distribution gap between the\nrepresentations of the merged and expert models, leading to the suboptimal\nperformance of the merged MTL model. To address this challenge, we first\npropose a representation surgery solution called Surgery. Surgery is a\nlightweight, task-specific module that aligns the final layer representations\nof the merged model with those of the expert models, effectively alleviating\nbias and improving the merged model's performance. Despite these improvements,\na performance gap remains compared to the traditional MTL method. Further\nanalysis reveals that representation bias phenomena exist at each layer of the\nmerged model, and aligning representations only in the last layer is\ninsufficient for fully reducing systemic bias because biases introduced at each\nlayer can accumulate and interact in complex ways. To tackle this, we then\npropose a more comprehensive solution, deep representation surgery (also called\nSurgeryV2), which mitigates representation bias across all layers, and thus\nbridges the performance gap between model merging-based MTL and traditional\nMTL. Finally, we design an unsupervised optimization objective to optimize both\nthe Surgery and SurgeryV2 modules. Our experimental results show that\nincorporating these modules into state-of-the-art (SOTA) model merging schemes\nleads to significant performance gains. Notably, our SurgeryV2 scheme reaches\nalmost the same level as individual expert models or the traditional MTL model.\nThe code is available at \\url{https://github.com/EnnengYang/SurgeryV2}.\n","authors":["Enneng Yang","Li Shen","Zhenyi Wang","Guibing Guo","Xingwei Wang","Xiaocun Cao","Jie Zhang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2410.14389v1.pdf","comment":"This paper is an extended version of our previous work\n  [arXiv:2402.02705] presented at ICML 2024"},{"id":"http://arxiv.org/abs/2410.06927v2","updated":"2024-10-18T11:47:40Z","published":"2024-10-09T14:21:59Z","title":"Spectral and Rhythm Features for Audio Classification with Deep\n  Convolutional Neural Networks","summary":"  Convolutional neural networks (CNNs) are widely used in computer vision. They\ncan be used not only for conventional digital image material to recognize\npatterns, but also for feature extraction from digital imagery representing\nspectral and rhythm features extracted from time-domain digital audio signals\nfor the acoustic classification of sounds. Different spectral and rhythm\nfeature representations like mel-scaled spectrograms, mel-frequency cepstral\ncoefficients (MFCCs), cyclic tempograms, short-time Fourier transform (STFT)\nchromagrams, constant-Q transform (CQT) chromagrams and chroma energy\nnormalized statistics (CENS) chromagrams are investigated in terms of the audio\nclassification performance using a deep convolutional neural network. It can be\nclearly shown that the mel-scaled spectrograms and the mel-frequency cepstral\ncoefficients (MFCCs) perform significantly better than the other spectral and\nrhythm features investigated in this research for audio classification tasks\nusing deep CNNs. The experiments were carried out with the aid of the ESC-50\ndataset with 2,000 labeled environmental audio recordings.\n","authors":["Friedrich Wolf-Monheim"],"pdf_url":"https://arxiv.org/pdf/2410.06927v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14388v1","updated":"2024-10-18T11:44:29Z","published":"2024-10-18T11:44:29Z","title":"Unscrambling disease progression at scale: fast inference of event\n  permutations with optimal transport","summary":"  Disease progression models infer group-level temporal trajectories of change\nin patients' features as a chronic degenerative condition plays out. They\nprovide unique insight into disease biology and staging systems with\nindividual-level clinical utility. Discrete models consider disease progression\nas a latent permutation of events, where each event corresponds to a feature\nbecoming measurably abnormal. However, permutation inference using traditional\nmaximum likelihood approaches becomes prohibitive due to combinatoric\nexplosion, severely limiting model dimensionality and utility. Here we leverage\nideas from optimal transport to model disease progression as a latent\npermutation matrix of events belonging to the Birkhoff polytope, facilitating\nfast inference via optimisation of the variational lower bound. This enables a\nfactor of 1000 times faster inference than the current state of the art and,\ncorrespondingly, supports models with several orders of magnitude more features\nthan the current state of the art can consider. Experiments demonstrate the\nincrease in speed, accuracy and robustness to noise in simulation. Further\nexperiments with real-world imaging data from two separate datasets, one from\nAlzheimer's disease patients, the other age-related macular degeneration,\nshowcase, for the first time, pixel-level disease progression events in the\nbrain and eye, respectively. Our method is low compute, interpretable and\napplicable to any progressive condition and data modality, giving it broad\npotential clinical utility.\n","authors":["Peter A. Wijeratne","Daniel C. Alexander"],"pdf_url":"https://arxiv.org/pdf/2410.14388v1.pdf","comment":"Pre-print of version accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2407.13625v2","updated":"2024-10-18T11:43:28Z","published":"2024-07-18T15:59:37Z","title":"Distributionally and Adversarially Robust Logistic Regression via\n  Intersecting Wasserstein Balls","summary":"  Adversarially robust optimization (ARO) has become the de facto standard for\ntraining models to defend against adversarial attacks during testing. However,\ndespite their robustness, these models often suffer from severe overfitting. To\nmitigate this issue, several successful approaches have been proposed,\nincluding replacing the empirical distribution in training with: (i) a\nworst-case distribution within an ambiguity set, leading to a distributionally\nrobust (DR) counterpart of ARO; or (ii) a mixture of the empirical distribution\nwith one derived from an auxiliary dataset (e.g., synthetic, external, or\nout-of-domain). Building on the first approach, we explore the Wasserstein DR\ncounterpart of ARO for logistic regression and show it admits a tractable\nconvex optimization reformulation. Adopting the second approach, we enhance the\nDR framework by intersecting its ambiguity set with one constructed from an\nauxiliary dataset, which yields significant improvements when the Wasserstein\ndistance between the data-generating and auxiliary distributions can be\nestimated. We analyze the resulting optimization problem, develop efficient\nsolutions, and show that our method outperforms benchmark approaches on\nstandard datasets.\n","authors":["Aras Selvi","Eleonora Kreacic","Mohsen Ghassemi","Vamsi Potluru","Tucker Balch","Manuela Veloso"],"pdf_url":"https://arxiv.org/pdf/2407.13625v2.pdf","comment":"33 pages, 3 color figures, under review at a conference"}]},"2024-10-21T00:00:00Z":{"Robotics":[{"id":"http://arxiv.org/abs/2410.16259v1","updated":"2024-10-21T17:57:50Z","published":"2024-10-21T17:57:50Z","title":"Agent-to-Sim: Learning Interactive Behavior Models from Casual\n  Longitudinal Videos","summary":"  We present Agent-to-Sim (ATS), a framework for learning interactive behavior\nmodels of 3D agents from casual longitudinal video collections. Different from\nprior works that rely on marker-based tracking and multiview cameras, ATS\nlearns natural behaviors of animal and human agents non-invasively through\nvideo observations recorded over a long time-span (e.g., a month) in a single\nenvironment. Modeling 3D behavior of an agent requires persistent 3D tracking\n(e.g., knowing which point corresponds to which) over a long time period. To\nobtain such data, we develop a coarse-to-fine registration method that tracks\nthe agent and the camera over time through a canonical 3D space, resulting in a\ncomplete and persistent spacetime 4D representation. We then train a generative\nmodel of agent behaviors using paired data of perception and motion of an agent\nqueried from the 4D reconstruction. ATS enables real-to-sim transfer from video\nrecordings of an agent to an interactive behavior simulator. We demonstrate\nresults on pets (e.g., cat, dog, bunny) and human given monocular RGBD videos\ncaptured by a smartphone.\n","authors":["Gengshan Yang","Andrea Bajcsy","Shunsuke Saito","Angjoo Kanazawa"],"pdf_url":"https://arxiv.org/pdf/2410.16259v1.pdf","comment":"Project page: https://gengshan-y.github.io/agent2sim-www/"},{"id":"http://arxiv.org/abs/2410.14468v2","updated":"2024-10-21T17:34:44Z","published":"2024-10-18T13:52:28Z","title":"Knowledge Transfer from Simple to Complex: A Safe and Efficient\n  Reinforcement Learning Framework for Autonomous Driving Decision-Making","summary":"  A safe and efficient decision-making system is crucial for autonomous\nvehicles. However, the complexity and variability of driving environments limit\nthe effectiveness of many rule-based and machine learning-based decision-making\napproaches. Reinforcement Learning in autonomous driving offers a promising\nsolution to these challenges. Nevertheless, concerns regarding safety and\nefficiency during training remain major obstacles to its widespread\napplication. To address these concerns, we propose a novel RL framework named\nSimple to Complex Collaborative Decision. First, we rapidly train the teacher\nmodel using the Proximal Policy Optimization algorithm in a lightweight\nsimulation environment. In the more intricate simulation environment, the\nteacher model intervenes when the student agent exhibits suboptimal behavior by\nassessing the value of actions to avert dangerous situations. We also introduce\nan innovative RL algorithm called Adaptive Clipping PPO, which is trained using\na combination of samples generated by both teacher and student policies, and\nemploys dynamic clipping strategies based on sample importance. Additionally,\nwe employ the KL divergence as a constraint on policy optimization,\ntransforming it into an unconstrained problem to accelerate the student's\nlearning of the teacher's policy. Finally, a gradual weaning strategy is\nemployed to ensure that, over time, the student agent learns to explore\nindependently. Simulation experiments in highway lane-change scenarios\ndemonstrate that the S2CD framework enhances learning efficiency, reduces\ntraining costs, and significantly improves safety during training when compared\nwith state-of-the-art baseline algorithms. This approach also ensures effective\nknowledge transfer between teacher and student models, and even when the\nteacher model is suboptimal.\n","authors":["Rongliang Zhou","Jiakun Huang","Mingjun Li","Hepeng Li","Haotian Cao","Xiaolin Song"],"pdf_url":"https://arxiv.org/pdf/2410.14468v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.17355v2","updated":"2024-10-21T17:27:00Z","published":"2024-08-30T15:39:34Z","title":"Bidirectional Decoding: Improving Action Chunking via Closed-Loop\n  Resampling","summary":"  Predicting and executing a sequence of actions without intermediate\nreplanning, known as action chunking, is increasingly used in robot learning\nfrom human demonstrations. Yet, its reported effects on the learned policy are\ninconsistent: some studies find it crucial for achieving strong results, while\nothers observe decreased performance. In this paper, we first dissect how\naction chunking impacts the divergence between a learner and a demonstrator. We\nfind that action chunking allows the learner to better capture the temporal\ndependencies in demonstrations but at the cost of reduced reactivity in\nstochastic environments. To address this tradeoff, we propose Bidirectional\nDecoding (BID), a test-time inference algorithm that bridges action chunking\nwith closed-loop operations. BID samples multiple predictions at each time step\nand searches for the optimal one based on two criteria: (i) backward coherence,\nwhich favors samples that align with previous decisions; (ii) forward contrast,\nwhich seeks samples of high likelihood for future plans. By coupling decisions\nwithin and across action chunks, BID promotes consistency over time while\nmaintaining reactivity to unexpected changes. Experimental results show that\nBID boosts the performance of two state-of-the-art generative policies across\nseven simulation benchmarks and two real-world tasks. Code and videos are\navailable at https://bid-robot.github.io.\n","authors":["Yuejiang Liu","Jubayer Ibn Hamid","Annie Xie","Yoonho Lee","Maximilian Du","Chelsea Finn"],"pdf_url":"https://arxiv.org/pdf/2408.17355v2.pdf","comment":"Project website: https://bid-robot.github.io/"},{"id":"http://arxiv.org/abs/2410.16207v1","updated":"2024-10-21T17:10:43Z","published":"2024-10-21T17:10:43Z","title":"CoT-TL: Low-Resource Temporal Knowledge Representation of Planning\n  Instructions Using Chain-of-Thought Reasoning","summary":"  Autonomous agents often face the challenge of interpreting uncertain natural\nlanguage instructions for planning tasks. Representing these instructions as\nLinear Temporal Logic (LTL) enables planners to synthesize actionable plans. We\nintroduce CoT-TL, a data-efficient in-context learning framework for\ntranslating natural language specifications into LTL representations. CoT-TL\naddresses the limitations of large language models, which typically rely on\nextensive fine-tuning data, by extending chain-of-thought reasoning and\nsemantic roles to align with the requirements of formal logic creation. This\napproach enhances the transparency and rationale behind LTL generation,\nfostering user trust. CoT-TL achieves state-of-the-art accuracy across three\ndiverse datasets in low-data scenarios, outperforming existing methods without\nfine-tuning or intermediate translations. To improve reliability and minimize\nhallucinations, we incorporate model checking to validate the syntax of the\ngenerated LTL output. We further demonstrate CoT-TL's effectiveness through\nablation studies and evaluations on unseen LTL structures and formulas in a new\ndataset. Finally, we validate CoT-TL's practicality by integrating it into a\nQuadCopter for multi-step drone planning based on natural language\ninstructions.\n","authors":["Kumar Manas","Stefan Zwicklbauer","Adrian Paschke"],"pdf_url":"https://arxiv.org/pdf/2410.16207v1.pdf","comment":"Accepted for publication in Proceedings of the 2024 IEEE/RSJ\n  International Conference on Intelligent Robots and Systems (IROS 2024), Abu\n  Dhabi 14-18 October 2024"},{"id":"http://arxiv.org/abs/2410.16197v1","updated":"2024-10-21T17:00:03Z","published":"2024-10-21T17:00:03Z","title":"LASER: Script Execution by Autonomous Agents for On-demand Traffic\n  Simulation","summary":"  Autonomous Driving Systems (ADS) require diverse and safety-critical traffic\nscenarios for effective training and testing, but the existing data generation\nmethods struggle to provide flexibility and scalability. We propose LASER, a\nnovel frame-work that leverage large language models (LLMs) to conduct traffic\nsimulations based on natural language inputs. The framework operates in two\nstages: it first generates scripts from user-provided descriptions and then\nexecutes them using autonomous agents in real time. Validated in the CARLA\nsimulator, LASER successfully generates complex, on-demand driving scenarios,\nsignificantly improving ADS training and testing data generation.\n","authors":["Hao Gao","Jingyue Wang","Wenyang Fang","Jingwei Xu","Yunpeng Huang","Taolue Chen","Xiaoxing Ma"],"pdf_url":"https://arxiv.org/pdf/2410.16197v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19307v3","updated":"2024-10-21T16:44:07Z","published":"2024-05-29T17:31:25Z","title":"Data Efficient Behavior Cloning for Fine Manipulation via\n  Continuity-based Corrective Labels","summary":"  We consider imitation learning with access only to expert demonstrations,\nwhose real-world application is often limited by covariate shift due to\ncompounding errors during execution. We investigate the effectiveness of the\nContinuity-based Corrective Labels for Imitation Learning (CCIL) framework in\nmitigating this issue for real-world fine manipulation tasks. CCIL generates\ncorrective labels by learning a locally continuous dynamics model from\ndemonstrations to guide the agent back toward expert states. Through extensive\nexperiments on peg insertion and fine grasping, we provide the first empirical\nvalidation that CCIL can significantly improve imitation learning performance\ndespite discontinuities present in contact-rich manipulation. We find that: (1)\nreal-world manipulation exhibits sufficient local smoothness to apply CCIL, (2)\ngenerated corrective labels are most beneficial in low-data regimes, and (3)\nlabel filtering based on estimated dynamics model error enables performance\ngains. To effectively apply CCIL to robotic domains, we offer a practical\ninstantiation of the framework and insights into design choices and\nhyperparameter selection. Our work demonstrates CCIL's practicality for\nalleviating compounding errors in imitation learning on physical robots.\n","authors":["Abhay Deshpande","Liyiming Ke","Quinn Pfeifer","Abhishek Gupta","Siddhartha S. Srinivasa"],"pdf_url":"https://arxiv.org/pdf/2405.19307v3.pdf","comment":"Presented at IROS 2024"},{"id":"http://arxiv.org/abs/2410.12054v2","updated":"2024-10-21T16:12:34Z","published":"2024-10-15T20:48:37Z","title":"A Lyapunov-Based Switching Scheme for Selecting the Stable Closed-Loop\n  Fixed Attitude-Error Quaternion During Flight","summary":"  We present a switching scheme, which uses both the attitude-error quaternion\n(AEQ) and the angular-velocity error, for controlling the rotational degrees of\nfreedom of an uncrewed aerial vehicle (UAV) during flight. In this approach,\nthe proposed controller continually selects the stable closed-loop (CL)\nequilibrium AEQ corresponding to the smallest cost between those computed with\ntwo energy-based Lyapunov functions. To analyze and enforce the stability of\nthe CL switching dynamics, we use basic nonlinear theory. This research problem\nis relevant because the selection of the stable CL equilibrium AEQ directly\ndetermines the power and energy requirements of the controlled UAV during\nflight. To test and demonstrate the implementation, suitability, functionality,\nand performance of the proposed approach, we present experimental results\nobtained using a 31-gram quadrotor, which was controlled to execute high-speed\nyaw maneuvers in flight. These flight tests show that the proposed switching\ncontroller can respectively reduce the control effort and rotational power by\nas much as 49.75 % and 28.14 %, on average, compared to those corresponding to\nan often-used benchmark controller.\n","authors":["Francisco M. F. R. Goncalves","Ryan M. Bena","Konstantin I. Matveev","Nestor O. Perez-Arancibia"],"pdf_url":"https://arxiv.org/pdf/2410.12054v2.pdf","comment":"8 pages, 5 figures, 2024 7th Iberian Robotics Conference (ROBOT)"},{"id":"http://arxiv.org/abs/2407.00299v4","updated":"2024-10-21T15:56:23Z","published":"2024-06-29T03:37:29Z","title":"Human-Agent Joint Learning for Efficient Robot Manipulation Skill\n  Acquisition","summary":"  Employing a teleoperation system for gathering demonstrations offers the\npotential for more efficient learning of robot manipulation. However,\nteleoperating a robot arm equipped with a dexterous hand or gripper, via a\nteleoperation system presents inherent challenges due to the task's high\ndimensionality, complexity of motion, and differences between physiological\nstructures. In this study, we introduce a novel system for joint learning\nbetween human operators and robots, that enables human operators to share\ncontrol of a robot end-effector with a learned assistive agent, simplifies the\ndata collection process, and facilitates simultaneous human demonstration\ncollection and robot manipulation training. As data accumulates, the assistive\nagent gradually learns. Consequently, less human effort and attention are\nrequired, enhancing the efficiency of the data collection process. It also\nallows the human operator to adjust the control ratio to achieve a trade-off\nbetween manual and automated control. We conducted experiments in both\nsimulated environments and physical real-world settings. Through user studies\nand quantitative evaluations, it is evident that the proposed system could\nenhance data collection efficiency and reduce the need for human adaptation\nwhile ensuring the collected data is of sufficient quality for downstream\ntasks. \\textit{For more details, please refer to our webpage\nhttps://norweig1an.github.io/HAJL.github.io/.\n","authors":["Shengcheng Luo","Quanquan Peng","Jun Lv","Kaiwen Hong","Katherine Rose Driggs-Campbell","Cewu Lu","Yong-Lu Li"],"pdf_url":"https://arxiv.org/pdf/2407.00299v4.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.07105v2","updated":"2024-10-21T14:15:54Z","published":"2023-11-13T06:40:31Z","title":"Collaborative Goal Tracking of Multiple Mobile Robots Based on Geometric\n  Graph Neural Network","summary":"  Multiple mobile robots play a significant role in various spatially\ndistributed tasks, highlighting the importance of collaborative path planning\nto enhance operational efficiency. In unfamiliar and non-repetitive scenarios,\nreconstructing the global map can be time-inefficient and sometimes\nunrealistic. Therefore, research has focused on achieving real-time\ncollaborative planning by utilizing sensor data from multiple robots located at\ndifferent positions, without relying on a global map. This paper introduces a\nMulti-Robot Collaborative Path Planning method based on a Geometric Graph\nNeural Network (MRPP-GeoGNN). First, the features of each neighboring robot's\nsensory data are extracted, and the relative positions of neighboring robots\nare integrated into each interaction layer to incorporate obstacle information\nalong with location details. Subsequently, GeoGNN maps the amalgamated local\nenvironment features to multiple forward directions for the robot's actual\nmovement. An expert data generation method is devised for the robot to advance\nstep by step in the physical environment, generating different expert data in\nROS to train the network. We conducted both simulations and physical\nexperiments to validate the effectiveness of the proposed method. Simulation\nresults demonstrate approximately a 5% improvement in accuracy compared to the\nmodel based solely on CNN using expert datasets. In the ROS simulation test,\nthe success rate is enhanced by about 4% compared to CNN, and the flow time\nincrease is reduced by approximately 8%, surpassing other GNN models. The\nphysical experimental results indicate that the proposed method enables the\nrobot to navigate successfully in the actual environment and achieve the\nshortest average path length compared to the benchmark method.\n","authors":["Weining Lu","Qingquan Lin","Litong Meng","Chenxi Li","Bin Liang"],"pdf_url":"https://arxiv.org/pdf/2311.07105v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16025v1","updated":"2024-10-21T13:58:41Z","published":"2024-10-21T13:58:41Z","title":"Continuum Robot Shape Estimation Using Magnetic Ball Chains","summary":"  Shape sensing of medical continuum robots is important both for closed-loop\ncontrol as well as for enabling the clinician to visualize the robot inside the\nbody. There is a need for inexpensive, but accurate shape sensing technologies.\nThis paper proposes the use of magnetic ball chains as a means of generating\nshape-specific magnetic fields that can be detected by an external array of\nHall effect sensors. Such a ball chain, encased in a flexible polymer sleeve,\ncould be inserted inside the lumen of any continuum robot to provide real-time\nshape feedback. The sleeve could be removed, as needed, during the procedure to\nenable use of the entire lumen. To investigate this approach, a shape-sensing\nmodel for a steerable catheter tip is derived and an observability and\nsensitivity analysis are presented. Experiments show maximum estimation errors\nof 7.1% and mean of 2.9% of the tip position with respect to total length.\n","authors":["Giovanni Pittiglio","Abdulhamit Donder","Pierre E. Dupont"],"pdf_url":"https://arxiv.org/pdf/2410.16025v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.10425v2","updated":"2024-10-21T13:28:20Z","published":"2024-04-16T09:43:58Z","title":"Optimizing BioTac Simulation for Realistic Tactile Perception","summary":"  Tactile sensing presents a promising opportunity for enhancing the\ninteraction capabilities of today's robots. BioTac is a commonly used tactile\nsensor that enables robots to perceive and respond to physical tactile stimuli.\nHowever, the sensor's non-linearity poses challenges in simulating its\nbehavior. In this paper, we first investigate a BioTac simulation that uses\ntemperature, force, and contact point positions to predict the sensor outputs.\nWe show that training with BioTac temperature readings does not yield accurate\nsensor output predictions during deployment. Consequently, we tested three\nalternative models, i.e., an XGBoost regressor, a neural network, and a\ntransformer encoder. We train these models without temperature readings and\nprovide a detailed investigation of the window size of the input vectors. We\ndemonstrate that we achieve statistically significant improvements over the\nbaseline network. Furthermore, our results reveal that the XGBoost regressor\nand transformer outperform traditional feed-forward neural networks in this\ntask. We make all our code and results available online on\nhttps://github.com/wzaielamri/Optimizing_BioTac_Simulation.\n","authors":["Wadhah Zai El Amri","Nicolás Navarro-Guerrero"],"pdf_url":"https://arxiv.org/pdf/2404.10425v2.pdf","comment":"12 pages (including appendix), Accepted at the International Joint\n  Conference on Neural Network (IJCNN) 2024, Yokohama, Japan. \\c{opyright} 2024\n  IEEE. Personal use of this material is permitted. Permission from IEEE must\n  be obtained for all other uses, in any current or future media... (We refer\n  to IEEE Copyrights)"},{"id":"http://arxiv.org/abs/2410.15994v1","updated":"2024-10-21T13:24:04Z","published":"2024-10-21T13:24:04Z","title":"ARCADE: Scalable Demonstration Collection and Generation via Augmented\n  Reality for Imitation Learning","summary":"  Robot Imitation Learning (IL) is a crucial technique in robot learning, where\nagents learn by mimicking human demonstrations. However, IL encounters\nscalability challenges stemming from both non-user-friendly demonstration\ncollection methods and the extensive time required to amass a sufficient number\nof demonstrations for effective training. In response, we introduce the\nAugmented Reality for Collection and generAtion of DEmonstrations (ARCADE)\nframework, designed to scale up demonstration collection for robot manipulation\ntasks. Our framework combines two key capabilities: 1) it leverages AR to make\ndemonstration collection as simple as users performing daily tasks using their\nhands, and 2) it enables the automatic generation of additional synthetic\ndemonstrations from a single human-derived demonstration, significantly\nreducing user effort and time. We assess ARCADE's performance on a real Fetch\nrobot across three robotics tasks: 3-Waypoints-Reach, Push, and Pick-And-Place.\nUsing our framework, we were able to rapidly train a policy using vanilla\nBehavioral Cloning (BC), a classic IL algorithm, which excelled across these\nthree tasks. We also deploy ARCADE on a real household task, Pouring-Water,\nachieving an 80% success rate.\n","authors":["Yue Yang","Bryce Ikeda","Gedas Bertasius","Daniel Szafir"],"pdf_url":"https://arxiv.org/pdf/2410.15994v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15987v1","updated":"2024-10-21T13:16:58Z","published":"2024-10-21T13:16:58Z","title":"Analyzing Closed-loop Training Techniques for Realistic Traffic Agent\n  Models in Autonomous Highway Driving Simulations","summary":"  Simulation plays a crucial role in the rapid development and safe deployment\nof autonomous vehicles. Realistic traffic agent models are indispensable for\nbridging the gap between simulation and the real world. Many existing\napproaches for imitating human behavior are based on learning from\ndemonstration. However, these approaches are often constrained by focusing on\nindividual training strategies. Therefore, to foster a broader understanding of\nrealistic traffic agent modeling, in this paper, we provide an extensive\ncomparative analysis of different training principles, with a focus on\nclosed-loop methods for highway driving simulation. We experimentally compare\n(i) open-loop vs. closed-loop multi-agent training, (ii) adversarial vs.\ndeterministic supervised training, (iii) the impact of reinforcement losses,\nand (iv) the impact of training alongside log-replayed agents to identify\nsuitable training techniques for realistic agent modeling. Furthermore, we\nidentify promising combinations of different closed-loop training methods.\n","authors":["Matthias Bitzer","Reinis Cimurs","Benjamin Coors","Johannes Goth","Sebastian Ziesche","Philipp Geiger","Maximilian Naumann"],"pdf_url":"https://arxiv.org/pdf/2410.15987v1.pdf","comment":"15 pages, 6 figures, 4 tables"},{"id":"http://arxiv.org/abs/2410.15979v1","updated":"2024-10-21T13:06:06Z","published":"2024-10-21T13:06:06Z","title":"Learning Quadrotor Control From Visual Features Using Differentiable\n  Simulation","summary":"  The sample inefficiency of reinforcement learning (RL) remains a significant\nchallenge in robotics. RL requires large-scale simulation and, still, can cause\nlong training times, slowing down research and innovation. This issue is\nparticularly pronounced in vision-based control tasks where reliable state\nestimates are not accessible. Differentiable simulation offers an alternative\nby enabling gradient back-propagation through the dynamics model, providing\nlow-variance analytical policy gradients and, hence, higher sample efficiency.\nHowever, its usage for real-world robotic tasks has yet been limited. This work\ndemonstrates the great potential of differentiable simulation for learning\nquadrotor control. We show that training in differentiable simulation\nsignificantly outperforms model-free RL in terms of both sample efficiency and\ntraining time, allowing a policy to learn to recover a quadrotor in seconds\nwhen providing vehicle state and in minutes when relying solely on visual\nfeatures. The key to our success is two-fold. First, the use of a simple\nsurrogate model for gradient computation greatly accelerates training without\nsacrificing control performance. Second, combining state representation\nlearning with policy learning enhances convergence speed in tasks where only\nvisual features are observable. These findings highlight the potential of\ndifferentiable simulation for real-world robotics and offer a compelling\nalternative to conventional RL approaches.\n","authors":["Johannes Heeg","Yunlong Song","Davide Scaramuzza"],"pdf_url":"https://arxiv.org/pdf/2410.15979v1.pdf","comment":"Under Submission"},{"id":"http://arxiv.org/abs/2407.09841v3","updated":"2024-10-21T13:00:55Z","published":"2024-07-13T10:29:41Z","title":"OmniRace: 6D Hand Pose Estimation for Intuitive Guidance of Racing Drone","summary":"  This paper presents the OmniRace approach to controlling a racing drone with\n6-degree of freedom (DoF) hand pose estimation and gesture recognition. To our\nknowledge, it is the first-ever technology that allows for low-level control of\nhigh-speed drones using gestures. OmniRace employs a gesture interface based on\ncomputer vision and a deep neural network to estimate a 6-DoF hand pose. The\nadvanced machine learning algorithm robustly interprets human gestures,\nallowing users to control drone motion intuitively. Real-time control of a\nracing drone demonstrates the effectiveness of the system, validating its\npotential to revolutionize drone racing and other applications. Experimental\nresults conducted in the Gazebo simulation environment revealed that OmniRace\nallows the users to complite the UAV race track significantly (by 25.1%) faster\nand to decrease the length of the test drone path (from 102.9 to 83.7 m). Users\npreferred the gesture interface for attractiveness (1.57 UEQ score), hedonic\nquality (1.56 UEQ score), and lower perceived temporal demand (32.0 score in\nNASA-TLX), while noting the high efficiency (0.75 UEQ score) and low physical\ndemand (19.0 score in NASA-TLX) of the baseline remote controller. The deep\nneural network attains an average accuracy of 99.75% when applied to both\nnormalized datasets and raw datasets. OmniRace can potentially change the way\nhumans interact with and navigate racing drones in dynamic and complex\nenvironments. The source code is available at\nhttps://github.com/SerValera/OmniRace.git.\n","authors":["Valerii Serpiva","Aleksey Fedoseev","Sausar Karaf","Ali Alridha Abdulkarim","Dzmitry Tsetserukou"],"pdf_url":"https://arxiv.org/pdf/2407.09841v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15959v1","updated":"2024-10-21T12:43:54Z","published":"2024-10-21T12:43:54Z","title":"Diffusion Transformer Policy","summary":"  Recent large visual-language action models pretrained on diverse robot\ndatasets have demonstrated the potential for generalizing to new environments\nwith a few in-domain data. However, those approaches usually predict\ndiscretized or continuous actions by a small action head, which limits the\nability in handling diverse action spaces. In contrast, we model the continuous\naction with a large multi-modal diffusion transformer, dubbed as Diffusion\nTransformer Policy, in which we directly denoise action chunks by a large\ntransformer model rather than a small action head. By leveraging the scaling\ncapability of transformers, the proposed approach can effectively model\ncontinuous end-effector actions across large diverse robot datasets, and\nachieve better generalization performance. Extensive experiments demonstrate\nDiffusion Transformer Policy pretrained on diverse robot data can generalize to\ndifferent embodiments, including simulation environments like Maniskill2 and\nCalvin, as well as the real-world Franka arm. Specifically, without bells and\nwhistles, the proposed approach achieves state-of-the-art performance with only\na single third-view camera stream in the Calvin novel task setting (ABC->D),\nimproving the average number of tasks completed in a row of 5 to 3.6, and the\npretraining stage significantly facilitates the success sequence length on the\nCalvin by over 1.2. The code will be publicly available.\n","authors":["Zhi Hou","Tianyi Zhang","Yuwen Xiong","Hengjun Pu","Chengyang Zhao","Ronglei Tong","Yu Qiao","Jifeng Dai","Yuntao Chen"],"pdf_url":"https://arxiv.org/pdf/2410.15959v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.15946v1","updated":"2024-10-21T12:25:34Z","published":"2024-10-21T12:25:34Z","title":"Neural Predictor for Flight Control with Payload","summary":"  Aerial robotics for transporting suspended payloads as the form of\nfreely-floating manipulator are growing great interest in recent years.\nHowever, the prior information of the payload, such as the mass, is always hard\nto obtain accurately in practice. The force/torque caused by payload and\nresidual dynamics will introduce unmodeled perturbations to the system, which\nnegatively affects the closed-loop performance. Different from estimation-like\nmethods, this paper proposes Neural Predictor, a learning-based approach to\nmodel force/torque caused by payload and residual dynamics as a dynamical\nsystem. It results a hybrid model including both the first-principles dynamics\nand the learned dynamics. This hybrid model is then integrated into a MPC\nframework to improve closed-loop performance. Effectiveness of proposed\nframework is verified extensively in both numerical simulations and real-world\nflight experiments. The results indicate that our approach can capture\nforce/torque caused by payload and residual dynamics accurately, respond\nquickly to the changes of them and improve the closed-loop performance\nsignificantly. In particular, Neural Predictor outperforms a state-of-the-art\nlearning-based estimator and has reduced the force and torque estimation errors\nby up to 66.15% and 33.33% while using less samples.\n","authors":["Ao Jin","Chenhao Li","Qinyi Wang","Ya Liu","Panfeng Huang","Fan Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.15946v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2406.04835v2","updated":"2024-10-21T11:58:46Z","published":"2024-06-07T11:06:26Z","title":"SLR: Learning Quadruped Locomotion without Privileged Information","summary":"  The recent mainstream reinforcement learning control for quadruped robots\noften relies on privileged information, demanding meticulous selection and\nprecise estimation, thereby imposing constraints on the development process.\nThis work proposes a Self-learning Latent Representation (SLR) method, which\nachieves high-performance control policy learning without the need for\nprivileged information. To enhance the credibility of the proposed method's\nevaluation, SLR was directly compared with state-of-the-art algorithms using\ntheir open-source code repositories and original configuration parameters.\nRemarkably, SLR surpasses the performance of previous methods using only\nlimited proprioceptive data, demonstrating significant potential for future\napplications. Ultimately, the trained policy and encoder empower the quadruped\nrobot to traverse various challenging terrains. Videos of our results can be\nfound on our website: https://11chens.github.io/SLR/\n","authors":["Shiyi Chen","Zeyu Wan","Shiyang Yan","Chun Zhang","Weiyi Zhang","Qiang Li","Debing Zhang","Fasih Ud Din Farrukh"],"pdf_url":"https://arxiv.org/pdf/2406.04835v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15921v1","updated":"2024-10-21T11:52:37Z","published":"2024-10-21T11:52:37Z","title":"Fully distributed and resilient source seeking for robot swarms","summary":"  We propose a self-contained, resilient and fully distributed solution for\nlocating the maximum of an unknown 3D scalar field using a swarm of robots that\ntravel at constant speeds. Unlike conventional reactive methods relying on\ngradient information, our methodology enables the swarm to determine an\nascending direction so that it approaches the source with arbitrary precision.\nOur source-seeking solution consists of three algorithms. The first two\nalgorithms run sequentially and distributively at a high frequency providing\nbarycentric coordinates and the ascending direction respectively to the\nindividual robots. The third algorithm is the individual control law for a\nrobot to track the estimated ascending direction. We show that the two\nalgorithms with higher frequency have an exponential convergence to their\neventual values since they are based on the standard consensus protocol for\nfirst-order dynamical systems; their high frequency depends on how fast the\nrobots travel through the scalar field. The robots are not constrained to any\nparticular geometric formation, and we study both discrete and continuous\ndistributions of robots within swarm shapes. The shape analysis reveals the\nresiliency of our approach as expected in robot swarms, i.e., by amassing\nrobots we ensure the source-seeking functionality in the event of missing or\nmisplaced individuals or even if the robot network splits into two or more\ndisconnected subnetworks. In addition, we also enhance the robustness of the\nalgorithm by presenting conditions for \\emph{optimal} swarm shapes, in the\nsense that the ascending directions can be closely parallel to the field's\ngradient. We exploit such an analysis so that the swarm can adapt to unknown\nenvironments by morphing its shape and maneuvering while still following an\nascending direction.\n","authors":["Jesús Bautista","Antonio Acuaviva","José Hinojosa","Weijia Yao","Juan Jiménez","Héctor García de Marina"],"pdf_url":"https://arxiv.org/pdf/2410.15921v1.pdf","comment":"15 pages, submitted version to T-RO. This version does not contain\n  the field experiments. arXiv admin note: text overlap with arXiv:2309.02937"},{"id":"http://arxiv.org/abs/2401.11432v2","updated":"2024-10-21T11:39:26Z","published":"2024-01-21T08:44:04Z","title":"Bimanual Deformable Bag Manipulation Using a Structure-of-Interest Based\n  Neural Dynamics Model","summary":"  The manipulation of deformable objects by robotic systems presents a\nsignificant challenge due to their complex and infinite-dimensional\nconfiguration spaces. This paper introduces a novel approach to Deformable\nObject Manipulation (DOM) by emphasizing the identification and manipulation of\nStructures of Interest (SOIs) in deformable fabric bags. We propose a bimanual\nmanipulation framework that leverages a Graph Neural Network (GNN)-based latent\ndynamics model to succinctly represent and predict the behavior of these SOIs.\nOur approach involves constructing a graph representation from partial point\ncloud data of the object and learning the latent dynamics model that\neffectively captures the essential deformations of the fabric bag within a\nreduced computational space. By integrating this latent dynamics model with\nModel Predictive Control (MPC), we empower robotic manipulators to perform\nprecise and stable manipulation tasks focused on the SOIs. We have validated\nour framework through various empirical experiments demonstrating its efficacy\nin bimanual manipulation of fabric bags. Our contributions not only address the\ncomplexities inherent in DOM but also provide new perspectives and\nmethodologies for enhancing robotic interactions with deformable objects by\nconcentrating on their critical structural elements. Experimental videos can be\nobtained from https://sites.google.com/view/bagbot.\n","authors":["Peng Zhou","Pai Zheng","Jiaming Qi","Chenxi Li","Samantha Lee","Chenguang Yang","David Navarro-Alarcon","Jia Pan"],"pdf_url":"https://arxiv.org/pdf/2401.11432v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15912v1","updated":"2024-10-21T11:35:33Z","published":"2024-10-21T11:35:33Z","title":"Bench4Merge: A Comprehensive Benchmark for Merging in Realistic Dense\n  Traffic with Micro-Interactive Vehicles","summary":"  While the capabilities of autonomous driving have advanced rapidly, merging\ninto dense traffic remains a significant challenge, many motion planning\nmethods for this scenario have been proposed but it is hard to evaluate them.\nMost existing closed-loop simulators rely on rule-based controls for other\nvehicles, which results in a lack of diversity and randomness, thus failing to\naccurately assess the motion planning capabilities in highly interactive\nscenarios. Moreover, traditional evaluation metrics are insufficient for\ncomprehensively evaluating the performance of merging in dense traffic. In\nresponse, we proposed a closed-loop evaluation benchmark for assessing motion\nplanning capabilities in merging scenarios. Our approach involves other\nvehicles trained in large scale datasets with micro-behavioral characteristics\nthat significantly enhance the complexity and diversity. Additionally, we have\nrestructured the evaluation mechanism by leveraging large language models to\nassess each autonomous vehicle merging onto the main road. Extensive\nexperiments have demonstrated the advanced nature of this evaluation benchmark.\nThrough this benchmark, we have obtained an evaluation of existing methods and\nidentified common issues. The environment and vehicle motion planning models we\nhave designed can be accessed at\nhttps://anonymous.4open.science/r/Bench4Merge-EB5D\n","authors":["Zhengming Wang","Junli Wang","Pengfei Li","Zhaohan Li","Peng Li","Yilun Chen"],"pdf_url":"https://arxiv.org/pdf/2410.15912v1.pdf","comment":"6 pages, 7 figures, IEEE international conference on robotics and\n  automation"},{"id":"http://arxiv.org/abs/2403.17633v4","updated":"2024-10-21T11:34:27Z","published":"2024-03-26T12:08:14Z","title":"UADA3D: Unsupervised Adversarial Domain Adaptation for 3D Object\n  Detection with Sparse LiDAR and Large Domain Gaps","summary":"  In this study, we address a gap in existing unsupervised domain adaptation\napproaches on LiDAR-based 3D object detection, which have predominantly\nconcentrated on adapting between established, high-density autonomous driving\ndatasets. We focus on sparser point clouds, capturing scenarios from different\nperspectives: not just from vehicles on the road but also from mobile robots on\nsidewalks, which encounter significantly different environmental conditions and\nsensor configurations. We introduce Unsupervised Adversarial Domain Adaptation\nfor 3D Object Detection (UADA3D). UADA3D does not depend on pre-trained source\nmodels or teacher-student architectures. Instead, it uses an adversarial\napproach to directly learn domain-invariant features. We demonstrate its\nefficacy in various adaptation scenarios, showing significant improvements in\nboth self-driving car and mobile robot domains. Our code is open-source and\nwill be available soon.\n","authors":["Maciej K Wozniak","Mattias Hansson","Marko Thiel","Patric Jensfelt"],"pdf_url":"https://arxiv.org/pdf/2403.17633v4.pdf","comment":"Accepted for IEEE RA-L 2024"},{"id":"http://arxiv.org/abs/2410.15882v1","updated":"2024-10-21T11:01:44Z","published":"2024-10-21T11:01:44Z","title":"Distributed Learning for UAV Swarms","summary":"  Unmanned Aerial Vehicle (UAV) swarms are increasingly deployed in dynamic,\ndata-rich environments for applications such as environmental monitoring and\nsurveillance. These scenarios demand efficient data processing while\nmaintaining privacy and security, making Federated Learning (FL) a promising\nsolution. FL allows UAVs to collaboratively train global models without sharing\nraw data, but challenges arise due to the non-Independent and Identically\nDistributed (non-IID) nature of the data collected by UAVs. In this study, we\nshow an integration of the state-of-the-art FL methods to UAV Swarm application\nand invetigate the performance of multiple aggregation methods (namely FedAvg,\nFedProx, FedOpt, and MOON) with a particular focus on tackling non-IID on a\nvariety of datasets, specifically MNIST for baseline performance, CIFAR10 for\nnatural object classification, EuroSAT for environment monitoring, and CelebA\nfor surveillance. These algorithms were selected to cover improved techniques\non both client-side updates and global aggregation. Results show that while all\nalgorithms perform comparably on IID data, their performance deteriorates\nsignificantly under non-IID conditions. FedProx demonstrated the most stable\noverall performance, emphasising the importance of regularising local updates\nin non-IID environments to mitigate drastic deviations in local models.\n","authors":["Chen Hu","Hanchi Ren","Jingjing Deng","Xianghua Xie"],"pdf_url":"https://arxiv.org/pdf/2410.15882v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15879v1","updated":"2024-10-21T10:59:27Z","published":"2024-10-21T10:59:27Z","title":"Triplane Grasping: Efficient 6-DoF Grasping with Single RGB Images","summary":"  Reliable object grasping is one of the fundamental tasks in robotics.\nHowever, determining grasping pose based on single-image input has long been a\nchallenge due to limited visual information and the complexity of real-world\nobjects. In this paper, we propose Triplane Grasping, a fast grasping\ndecision-making method that relies solely on a single RGB-only image as input.\nTriplane Grasping creates a hybrid Triplane-Gaussian 3D representation through\na point decoder and a triplane decoder, which produce an efficient and\nhigh-quality reconstruction of the object to be grasped to meet real-time\ngrasping requirements. We propose to use an end-to-end network to generate\n6-DoF parallel-jaw grasp distributions directly from 3D points in the point\ncloud as potential grasp contacts and anchor the grasp pose in the observed\ndata. Experiments demonstrate that our method achieves rapid modeling and\ngrasping pose decision-making for daily objects, and exhibits a high grasping\nsuccess rate in zero-shot scenarios.\n","authors":["Yiming Li","Hanchi Ren","Jingjing Deng","Xianghua Xie"],"pdf_url":"https://arxiv.org/pdf/2410.15879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15877v1","updated":"2024-10-21T10:58:03Z","published":"2024-10-21T10:58:03Z","title":"Safety-critical Control with Control Barrier Functions: A Hierarchical\n  Optimization Framework","summary":"  The control barrier function (CBF) has become a fundamental tool in\nsafety-critical systems design since its invention. Typically, the quadratic\noptimization framework is employed to accommodate CBFs, control Lyapunov\nfunctions (CLFs), other constraints and nominal control design. However, the\nconstrained optimization framework involves hyper-parameters to tradeoff\ndifferent objectives and constraints, which, if not well-tuned beforehand,\nimpact system performance and even lead to infeasibility. In this paper, we\npropose a hierarchical optimization framework that decomposes the\nmulti-objective optimization problem into nested optimization sub-problems in a\nsafety-first approach. The new framework addresses potential infeasibility on\nthe premise of ensuring safety and performance as much as possible and applies\neasily in multi-certificate cases. With vivid visualization aids, we\nsystematically analyze the advantages of our proposed method over existing\nQP-based ones in terms of safety, feasibility and convergence rates. Moreover,\ntwo numerical examples are provided that verify our analysis and show the\nsuperiority of our proposed method.\n","authors":["Junjun Xie","Liang Hu","Jiahu Qin","Jun Yang","Huijun Gao"],"pdf_url":"https://arxiv.org/pdf/2410.15877v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15869v1","updated":"2024-10-21T10:54:38Z","published":"2024-10-21T10:54:38Z","title":"Robust Loop Closure by Textual Cues in Challenging Environments","summary":"  Loop closure is an important task in robot navigation. However, existing\nmethods mostly rely on some implicit or heuristic features of the environment,\nwhich can still fail to work in common environments such as corridors, tunnels,\nand warehouses. Indeed, navigating in such featureless, degenerative, and\nrepetitive (FDR) environments would also pose a significant challenge even for\nhumans, but explicit text cues in the surroundings often provide the best\nassistance. This inspires us to propose a multi-modal loop closure method based\non explicit human-readable textual cues in FDR environments. Specifically, our\napproach first extracts scene text entities based on Optical Character\nRecognition (OCR), then creates a local map of text cues based on accurate\nLiDAR odometry and finally identifies loop closure events by a graph-theoretic\nscheme. Experiment results demonstrate that this approach has superior\nperformance over existing methods that rely solely on visual and LiDAR sensors.\nTo benefit the community, we release the source code and datasets at\n\\url{https://github.com/TongxingJin/TXTLCD}.\n","authors":["Tongxing Jin","Thien-Minh Nguyen","Xinhang Xu","Yizhuo Yang","Shenghai Yuan","Jianping Li","Lihua Xie"],"pdf_url":"https://arxiv.org/pdf/2410.15869v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15863v1","updated":"2024-10-21T10:43:49Z","published":"2024-10-21T10:43:49Z","title":"Task-oriented Robotic Manipulation with Vision Language Models","summary":"  Vision-Language Models (VLMs) play a crucial role in robotic manipulation by\nenabling robots to understand and interpret the visual properties of objects\nand their surroundings, allowing them to perform manipulation based on this\nmultimodal understanding. However, understanding object attributes and spatial\nrelationships is a non-trivial task but is critical in robotic manipulation\ntasks. In this work, we present a new dataset focused on spatial relationships\nand attribute assignment and a novel method to utilize VLMs to perform object\nmanipulation with task-oriented, high-level input. In this dataset, the spatial\nrelationships between objects are manually described as captions. Additionally,\neach object is labeled with multiple attributes, such as fragility, mass,\nmaterial, and transparency, derived from a fine-tuned vision language model.\nThe embedded object information from captions are automatically extracted and\ntransformed into a data structure (in this case, tree, for demonstration\npurposes) that captures the spatial relationships among the objects within each\nimage. The tree structures, along with the object attributes, are then fed into\na language model to transform into a new tree structure that determines how\nthese objects should be organized in order to accomplish a specific\n(high-level) task. We demonstrate that our method not only improves the\ncomprehension of spatial relationships among objects in the visual environment\nbut also enables robots to interact with these objects more effectively. As a\nresult, this approach significantly enhances spatial reasoning in robotic\nmanipulation tasks. To our knowledge, this is the first method of its kind in\nthe literature, offering a novel solution that allows robots to more\nefficiently organize and utilize objects in their surroundings.\n","authors":["Nurhan Bulus Guran","Hanchi Ren","Jingjing Deng","Xianghua Xie"],"pdf_url":"https://arxiv.org/pdf/2410.15863v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15837v1","updated":"2024-10-21T09:57:42Z","published":"2024-10-21T09:57:42Z","title":"Long-distance Geomagnetic Navigation in GNSS-denied Environments with\n  Deep Reinforcement Learning","summary":"  Geomagnetic navigation has drawn increasing attention with its capacity in\nnavigating through complex environments and its independence from external\nnavigation services like global navigation satellite systems (GNSS). Existing\nstudies on geomagnetic navigation, i.e., matching navigation and bionic\nnavigation, rely on pre-stored map or extensive searches, leading to limited\napplicability or reduced navigation efficiency in unexplored areas. To address\nthe issues with geomagnetic navigation in areas where GNSS is unavailable, this\npaper develops a deep reinforcement learning (DRL)-based mechanism, especially\nfor long-distance geomagnetic navigation. The designed mechanism trains an\nagent to learn and gain the magnetoreception capacity for geomagnetic\nnavigation, rather than using any pre-stored map or extensive and expensive\nsearching approaches. Particularly, we integrate the geomagnetic gradient-based\nparallel approach into geomagnetic navigation. This integration mitigates the\nover-exploration of the learning agent by adjusting the geomagnetic gradient,\nsuch that the obtained gradient is aligned towards the destination. We explore\nthe effectiveness of the proposed approach via detailed numerical simulations,\nwhere we implement twin delayed deep deterministic policy gradient (TD3) in\nrealizing the proposed approach. The results demonstrate that our approach\noutperforms existing metaheuristic and bionic navigation methods in\nlong-distance missions under diverse navigation conditions.\n","authors":["Wenqi Bai","Xiaohui Zhang","Shiliang Zhang","Songnan Yang","Yushuai Li","Tingwen Huang"],"pdf_url":"https://arxiv.org/pdf/2410.15837v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15802v1","updated":"2024-10-21T09:20:33Z","published":"2024-10-21T09:20:33Z","title":"Assisted Physical Interaction: Autonomous Aerial Robots with Neural\n  Network Detection, Navigation, and Safety Layers","summary":"  The paper introduces a novel framework for safe and autonomous aerial\nphysical interaction in industrial settings. It comprises two main components:\na neural network-based target detection system enhanced with edge computing for\nreduced onboard computational load, and a control barrier function (CBF)-based\ncontroller for safe and precise maneuvering. The target detection system is\ntrained on a dataset under challenging visual conditions and evaluated for\naccuracy across various unseen data with changing lighting conditions. Depth\nfeatures are utilized for target pose estimation, with the entire detection\nframework offloaded into low-latency edge computing. The CBF-based controller\nenables the UAV to converge safely to the target for precise contact. Simulated\nevaluations of both the controller and target detection are presented,\nalongside an analysis of real-world detection performance.\n","authors":["Andrea Berra","Viswa Narayanan Sankaranarayanan","Achilleas Santi Seisa","Julien Mellet","Udayanga G. W. K. N. Gamage","Sumeet Gajanan Satpute","Fabio Ruggiero","Vincenzo Lippiello","Silvia Tolu","Matteo Fumagalli","George Nikolakopoulos","Miguel Ángel Trujillo Soto","Guillermo Heredia"],"pdf_url":"https://arxiv.org/pdf/2410.15802v1.pdf","comment":"8 pages,14 figures, ICUAS 2024"},{"id":"http://arxiv.org/abs/2410.15799v1","updated":"2024-10-21T09:13:07Z","published":"2024-10-21T09:13:07Z","title":"Flying through Moving Gates without Full State Estimation","summary":"  Autonomous drone racing requires powerful perception, planning, and control\nand has become a benchmark and test field for autonomous, agile flight.\nExisting work usually assumes static race tracks with known maps, which enables\noffline planning of time-optimal trajectories, performing localization to the\ngates to reduce the drift in visual-inertial odometry (VIO) for state\nestimation or training learning-based methods for the particular race track and\noperating environment. In contrast, many real-world tasks like disaster\nresponse or delivery need to be performed in unknown and dynamic environments.\nTo close this gap and make drone racing more robust against unseen environments\nand moving gates, we propose a control algorithm that does not require a race\ntrack map or VIO and uses only monocular measurements of the line of sight\n(LOS) to the gates. For this purpose, we adopt the law of proportional\nnavigation (PN) to accurately fly through the gates despite gate motions or\nwind. We formulate the PN-informed vision-based control problem for drone\nracing as a constrained optimization problem and derive a closed-form optimal\nsolution. We demonstrate through extensive simulations and real-world\nexperiments that our method can navigate through moving gates at high speeds\nwhile being robust to different gate movements, model errors, wind, and delays.\n","authors":["Ralf Römer","Tim Emmert","Angela P. Schoellig"],"pdf_url":"https://arxiv.org/pdf/2410.15799v1.pdf","comment":"7 pages, 6 figures"},{"id":"http://arxiv.org/abs/2407.13432v2","updated":"2024-10-21T09:12:21Z","published":"2024-07-18T12:01:09Z","title":"The Art of Imitation: Learning Long-Horizon Manipulation Tasks from Few\n  Demonstrations","summary":"  Task Parametrized Gaussian Mixture Models (TP-GMM) are a sample-efficient\nmethod for learning object-centric robot manipulation tasks. However, there are\nseveral open challenges to applying TP-GMMs in the wild. In this work, we\ntackle three crucial challenges synergistically. First, end-effector velocities\nare non-Euclidean and thus hard to model using standard GMMs. We thus propose\nto factorize the robot's end-effector velocity into its direction and\nmagnitude, and model them using Riemannian GMMs. Second, we leverage the\nfactorized velocities to segment and sequence skills from complex demonstration\ntrajectories. Through the segmentation, we further align skill trajectories and\nhence leverage time as a powerful inductive bias. Third, we present a method to\nautomatically detect relevant task parameters per skill from visual\nobservations. Our approach enables learning complex manipulation tasks from\njust five demonstrations while using only RGB-D observations. Extensive\nexperimental evaluations on RLBench demonstrate that our approach achieves\nstate-of-the-art performance with 20-fold improved sample efficiency. Our\npolicies generalize across different environments, object instances, and object\npositions, while the learned skills are reusable.\n","authors":["Jan Ole von Hartz","Tim Welschehold","Abhinav Valada","Joschka Boedecker"],"pdf_url":"https://arxiv.org/pdf/2407.13432v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15797v1","updated":"2024-10-21T09:08:59Z","published":"2024-10-21T09:08:59Z","title":"Design of a Flexible Robot Arm for Safe Aerial Physical Interaction","summary":"  This paper introduces a novel compliant mechanism combining lightweight and\nenergy dissipation for aerial physical interaction. Weighting 400~g at\ntake-off, the mechanism is actuated in the forward body direction, enabling\nprecise position control for force interaction and various other aerial\nmanipulation tasks. The robotic arm, structured as a closed-loop kinematic\nchain, employs two deported servomotors. Each joint is actuated with a single\ntendon for active motion control in compression of the arm at the end-effector.\nIts elasto-mechanical design reduces weight and provides flexibility, allowing\npassive-compliant interactions without impacting the motors' integrity.\nNotably, the arm's damping can be adjusted based on the proposed inner\nfrictional bulges. Experimental applications showcase the aerial system\nperformance in both free-flight and physical interaction. The presented work\nmay open safer applications for \\ac{MAV} in real environments subject to\nperturbations during interaction.\n","authors":["Julien Mellet","Andrea Berra","Achilleas Santi Seisa","Viswa Sankaranarayanan","Udayanga G. W. K. N. Gamage","Miguel Angel Trujillo Soto","Guillermo Heredia","George Nikolakopoulos","Vincenzo Lippiello","Fabio Ruggiero"],"pdf_url":"https://arxiv.org/pdf/2410.15797v1.pdf","comment":"6 pages, 7 figures, ROBOSOFT 2024"},{"id":"http://arxiv.org/abs/2410.15792v1","updated":"2024-10-21T09:02:40Z","published":"2024-10-21T09:02:40Z","title":"WildOcc: A Benchmark for Off-Road 3D Semantic Occupancy Prediction","summary":"  3D semantic occupancy prediction is an essential part of autonomous driving,\nfocusing on capturing the geometric details of scenes. Off-road environments\nare rich in geometric information, therefore it is suitable for 3D semantic\noccupancy prediction tasks to reconstruct such scenes. However, most of\nresearches concentrate on on-road environments, and few methods are designed\nfor off-road 3D semantic occupancy prediction due to the lack of relevant\ndatasets and benchmarks. In response to this gap, we introduce WildOcc, to our\nknowledge, the first benchmark to provide dense occupancy annotations for\noff-road 3D semantic occupancy prediction tasks. A ground truth generation\npipeline is proposed in this paper, which employs a coarse-to-fine\nreconstruction to achieve a more realistic result. Moreover, we introduce a\nmulti-modal 3D semantic occupancy prediction framework, which fuses\nspatio-temporal information from multi-frame images and point clouds at voxel\nlevel. In addition, a cross-modality distillation function is introduced, which\ntransfers geometric knowledge from point clouds to image features.\n","authors":["Heng Zhai","Jilin Mei","Chen Min","Liang Chen","Fangzhou Zhao","Yu Hu"],"pdf_url":"https://arxiv.org/pdf/2410.15792v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15774v1","updated":"2024-10-21T08:36:25Z","published":"2024-10-21T08:36:25Z","title":"Generalizing Motion Planners with Mixture of Experts for Autonomous\n  Driving","summary":"  Large real-world driving datasets have sparked significant research into\nvarious aspects of data-driven motion planners for autonomous driving. These\ninclude data augmentation, model architecture, reward design, training\nstrategies, and planner pipelines. These planners promise better\ngeneralizations on complicated and few-shot cases than previous methods.\nHowever, experiment results show that many of these approaches produce limited\ngeneralization abilities in planning performance due to overly complex designs\nor training paradigms. In this paper, we review and benchmark previous methods\nfocusing on generalizations. The experimental results indicate that as models\nare appropriately scaled, many design elements become redundant. We introduce\nStateTransformer-2 (STR2), a scalable, decoder-only motion planner that uses a\nVision Transformer (ViT) encoder and a mixture-of-experts (MoE) causal\nTransformer architecture. The MoE backbone addresses modality collapse and\nreward balancing by expert routing during training. Extensive experiments on\nthe NuPlan dataset show that our method generalizes better than previous\napproaches across different test sets and closed-loop simulations. Furthermore,\nwe assess its scalability on billions of real-world urban driving scenarios,\ndemonstrating consistent accuracy improvements as both data and model size\ngrow.\n","authors":["Qiao Sun","Huimin Wang","Jiahao Zhan","Fan Nie","Xin Wen","Leimeng Xu","Kun Zhan","Peng Jia","Xianpeng Lang","Hang Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.15774v1.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2407.12381v2","updated":"2024-10-21T08:34:11Z","published":"2024-07-17T07:58:37Z","title":"Flow Matching Imitation Learning for Multi-Support Manipulation","summary":"  Humanoid robots could benefit from using their upper bodies for support\ncontacts, enhancing their workspace, stability, and ability to perform\ncontact-rich and pushing tasks. In this paper, we propose a unified approach\nthat combines an optimization-based multi-contact whole-body controller with\nFlow Matching, a recently introduced method capable of generating multi-modal\ntrajectory distributions for imitation learning. In simulation, we show that\nFlow Matching is more appropriate for robotics than Diffusion and traditional\nbehavior cloning. On a real full-size humanoid robot (Talos), we demonstrate\nthat our approach can learn a whole-body non-prehensile box-pushing task and\nthat the robot can close dishwasher drawers by adding contacts with its free\nhand when needed for balance. We also introduce a shared autonomy mode for\nassisted teleoperation, providing automatic contact placement for tasks not\ncovered in the demonstrations. Full experimental videos are available at:\nhttps://hucebot.github.io/flow_multisupport_website/\n","authors":["Quentin Rouxel","Andrea Ferrari","Serena Ivaldi","Jean-Baptiste Mouret"],"pdf_url":"https://arxiv.org/pdf/2407.12381v2.pdf","comment":"2024 IEEE-RAS 23rd International Conference on Humanoid Robots\n  (Humanoids), Nov 2024, Nancy, France"},{"id":"http://arxiv.org/abs/2407.20619v3","updated":"2024-10-21T08:16:41Z","published":"2024-07-30T07:49:17Z","title":"ATI-CTLO:Adaptive Temporal Interval-based Continuous-Time LiDAR-Only\n  Odometry","summary":"  The motion distortion in LiDAR scans caused by aggressive robot motion and\nvarying terrain features significantly impacts the positioning and mapping\nperformance of 3D LiDAR odometry. Existing distortion correction solutions\noften struggle to balance computational complexity and accuracy. In this work,\nwe propose an Adaptive Temporal Interval-based Continuous-Time LiDAR-only\nOdometry, utilizing straightforward and efficient linear interpolation. Our\nmethod flexibly adjusts the temporal intervals between control nodes according\nto the dynamics of motion and environmental characteristics. This adaptability\nenhances performance across various motion states and improves robustness in\nchallenging, feature-sparse environments. We validate the effectiveness of our\nmethod on multiple datasets across different platforms, achieving accuracy\ncomparable to state-of-the-art LiDAR-only odometry methods. Notably, in\nscenarios involving aggressive motion and sparse features, our method\noutperforms existing solutions.\n","authors":["Bo Zhou","Jiajie Wu","Yan Pan","Chuanzhao Lu"],"pdf_url":"https://arxiv.org/pdf/2407.20619v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15730v1","updated":"2024-10-21T07:46:56Z","published":"2024-10-21T07:46:56Z","title":"MSGField: A Unified Scene Representation Integrating Motion, Semantics,\n  and Geometry for Robotic Manipulation","summary":"  Combining accurate geometry with rich semantics has been proven to be highly\neffective for language-guided robotic manipulation. Existing methods for\ndynamic scenes either fail to update in real-time or rely on additional depth\nsensors for simple scene editing, limiting their applicability in real-world.\nIn this paper, we introduce MSGField, a representation that uses a collection\nof 2D Gaussians for high-quality reconstruction, further enhanced with\nattributes to encode semantic and motion information. Specially, we represent\nthe motion field compactly by decomposing each primitive's motion into a\ncombination of a limited set of motion bases. Leveraging the differentiable\nreal-time rendering of Gaussian splatting, we can quickly optimize object\nmotion, even for complex non-rigid motions, with image supervision from only\ntwo camera views. Additionally, we designed a pipeline that utilizes object\npriors to efficiently obtain well-defined semantics. In our challenging\ndataset, which includes flexible and extremely small objects, our method\nachieve a success rate of 79.2% in static and 63.3% in dynamic environments for\nlanguage-guided manipulation. For specified object grasping, we achieve a\nsuccess rate of 90%, on par with point cloud-based methods. Code and dataset\nwill be released at:https://shengyu724.github.io/MSGField.github.io.\n","authors":["Yu Sheng","Runfeng Lin","Lidian Wang","Quecheng Qiu","YanYong Zhang","Yu Zhang","Bei Hua","Jianmin Ji"],"pdf_url":"https://arxiv.org/pdf/2410.15730v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15720v1","updated":"2024-10-21T07:39:13Z","published":"2024-10-21T07:39:13Z","title":"Efficient Non-Myopic Layered Bayesian Optimization For Large-Scale\n  Bathymetric Informative Path Planning","summary":"  Informative path planning (IPP) applied to bathymetric mapping allows AUVs to\nfocus on feature-rich areas to quickly reduce uncertainty and increase mapping\nefficiency. Existing methods based on Bayesian optimization (BO) over Gaussian\nProcess (GP) maps work well on small scenarios but they are short-sighted and\ncomputationally heavy when mapping larger areas, hindering deployment in real\napplications. To overcome this, we present a 2-layered BO IPP method that\nperforms non-myopic, real-time planning in a tree search fashion over large\nStochastic Variational GP maps, while respecting the AUV motion constraints and\naccounting for localization uncertainty. Our framework outperforms the standard\nindustrial lawn-mowing pattern and a myopic baseline in a set of hardware in\nthe loop (HIL) experiments in an embedded platform over real bathymetry.\n","authors":["Alexander Kiessling","Ignacio Torroba","Chelsea Rose Sidrane","Ivan Stenius","Jana Tumova","John Folkesson"],"pdf_url":"https://arxiv.org/pdf/2410.15720v1.pdf","comment":"6 pages + 1 page of references, 4 figures, submitted to International\n  Conference on Robotics and Automation (ICRA)"},{"id":"http://arxiv.org/abs/2410.15710v1","updated":"2024-10-21T07:31:01Z","published":"2024-10-21T07:31:01Z","title":"Hierarchical Search-Based Cooperative Motion Planning","summary":"  Cooperative path planning, a crucial aspect of multi-agent systems research,\nserves a variety of sectors, including military, agriculture, and industry.\nMany existing algorithms, however, come with certain limitations, such as\nsimplified kinematic models and inadequate support for multiple group\nscenarios. Focusing on the planning problem associated with a nonholonomic\nAckermann model for Unmanned Ground Vehicles (UGV), we propose a leaderless,\nhierarchical Search-Based Cooperative Motion Planning (SCMP) method. The\nhigh-level utilizes a binary conflict search tree to minimize runtime, while\nthe low-level fabricates kinematically feasible, collision-free paths that are\nshape-constrained. Our algorithm can adapt to scenarios featuring multiple\ngroups with different shapes, outlier agents, and elaborate obstacles. We\nconduct algorithm comparisons, performance testing, simulation, and real-world\ntesting, verifying the effectiveness and applicability of our algorithm. The\nimplementation of our method will be open-sourced at\nhttps://github.com/WYCUniverStar/SCMP.\n","authors":["Yuchen Wu","Yifan Yang","Gang Xu","Junjie Cao","Yansong Chen","Licheng Wen","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2410.15710v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15694v1","updated":"2024-10-21T07:05:07Z","published":"2024-10-21T07:05:07Z","title":"PALMS: Plane-based Accessible Indoor Localization Using Mobile\n  Smartphones","summary":"  In this paper, we present PALMS, an innovative indoor global localization and\nrelocalization system for mobile smartphones that utilizes publicly available\nfloor plans. Unlike most vision-based methods that require constant visual\ninput, our system adopts a dynamic form of localization that considers a single\ninstantaneous observation and odometry data. The core contribution of this work\nis the introduction of a particle filter initialization method that leverages\nthe Certainly Empty Space (CES) constraint along with principal orientation\nmatching. This approach creates a spatial probability distribution of the\ndevice's location, significantly improving localization accuracy and reducing\nparticle filter convergence time. Our experimental evaluations demonstrate that\nPALMS outperforms traditional methods with uniformly initialized particle\nfilters, providing a more efficient and accessible approach to indoor\nwayfinding. By eliminating the need for prior environmental fingerprinting,\nPALMS provides a scalable and practical approach to indoor navigation.\n","authors":["Yunqian Cheng","Roberto Manduchi"],"pdf_url":"https://arxiv.org/pdf/2410.15694v1.pdf","comment":"7 pages, 3 figures, accepted to the 14th International Conference on\n  Indoor Positioning and Indoor Navigation (IPIN) 2024, Best Presentation Award"},{"id":"http://arxiv.org/abs/2410.05273v2","updated":"2024-10-21T06:50:05Z","published":"2024-09-12T09:18:09Z","title":"HiRT: Enhancing Robotic Control with Hierarchical Robot Transformers","summary":"  Large Vision-Language-Action (VLA) models, leveraging powerful pre trained\nVision-Language Models (VLMs) backends, have shown promise in robotic control\ndue to their impressive generalization ability. However, the success comes at a\ncost. Their reliance on VLM backends with billions of parameters leads to high\ncomputational costs and inference latency, limiting the testing scenarios to\nmainly quasi-static tasks and hindering performance in dynamic tasks requiring\nrapid interactions. To address these limitations, this paper proposes HiRT, a\nHierarchical Robot Transformer framework that enables flexible frequency and\nperformance trade-off. HiRT keeps VLMs running at low frequencies to capture\ntemporarily invariant features while enabling real-time interaction through a\nhigh-frequency vision-based policy guided by the slowly updated features.\nExperiment results in both simulation and real-world settings demonstrate\nsignificant improvements over baseline methods. Empirically, in static tasks,\nwe double the control frequency and achieve comparable success rates.\nAdditionally, on novel real-world dynamic ma nipulation tasks which are\nchallenging for previous VLA models, HiRT improves the success rate from 48% to\n75%.\n","authors":["Jianke Zhang","Yanjiang Guo","Xiaoyu Chen","Yen-Jen Wang","Yucheng Hu","Chengming Shi","Jianyu Chen"],"pdf_url":"https://arxiv.org/pdf/2410.05273v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15682v1","updated":"2024-10-21T06:46:49Z","published":"2024-10-21T06:46:49Z","title":"RANSAC Back to SOTA: A Two-stage Consensus Filtering for Real-time 3D\n  Registration","summary":"  Correspondence-based point cloud registration (PCR) plays a key role in\nrobotics and computer vision. However, challenges like sensor noises, object\nocclusions, and descriptor limitations inevitably result in numerous outliers.\nRANSAC family is the most popular outlier removal solution. However, the\nrequisite iterations escalate exponentially with the outlier ratio, rendering\nit far inferior to existing methods (SC2PCR [1], MAC [2], etc.) in terms of\naccuracy or speed. Thus, we propose a two-stage consensus filtering (TCF) that\nelevates RANSAC to state-of-the-art (SOTA) speed and accuracy. Firstly,\none-point RANSAC obtains a consensus set based on length consistency.\nSubsequently, two-point RANSAC refines the set via angle consistency. Then,\nthree-point RANSAC computes a coarse pose and removes outliers based on\ntransformed correspondence's distances. Drawing on optimizations from one-point\nand two-point RANSAC, three-point RANSAC requires only a few iterations.\nEventually, an iterative reweighted least squares (IRLS) is applied to yield\nthe optimal pose. Experiments on the large-scale KITTI and ETH datasets\ndemonstrate our method achieves up to three-orders-of-magnitude speedup\ncompared to MAC while maintaining registration accuracy and recall. Our code is\navailable at https://github.com/ShiPC-AI/TCF.\n","authors":["Pengcheng Shi","Shaocheng Yan","Yilin Xiao","Xinyi Liu","Yongjun Zhang","Jiayuan Li"],"pdf_url":"https://arxiv.org/pdf/2410.15682v1.pdf","comment":"8 pages, 8 figures"},{"id":"http://arxiv.org/abs/2407.05717v5","updated":"2024-10-21T06:40:33Z","published":"2024-07-08T08:21:22Z","title":"A New Framework for Nonlinear Kalman Filters","summary":"  The Kalman filter (KF) is a state estimation algorithm that optimally\ncombines system knowledge and measurements to minimize the mean squared error\nof the estimated states. While KF was initially designed for linear systems,\nnumerous extensions of it, such as extended Kalman filter (EKF), unscented\nKalman filter (UKF), cubature Kalman filter (CKF), etc., have been proposed for\nnonlinear systems. Although different types of nonlinear KFs have different\npros and cons, they all use the same framework of linear KF, which, according\nto what we found in this paper, tends to give overconfident and less accurate\nstate estimations when the measurement functions are nonlinear. Therefore, in\nthis study, we designed a new framework for nonlinear KFs and showed\ntheoretically and empirically that the new framework estimates the states and\ncovariance matrix more accurately than the old one. The new framework was\ntested on four different nonlinear KFs and five different tasks, showcasing its\nability to reduce the estimation errors by several orders of magnitude in\nlow-measurement-noise conditions, with only about a 10 to 90% increase in\ncomputational time. All types of nonlinear KFs can benefit from the new\nframework, and the benefit will increase as the sensors become more and more\naccurate in the future. As an example, EKF, the simplest nonlinear KF that was\npreviously believed to work poorly for strongly nonlinear systems, can now\nprovide fast and fairly accurate state estimations with the help of the new\nframework. The codes are available at\nhttps://github.com/Shida-Jiang/A-new-framework-for-nonlinear-Kalman-filters.\n","authors":["Shida Jiang","Junzhe Shi","Scott Moura"],"pdf_url":"https://arxiv.org/pdf/2407.05717v5.pdf","comment":"Some typo fixed"},{"id":"http://arxiv.org/abs/2410.04419v2","updated":"2024-10-21T06:35:08Z","published":"2024-10-06T09:26:07Z","title":"LiteVLoc: Map-Lite Visual Localization for Image Goal Navigation","summary":"  This paper presents LiteVLoc, a hierarchical visual localization framework\nthat uses a lightweight topo-metric map to represent the environment. The\nmethod consists of three sequential modules that estimate camera poses in a\ncoarse-to-fine manner. Unlike mainstream approaches relying on detailed 3D\nrepresentations, LiteVLoc reduces storage overhead by leveraging learning-based\nfeature matching and geometric solvers for metric pose estimation. A novel\ndataset for the map-free relocalization task is also introduced. Extensive\nexperiments including localization and navigation in both simulated and\nreal-world scenarios have validate the system's performance and demonstrated\nits precision and efficiency for large-scale deployment. Code and data will be\nmade publicly available.\n","authors":["Jianhao Jiao","Jinhao He","Changkun Liu","Sebastian Aegidius","Xiangcheng Hu","Tristan Braud","Dimitrios Kanoulas"],"pdf_url":"https://arxiv.org/pdf/2410.04419v2.pdf","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2406.13165v2","updated":"2024-10-21T06:25:57Z","published":"2024-06-19T02:42:29Z","title":"Cardiac Copilot: Automatic Probe Guidance for Echocardiography with\n  World Model","summary":"  Echocardiography is the only technique capable of real-time imaging of the\nheart and is vital for diagnosing the majority of cardiac diseases. However,\nthere is a severe shortage of experienced cardiac sonographers, due to the\nheart's complex structure and significant operational challenges. To mitigate\nthis situation, we present a Cardiac Copilot system capable of providing\nreal-time probe movement guidance to assist less experienced sonographers in\nconducting freehand echocardiography. This system can enable non-experts,\nespecially in primary departments and medically underserved areas, to perform\ncardiac ultrasound examinations, potentially improving global healthcare\ndelivery. The core innovation lies in proposing a data-driven world model,\nnamed Cardiac Dreamer, for representing cardiac spatial structures. This world\nmodel can provide structure features of any cardiac planes around the current\nprobe position in the latent space, serving as an precise navigation map for\nautonomous plane localization. We train our model with real-world ultrasound\ndata and corresponding probe motion from 110 routine clinical scans with 151K\nsample pairs by three certified sonographers. Evaluations on three standard\nplanes with 37K sample pairs demonstrate that the world model can reduce\nnavigation errors by up to 33\\% and exhibit more stable performance.\n","authors":["Haojun Jiang","Zhenguo Sun","Ning Jia","Meng Li","Yu Sun","Shaqi Luo","Shiji Song","Gao Huang"],"pdf_url":"https://arxiv.org/pdf/2406.13165v2.pdf","comment":"Accepted by MICCAI2024"},{"id":"http://arxiv.org/abs/2404.18580v2","updated":"2024-10-21T06:25:33Z","published":"2024-04-29T10:41:30Z","title":"Data-Driven Dynamics Modeling of Miniature Robotic Blimps Using Neural\n  ODEs With Parameter Auto-Tuning","summary":"  Miniature robotic blimps, as one type of lighter-than-air aerial vehicles,\nhave attracted increasing attention in the science and engineering community\nfor their enhanced safety, extended endurance, and quieter operation compared\nto quadrotors. Accurately modeling the dynamics of these robotic blimps poses a\nsignificant challenge due to the complex aerodynamics stemming from their large\nlifting bodies. Traditional first-principle models have difficulty obtaining\naccurate aerodynamic parameters and often overlook high-order nonlinearities,\nthus coming to its limit in modeling the motion dynamics of miniature robotic\nblimps. To tackle this challenge, this letter proposes the Auto-tuning\nBlimp-oriented Neural Ordinary Differential Equation method (ABNODE), a\ndata-driven approach that integrates first-principle and neural network\nmodeling. Spiraling motion experiments of robotic blimps are conducted,\ncomparing the ABNODE with first-principle and other data-driven benchmark\nmodels, the results of which demonstrate the effectiveness of the proposed\nmethod.\n","authors":["Yongjian Zhu","Hao Cheng","Feitian Zhang"],"pdf_url":"https://arxiv.org/pdf/2404.18580v2.pdf","comment":"8 pages, 8 figures"},{"id":"http://arxiv.org/abs/2410.10284v3","updated":"2024-10-21T05:22:13Z","published":"2024-10-14T08:36:06Z","title":"Trust or Bust: Ensuring Trustworthiness in Autonomous Weapon Systems","summary":"  The integration of Autonomous Weapon Systems (AWS) into military operations\npresents both significant opportunities and challenges. This paper explores the\nmultifaceted nature of trust in AWS, emphasising the necessity of establishing\nreliable and transparent systems to mitigate risks associated with bias,\noperational failures, and accountability. Despite advancements in Artificial\nIntelligence (AI), the trustworthiness of these systems, especially in\nhigh-stakes military applications, remains a critical issue. Through a\nsystematic review of existing literature, this research identifies gaps in the\nunderstanding of trust dynamics during the development and deployment phases of\nAWS. It advocates for a collaborative approach that includes technologists,\nethicists, and military strategists to address these ongoing challenges. The\nfindings underscore the importance of Human-Machine teaming and enhancing\nsystem intelligibility to ensure accountability and adherence to International\nHumanitarian Law. Ultimately, this paper aims to contribute to the ongoing\ndiscourse on the ethical implications of AWS and the imperative for trustworthy\nAI in defense contexts.\n","authors":["Kasper Cools","Clara Maathuis"],"pdf_url":"https://arxiv.org/pdf/2410.10284v3.pdf","comment":"Accepted as a workshop paper at MILCOM 2024, 8 pages"},{"id":"http://arxiv.org/abs/2409.10747v3","updated":"2024-10-21T04:06:18Z","published":"2024-09-16T21:37:25Z","title":"Uncovering the Secrets of Human-Like Movement: A Fresh Perspective on\n  Motion Planning","summary":"  This article explores human-like movement from a fresh perspective on motion\nplanning. We analyze the coordinated and compliant movement mechanisms of the\nhuman body from the perspective of biomechanics. Based on these mechanisms, we\npropose an optimal control framework that integrates compliant control\ndynamics, optimizing robotic arm motion through a response time matrix. This\nmatrix sets the timing parameters for joint movements, turning the system into\na time-parameterized optimal control problem. The model focuses on the\ninteraction between active and passive joints under external disturbances,\nimproving adaptability and compliance. This method achieves optimal trajectory\ngeneration and balances precision and compliance. Experimental results on both\na manipulator and a humanoid robot validate the approach.\n","authors":["Lei Shi","Qichao Liu","Cheng Zhou","Wentao Gao","Haotian Wu","Yu Zheng","Xiong Li"],"pdf_url":"https://arxiv.org/pdf/2409.10747v3.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2402.11507v2","updated":"2024-10-21T03:13:20Z","published":"2024-02-18T08:34:15Z","title":"MAL: Motion-Aware Loss with Temporal and Distillation Hints for\n  Self-Supervised Depth Estimation","summary":"  Depth perception is crucial for a wide range of robotic applications.\nMulti-frame self-supervised depth estimation methods have gained research\ninterest due to their ability to leverage large-scale, unlabeled real-world\ndata. However, the self-supervised methods often rely on the assumption of a\nstatic scene and their performance tends to degrade in dynamic environments. To\naddress this issue, we present Motion-Aware Loss, which leverages the temporal\nrelation among consecutive input frames and a novel distillation scheme between\nthe teacher and student networks in the multi-frame self-supervised depth\nestimation methods. Specifically, we associate the spatial locations of moving\nobjects with the temporal order of input frames to eliminate errors induced by\nobject motion. Meanwhile, we enhance the original distillation scheme in\nmulti-frame methods to better exploit the knowledge from a teacher network. MAL\nis a novel, plug-and-play module designed for seamless integration into\nmulti-frame self-supervised monocular depth estimation methods. Adding MAL into\nprevious state-of-the-art methods leads to a reduction in depth estimation\nerrors by up to 4.2% and 10.8% on KITTI and CityScapes benchmarks,\nrespectively.\n","authors":["Yue-Jiang Dong","Fang-Lue Zhang","Song-Hai Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.11507v2.pdf","comment":"Accepted by ICRA 2024; Project homepage:\n  https://yuejiangdong.github.io/MotionAwareLoss/"},{"id":"http://arxiv.org/abs/2410.15607v1","updated":"2024-10-21T03:04:29Z","published":"2024-10-21T03:04:29Z","title":"Reinforced Imitative Trajectory Planning for Urban Automated Driving","summary":"  Reinforcement learning (RL) faces challenges in trajectory planning for urban\nautomated driving due to the poor convergence of RL and the difficulty in\ndesigning reward functions. The convergence problem is alleviated by combining\nRL with supervised learning. However, most existing approaches only reason one\nstep ahead and lack the capability to plan for multiple future steps. Besides,\nalthough inverse reinforcement learning holds promise for solving the reward\nfunction design issue, existing methods for automated driving impose a linear\nstructure assumption on reward functions, making them difficult to apply to\nurban automated driving. In light of these challenges, this paper proposes a\nnovel RL-based trajectory planning method that integrates RL with imitation\nlearning to enable multi-step planning. Furthermore, a transformer-based\nBayesian reward function is developed, providing effective reward signals for\nRL in urban scenarios. Moreover, a hybrid-driven trajectory planning framework\nis proposed to enhance safety and interpretability. The proposed methods were\nvalidated on the large-scale real-world urban automated driving nuPlan dataset.\nThe results demonstrated the significant superiority of the proposed methods\nover the baselines in terms of the closed-loop metrics. The code is available\nat https://github.com/Zigned/nuplan_zigned.\n","authors":["Di Zeng","Ling Zheng","Xiantong Yang","Yinong Li"],"pdf_url":"https://arxiv.org/pdf/2410.15607v1.pdf","comment":"19 pages, 9 figures"},{"id":"http://arxiv.org/abs/2410.15600v1","updated":"2024-10-21T02:53:18Z","published":"2024-10-21T02:53:18Z","title":"Patrol Security Game: Defending Against Adversary with Freedom in Attack\n  Timing, Location, and Duration","summary":"  We explored the Patrol Security Game (PSG), a robotic patrolling problem\nmodeled as an extensive-form Stackelberg game, where the attacker determines\nthe timing, location, and duration of their attack. Our objective is to devise\na patrolling schedule with an infinite time horizon that minimizes the\nattacker's payoff. We demonstrated that PSG can be transformed into a\ncombinatorial minimax problem with a closed-form objective function. By\nconstraining the defender's strategy to a time-homogeneous first-order Markov\nchain (i.e., the patroller's next move depends solely on their current\nlocation), we proved that the optimal solution in cases of zero penalty\ninvolves either minimizing the expected hitting time or return time, depending\non the attacker model, and that these solutions can be computed efficiently.\nAdditionally, we observed that increasing the randomness in the patrol schedule\nreduces the attacker's expected payoff in high-penalty cases. However, the\nminimax problem becomes non-convex in other scenarios. To address this, we\nformulated a bi-criteria optimization problem incorporating two objectives:\nexpected maximum reward and entropy. We proposed three graph-based algorithms\nand one deep reinforcement learning model, designed to efficiently balance the\ntrade-off between these two objectives. Notably, the third algorithm can\nidentify the optimal deterministic patrol schedule, though its runtime grows\nexponentially with the number of patrol spots. Experimental results validate\nthe effectiveness and scalability of our solutions, demonstrating that our\napproaches outperform state-of-the-art baselines on both synthetic and\nreal-world crime datasets.\n","authors":["Hao-Tsung Yang","Ting-Kai Weng","Ting-Yu Chang","Kin Sum Liu","Shan Lin","Jie Gao","Shih-Yu Tsai"],"pdf_url":"https://arxiv.org/pdf/2410.15600v1.pdf","comment":"Under review of TCPS"},{"id":"http://arxiv.org/abs/2410.15559v1","updated":"2024-10-21T01:05:20Z","published":"2024-10-21T01:05:20Z","title":"Development of Minimal Biorobotic Stealth Distance and Its Application\n  in the Design of Direct-Drive Dragonfly-Inspired Aircraft","summary":"  This paper introduces the Minimal Biorobotic Stealth Distance (MBSD), a novel\nquantitative metric to evaluate the bionic resemblance of biorobotic aircraft.\nCurrent technological limitations prevent dragonfly-inspired aircrafts from\nachieving optimal performance at biological scales. To address these\nchallenges, we use the DDD-1 dragonfly-inspired aircraft, a hover-capable\ndirect-drive aircraft, to explore the impact of the MBSD on aircraft design.\nKey contributions of this research include: (1) the establishment of the MBSD\nas a quantifiable and operable evaluation metric that influences aircraft\ndesign, integrating seamlessly with the overall design process and providing a\nnew dimension for optimizing bionic aircraft, balancing mechanical attributes\nand bionic characteristics; (2) the creation and analysis of a typical aircraft\nin four directions: essential characteristics of the MBSD, its coupling\nrelationship with existing performance metrics (Longest Hover Duration and\nMaximum Instantaneous Forward Flight Speed), multi-objective optimization, and\napplication in a typical mission scenario; (3) the construction and validation\nof a full-system model for the direct-drive dragonfly-inspired aircraft,\ndemonstrating the design model's effectiveness against existing aircraft data.\nDetailed calculations of the MBSD consider appearance similarity, dynamic\nsimilarity, and environmental similarity.\n","authors":["Zhang Minghao","Song Bifeng","Yang Xiaojun","Wang Liang","Lang Xinyua"],"pdf_url":"https://arxiv.org/pdf/2410.15559v1.pdf","comment":"61 pages, 32 figures"},{"id":"http://arxiv.org/abs/2410.15554v1","updated":"2024-10-21T00:59:50Z","published":"2024-10-21T00:59:50Z","title":"A Plug-and-Play Fully On-the-Job Real-Time Reinforcement Learning\n  Algorithm for a Direct-Drive Tandem-Wing Experiment Platforms Under Multiple\n  Random Operating Conditions","summary":"  The nonlinear and unstable aerodynamic interference generated by the tandem\nwings of such biomimetic systems poses substantial challenges for motion\ncontrol, especially under multiple random operating conditions. To address\nthese challenges, the Concerto Reinforcement Learning Extension (CRL2E)\nalgorithm has been developed. This plug-and-play, fully on-the-job, real-time\nreinforcement learning algorithm incorporates a novel Physics-Inspired\nRule-Based Policy Composer Strategy with a Perturbation Module alongside a\nlightweight network optimized for real-time control. To validate the\nperformance and the rationality of the module design, experiments were\nconducted under six challenging operating conditions, comparing seven different\nalgorithms. The results demonstrate that the CRL2E algorithm achieves safe and\nstable training within the first 500 steps, improving tracking accuracy by 14\nto 66 times compared to the Soft Actor-Critic, Proximal Policy Optimization,\nand Twin Delayed Deep Deterministic Policy Gradient algorithms. Additionally,\nCRL2E significantly enhances performance under various random operating\nconditions, with improvements in tracking accuracy ranging from 8.3% to 60.4%\ncompared to the Concerto Reinforcement Learning (CRL) algorithm. The\nconvergence speed of CRL2E is 36.11% to 57.64% faster than the CRL algorithm\nwith only the Composer Perturbation and 43.52% to 65.85% faster than the CRL\nalgorithm when both the Composer Perturbation and Time-Interleaved Capability\nPerturbation are introduced, especially in conditions where the standard CRL\nstruggles to converge. Hardware tests indicate that the optimized lightweight\nnetwork structure excels in weight loading and average inference time, meeting\nreal-time control requirements.\n","authors":["Zhang Minghao","Song Bifeng","Yang Xiaojun","Wang Liang"],"pdf_url":"https://arxiv.org/pdf/2410.15554v1.pdf","comment":"63 pages, 32 figures"},{"id":"http://arxiv.org/abs/2410.15549v1","updated":"2024-10-21T00:36:02Z","published":"2024-10-21T00:36:02Z","title":"A Dual Process VLA: Efficient Robotic Manipulation Leveraging VLM","summary":"  Vision-Language-Action (VLA) models are receiving increasing attention for\ntheir ability to enable robots to perform complex tasks by integrating visual\ncontext with linguistic commands. However, achieving efficient real-time\nperformance remains challenging due to the high computational demands of\nexisting models. To overcome this, we propose Dual Process VLA (DP-VLA), a\nhierarchical framework inspired by dual-process theory. DP-VLA utilizes a Large\nSystem 2 Model (L-Sys2) for complex reasoning and decision-making, while a\nSmall System 1 Model (S-Sys1) handles real-time motor control and sensory\nprocessing. By leveraging Vision-Language Models (VLMs), the L-Sys2 operates at\nlow frequencies, reducing computational overhead, while the S-Sys1 ensures fast\nand accurate task execution. Experimental results on the RoboCasa dataset\ndemonstrate that DP-VLA achieves faster inference and higher task success\nrates, providing a scalable solution for advanced robotic applications.\n","authors":["ByungOk Han","Jaehong Kim","Jinhyeok Jang"],"pdf_url":"https://arxiv.org/pdf/2410.15549v1.pdf","comment":"10 page"},{"id":"http://arxiv.org/abs/2406.14746v2","updated":"2024-10-21T00:16:51Z","published":"2024-06-20T21:36:54Z","title":"Behavior-Inspired Neural Networks for Relational Inference","summary":"  From pedestrians to Kuramoto oscillators, interactions between agents govern\nhow a multitude of dynamical systems evolve in space and time. Discovering how\nthese agents relate to each other can improve our understanding of the often\ncomplex dynamics that underlie these systems. Recent works learn to categorize\nrelationships between agents based on observations of their physical behavior.\nThese approaches are limited in that the relationship categories are modelled\nas outcomes of categorical distribution, when in real world systems categories\noften intermingle and interact. In this work, we introduce a level of\nabstraction between the observable behavior of agents and the latent categories\nthat determine their behavior. To do this, we learn a mapping from agent\nbehavior to agent preferences for each latent category in a graph neural\nnetwork. We integrate the physical proximity of agents and their preferences in\na nonlinear opinion dynamics model which provides a mechanism to identify\nmutually exclusive latent categories, predict an agent's evolution in time, and\ncontrol an agent's physical behavior. We demonstrate the utility of our model\nfor learning interpretable categories, and its efficacy on long-horizon\nprediction across several benchmarks where we outperform existing methods.\n","authors":["Yulong Yang","Bowen Feng","Keqin Wang","Naomi Leonard","Adji Bousso Dieng","Christine Allen-Blanchette"],"pdf_url":"https://arxiv.org/pdf/2406.14746v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16571v1","updated":"2024-10-21T23:07:48Z","published":"2024-10-21T23:07:48Z","title":"Implicit Contact Diffuser: Sequential Contact Reasoning with Latent\n  Point Cloud Diffusion","summary":"  Long-horizon contact-rich manipulation has long been a challenging problem,\nas it requires reasoning over both discrete contact modes and continuous object\nmotion. We introduce Implicit Contact Diffuser (ICD), a diffusion-based model\nthat generates a sequence of neural descriptors that specify a series of\ncontact relationships between the object and the environment. This sequence is\nthen used as guidance for an MPC method to accomplish a given task. The key\nadvantage of this approach is that the latent descriptors provide more\ntask-relevant guidance to MPC, helping to avoid local minima for contact-rich\nmanipulation tasks. Our experiments demonstrate that ICD outperforms baselines\non complex, long-horizon, contact-rich manipulation tasks, such as cable\nrouting and notebook folding. Additionally, our experiments also indicate that\n\\methodshort can generalize a target contact relationship to a different\nenvironment. More visualizations can be found on our website\n$\\href{https://implicit-contact-diffuser.github.io/}{https://implicit-contact-diffuser.github.io}$\n","authors":["Zixuan Huang","Yinong He","Yating Lin","Dmitry Berenson"],"pdf_url":"https://arxiv.org/pdf/2410.16571v1.pdf","comment":"In submussion"},{"id":"http://arxiv.org/abs/2410.16481v1","updated":"2024-10-21T20:12:45Z","published":"2024-10-21T20:12:45Z","title":"Caging in Time: A Framework for Robust Object Manipulation under\n  Uncertainties and Limited Robot Perception","summary":"  Real-world object manipulation has been commonly challenged by physical\nuncertainties and perception limitations. Being an effective strategy, while\ncaging configuration-based manipulation frameworks have successfully provided\nrobust solutions, they are not broadly applicable due to their strict\nrequirements on the availability of multiple robots, widely distributed\ncontacts, or specific geometries of the robots or the objects. To this end,\nthis work proposes a novel concept, termed Caging in Time, to allow caging\nconfigurations to be formed even if there is just one robot engaged in a task.\nThis novel concept can be explained by an insight that even if a caging\nconfiguration is needed to constrain the motion of an object, only a small\nportion of the cage is actively manipulating at a time. As such, we can switch\nthe configuration of the robot strategically so that by collapsing its\nconfiguration in time, we will see a cage formed and its necessary portion\nactive whenever needed. We instantiate our Caging in Time theory on challenging\nquasistatic and dynamic manipulation tasks, showing that Caging in Time can be\nachieved in general state spaces including geometry-based and energy-based\nspaces. With extensive experiments, we show robust and accurate manipulation,\nin an open-loop manner, without requiring detailed knowledge of the object\ngeometry or physical properties, nor realtime accurate feedback on the\nmanipulation states. In addition to being an effective and robust open-loop\nmanipulation solution, the proposed theory can be a supplementary strategy to\nother manipulation systems affected by uncertain or limited robot perception.\n","authors":["Gaotian Wang","Kejia Ren","Andrew S. Morgan","Kaiyu Hang"],"pdf_url":"https://arxiv.org/pdf/2410.16481v1.pdf","comment":"24 pages, 25 figures, video available at:\n  www.youtube.com/watch?v=Ag_jTzazuSM"},{"id":"http://arxiv.org/abs/2410.05494v2","updated":"2024-10-21T19:43:45Z","published":"2024-10-07T21:05:45Z","title":"Tactile Displays Driven by Projected Light","summary":"  Tactile displays that lend tangible form to digital content could transform\ncomputing interactions. However, achieving the resolution, speed, and dynamic\nrange needed for perceptual fidelity remains challenging. We present a tactile\ndisplay that directly converts projected light into visible tactile patterns\nvia a photomechanical surface populated with millimeter-scale optotactile\npixels. The pixels transduce incident light into mechanical displacements\nthrough photostimulated thermal gas expansion, yielding millimeter scale\ndisplacements with response times of 2 to 100 milliseconds. Employing projected\nlight for power transmission and addressing renders these displays highly\nscalable. We demonstrate devices with up to 1511 addressable pixels. Perceptual\nstudies confirm that they can reproduce diverse spatiotemporal tactile patterns\nwith high fidelity. This research establishes a foundation for practical,\nversatile high-resolution tactile displays driven by light.\n","authors":["Max Linnander","Dustin Goetz","Gregory Reardon","Elliot Hawkes","Yon Visell"],"pdf_url":"https://arxiv.org/pdf/2410.05494v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16445v1","updated":"2024-10-21T19:15:41Z","published":"2024-10-21T19:15:41Z","title":"Automated Planning Domain Inference for Task and Motion Planning","summary":"  Task and motion planning (TAMP) frameworks address long and complex planning\nproblems by integrating high-level task planners with low-level motion\nplanners. However, existing TAMP methods rely heavily on the manual design of\nplanning domains that specify the preconditions and postconditions of all\nhigh-level actions. This paper proposes a method to automate planning domain\ninference from a handful of test-time trajectory demonstrations, reducing the\nreliance on human design. Our approach incorporates a deep learning-based\nestimator that predicts the appropriate components of a domain for a new task\nand a search algorithm that refines this prediction, reducing the size and\nensuring the utility of the inferred domain. Our method is able to generate new\ndomains from minimal demonstrations at test time, enabling robots to handle\ncomplex tasks more efficiently. We demonstrate that our approach outperforms\nbehavior cloning baselines, which directly imitate planner behavior, in terms\nof planning performance and generalization across a variety of tasks.\nAdditionally, our method reduces computational costs and data amount\nrequirements at test time for inferring new planning domains.\n","authors":["Jinbang Huang","Allen Tao","Rozilyn Marco","Miroslav Bogdanovic","Jonathan Kelly","Florian Shkurti"],"pdf_url":"https://arxiv.org/pdf/2410.16445v1.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.16444v1","updated":"2024-10-21T19:12:51Z","published":"2024-10-21T19:12:51Z","title":"Agent-Based Emulation for Deploying Robot Swarm Behaviors","summary":"  Despite significant research, robotic swarms have yet to be useful in solving\nreal-world problems, largely due to the difficulty of creating and controlling\nswarming behaviors in multi-agent systems. Traditional top-down approaches in\nwhich a desired emergent behavior is produced often require complex,\nresource-heavy robots, limiting their practicality. This paper introduces a\nbottom-up approach by employing an Embodied Agent-Based Modeling and Simulation\napproach, emphasizing the use of simple robots and identifying conditions that\nnaturally lead to self-organized collective behaviors. Using the\nReality-to-Simulation-to-Reality for Swarms (RSRS) process, we tightly\nintegrate real-world experiments with simulations to reproduce known swarm\nbehaviors as well as discovering a novel emergent behavior without aiming to\neliminate or even reduce the sim2real gap. This paper presents the development\nof an Agent-Based Embodiment and Emulation process that balances the importance\nof running physical swarming experiments and the prohibitively time-consuming\nprocess of even setting up and running a single experiment with 20+ robots by\nleveraging low-fidelity lightweight simulations to enable hypothesis-formation\nto guide physical experiments. We demonstrate the usefulness of our methods by\nemulating two known behaviors from the literature and show a third behavior\n`discovered' by accident.\n","authors":["Ricardo Vega","Kevin Zhu","Connor Mattson","Daniel S. Brown","Cameron Nowzari"],"pdf_url":"https://arxiv.org/pdf/2410.16444v1.pdf","comment":"8 pages, 6 figures, submitted to ICRA 2025"},{"id":"http://arxiv.org/abs/2410.16441v1","updated":"2024-10-21T19:10:49Z","published":"2024-10-21T19:10:49Z","title":"Policies with Sparse Inter-Agent Dependencies in Dynamic Games: A\n  Dynamic Programming Approach","summary":"  Common feedback strategies in multi-agent dynamic games require all players'\nstate information to compute control strategies. However, in real-world\nscenarios, sensing and communication limitations between agents make full state\nfeedback expensive or impractical, and such strategies can become fragile when\nstate information from other agents is inaccurate. To this end, we propose a\nregularized dynamic programming approach for finding sparse feedback policies\nthat selectively depend on the states of a subset of agents in dynamic games.\nThe proposed approach solves convex adaptive group Lasso problems to compute\nsparse policies approximating Nash equilibrium solutions. We prove the\nregularized solutions' asymptotic convergence to a neighborhood of Nash\nequilibrium policies in linear-quadratic (LQ) games. We extend the proposed\napproach to general non-LQ games via an iterative algorithm. Empirical results\nin multi-robot interaction scenarios show that the proposed approach\neffectively computes feedback policies with varying sparsity levels. When\nagents have noisy observations of other agents' states, simulation results\nindicate that the proposed regularized policies consistently achieve lower\ncosts than standard Nash equilibrium policies by up to 77% for all interacting\nagents whose costs are coupled with other agents' states.\n","authors":["Xinjie Liu","Jingqi Li","Filippos Fotiadis","Mustafa O. Karabag","Jesse Milzman","David Fridovich-Keil","Ufuk Topcu"],"pdf_url":"https://arxiv.org/pdf/2410.16441v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.05500v3","updated":"2024-10-21T19:03:47Z","published":"2024-03-08T18:17:56Z","title":"Using Fiber Optic Bundles to Miniaturize Vision-Based Tactile Sensors","summary":"  Vision-based tactile sensors have recently become popular due to their\ncombination of low cost, very high spatial resolution, and ease of integration\nusing widely available miniature cameras. The associated field of view and\nfocal length, however, are difficult to package in a human-sized finger. In\nthis paper we employ optical fiber bundles to achieve a form factor that, at 15\nmm diameter, is smaller than an average human fingertip. The electronics and\ncamera are also located remotely, further reducing package size. The sensor\nachieves a spatial resolution of 0.22 mm and a minimum force resolution 5 mN\nfor normal and shear contact forces. With these attributes, the DIGIT Pinki\nsensor is suitable for applications such as robotic and teleoperated digital\npalpation. We demonstrate its utility for palpation of the prostate gland and\nshow that it can achieve clinically relevant discrimination of prostate\nstiffness for phantom and ex vivo tissue.\n","authors":["Julia Di","Zdravko Dugonjic","Will Fu","Tingfan Wu","Romeo Mercado","Kevin Sawyer","Victoria Rose Most","Gregg Kammerer","Stefanie Speidel","Richard E. Fan","Geoffrey Sonn","Mark R. Cutkosky","Mike Lambeta","Roberto Calandra"],"pdf_url":"https://arxiv.org/pdf/2403.05500v3.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  The CAD design files of DIGIT Pinki are available at\n  https://github.com/facebookresearch/digit-design"},{"id":"http://arxiv.org/abs/2410.16417v1","updated":"2024-10-21T18:32:41Z","published":"2024-10-21T18:32:41Z","title":"Online Optimization of Central Pattern Generators for Quadruped\n  Locomotion","summary":"  Typical legged locomotion controllers are designed or trained offline. This\nis in contrast to many animals, which are able to locomote at birth, and\nrapidly improve their locomotion skills with few real-world interactions. Such\nmotor control is possible through oscillatory neural networks located in the\nspinal cord of vertebrates, known as Central Pattern Generators (CPGs). Models\nof the CPG have been widely used to generate locomotion skills in robotics, but\ncan require extensive hand-tuning or offline optimization of inter-connected\nparameters with genetic algorithms. In this paper, we present a framework for\nthe \\textit{online} optimization of the CPG parameters through Bayesian\nOptimization. We show that our framework can rapidly optimize and adapt to\nvarying velocity commands and changes in the terrain, for example to varying\ncoefficients of friction, terrain slope angles, and added mass payloads placed\non the robot. We study the effects of sensory feedback on the CPG, and find\nthat both force feedback in the phase equations, as well as posture control\n(Virtual Model Control) are both beneficial for robot stability and energy\nefficiency. In hardware experiments on the Unitree Go1, we show rapid\noptimization (in under 3 minutes) and adaptation of energy-efficient gaits to\nvarying target velocities in a variety of scenarios: varying coefficients of\nfriction, added payloads up to 15 kg, and variable slopes up to 10 degrees. See\ndemo at: https://youtu.be/4qq5leCI2AI\n","authors":["Zewei Zhang","Guillaume Bellegarda","Milad Shafiee","Auke Ijspeert"],"pdf_url":"https://arxiv.org/pdf/2410.16417v1.pdf","comment":"Accepted by IROS2024"},{"id":"http://arxiv.org/abs/2410.16411v1","updated":"2024-10-21T18:27:48Z","published":"2024-10-21T18:27:48Z","title":"Integrating Reinforcement Learning with Foundation Models for Autonomous\n  Robotics: Methods and Perspectives","summary":"  Foundation models (FMs), large deep learning models pre-trained on vast,\nunlabeled datasets, exhibit powerful capabilities in understanding complex\npatterns and generating sophisticated outputs. However, they often struggle to\nadapt to specific tasks. Reinforcement learning (RL), which allows agents to\nlearn through interaction and feedback, offers a compelling solution.\nIntegrating RL with FMs enables these models to achieve desired outcomes and\nexcel at particular tasks. Additionally, RL can be enhanced by leveraging the\nreasoning and generalization capabilities of FMs. This synergy is\nrevolutionizing various fields, including robotics. FMs, rich in knowledge and\ngeneralization, provide robots with valuable information, while RL facilitates\nlearning and adaptation through real-world interactions.\n  This survey paper comprehensively explores this exciting intersection,\nexamining how these paradigms can be integrated to advance robotic\nintelligence. We analyze the use of foundation models as action planners, the\ndevelopment of robotics-specific foundation models, and the mutual benefits of\ncombining FMs with RL. Furthermore, we present a taxonomy of integration\napproaches, including large language models, vision-language models, diffusion\nmodels, and transformer-based RL models. We also explore how RL can utilize\nworld representations learned from FMs to enhance robotic task execution.\n  Our survey aims to synthesize current research and highlight key challenges\nin robotic reasoning and control, particularly in the context of integrating\nFMs and RL--two rapidly evolving technologies. By doing so, we seek to spark\nfuture research and emphasize critical areas that require further investigation\nto enhance robotics. We provide an updated collection of papers based on our\ntaxonomy, accessible on our open-source project website at:\nhttps://github.com/clmoro/Robotics-RL-FMs-Integration.\n","authors":["Angelo Moroncelli","Vishal Soni","Asad Ali Shahid","Marco Maccarini","Marco Forgione","Dario Piga","Blerina Spahiu","Loris Roveda"],"pdf_url":"https://arxiv.org/pdf/2410.16411v1.pdf","comment":"Submitted for publication to the Special Issue on Foundation Models\n  and Neural-Symbolic AI for Robotics in The International Journal of Robotics\n  Research (IJRR)"},{"id":"http://arxiv.org/abs/2410.16405v1","updated":"2024-10-21T18:17:28Z","published":"2024-10-21T18:17:28Z","title":"Magnetic Ball Chain Robots for Cardiac Arrhythmia Treatment","summary":"  This paper introduces a novel magnetic navigation system for cardiac\nablation. The system is formed from two key elements: a magnetic ablation\ncatheter consisting of a chain of spherical permanent magnets; and an actuation\nsystem comprised of two cart-mounted permanent magnets undergoing pure\nrotation. The catheter design enables a large magnetic content with the goal of\nminimizing the footprint of the actuation system for easier integration with\nthe clinical workflow. We present a quasi-static model of the catheter, the\ndesign of the actuation units, and their control modalities. Experimental\nvalidation shows that we can use small rotating magnets (119mm diameter) to\nreach cardiac ablation targets while generating clinically-relevant forces.\nCatheter control using a joystick is compared with manual catheter control.\nblue While total task completion time is similar, smoother navigation is\nobserved using the proposed robotic system. We also demonstrate that the ball\nchain can ablate heart tissue and generate lesions comparable to the current\nclinical ablation catheters.\n","authors":["Giovanni Pittiglio","Fabio Leuenberger","Margherita Mencattelli","Max McCandless","Edward O'Leary","Pierre E. Dupont"],"pdf_url":"https://arxiv.org/pdf/2410.16405v1.pdf","comment":"in IEEE Transactions on Medical Robotics and Bionics, 2024"},{"id":"http://arxiv.org/abs/2409.06111v2","updated":"2024-10-21T18:16:09Z","published":"2024-09-09T23:34:24Z","title":"Competency-Aware Planning for Probabilistically Safe Navigation Under\n  Perception Uncertainty","summary":"  Perception-based navigation systems are useful for unmanned ground vehicle\n(UGV) navigation in complex terrains, where traditional depth-based navigation\nschemes are insufficient. However, these data-driven methods are highly\ndependent on their training data and can fail in surprising and dramatic ways\nwith little warning. To ensure the safety of the vehicle and the surrounding\nenvironment, it is imperative that the navigation system is able to recognize\nthe predictive uncertainty of the perception model and respond safely and\neffectively in the face of uncertainty. In an effort to enable safe navigation\nunder perception uncertainty, we develop a probabilistic and\nreconstruction-based competency estimation (PaRCE) method to estimate the\nmodel's level of familiarity with an input image as a whole and with specific\nregions in the image. We find that the overall competency score can correctly\npredict correctly classified, misclassified, and out-of-distribution (OOD)\nsamples. We also confirm that the regional competency maps can accurately\ndistinguish between familiar and unfamiliar regions across images. We then use\nthis competency information to develop a planning and control scheme that\nenables effective navigation while maintaining a low probability of error. We\nfind that the competency-aware scheme greatly reduces the number of collisions\nwith unfamiliar obstacles, compared to a baseline controller with no competency\nawareness. Furthermore, the regional competency information is very valuable in\nenabling efficient navigation.\n","authors":["Sara Pohland","Claire Tomlin"],"pdf_url":"https://arxiv.org/pdf/2409.06111v2.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2410.16271v1","updated":"2024-10-21T17:59:53Z","published":"2024-10-21T17:59:53Z","title":"FrugalNeRF: Fast Convergence for Few-shot Novel View Synthesis without\n  Learned Priors","summary":"  Neural Radiance Fields (NeRF) face significant challenges in few-shot\nscenarios, primarily due to overfitting and long training times for\nhigh-fidelity rendering. Existing methods, such as FreeNeRF and SparseNeRF, use\nfrequency regularization or pre-trained priors but struggle with complex\nscheduling and bias. We introduce FrugalNeRF, a novel few-shot NeRF framework\nthat leverages weight-sharing voxels across multiple scales to efficiently\nrepresent scene details. Our key contribution is a cross-scale geometric\nadaptation scheme that selects pseudo ground truth depth based on reprojection\nerrors across scales. This guides training without relying on externally\nlearned priors, enabling full utilization of the training data. It can also\nintegrate pre-trained priors, enhancing quality without slowing convergence.\nExperiments on LLFF, DTU, and RealEstate-10K show that FrugalNeRF outperforms\nother few-shot NeRF methods while significantly reducing training time, making\nit a practical solution for efficient and accurate 3D scene reconstruction.\n","authors":["Chin-Yang Lin","Chung-Ho Wu","Chang-Han Yeh","Shih-Han Yen","Cheng Sun","Yu-Lun Liu"],"pdf_url":"https://arxiv.org/pdf/2410.16271v1.pdf","comment":"Project page: https://linjohnss.github.io/frugalnerf/"},{"id":"http://arxiv.org/abs/2410.16272v1","updated":"2024-10-21T17:59:53Z","published":"2024-10-21T17:59:53Z","title":"MvDrag3D: Drag-based Creative 3D Editing via Multi-view\n  Generation-Reconstruction Priors","summary":"  Drag-based editing has become popular in 2D content creation, driven by the\ncapabilities of image generative models. However, extending this technique to\n3D remains a challenge. Existing 3D drag-based editing methods, whether\nemploying explicit spatial transformations or relying on implicit latent\noptimization within limited-capacity 3D generative models, fall short in\nhandling significant topology changes or generating new textures across diverse\nobject categories. To overcome these limitations, we introduce MVDrag3D, a\nnovel framework for more flexible and creative drag-based 3D editing that\nleverages multi-view generation and reconstruction priors. At the core of our\napproach is the usage of a multi-view diffusion model as a strong generative\nprior to perform consistent drag editing over multiple rendered views, which is\nfollowed by a reconstruction model that reconstructs 3D Gaussians of the edited\nobject. While the initial 3D Gaussians may suffer from misalignment between\ndifferent views, we address this via view-specific deformation networks that\nadjust the position of Gaussians to be well aligned. In addition, we propose a\nmulti-view score function that distills generative priors from multiple views\nto further enhance the view consistency and visual quality. Extensive\nexperiments demonstrate that MVDrag3D provides a precise, generative, and\nflexible solution for 3D drag-based editing, supporting more versatile editing\neffects across various object categories and 3D representations.\n","authors":["Honghua Chen","Yushi Lan","Yongwei Chen","Yifan Zhou","Xingang Pan"],"pdf_url":"https://arxiv.org/pdf/2410.16272v1.pdf","comment":"16 pages, 10 figures, conference"},{"id":"http://arxiv.org/abs/2410.16268v1","updated":"2024-10-21T17:59:19Z","published":"2024-10-21T17:59:19Z","title":"SAM2Long: Enhancing SAM 2 for Long Video Segmentation with a\n  Training-Free Memory Tree","summary":"  The Segment Anything Model 2 (SAM 2) has emerged as a powerful foundation\nmodel for object segmentation in both images and videos, paving the way for\nvarious downstream video applications. The crucial design of SAM 2 for video\nsegmentation is its memory module, which prompts object-aware memories from\nprevious frames for current frame prediction. However, its greedy-selection\nmemory design suffers from the \"error accumulation\" problem, where an errored\nor missed mask will cascade and influence the segmentation of the subsequent\nframes, which limits the performance of SAM 2 toward complex long-term videos.\nTo this end, we introduce SAM2Long, an improved training-free video object\nsegmentation strategy, which considers the segmentation uncertainty within each\nframe and chooses the video-level optimal results from multiple segmentation\npathways in a constrained tree search manner. In practice, we maintain a fixed\nnumber of segmentation pathways throughout the video. For each frame, multiple\nmasks are proposed based on the existing pathways, creating various candidate\nbranches. We then select the same fixed number of branches with higher\ncumulative scores as the new pathways for the next frame. After processing the\nfinal frame, the pathway with the highest cumulative score is chosen as the\nfinal segmentation result. Benefiting from its heuristic search design,\nSAM2Long is robust toward occlusions and object reappearances, and can\neffectively segment and track objects for complex long-term videos. Notably,\nSAM2Long achieves an average improvement of 3.0 points across all 24\nhead-to-head comparisons, with gains of up to 5.3 points in J&F on long-term\nvideo object segmentation benchmarks such as SA-V and LVOS. The code is\nreleased at https://github.com/Mark12Ding/SAM2Long.\n","authors":["Shuangrui Ding","Rui Qian","Xiaoyi Dong","Pan Zhang","Yuhang Zang","Yuhang Cao","Yuwei Guo","Dahua Lin","Jiaqi Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16268v1.pdf","comment":"Project page: https://mark12ding.github.io/project/SAM2Long/"},{"id":"http://arxiv.org/abs/2410.16267v1","updated":"2024-10-21T17:59:11Z","published":"2024-10-21T17:59:11Z","title":"xGen-MM-Vid (BLIP-3-Video): You Only Need 32 Tokens to Represent a Video\n  Even in VLMs","summary":"  We present xGen-MM-Vid (BLIP-3-Video): a multimodal language model for\nvideos, particularly designed to efficiently capture temporal information over\nmultiple frames. BLIP-3-Video takes advantage of the 'temporal encoder' in\naddition to the conventional visual tokenizer, which maps a sequence of tokens\nover multiple frames into a compact set of visual tokens. This enables\nBLIP3-Video to use much fewer visual tokens than its competing models (e.g., 32\nvs. 4608 tokens). We explore different types of temporal encoders, including\nlearnable spatio-temporal pooling as well as sequential models like Token\nTuring Machines. We experimentally confirm that BLIP-3-Video obtains video\nquestion-answering accuracies comparable to much larger state-of-the-art models\n(e.g., 34B), while being much smaller (i.e., 4B) and more efficient by using\nfewer visual tokens. The project website is at\nhttps://www.salesforceairesearch.com/opensource/xGen-MM-Vid/index.html\n","authors":["Michael S. Ryoo","Honglu Zhou","Shrikant Kendre","Can Qin","Le Xue","Manli Shu","Silvio Savarese","Ran Xu","Caiming Xiong","Juan Carlos Niebles"],"pdf_url":"https://arxiv.org/pdf/2410.16267v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16266v1","updated":"2024-10-21T17:59:09Z","published":"2024-10-21T17:59:09Z","title":"3DGS-Enhancer: Enhancing Unbounded 3D Gaussian Splatting with\n  View-consistent 2D Diffusion Priors","summary":"  Novel-view synthesis aims to generate novel views of a scene from multiple\ninput images or videos, and recent advancements like 3D Gaussian splatting\n(3DGS) have achieved notable success in producing photorealistic renderings\nwith efficient pipelines. However, generating high-quality novel views under\nchallenging settings, such as sparse input views, remains difficult due to\ninsufficient information in under-sampled areas, often resulting in noticeable\nartifacts. This paper presents 3DGS-Enhancer, a novel pipeline for enhancing\nthe representation quality of 3DGS representations. We leverage 2D video\ndiffusion priors to address the challenging 3D view consistency problem,\nreformulating it as achieving temporal consistency within a video generation\nprocess. 3DGS-Enhancer restores view-consistent latent features of rendered\nnovel views and integrates them with the input views through a spatial-temporal\ndecoder. The enhanced views are then used to fine-tune the initial 3DGS model,\nsignificantly improving its rendering performance. Extensive experiments on\nlarge-scale datasets of unbounded scenes demonstrate that 3DGS-Enhancer yields\nsuperior reconstruction performance and high-fidelity rendering results\ncompared to state-of-the-art methods. The project webpage is\nhttps://xiliu8006.github.io/3DGS-Enhancer-project .\n","authors":["Xi Liu","Chaoyi Zhou","Siyu Huang"],"pdf_url":"https://arxiv.org/pdf/2410.16266v1.pdf","comment":"Accepted by NeurIPS 2024 Spotlight"},{"id":"http://arxiv.org/abs/2410.16261v1","updated":"2024-10-21T17:58:20Z","published":"2024-10-21T17:58:20Z","title":"Mini-InternVL: A Flexible-Transfer Pocket Multimodal Model with 5%\n  Parameters and 90% Performance","summary":"  Multimodal large language models (MLLMs) have demonstrated impressive\nperformance in vision-language tasks across a broad spectrum of domains.\nHowever, the large model scale and associated high computational costs pose\nsignificant challenges for training and deploying MLLMs on consumer-grade GPUs\nor edge devices, thereby hindering their widespread application. In this work,\nwe introduce Mini-InternVL, a series of MLLMs with parameters ranging from 1B\nto 4B, which achieves 90% of the performance with only 5% of the parameters.\nThis significant improvement in efficiency and effectiveness makes our models\nmore accessible and applicable in various real-world scenarios. To further\npromote the adoption of our models, we develop a unified adaptation framework\nfor Mini-InternVL, which enables our models to transfer and outperform\nspecialized models in downstream tasks, including autonomous driving, medical\nimages, and remote sensing. We believe that our study can provide valuable\ninsights and resources to advance the development of efficient and effective\nMLLMs. Code is available at https://github.com/OpenGVLab/InternVL.\n","authors":["Zhangwei Gao","Zhe Chen","Erfei Cui","Yiming Ren","Weiyun Wang","Jinguo Zhu","Hao Tian","Shenglong Ye","Junjun He","Xizhou Zhu","Lewei Lu","Tong Lu","Yu Qiao","Jifeng Dai","Wenhai Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16261v1.pdf","comment":"Technical report"},{"id":"http://arxiv.org/abs/2410.16259v1","updated":"2024-10-21T17:57:50Z","published":"2024-10-21T17:57:50Z","title":"Agent-to-Sim: Learning Interactive Behavior Models from Casual\n  Longitudinal Videos","summary":"  We present Agent-to-Sim (ATS), a framework for learning interactive behavior\nmodels of 3D agents from casual longitudinal video collections. Different from\nprior works that rely on marker-based tracking and multiview cameras, ATS\nlearns natural behaviors of animal and human agents non-invasively through\nvideo observations recorded over a long time-span (e.g., a month) in a single\nenvironment. Modeling 3D behavior of an agent requires persistent 3D tracking\n(e.g., knowing which point corresponds to which) over a long time period. To\nobtain such data, we develop a coarse-to-fine registration method that tracks\nthe agent and the camera over time through a canonical 3D space, resulting in a\ncomplete and persistent spacetime 4D representation. We then train a generative\nmodel of agent behaviors using paired data of perception and motion of an agent\nqueried from the 4D reconstruction. ATS enables real-to-sim transfer from video\nrecordings of an agent to an interactive behavior simulator. We demonstrate\nresults on pets (e.g., cat, dog, bunny) and human given monocular RGBD videos\ncaptured by a smartphone.\n","authors":["Gengshan Yang","Andrea Bajcsy","Shunsuke Saito","Angjoo Kanazawa"],"pdf_url":"https://arxiv.org/pdf/2410.16259v1.pdf","comment":"Project page: https://gengshan-y.github.io/agent2sim-www/"},{"id":"http://arxiv.org/abs/2410.16257v1","updated":"2024-10-21T17:57:04Z","published":"2024-10-21T17:57:04Z","title":"Elucidating the design space of language models for image generation","summary":"  The success of autoregressive (AR) language models in text generation has\ninspired the computer vision community to adopt Large Language Models (LLMs)\nfor image generation. However, considering the essential differences between\ntext and image modalities, the design space of language models for image\ngeneration remains underexplored. We observe that image tokens exhibit greater\nrandomness compared to text tokens, which presents challenges when training\nwith token prediction. Nevertheless, AR models demonstrate their potential by\neffectively learning patterns even from a seemingly suboptimal optimization\nproblem. Our analysis also reveals that while all models successfully grasp the\nimportance of local information in image generation, smaller models struggle to\ncapture the global context. In contrast, larger models showcase improved\ncapabilities in this area, helping to explain the performance gains achieved\nwhen scaling up model size. We further elucidate the design space of language\nmodels for vision generation, including tokenizer choice, model choice, model\nscalability, vocabulary design, and sampling strategy through extensive\ncomparative experiments. Our work is the first to analyze the optimization\nbehavior of language models in vision generation, and we believe it can inspire\nmore effective designs when applying LMs to other domains. Finally, our\nelucidated language model for image generation, termed as ELM, achieves\nstate-of-the-art performance on the ImageNet 256*256 benchmark. The code is\navailable at https://github.com/Pepperlll/LMforImageGeneration.git.\n","authors":["Xuantong Liu","Shaozhe Hao","Xianbiao Qi","Tianyang Hu","Jun Wang","Rong Xiao","Yuan Yao"],"pdf_url":"https://arxiv.org/pdf/2410.16257v1.pdf","comment":"Project page: https://pepper-lll.github.io/LMforImageGeneration/"},{"id":"http://arxiv.org/abs/2410.16255v1","updated":"2024-10-21T17:56:47Z","published":"2024-10-21T17:56:47Z","title":"Revisiting Deep Feature Reconstruction for Logical and Structural\n  Industrial Anomaly Detection","summary":"  Industrial anomaly detection is crucial for quality control and predictive\nmaintenance, but it presents challenges due to limited training data, diverse\nanomaly types, and external factors that alter object appearances. Existing\nmethods commonly detect structural anomalies, such as dents and scratches, by\nleveraging multi-scale features from image patches extracted through deep\npre-trained networks. However, significant memory and computational demands\noften limit their practical application. Additionally, detecting logical\nanomalies-such as images with missing or excess elements-requires an\nunderstanding of spatial relationships that traditional patch-based methods\nfail to capture. In this work, we address these limitations by focusing on Deep\nFeature Reconstruction (DFR), a memory- and compute-efficient approach for\ndetecting structural anomalies. We further enhance DFR into a unified\nframework, called ULSAD, which is capable of detecting both structural and\nlogical anomalies. Specifically, we refine the DFR training objective to\nimprove performance in structural anomaly detection, while introducing an\nattention-based loss mechanism using a global autoencoder-like network to\nhandle logical anomaly detection. Our empirical evaluation across five\nbenchmark datasets demonstrates the performance of ULSAD in detecting and\nlocalizing both structural and logical anomalies, outperforming eight\nstate-of-the-art methods. An extensive ablation study further highlights the\ncontribution of each component to the overall performance improvement. Our code\nis available at https://github.com/sukanyapatra1997/ULSAD-2024.git\n","authors":["Sukanya Patra","Souhaib Ben Taieb"],"pdf_url":"https://arxiv.org/pdf/2410.16255v1.pdf","comment":"Accepted in Transactions on Machine Learning Research (TMLR). Link to\n  OpenReview: https://openreview.net/forum?id=kdTC4ktHPD"},{"id":"http://arxiv.org/abs/2410.16239v1","updated":"2024-10-21T17:42:41Z","published":"2024-10-21T17:42:41Z","title":"MoRE: Multi-Modal Contrastive Pre-training with Transformers on X-Rays,\n  ECGs, and Diagnostic Report","summary":"  In this paper, we introduce a novel Multi-Modal Contrastive Pre-training\nFramework that synergistically combines X-rays, electrocardiograms (ECGs), and\nradiology/cardiology reports. Our approach leverages transformers to encode\nthese diverse modalities into a unified representation space, aiming to enhance\ndiagnostic accuracy and facilitate comprehensive patient assessments. We\nutilize LoRA-Peft to significantly reduce trainable parameters in the LLM and\nincorporate recent linear attention dropping strategy in the Vision\nTransformer(ViT) for smoother attention. Furthermore, we provide novel\nmultimodal attention explanations and retrieval for our model. To the best of\nour knowledge, we are the first to propose an integrated model that combines\nX-ray, ECG, and Radiology/Cardiology Report with this approach. By utilizing\ncontrastive loss, MoRE effectively aligns modality-specific features into a\ncoherent embedding, which supports various downstream tasks such as zero-shot\nclassification and multimodal retrieval. Employing our proposed methodology, we\nachieve state-of-the-art (SOTA) on the Mimic-IV, CheXpert, Edema Severity, and\nPtbXl downstream datasets, surpassing existing multimodal approaches. Our\nproposed framework shows significant improvements in capturing intricate\ninter-modal relationships and its robustness in medical diagnosis that\nestablishes a framework for future research in multimodal learning in the\nhealthcare sector.\n","authors":["Samrajya Thapa","Koushik Howlader","Subhankar Bhattacharjee","Wei le"],"pdf_url":"https://arxiv.org/pdf/2410.16239v1.pdf","comment":"10 pages, 5 figures, 9 tables. Supplementary detail in Appendix. Code\n  made available in Github for reproducibility"},{"id":"http://arxiv.org/abs/2410.16238v1","updated":"2024-10-21T17:41:58Z","published":"2024-10-21T17:41:58Z","title":"Deep Radiomics Detection of Clinically Significant Prostate Cancer on\n  Multicenter MRI: Initial Comparison to PI-RADS Assessment","summary":"  Objective: To develop and evaluate a deep radiomics model for clinically\nsignificant prostate cancer (csPCa, grade group >= 2) detection and compare its\nperformance to Prostate Imaging Reporting and Data System (PI-RADS) assessment\nin a multicenter cohort. Materials and Methods: This retrospective study\nanalyzed biparametric (T2W and DW) prostate MRI sequences of 615 patients (mean\nage, 63.1 +/- 7 years) from four datasets acquired between 2010 and 2020:\nPROSTATEx challenge, Prostate158 challenge, PCaMAP trial, and an in-house\n(NTNU/St. Olavs Hospital) dataset. With expert annotations as ground truth, a\ndeep radiomics model was trained, including nnU-Net segmentation of the\nprostate gland, voxel-wise radiomic feature extraction, extreme gradient boost\nclassification, and post-processing of tumor probability maps into csPCa\ndetection maps. Training involved 5-fold cross-validation using the PROSTATEx\n(n=199), Prostate158 (n=138), and PCaMAP (n=78) datasets, and testing on the\nin-house (n=200) dataset. Patient- and lesion-level performance were compared\nto PI-RADS using area under ROC curve (AUROC [95% CI]), sensitivity, and\nspecificity analysis. Results: On the test data, the radiologist achieved a\npatient-level AUROC of 0.94 [0.91-0.98] with 94% (75/80) sensitivity and 77%\n(92/120) specificity at PI-RADS >= 3. The deep radiomics model at a tumor\nprobability cut-off >= 0.76 achieved 0.91 [0.86-0.95] AUROC with 90% (72/80)\nsensitivity and 73% (87/120) specificity, not significantly different (p =\n0.068) from PI-RADS. On the lesion level, PI-RADS cut-off >= 3 had 84% (91/108)\nsensitivity at 0.2 (40/200) false positives per patient, while deep radiomics\nattained 68% (73/108) sensitivity at the same false positive rate. Conclusion:\nDeep radiomics machine learning model achieved comparable performance to\nPI-RADS assessment in csPCa detection at the patient-level but not at the\nlesion-level.\n","authors":["G. A. Nketiah","M. R. Sunoqrot","E. Sandsmark","S. Langørgen","K. M. Selnæs","H. Bertilsson","M. Elschot","T. F. Bathen"],"pdf_url":"https://arxiv.org/pdf/2410.16238v1.pdf","comment":"20 pages, 4 figures, 4 tables"},{"id":"http://arxiv.org/abs/2410.16236v1","updated":"2024-10-21T17:41:28Z","published":"2024-10-21T17:41:28Z","title":"LLaVA-KD: A Framework of Distilling Multimodal Large Language Models","summary":"  The success of Large Language Models (LLM) has led researchers to explore\nMultimodal Large Language Models (MLLM) for unified visual and linguistic\nunderstanding. However, the increasing model size and computational complexity\nof MLLM limit their use in resource-constrained environments. Small-scale MLLM\n(s-MLLM) aims to retain the capabilities of the large-scale model (l-MLLM)\nwhile reducing computational demands, but resulting in a significant decline in\nperformance. To address the aforementioned issues, we propose a novel LLaVA-KD\nframework to transfer knowledge from l-MLLM to s-MLLM. Specifically, we\nintroduce Multimodal Distillation (MDist) to minimize the divergence between\nthe visual-textual output distributions of l-MLLM and s-MLLM, and Relation\nDistillation (RDist) to transfer l-MLLM's ability to model correlations between\nvisual features. Additionally, we propose a three-stage training scheme to\nfully exploit the potential of s-MLLM: 1) Distilled Pre-Training to align\nvisual-textual representations, 2) Supervised Fine-Tuning to equip the model\nwith multimodal understanding, and 3) Distilled Fine-Tuning to further transfer\nl-MLLM capabilities. Our approach significantly improves performance without\naltering the small model's architecture. Extensive experiments and ablation\nstudies validate the effectiveness of each proposed component. Code will be\navailable at https://github.com/caiyuxuan1120/LLaVA-KD.\n","authors":["Yuxuan Cai","Jiangning Zhang","Haoyang He","Xinwei He","Ao Tong","Zhenye Gan","Chengjie Wang","Xiang Bai"],"pdf_url":"https://arxiv.org/pdf/2410.16236v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2410.16227v1","updated":"2024-10-21T17:32:36Z","published":"2024-10-21T17:32:36Z","title":"Managing Bandwidth: The Key to Cloud-Assisted Autonomous Driving","summary":"  Prevailing wisdom asserts that one cannot rely on the cloud for critical\nreal-time control systems like self-driving cars. We argue that we can, and\nmust. Following the trends of increasing model sizes, improvements in hardware,\nand evolving mobile networks, we identify an opportunity to offload parts of\ntime-sensitive and latency-critical compute to the cloud. Doing so requires\ncarefully allocating bandwidth to meet strict latency SLOs, while maximizing\nbenefit to the car.\n","authors":["Alexander Krentsel","Peter Schafhalter","Joseph E. Gonzalez","Sylvia Ratnasamy","Scott Shenker","Ion Stoica"],"pdf_url":"https://arxiv.org/pdf/2410.16227v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2406.01583v2","updated":"2024-10-21T17:25:44Z","published":"2024-06-03T17:58:43Z","title":"Decomposing and Interpreting Image Representations via Text in ViTs\n  Beyond CLIP","summary":"  Recent work has explored how individual components of the CLIP-ViT model\ncontribute to the final representation by leveraging the shared image-text\nrepresentation space of CLIP. These components, such as attention heads and\nMLPs, have been shown to capture distinct image features like shape, color or\ntexture. However, understanding the role of these components in arbitrary\nvision transformers (ViTs) is challenging. To this end, we introduce a general\nframework which can identify the roles of various components in ViTs beyond\nCLIP. Specifically, we (a) automate the decomposition of the final\nrepresentation into contributions from different model components, and (b)\nlinearly map these contributions to CLIP space to interpret them via text.\nAdditionally, we introduce a novel scoring function to rank components by their\nimportance with respect to specific features. Applying our framework to various\nViT variants (e.g. DeiT, DINO, DINOv2, Swin, MaxViT), we gain insights into the\nroles of different components concerning particular image features. These\ninsights facilitate applications such as image retrieval using text\ndescriptions or reference images, visualizing token importance heatmaps, and\nmitigating spurious correlations. We release our code to reproduce the\nexperiments at https://github.com/SriramB-98/vit-decompose\n","authors":["Sriram Balasubramanian","Samyadeep Basu","Soheil Feizi"],"pdf_url":"https://arxiv.org/pdf/2406.01583v2.pdf","comment":"NeurIPS 2024, 31 pages, 15 figures"},{"id":"http://arxiv.org/abs/2410.16198v1","updated":"2024-10-21T17:00:06Z","published":"2024-10-21T17:00:06Z","title":"Improve Vision Language Model Chain-of-thought Reasoning","summary":"  Chain-of-thought (CoT) reasoning in vision language models (VLMs) is crucial\nfor improving interpretability and trustworthiness. However, current training\nrecipes lack robust CoT reasoning data, relying on datasets dominated by short\nannotations with minimal rationales. In this work, we show that training VLM on\nshort answers does not generalize well to reasoning tasks that require more\ndetailed responses. To address this, we propose a two-fold approach. First, we\ndistill rationales from GPT-4o model to enrich the training data and fine-tune\nVLMs, boosting their CoT performance. Second, we apply reinforcement learning\nto further calibrate reasoning quality. Specifically, we construct positive\n(correct) and negative (incorrect) pairs of model-generated reasoning chains,\nby comparing their predictions with annotated short answers. Using this\npairwise data, we apply the Direct Preference Optimization algorithm to refine\nthe model's reasoning abilities. Our experiments demonstrate significant\nimprovements in CoT reasoning on benchmark datasets and better generalization\nto direct answer prediction as well. This work emphasizes the importance of\nincorporating detailed rationales in training and leveraging reinforcement\nlearning to strengthen the reasoning capabilities of VLMs.\n","authors":["Ruohong Zhang","Bowen Zhang","Yanghao Li","Haotian Zhang","Zhiqing Sun","Zhe Gan","Yinfei Yang","Ruoming Pang","Yiming Yang"],"pdf_url":"https://arxiv.org/pdf/2410.16198v1.pdf","comment":"10 pages + appendix"},{"id":"http://arxiv.org/abs/2410.16190v1","updated":"2024-10-21T16:52:44Z","published":"2024-10-21T16:52:44Z","title":"Training Better Deep Learning Models Using Human Saliency","summary":"  This work explores how human judgement about salient regions of an image can\nbe introduced into deep convolutional neural network (DCNN) training.\nTraditionally, training of DCNNs is purely data-driven. This often results in\nlearning features of the data that are only coincidentally correlated with\nclass labels. Human saliency can guide network training using our proposed new\ncomponent of the loss function that ConveYs Brain Oversight to Raise\nGeneralization (CYBORG) and penalizes the model for using non-salient regions.\nThis mechanism produces DCNNs achieving higher accuracy and generalization\ncompared to using the same training data without human salience. Experimental\nresults demonstrate that CYBORG applies across multiple network architectures\nand problem domains (detection of synthetic faces, iris presentation attacks\nand anomalies in chest X-rays), while requiring significantly less data than\ntraining without human saliency guidance. Visualizations show that\nCYBORG-trained models' saliency is more consistent across independent training\nruns than traditionally-trained models, and also in better agreement with\nhumans. To lower the cost of collecting human annotations, we also explore\nusing deep learning to provide automated annotations. CYBORG training of CNNs\naddresses important issues such as reducing the appetite for large training\nsets, increasing interpretability, and reducing fragility by generalizing\nbetter to new types of data.\n","authors":["Aidan Boyd","Patrick Tinsley","Kevin W. Bowyer","Adam Czajka"],"pdf_url":"https://arxiv.org/pdf/2410.16190v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16177v1","updated":"2024-10-21T16:43:16Z","published":"2024-10-21T16:43:16Z","title":"A Framework for Evaluating Predictive Models Using Synthetic Image\n  Covariates and Longitudinal Data","summary":"  We present a novel framework for synthesizing patient data with complex\ncovariates (e.g., eye scans) paired with longitudinal observations (e.g.,\nvisual acuity over time), addressing privacy concerns in healthcare research.\nOur approach introduces controlled association in latent spaces generating each\ndata modality, enabling the creation of complex covariate-longitudinal\nobservation pairs. This framework facilitates the development of predictive\nmodels and provides openly available benchmarking datasets for healthcare\nresearch. We demonstrate our framework using optical coherence tomography (OCT)\nscans, though it is applicable across domains. Using 109,309 2D OCT scan\nslices, we trained an image generative model combining a variational\nautoencoder and a diffusion model. Longitudinal observations were simulated\nusing a nonlinear mixed effect (NLME) model from a low-dimensional space of\nrandom effects. We generated 1.1M OCT scan slices paired with five sets of\nlongitudinal observations at controlled association levels (100%, 50%, 10%,\n5.26%, and 2% of between-subject variability). To assess the framework, we\nmodeled synthetic longitudinal observations with another NLME model, computed\nempirical Bayes estimates of random effects, and trained a ResNet to predict\nthese estimates from synthetic OCT scans. We then incorporated ResNet\npredictions into the NLME model for patient-individualized predictions.\nPrediction accuracy on withheld data declined as intended with reduced\nassociation between images and longitudinal measurements. Notably, in all but\nthe 2% case, we achieved within 50% of the theoretical best possible prediction\non withheld data, demonstrating our ability to detect even weak signals. This\nconfirms the effectiveness of our framework in generating synthetic data with\ncontrolled levels of association, providing a valuable tool for healthcare\nresearch.\n","authors":["Simon Deltadahl","Andreu Vall","Vijay Ivaturi","Niklas Korsbo"],"pdf_url":"https://arxiv.org/pdf/2410.16177v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16166v1","updated":"2024-10-21T16:32:41Z","published":"2024-10-21T16:32:41Z","title":"Beyond Filtering: Adaptive Image-Text Quality Enhancement for MLLM\n  Pretraining","summary":"  Multimodal large language models (MLLMs) have made significant strides by\nintegrating visual and textual modalities. A critical factor in training MLLMs\nis the quality of image-text pairs within multimodal pretraining datasets.\nHowever, $\\textit {de facto}$ filter-based data quality enhancement paradigms\noften discard a substantial portion of high-quality image data due to\ninadequate semantic alignment between images and texts, leading to\ninefficiencies in data utilization and scalability. In this paper, we propose\nthe Adaptive Image-Text Quality Enhancer (AITQE), a model that dynamically\nassesses and enhances the quality of image-text pairs. AITQE employs a text\nrewriting mechanism for low-quality pairs and incorporates a negative sample\nlearning strategy to improve evaluative capabilities by integrating\ndeliberately selected low-quality samples during training. Unlike prior\napproaches that significantly alter text distributions, our method minimally\nadjusts text to preserve data volume while enhancing quality. Experimental\nresults demonstrate that AITQE surpasses existing methods on various benchmark,\neffectively leveraging raw data and scaling efficiently with increasing data\nvolumes. We hope our work will inspire future works. The code and model are\navailable at: https://github.com/hanhuang22/AITQE.\n","authors":["Han Huang","Yuqi Huo","Zijia Zhao","Haoyu Lu","Shu Wu","Bingning Wang","Qiang Liu","Weipeng Chen","Liang Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16166v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16163v1","updated":"2024-10-21T16:30:29Z","published":"2024-10-21T16:30:29Z","title":"Griffon-G: Bridging Vision-Language and Vision-Centric Tasks via Large\n  Multimodal Models","summary":"  Large Multimodal Models (LMMs) have achieved significant breakthroughs in\nvarious vision-language and vision-centric tasks based on auto-regressive\nmodeling. However, these models typically focus on either vision-centric tasks,\nsuch as visual grounding and region description, or vision-language tasks, like\nimage caption and multi-scenario VQAs. None of the LMMs have yet\ncomprehensively unified both types of tasks within a single model, as seen in\nLarge Language Models in the natural language processing field. Furthermore,\neven with abundant multi-task instruction-following data, directly stacking\nthese data for universal capabilities extension remains challenging. To address\nthese issues, we introduce a novel multi-dimension curated and consolidated\nmultimodal dataset, named CCMD-8M, which overcomes the data barriers of\nunifying vision-centric and vision-language tasks through multi-level data\ncuration and multi-task consolidation. More importantly, we present Griffon-G,\na general large multimodal model that addresses both vision-centric and\nvision-language tasks within a single end-to-end paradigm. Griffon-G resolves\nthe training collapse issue encountered during the joint optimization of these\ntasks, achieving better training efficiency. Evaluations across multimodal\nbenchmarks, general Visual Question Answering (VQA) tasks, scene text-centric\nVQA tasks, document-related VQA tasks, Referring Expression Comprehension, and\nobject detection demonstrate that Griffon-G surpasses the advanced LMMs and\nachieves expert-level performance in complicated vision-centric tasks.\n","authors":["Yufei Zhan","Hongyin Zhao","Yousong Zhu","Fan Yang","Ming Tang","Jinqiao Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16163v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Codes and data will be later released at\n  https://github.com/jefferyZhan/Griffon"},{"id":"http://arxiv.org/abs/2410.16162v1","updated":"2024-10-21T16:26:09Z","published":"2024-10-21T16:26:09Z","title":"Sparkle: Mastering Basic Spatial Capabilities in Vision Language Models\n  Elicits Generalization to Composite Spatial Reasoning","summary":"  Vision language models (VLMs) have demonstrated impressive performance across\na wide range of downstream tasks. However, their proficiency in spatial\nreasoning remains limited, despite its crucial role in tasks involving\nnavigation and interaction with physical environments. Specifically, much of\nthe spatial reasoning in these tasks occurs in two-dimensional (2D)\nenvironments, and our evaluation reveals that state-of-the-art VLMs frequently\ngenerate implausible and incorrect responses to composite spatial reasoning\nproblems, including simple pathfinding tasks that humans can solve effortlessly\nat a glance. To address this, we explore an effective approach to enhance 2D\nspatial reasoning within VLMs by training the model on basic spatial\ncapabilities. We begin by disentangling the key components of 2D spatial\nreasoning: direction comprehension, distance estimation, and localization. Our\ncentral hypothesis is that mastering these basic spatial capabilities can\nsignificantly enhance a model's performance on composite spatial tasks\nrequiring advanced spatial understanding and combinatorial problem-solving. To\ninvestigate this hypothesis, we introduce Sparkle, a framework that fine-tunes\nVLMs on these three basic spatial capabilities by synthetic data generation and\ntargeted supervision to form an instruction dataset for each capability. Our\nexperiments demonstrate that VLMs fine-tuned with Sparkle achieve significant\nperformance gains, not only in the basic tasks themselves but also in\ngeneralizing to composite and out-of-distribution spatial reasoning tasks\n(e.g., improving from 13.5% to 40.0% on the shortest path problem). These\nfindings underscore the effectiveness of mastering basic spatial capabilities\nin enhancing composite spatial problem-solving, offering insights for improving\nVLMs' spatial reasoning capabilities.\n","authors":["Yihong Tang","Ao Qu","Zhaokai Wang","Dingyi Zhuang","Zhaofeng Wu","Wei Ma","Shenhao Wang","Yunhan Zheng","Zhan Zhao","Jinhua Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.16162v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16159v1","updated":"2024-10-21T16:22:19Z","published":"2024-10-21T16:22:19Z","title":"Metric as Transform: Exploring beyond Affine Transform for Interpretable\n  Neural Network","summary":"  Artificial Neural Networks of varying architectures are generally paired with\naffine transformation at the core. However, we find dot product neurons with\nglobal influence less interpretable as compared to local influence of euclidean\ndistance (as used in Radial Basis Function Network). In this work, we explore\nthe generalization of dot product neurons to $l^p$-norm, metrics, and beyond.\nWe find that metrics as transform performs similarly to affine transform when\nused in MultiLayer Perceptron or Convolutional Neural Network. Moreover, we\nexplore various properties of Metrics, compare it with Affine, and present\nmultiple cases where metrics seem to provide better interpretability. We\ndevelop an interpretable local dictionary based Neural Networks and use it to\nunderstand and reject adversarial examples.\n","authors":["Suman Sapkota"],"pdf_url":"https://arxiv.org/pdf/2410.16159v1.pdf","comment":"22 pages, 20 figures, 3 tables"},{"id":"http://arxiv.org/abs/2410.16153v1","updated":"2024-10-21T16:19:41Z","published":"2024-10-21T16:19:41Z","title":"Pangea: A Fully Open Multilingual Multimodal LLM for 39 Languages","summary":"  Despite recent advances in multimodal large language models (MLLMs), their\ndevelopment has predominantly focused on English- and western-centric datasets\nand tasks, leaving most of the world's languages and diverse cultural contexts\nunderrepresented. This paper introduces Pangea, a multilingual multimodal LLM\ntrained on PangeaIns, a diverse 6M instruction dataset spanning 39 languages.\nPangeaIns features: 1) high-quality English instructions, 2) carefully\nmachine-translated instructions, and 3) culturally relevant multimodal tasks to\nensure cross-cultural coverage. To rigorously assess models' capabilities, we\nintroduce PangeaBench, a holistic evaluation suite encompassing 14 datasets\ncovering 47 languages. Results show that Pangea significantly outperforms\nexisting open-source models in multilingual settings and diverse cultural\ncontexts. Ablation studies further reveal the importance of English data\nproportions, language popularity, and the number of multimodal training samples\non overall performance. We fully open-source our data, code, and trained\ncheckpoints, to facilitate the development of inclusive and robust multilingual\nMLLMs, promoting equity and accessibility across a broader linguistic and\ncultural spectrum.\n","authors":["Xiang Yue","Yueqi Song","Akari Asai","Seungone Kim","Jean de Dieu Nyandwi","Simran Khanuja","Anjali Kantharuban","Lintang Sutawika","Sathyanarayanan Ramamoorthy","Graham Neubig"],"pdf_url":"https://arxiv.org/pdf/2410.16153v1.pdf","comment":"52 pages, 27 figures"},{"id":"http://arxiv.org/abs/2410.16152v1","updated":"2024-10-21T16:19:34Z","published":"2024-10-21T16:19:34Z","title":"Warped Diffusion: Solving Video Inverse Problems with Image Diffusion\n  Models","summary":"  Using image models naively for solving inverse video problems often suffers\nfrom flickering, texture-sticking, and temporal inconsistency in generated\nvideos. To tackle these problems, in this paper, we view frames as continuous\nfunctions in the 2D space, and videos as a sequence of continuous warping\ntransformations between different frames. This perspective allows us to train\nfunction space diffusion models only on images and utilize them to solve\ntemporally correlated inverse problems. The function space diffusion models\nneed to be equivariant with respect to the underlying spatial transformations.\nTo ensure temporal consistency, we introduce a simple post-hoc test-time\nguidance towards (self)-equivariant solutions. Our method allows us to deploy\nstate-of-the-art latent diffusion models such as Stable Diffusion XL to solve\nvideo inverse problems. We demonstrate the effectiveness of our method for\nvideo inpainting and $8\\times$ video super-resolution, outperforming existing\ntechniques based on noise transformations. We provide generated video results:\nhttps://giannisdaras.github.io/warped\\_diffusion.github.io/.\n","authors":["Giannis Daras","Weili Nie","Karsten Kreis","Alex Dimakis","Morteza Mardani","Nikola Borislavov Kovachki","Arash Vahdat"],"pdf_url":"https://arxiv.org/pdf/2410.16152v1.pdf","comment":"Accepted in NeurIPS 2024"},{"id":"http://arxiv.org/abs/2405.18406v2","updated":"2024-10-21T16:18:37Z","published":"2024-05-28T17:46:36Z","title":"RACCooN: A Versatile Instructional Video Editing Framework with\n  Auto-Generated Narratives","summary":"  Recent video generative models primarily rely on carefully written text\nprompts for specific tasks, like inpainting or style editing. They require\nlabor-intensive textual descriptions for input videos, hindering their\nflexibility to adapt personal/raw videos to user specifications. This paper\nproposes RACCooN, a versatile and user-friendly video-to-paragraph-to-video\ngenerative framework that supports multiple video editing capabilities such as\nremoval, addition, and modification, through a unified pipeline. RACCooN\nconsists of two principal stages: Video-to-Paragraph (V2P) and\nParagraph-to-Video (P2V). In the V2P stage, we automatically describe video\nscenes in well-structured natural language, capturing both the holistic context\nand focused object details. Subsequently, in the P2V stage, users can\noptionally refine these descriptions to guide the video diffusion model,\nenabling various modifications to the input video, such as removing, changing\nsubjects, and/or adding new objects. The proposed approach stands out from\nother methods through several significant contributions: (1) RACCooN suggests a\nmulti-granular spatiotemporal pooling strategy to generate well-structured\nvideo descriptions, capturing both the broad context and object details without\nrequiring complex human annotations, simplifying precise video content editing\nbased on text for users. (2) Our video generative model incorporates\nauto-generated narratives or instructions to enhance the quality and accuracy\nof the generated content. (3) RACCooN also plans to imagine new objects in a\ngiven video, so users simply prompt the model to receive a detailed video\nediting plan for complex video editing. The proposed framework demonstrates\nimpressive versatile capabilities in video-to-paragraph generation, video\ncontent editing, and can be incorporated into other SoTA video generative\nmodels for further enhancement.\n","authors":["Jaehong Yoon","Shoubin Yu","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2405.18406v2.pdf","comment":"The first two authors contribute equally. Project Page:\n  https://raccoon-mllm-gen.github.io/"},{"id":"http://arxiv.org/abs/2410.16146v1","updated":"2024-10-21T16:17:01Z","published":"2024-10-21T16:17:01Z","title":"Towards Combating Frequency Simplicity-biased Learning for Domain\n  Generalization","summary":"  Domain generalization methods aim to learn transferable knowledge from source\ndomains that can generalize well to unseen target domains. Recent studies show\nthat neural networks frequently suffer from a simplicity-biased learning\nbehavior which leads to over-reliance on specific frequency sets, namely as\nfrequency shortcuts, instead of semantic information, resulting in poor\ngeneralization performance. Despite previous data augmentation techniques\nsuccessfully enhancing generalization performances, they intend to apply more\nfrequency shortcuts, thereby causing hallucinations of generalization\nimprovement. In this paper, we aim to prevent such learning behavior of\napplying frequency shortcuts from a data-driven perspective. Given the\ntheoretical justification of models' biased learning behavior on different\nspatial frequency components, which is based on the dataset frequency\nproperties, we argue that the learning behavior on various frequency components\ncould be manipulated by changing the dataset statistical structure in the\nFourier domain. Intuitively, as frequency shortcuts are hidden in the dominant\nand highly dependent frequencies of dataset structure, dynamically perturbating\nthe over-reliance frequency components could prevent the application of\nfrequency shortcuts. To this end, we propose two effective data augmentation\nmodules designed to collaboratively and adaptively adjust the frequency\ncharacteristic of the dataset, aiming to dynamically influence the learning\nbehavior of the model and ultimately serving as a strategy to mitigate shortcut\nlearning. Code is available at AdvFrequency\n(https://github.com/C0notSilly/AdvFrequency).\n","authors":["Xilin He","Jingyu Hu","Qinliang Lin","Cheng Luo","Weicheng Xie","Siyang Song","Muhammad Haris Khan","Linlin Shen"],"pdf_url":"https://arxiv.org/pdf/2410.16146v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.16143v1","updated":"2024-10-21T16:14:50Z","published":"2024-10-21T16:14:50Z","title":"An Explainable Contrastive-based Dilated Convolutional Network with\n  Transformer for Pediatric Pneumonia Detection","summary":"  Pediatric pneumonia remains a significant global threat, posing a larger\nmortality risk than any other communicable disease. According to UNICEF, it is\na leading cause of mortality in children under five and requires prompt\ndiagnosis. Early diagnosis using chest radiographs is the prevalent standard,\nbut limitations include low radiation levels in unprocessed images and data\nimbalance issues. This necessitates the development of efficient,\ncomputer-aided diagnosis techniques. To this end, we propose a novel\nEXplainable Contrastive-based Dilated Convolutional Network with Transformer\n(XCCNet) for pediatric pneumonia detection. XCCNet harnesses the spatial power\nof dilated convolutions and the global insights from contrastive-based\ntransformers for effective feature refinement. A robust chest X-ray processing\nmodule tackles low-intensity radiographs, while adversarial-based data\naugmentation mitigates the skewed distribution of chest X-rays in the dataset.\nFurthermore, we actively integrate an explainability approach through feature\nvisualization, directly aligning it with the attention region that pinpoints\nthe presence of pneumonia or normality in radiographs. The efficacy of XCCNet\nis comprehensively assessed on four publicly available datasets. Extensive\nperformance evaluation demonstrates the superiority of XCCNet compared to\nstate-of-the-art methods.\n","authors":["Chandravardhan Singh Raghaw","Parth Shirish Bhore","Mohammad Zia Ur Rehman","Nagendra Kumar"],"pdf_url":"https://arxiv.org/pdf/2410.16143v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00299v4","updated":"2024-10-21T15:56:23Z","published":"2024-06-29T03:37:29Z","title":"Human-Agent Joint Learning for Efficient Robot Manipulation Skill\n  Acquisition","summary":"  Employing a teleoperation system for gathering demonstrations offers the\npotential for more efficient learning of robot manipulation. However,\nteleoperating a robot arm equipped with a dexterous hand or gripper, via a\nteleoperation system presents inherent challenges due to the task's high\ndimensionality, complexity of motion, and differences between physiological\nstructures. In this study, we introduce a novel system for joint learning\nbetween human operators and robots, that enables human operators to share\ncontrol of a robot end-effector with a learned assistive agent, simplifies the\ndata collection process, and facilitates simultaneous human demonstration\ncollection and robot manipulation training. As data accumulates, the assistive\nagent gradually learns. Consequently, less human effort and attention are\nrequired, enhancing the efficiency of the data collection process. It also\nallows the human operator to adjust the control ratio to achieve a trade-off\nbetween manual and automated control. We conducted experiments in both\nsimulated environments and physical real-world settings. Through user studies\nand quantitative evaluations, it is evident that the proposed system could\nenhance data collection efficiency and reduce the need for human adaptation\nwhile ensuring the collected data is of sufficient quality for downstream\ntasks. \\textit{For more details, please refer to our webpage\nhttps://norweig1an.github.io/HAJL.github.io/.\n","authors":["Shengcheng Luo","Quanquan Peng","Jun Lv","Kaiwen Hong","Katherine Rose Driggs-Campbell","Cewu Lu","Yong-Lu Li"],"pdf_url":"https://arxiv.org/pdf/2407.00299v4.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.08797v2","updated":"2024-10-21T15:45:23Z","published":"2024-10-11T13:31:28Z","title":"CoTCoNet: An Optimized Coupled Transformer-Convolutional Network with an\n  Adaptive Graph Reconstruction for Leukemia Detection","summary":"  Swift and accurate blood smear analysis is an effective diagnostic method for\nleukemia and other hematological malignancies. However, manual leukocyte count\nand morphological evaluation using a microscope is time-consuming and prone to\nerrors. Conventional image processing methods also exhibit limitations in\ndifferentiating cells due to the visual similarity between malignant and benign\ncell morphology. This limitation is further compounded by the skewed training\ndata that hinders the extraction of reliable and pertinent features. In\nresponse to these challenges, we propose an optimized Coupled Transformer\nConvolutional Network (CoTCoNet) framework for the classification of leukemia,\nwhich employs a well-designed transformer integrated with a deep convolutional\nnetwork to effectively capture comprehensive global features and scalable\nspatial patterns, enabling the identification of complex and large-scale\nhematological features. Further, the framework incorporates a graph-based\nfeature reconstruction module to reveal the hidden or unobserved hard-to-see\nbiological features of leukocyte cells and employs a Population-based\nMeta-Heuristic Algorithm for feature selection and optimization. To mitigate\ndata imbalance issues, we employ a synthetic leukocyte generator. In the\nevaluation phase, we initially assess CoTCoNet on a dataset containing 16,982\nannotated cells, and it achieves remarkable accuracy and F1-Score rates of\n0.9894 and 0.9893, respectively. To broaden the generalizability of our model,\nwe evaluate it across four publicly available diverse datasets, which include\nthe aforementioned dataset. This evaluation demonstrates that our method\noutperforms current state-of-the-art approaches. We also incorporate an\nexplainability approach in the form of feature visualization closely aligned\nwith cell annotations to provide a deeper understanding of the framework.\n","authors":["Chandravardhan Singh Raghaw","Arnav Sharma","Shubhi Bansal","Mohammad Zia Ur Rehman","Nagendra Kumar"],"pdf_url":"https://arxiv.org/pdf/2410.08797v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16116v1","updated":"2024-10-21T15:42:47Z","published":"2024-10-21T15:42:47Z","title":"Multimodal Flare Forecasting with Deep Learning","summary":"  Solar flare forecasting mainly relies on photospheric magnetograms and\nassociated physical features to predict forthcoming flares. However, it is\nbelieved that flare initiation mechanisms often originate in the chromosphere\nand the lower corona. In this study, we employ deep learning as a purely\ndata-driven approach to compare the predictive capabilities of chromospheric\nand coronal UV and EUV emissions across different wavelengths with those of\nphotospheric line-of-sight magnetograms. Our findings indicate that individual\nEUV wavelengths can provide discriminatory power comparable or better to that\nof line-of-sight magnetograms. Moreover, we identify simple multimodal neural\nnetwork architectures that consistently outperform single-input models, showing\ncomplementarity between the flare precursors that can be extracted from the\ndistinct layers of the solar atmosphere. To mitigate potential biases from\nknown misattributions in Active Region flare catalogs, our models are trained\nand evaluated using full-disk images and a comprehensive flare event catalog at\nthe full-disk level. We introduce a deep-learning architecture suited for\nextracting temporal features from full-disk videos.\n","authors":["Grégoire Francisco","Sabrina Guastavino","Teresa Barata","João Fernandes","Dario Del Moro"],"pdf_url":"https://arxiv.org/pdf/2410.16116v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13861v2","updated":"2024-10-21T15:42:46Z","published":"2024-10-17T17:59:57Z","title":"PUMA: Empowering Unified MLLM with Multi-granular Visual Generation","summary":"  Recent advancements in multimodal foundation models have yielded significant\nprogress in vision-language understanding. Initial attempts have also explored\nthe potential of multimodal large language models (MLLMs) for visual content\ngeneration. However, existing works have insufficiently addressed the varying\ngranularity demands of different image generation tasks within a unified MLLM\nparadigm - from the diversity required in text-to-image generation to the\nprecise controllability needed in image manipulation. In this work, we propose\nPUMA, emPowering Unified MLLM with Multi-grAnular visual generation. PUMA\nunifies multi-granular visual features as both inputs and outputs of MLLMs,\nelegantly addressing the different granularity requirements of various image\ngeneration tasks within a unified MLLM framework. Following multimodal\npretraining and task-specific instruction tuning, PUMA demonstrates proficiency\nin a wide range of multimodal tasks. This work represents a significant step\ntowards a truly unified MLLM capable of adapting to the granularity demands of\nvarious visual tasks. The code and model will be released in\nhttps://github.com/rongyaofang/PUMA.\n","authors":["Rongyao Fang","Chengqi Duan","Kun Wang","Hao Li","Hao Tian","Xingyu Zeng","Rui Zhao","Jifeng Dai","Hongsheng Li","Xihui Liu"],"pdf_url":"https://arxiv.org/pdf/2410.13861v2.pdf","comment":"Project page: https://rongyaofang.github.io/puma/"},{"id":"http://arxiv.org/abs/2410.16115v1","updated":"2024-10-21T15:42:27Z","published":"2024-10-21T15:42:27Z","title":"Increasing Interpretability of Neural Networks By Approximating Human\n  Visual Saliency","summary":"  Understanding specifically where a model focuses on within an image is\ncritical for human interpretability of the decision-making process. Deep\nlearning-based solutions are prone to learning coincidental correlations in\ntraining datasets, causing over-fitting and reducing the explainability. Recent\nadvances have shown that guiding models to human-defined regions of saliency\nwithin individual images significantly increases performance and\ninterpretability. Human-guided models also exhibit greater generalization\ncapabilities, as coincidental dataset features are avoided. Results show that\nmodels trained with saliency incorporation display an increase in\ninterpretability of up to 30% over models trained without saliency information.\nThe collection of this saliency information, however, can be costly, laborious\nand in some cases infeasible. To address this limitation, we propose a\ncombination strategy of saliency incorporation and active learning to reduce\nthe human annotation data required by 80% while maintaining the\ninterpretability and performance increase from human saliency. Extensive\nexperimentation outlines the effectiveness of the proposed approach across five\npublic datasets and six active learning criteria.\n","authors":["Aidan Boyd","Mohamed Trabelsi","Huseyin Uzunalioglu","Dan Kushnir"],"pdf_url":"https://arxiv.org/pdf/2410.16115v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16095v1","updated":"2024-10-21T15:20:02Z","published":"2024-10-21T15:20:02Z","title":"LMHaze: Intensity-aware Image Dehazing with a Large-scale\n  Multi-intensity Real Haze Dataset","summary":"  Image dehazing has drawn a significant attention in recent years.\nLearning-based methods usually require paired hazy and corresponding ground\ntruth (haze-free) images for training. However, it is difficult to collect\nreal-world image pairs, which prevents developments of existing methods.\nAlthough several works partially alleviate this issue by using synthetic\ndatasets or small-scale real datasets. The haze intensity distribution bias and\nscene homogeneity in existing datasets limit the generalization ability of\nthese methods, particularly when encountering images with previously unseen\nhaze intensities. In this work, we present LMHaze, a large-scale, high-quality\nreal-world dataset. LMHaze comprises paired hazy and haze-free images captured\nin diverse indoor and outdoor environments, spanning multiple scenarios and\nhaze intensities. It contains over 5K high-resolution image pairs, surpassing\nthe size of the biggest existing real-world dehazing dataset by over 25 times.\nMeanwhile, to better handle images with different haze intensities, we propose\na mixture-of-experts model based on Mamba (MoE-Mamba) for dehazing, which\ndynamically adjusts the model parameters according to the haze intensity.\nMoreover, with our proposed dataset, we conduct a new large multimodal model\n(LMM)-based benchmark study to simulate human perception for evaluating dehazed\nimages. Experiments demonstrate that LMHaze dataset improves the dehazing\nperformance in real scenarios and our dehazing method provides better results\ncompared to state-of-the-art methods.\n","authors":["Ruikun Zhang","Hao Yang","Yan Yang","Ying Fu","Liyuan Pan"],"pdf_url":"https://arxiv.org/pdf/2410.16095v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.08381v4","updated":"2024-10-21T15:18:39Z","published":"2024-08-15T18:54:31Z","title":"Pre-processing and Compression: Understanding Hidden Representation\n  Refinement Across Imaging Domains via Intrinsic Dimension","summary":"  In recent years, there has been interest in how geometric properties such as\nintrinsic dimension (ID) of a neural network's hidden representations change\nthrough its layers, and how such properties are predictive of important model\nbehavior such as generalization ability. However, evidence has begun to emerge\nthat such behavior can change significantly depending on the domain of the\nnetwork's training data, such as natural versus medical images. Here, we\nfurther this inquiry by exploring how the ID of a network's learned\nrepresentations changes through its layers, in essence, characterizing how the\nnetwork successively refines the information content of input data to be used\nfor predictions. Analyzing eleven natural and medical image datasets across six\nnetwork architectures, we find that how ID changes through the network differs\nnoticeably between natural and medical image models. Specifically, medical\nimage models peak in representation ID earlier in the network, implying a\ndifference in the image features and their abstractness that are typically used\nfor downstream tasks in these domains. Additionally, we discover a strong\ncorrelation of this peak representation ID with the ID of the data in its input\nspace, implying that the intrinsic information content of a model's learned\nrepresentations is guided by that of the data it was trained on. Overall, our\nfindings emphasize notable discrepancies in network behavior between natural\nand non-natural imaging domains regarding hidden representation information\ncontent, and provide further insights into how a network's learned features are\nshaped by its training data.\n","authors":["Nicholas Konz","Maciej A. Mazurowski"],"pdf_url":"https://arxiv.org/pdf/2408.08381v4.pdf","comment":"Published in NeurIPS 2024 Workshop on Scientific Methods for\n  Understanding Deep Learning (SciForDL)"},{"id":"http://arxiv.org/abs/2410.16093v1","updated":"2024-10-21T15:16:00Z","published":"2024-10-21T15:16:00Z","title":"Final Report for CHESS: Cloud, High-Performance Computing, and Edge for\n  Science and Security","summary":"  Automating the theory-experiment cycle requires effective distributed\nworkflows that utilize a computing continuum spanning lab instruments, edge\nsensors, computing resources at multiple facilities, data sets distributed\nacross multiple information sources, and potentially cloud. Unfortunately, the\nobvious methods for constructing continuum platforms, orchestrating workflow\ntasks, and curating datasets over time fail to achieve scientific requirements\nfor performance, energy, security, and reliability. Furthermore, achieving the\nbest use of continuum resources depends upon the efficient composition and\nexecution of workflow tasks, i.e., combinations of numerical solvers, data\nanalytics, and machine learning. Pacific Northwest National Laboratory's LDRD\n\"Cloud, High-Performance Computing (HPC), and Edge for Science and Security\"\n(CHESS) has developed a set of interrelated capabilities for enabling\ndistributed scientific workflows and curating datasets. This report describes\nthe results and successes of CHESS from the perspective of open science.\n","authors":["Nathan Tallent","Jan Strube","Luanzheng Guo","Hyungro Lee","Jesun Firoz","Sayan Ghosh","Bo Fang","Oceane Bel","Steven Spurgeon","Sarah Akers","Christina Doty","Erol Cromwell"],"pdf_url":"https://arxiv.org/pdf/2410.16093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16063v1","updated":"2024-10-21T14:44:08Z","published":"2024-10-21T14:44:08Z","title":"Integrated Image-Text Based on Semi-supervised Learning for Small Sample\n  Instance Segmentation","summary":"  Small sample instance segmentation is a very challenging task, and many\nexisting methods follow the training strategy of meta-learning which pre-train\nmodels on support set and fine-tune on query set. The pre-training phase, which\nis highly task related, requires a significant amount of additional training\ntime and the selection of datasets with close proximity to ensure\neffectiveness. The article proposes a novel small sample instance segmentation\nsolution from the perspective of maximizing the utilization of existing\ninformation without increasing annotation burden and training costs. The\nproposed method designs two modules to address the problems encountered in\nsmall sample instance segmentation. First, it helps the model fully utilize\nunlabeled data by learning to generate pseudo labels, increasing the number of\navailable samples. Second, by integrating the features of text and image, more\naccurate classification results can be obtained. These two modules are suitable\nfor box-free and box-dependent frameworks. In the way, the proposed method not\nonly improves the performance of small sample instance segmentation, but also\ngreatly reduce reliance on pre-training. We have conducted experiments in three\ndatasets from different scenes: on land, underwater and under microscope. As\nevidenced by our experiments, integrated image-text corrects the confidence of\nclassification, and pseudo labels help the model obtain preciser masks. All the\nresults demonstrate the effectiveness and superiority of our method.\n","authors":["Ruting Chi","Zhiyi Huang","Yuexing Han"],"pdf_url":"https://arxiv.org/pdf/2410.16063v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11792v2","updated":"2024-10-21T14:42:16Z","published":"2024-03-18T13:50:35Z","title":"SETA: Semantic-Aware Token Augmentation for Domain Generalization","summary":"  Domain generalization (DG) aims to enhance the model robustness against\ndomain shifts without accessing target domains. A prevalent category of methods\nfor DG is data augmentation, which focuses on generating virtual samples to\nsimulate domain shifts. However, existing augmentation techniques in DG are\nmainly tailored for convolutional neural networks (CNNs), with limited\nexploration in token-based architectures, i.e., vision transformer (ViT) and\nmulti-layer perceptrons (MLP) models. In this paper, we study the impact of\nprior CNN-based augmentation methods on token-based models, revealing their\nperformance is suboptimal due to the lack of incentivizing the model to learn\nholistic shape information. To tackle the issue, we propose the SEmantic-aware\nToken Augmentation (SETA) method. SETA transforms token features by perturbing\nlocal edge cues while preserving global shape features, thereby enhancing the\nmodel learning of shape information. To further enhance the generalization\nability of the model, we introduce two stylized variants of our method combined\nwith two state-of-the-art style augmentation methods in DG. We provide a\ntheoretical insight into our method, demonstrating its effectiveness in\nreducing the generalization risk bound. Comprehensive experiments on five\nbenchmarks prove that our method achieves SOTA performances across various ViT\nand MLP architectures. Our code is available at\nhttps://github.com/lingeringlight/SETA.\n","authors":["Jintao Guo","Lei Qi","Yinghuan Shi","Yang Gao"],"pdf_url":"https://arxiv.org/pdf/2403.11792v2.pdf","comment":"Accepted by IEEE TIP 2024. The code is available at\n  https://github.com/lingeringlight/SETA"},{"id":"http://arxiv.org/abs/2410.16057v1","updated":"2024-10-21T14:36:36Z","published":"2024-10-21T14:36:36Z","title":"Label Filling via Mixed Supervision for Medical Image Segmentation from\n  Noisy Annotations","summary":"  The success of medical image segmentation usually requires a large number of\nhigh-quality labels. But since the labeling process is usually affected by the\nraters' varying skill levels and characteristics, the estimated masks provided\nby different raters usually suffer from high inter-rater variability. In this\npaper, we propose a simple yet effective Label Filling framework, termed as\nLF-Net, predicting the groundtruth segmentation label given only noisy\nannotations during training. The fundamental idea of label filling is to\nsupervise the segmentation model by a subset of pixels with trustworthy labels,\nmeanwhile filling labels of other pixels by mixed supervision. More concretely,\nwe propose a qualified majority voting strategy, i.e., a threshold voting\nscheme is designed to model agreement among raters and the majority-voted\nlabels of the selected subset of pixels are regarded as supervision. To fill\nlabels of other pixels, two types of mixed auxiliary supervision are proposed:\na soft label learned from intrinsic structures of noisy annotations, and\nraters' characteristics labels which propagate individual rater's\ncharacteristics information. LF-Net has two main advantages. 1) Training with\ntrustworthy pixels incorporates training with confident supervision, guiding\nthe direction of groundtruth label learning. 2) Two types of mixed supervision\nprevent over-fitting issues when the network is supervised by a subset of\npixels, and guarantee high fidelity with the true label. Results on five\ndatasets of diverse imaging modalities show that our LF-Net boosts segmentation\naccuracy in all datasets compared with state-of-the-art methods, with even a 7%\nimprovement in DSC for MS lesion segmentation.\n","authors":["Ming Li","Wei Shen","Qingli Li","Yan Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16057v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.06446v2","updated":"2024-10-21T14:28:18Z","published":"2024-10-09T01:12:07Z","title":"Machine Unlearning in Forgettability Sequence","summary":"  Machine unlearning (MU) is becoming a promising paradigm to achieve the\n\"right to be forgotten\", where the training trace of any chosen data points\ncould be eliminated, while maintaining the model utility on general testing\nsamples after unlearning. With the advancement of forgetting research, many\nfundamental open questions remain unanswered: do different samples exhibit\nvarying levels of difficulty in being forgotten? Further, does the sequence in\nwhich samples are forgotten, determined by their respective difficulty levels,\ninfluence the performance of forgetting algorithms? In this paper, we identify\nkey factor affecting unlearning difficulty and the performance of unlearning\nalgorithms. We find that samples with higher privacy risks are more likely to\nbe unlearning, indicating that the unlearning difficulty varies among different\nsamples which motives a more precise unlearning mode. Built upon this insight,\nwe propose a general unlearning framework, dubbed RSU, which consists of\nRanking module and SeqUnlearn module.\n","authors":["Junjie Chen","Qian Chen","Jian Lou","Xiaoyu Zhang","Kai Wu","Zilong Wang"],"pdf_url":"https://arxiv.org/pdf/2410.06446v2.pdf","comment":"The senior authors of the draft are not fully convinced that the\n  novelty is significant enough for this submission compared to the latest\n  research progress in this area. Additionally, the senior authors have\n  identified writing issues. Based on these two reasons, we have decided to\n  withdraw the draft from arXiv"},{"id":"http://arxiv.org/abs/2409.09478v2","updated":"2024-10-21T14:15:30Z","published":"2024-09-14T16:39:17Z","title":"From FDG to PSMA: A Hitchhiker's Guide to Multitracer, Multicenter\n  Lesion Segmentation in PET/CT Imaging","summary":"  Automated lesion segmentation in PET/CT scans is crucial for improving\nclinical workflows and advancing cancer diagnostics. However, the task is\nchallenging due to physiological variability, different tracers used in PET\nimaging, and diverse imaging protocols across medical centers. To address this,\nthe autoPET series was created to challenge researchers to develop algorithms\nthat generalize across diverse PET/CT environments. This paper presents our\nsolution for the autoPET III challenge, targeting multitracer, multicenter\ngeneralization using the nnU-Net framework with the ResEncL architecture. Key\ntechniques include misalignment data augmentation and multi-modal pretraining\nacross CT, MR, and PET datasets to provide an initial anatomical understanding.\nWe incorporate organ supervision as a multitask approach, enabling the model to\ndistinguish between physiological uptake and tracer-specific patterns, which is\nparticularly beneficial in cases where no lesions are present. Compared to the\ndefault nnU-Net, which achieved a Dice score of 57.61, or the larger ResEncL\n(65.31) our model significantly improved performance with a Dice score of\n68.40, alongside a reduction in false positive (FPvol: 7.82) and false negative\n(FNvol: 10.35) volumes. These results underscore the effectiveness of combining\nadvanced network design, augmentation, pretraining, and multitask learning for\nPET/CT lesion segmentation. After evaluation on the test set, our approach was\nawarded the first place in the model-centric category (Team LesionTracer). Code\nis publicly available at https://github.com/MIC-DKFZ/autopet-3-submission.\n","authors":["Maximilian Rokuss","Balint Kovacs","Yannick Kirchhoff","Shuhan Xiao","Constantin Ulrich","Klaus H. Maier-Hein","Fabian Isensee"],"pdf_url":"https://arxiv.org/pdf/2409.09478v2.pdf","comment":"Winning method of the autoPET III challenge (model-centric) - Team\n  LesionTracer"},{"id":"http://arxiv.org/abs/2410.06558v4","updated":"2024-10-21T14:11:54Z","published":"2024-10-09T05:28:43Z","title":"Deep Correlated Prompting for Visual Recognition with Missing Modalities","summary":"  Large-scale multimodal models have shown excellent performance over a series\nof tasks powered by the large corpus of paired multimodal training data.\nGenerally, they are always assumed to receive modality-complete inputs.\nHowever, this simple assumption may not always hold in the real world due to\nprivacy constraints or collection difficulty, where models pretrained on\nmodality-complete data easily demonstrate degraded performance on\nmissing-modality cases. To handle this issue, we refer to prompt learning to\nadapt large pretrained multimodal models to handle missing-modality scenarios\nby regarding different missing cases as different types of input. Instead of\nonly prepending independent prompts to the intermediate layers, we present to\nleverage the correlations between prompts and input features and excavate the\nrelationships between different layers of prompts to carefully design the\ninstructions. We also incorporate the complementary semantics of different\nmodalities to guide the prompting design for each modality. Extensive\nexperiments on three commonly-used datasets consistently demonstrate the\nsuperiority of our method compared to the previous approaches upon different\nmissing scenarios. Plentiful ablations are further given to show the\ngeneralizability and reliability of our method upon different modality-missing\nratios and types.\n","authors":["Lianyu Hu","Tongkai Shi","Wei Feng","Fanhua Shang","Liang Wan"],"pdf_url":"https://arxiv.org/pdf/2410.06558v4.pdf","comment":"NeurIPS 2024, add some results"},{"id":"http://arxiv.org/abs/2410.16038v1","updated":"2024-10-21T14:10:18Z","published":"2024-10-21T14:10:18Z","title":"Benchmarking Pathology Foundation Models: Adaptation Strategies and\n  Scenarios","summary":"  In computational pathology, several foundation models have recently emerged\nand demonstrated enhanced learning capability for analyzing pathology images.\nHowever, adapting these models to various downstream tasks remains challenging,\nparticularly when faced with datasets from different sources and acquisition\nconditions, as well as limited data availability. In this study, we benchmark\nfour pathology-specific foundation models across 14 datasets and two\nscenarios-consistency assessment and flexibility assessment-addressing diverse\nadaptation scenarios and downstream tasks. In the consistency assessment\nscenario, involving five fine-tuning methods, we found that the\nparameter-efficient fine-tuning approach was both efficient and effective for\nadapting pathology-specific foundation models to diverse datasets within the\nsame downstream task. In the flexibility assessment scenario under data-limited\nenvironments, utilizing five few-shot learning methods, we observed that the\nfoundation models benefited more from the few-shot learning methods that\ninvolve modification during the testing phase only. These findings provide\ninsights that could guide the deployment of pathology-specific foundation\nmodels in real clinical settings, potentially improving the accuracy and\nreliability of pathology image analysis. The code for this study is available\nat: https://github.com/QuIIL/BenchmarkingPathologyFoundationModels.\n","authors":["Jeaung Lee","Jeewoo Lim","Keunho Byeon","Jin Tae Kwak"],"pdf_url":"https://arxiv.org/pdf/2410.16038v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16037v1","updated":"2024-10-21T14:10:14Z","published":"2024-10-21T14:10:14Z","title":"Improving the Multi-label Atomic Activity Recognition by Robust Visual\n  Feature and Advanced Attention @ ROAD++ Atomic Activity Recognition 2024","summary":"  Road++ Track3 proposes a multi-label atomic activity recognition task in\ntraffic scenarios, which can be standardized as a 64-class multi-label video\naction recognition task. In the multi-label atomic activity recognition task,\nthe robustness of visual feature extraction remains a key challenge, which\ndirectly affects the model performance and generalization ability. To cope with\nthese issues, our team optimized three aspects: data processing, model and\npost-processing. Firstly, the appropriate resolution and video sampling\nstrategy are selected, and a fixed sampling strategy is set on the validation\nand test sets. Secondly, in terms of model training, the team selects a variety\nof visual backbone networks for feature extraction, and then introduces the\naction-slot model, which is trained on the training and validation sets, and\nreasoned on the test set. Finally, for post-processing, the team combined the\nstrengths and weaknesses of different models for weighted fusion, and the final\nmAP on the test set was 58%, which is 4% higher than the challenge baseline.\n","authors":["Jiamin Cao","Lingqi Wang","Kexin Zhang","Yuting Yang","Licheng Jiao","Yuwei Guo"],"pdf_url":"https://arxiv.org/pdf/2410.16037v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.11545v3","updated":"2024-10-21T14:04:16Z","published":"2024-08-21T11:53:53Z","title":"UNetMamba: An Efficient UNet-Like Mamba for Semantic Segmentation of\n  High-Resolution Remote Sensing Images","summary":"  Semantic segmentation of high-resolution remote sensing images is vital in\ndownstream applications such as land-cover mapping, urban planning and disaster\nassessment.Existing Transformer-based methods suffer from the constraint\nbetween accuracy and efficiency, while the recently proposed Mamba is renowned\nfor being efficient. Therefore, to overcome the dilemma, we propose UNetMamba,\na UNet-like semantic segmentation model based on Mamba. It incorporates a mamba\nsegmentation decoder (MSD) that can efficiently decode the complex information\nwithin high-resolution images, and a local supervision module (LSM), which is\ntrain-only but can significantly enhance the perception of local contents.\nExtensive experiments demonstrate that UNetMamba outperforms the\nstate-of-the-art methods with mIoU increased by 0.87% on LoveDA and 0.39% on\nISPRS Vaihingen, while achieving high efficiency through the lightweight\ndesign, less memory footprint and reduced computational cost. The source code\nis available at https://github.com/EnzeZhu2001/UNetMamba.\n","authors":["Enze Zhu","Zhan Chen","Dingkai Wang","Hanru Shi","Xiaoxuan Liu","Lei Wang"],"pdf_url":"https://arxiv.org/pdf/2408.11545v3.pdf","comment":"5 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.16028v1","updated":"2024-10-21T14:03:15Z","published":"2024-10-21T14:03:15Z","title":"Few-shot target-driven instance detection based on open-vocabulary\n  object detection models","summary":"  Current large open vision models could be useful for one and few-shot object\nrecognition. Nevertheless, gradient-based re-training solutions are costly. On\nthe other hand, open-vocabulary object detection models bring closer visual and\ntextual concepts in the same latent space, allowing zero-shot detection via\nprompting at small computational cost. We propose a lightweight method to turn\nthe latter into a one-shot or few-shot object recognition models without\nrequiring textual descriptions. Our experiments on the TEgO dataset using the\nYOLO-World model as a base show that performance increases with the model size,\nthe number of examples and the use of image augmentation.\n","authors":["Ben Crulis","Barthelemy Serres","Cyril De Runz","Gilles Venturini"],"pdf_url":"https://arxiv.org/pdf/2410.16028v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16020v1","updated":"2024-10-21T13:50:32Z","published":"2024-10-21T13:50:32Z","title":"START: A Generalized State Space Model with Saliency-Driven Token-Aware\n  Transformation","summary":"  Domain Generalization (DG) aims to enable models to generalize to unseen\ntarget domains by learning from multiple source domains. Existing DG methods\nprimarily rely on convolutional neural networks (CNNs), which inherently learn\ntexture biases due to their limited receptive fields, making them prone to\noverfitting source domains. While some works have introduced transformer-based\nmethods (ViTs) for DG to leverage the global receptive field, these methods\nincur high computational costs due to the quadratic complexity of\nself-attention. Recently, advanced state space models (SSMs), represented by\nMamba, have shown promising results in supervised learning tasks by achieving\nlinear complexity in sequence length during training and fast RNN-like\ncomputation during inference. Inspired by this, we investigate the\ngeneralization ability of the Mamba model under domain shifts and find that\ninput-dependent matrices within SSMs could accumulate and amplify\ndomain-specific features, thus hindering model generalization. To address this\nissue, we propose a novel SSM-based architecture with saliency-based\ntoken-aware transformation (namely START), which achieves state-of-the-art\n(SOTA) performances and offers a competitive alternative to CNNs and ViTs. Our\nSTART can selectively perturb and suppress domain-specific features in salient\ntokens within the input-dependent matrices of SSMs, thus effectively reducing\nthe discrepancy between different domains. Extensive experiments on five\nbenchmarks demonstrate that START outperforms existing SOTA DG methods with\nefficient linear complexity. Our code is available at\nhttps://github.com/lingeringlight/START.\n","authors":["Jintao Guo","Lei Qi","Yinghuan Shi","Yang Gao"],"pdf_url":"https://arxiv.org/pdf/2410.16020v1.pdf","comment":"Accepted by NeurIPS2024. The code is available at\n  https://github.com/lingeringlight/START"},{"id":"http://arxiv.org/abs/2410.16019v1","updated":"2024-10-21T13:49:54Z","published":"2024-10-21T13:49:54Z","title":"Multispectral Texture Synthesis using RGB Convolutional Neural Networks","summary":"  State-of-the-art RGB texture synthesis algorithms rely on style distances\nthat are computed through statistics of deep features. These deep features are\nextracted by classification neural networks that have been trained on large\ndatasets of RGB images. Extending such synthesis methods to multispectral\nimages is not straightforward, since the pre-trained networks are designed for\nand have been trained on RGB images. In this work, we propose two solutions to\nextend these methods to multispectral imaging. Neither of them require\nadditional training of the neural network from which the second order neural\nstatistics are extracted. The first one consists in optimizing over batches of\nrandom triplets of spectral bands throughout training. The second one projects\nmultispectral pixels onto a 3 dimensional space. We further explore the benefit\nof a color transfer operation upstream of the projection to avoid the\npotentially abnormal color distributions induced by the projection. Our\nexperiments compare the performances of the various methods through different\nmetrics. We demonstrate that they can be used to perform exemplar-based texture\nsynthesis, achieve good visual quality and comes close to state-of-the art\nmethods on RGB bands.\n","authors":["Sélim Ollivier","Yann Gousseau","Sidonie Lefebvre"],"pdf_url":"https://arxiv.org/pdf/2410.16019v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.09283v2","updated":"2024-10-21T13:45:54Z","published":"2024-01-17T15:37:00Z","title":"A gradient-based approach to fast and accurate head motion compensation\n  in cone-beam CT","summary":"  Cone-beam computed tomography (CBCT) systems, with their flexibility, present\na promising avenue for direct point-of-care medical imaging, particularly in\ncritical scenarios such as acute stroke assessment. However, the integration of\nCBCT into clinical workflows faces challenges, primarily linked to long scan\nduration resulting in patient motion during scanning and leading to image\nquality degradation in the reconstructed volumes. This paper introduces a novel\napproach to CBCT motion estimation using a gradient-based optimization\nalgorithm, which leverages generalized derivatives of the backprojection\noperator for cone-beam CT geometries. Building on that, a fully differentiable\ntarget function is formulated which grades the quality of the current motion\nestimate in reconstruction space. We drastically accelerate motion estimation\nyielding a 19-fold speed-up compared to existing methods. Additionally, we\ninvestigate the architecture of networks used for quality metric regression and\npropose predicting voxel-wise quality maps, favoring autoencoder-like\narchitectures over contracting ones. This modification improves gradient flow,\nleading to more accurate motion estimation. The presented method is evaluated\nthrough realistic experiments on head anatomy. It achieves a reduction in\nreprojection error from an initial average of 3mm to 0.61mm after motion\ncompensation and consistently demonstrates superior performance compared to\nexisting approaches. The analytic Jacobian for the backprojection operation,\nwhich is at the core of the proposed method, is made publicly available. In\nsummary, this paper contributes to the advancement of CBCT integration into\nclinical workflows by proposing a robust motion estimation approach that\nenhances efficiency and accuracy, addressing critical challenges in\ntime-sensitive scenarios.\n","authors":["Mareike Thies","Fabian Wagner","Noah Maul","Haijun Yu","Manuela Goldmann","Linda-Sophie Schneider","Mingxuan Gu","Siyuan Mei","Lukas Folle","Alexander Preuhs","Michael Manhart","Andreas Maier"],"pdf_url":"https://arxiv.org/pdf/2401.09283v2.pdf","comment":"\\copyright 2024 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works"},{"id":"http://arxiv.org/abs/2410.16012v1","updated":"2024-10-21T13:43:02Z","published":"2024-10-21T13:43:02Z","title":"Massimo: Public Queue Monitoring and Management using Mass-Spring Model","summary":"  An efficient system of a queue control and regulation in public spaces is\nvery important in order to avoid the traffic jams and to improve the customer\nsatisfaction. This article offers a detailed road map based on a merger of\nintelligent systems and creating an efficient systems of queues in public\nplaces. Through the utilization of different technologies i.e. computer vision,\nmachine learning algorithms, deep learning our system provide accurate\ninformation about the place is crowded or not and the necessary efforts to be\ntaken.\n","authors":["Abhijeet Kumar","Unnati Singh","Rajdeep Chatterjee","Tathagata Bandyopadhyay"],"pdf_url":"https://arxiv.org/pdf/2410.16012v1.pdf","comment":"8 pages, 6 figures, 3 algorithms, 3 tables"},{"id":"http://arxiv.org/abs/2410.16009v1","updated":"2024-10-21T13:42:06Z","published":"2024-10-21T13:42:06Z","title":"3D-GANTex: 3D Face Reconstruction with StyleGAN3-based Multi-View Images\n  and 3DDFA based Mesh Generation","summary":"  Geometry and texture estimation from a single face image is an ill-posed\nproblem since there is very little information to work with. The problem\nfurther escalates when the face is rotated at a different angle. This paper\ntries to tackle this problem by introducing a novel method for texture\nestimation from a single image by first using StyleGAN and 3D Morphable Models.\nThe method begins by generating multi-view faces using the latent space of GAN.\nThen 3DDFA trained on 3DMM estimates a 3D face mesh as well as a\nhigh-resolution texture map that is consistent with the estimated face shape.\nThe result shows that the generated mesh is of high quality with near to\naccurate texture representation.\n","authors":["Rohit Das","Tzung-Han Lin","Ko-Chih Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16009v1.pdf","comment":"7 pages, 4 figures, 2 tables, pre-print version"},{"id":"http://arxiv.org/abs/2410.15981v1","updated":"2024-10-21T13:06:38Z","published":"2024-10-21T13:06:38Z","title":"Visual Representation Learning Guided By Multi-modal Prior Knowledge","summary":"  Despite the remarkable success of deep neural networks (DNNs) in computer\nvision, they fail to remain high-performing when facing distribution shifts\nbetween training and testing data. In this paper, we propose Knowledge-Guided\nVisual representation learning (KGV), a distribution-based learning approach\nleveraging multi-modal prior knowledge, to improve generalization under\ndistribution shift. We use prior knowledge from two distinct modalities: 1) a\nknowledge graph (KG) with hierarchical and association relationships; and 2)\ngenerated synthetic images of visual elements semantically represented in the\nKG. The respective embeddings are generated from the given modalities in a\ncommon latent space, i.e., visual embeddings from original and synthetic images\nas well as knowledge graph embeddings (KGEs). These embeddings are aligned via\na novel variant of translation-based KGE methods, where the node and relation\nembeddings of the KG are modeled as Gaussian distributions and translations\nrespectively. We claim that incorporating multi-model prior knowledge enables\nmore regularized learning of image representations. Thus, the models are able\nto better generalize across different data distributions. We evaluate KGV on\ndifferent image classification tasks with major or minor distribution shifts,\nnamely road sign classification across datasets from Germany, China, and\nRussia, image classification with the mini-ImageNet dataset and its variants,\nas well as the DVM-CAR dataset. The results demonstrate that KGV consistently\nexhibits higher accuracy and data efficiency than the baselines across all\nexperiments.\n","authors":["Hongkuan Zhou","Lavdim Halilaj","Sebastian Monka","Stefan Schmid","Yuqicheng Zhu","Bo Xiong","Steffen Staab"],"pdf_url":"https://arxiv.org/pdf/2410.15981v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15980v1","updated":"2024-10-21T13:06:21Z","published":"2024-10-21T13:06:21Z","title":"Granularity Matters in Long-Tail Learning","summary":"  Balancing training on long-tail data distributions remains a long-standing\nchallenge in deep learning. While methods such as re-weighting and re-sampling\nhelp alleviate the imbalance issue, limited sample diversity continues to\nhinder models from learning robust and generalizable feature representations,\nparticularly for tail classes. In contrast to existing methods, we offer a\nnovel perspective on long-tail learning, inspired by an observation: datasets\nwith finer granularity tend to be less affected by data imbalance. In this\npaper, we investigate this phenomenon through both quantitative and qualitative\nstudies, showing that increased granularity enhances the generalization of\nlearned features in tail categories. Motivated by these findings, we propose a\nmethod to increase dataset granularity through category extrapolation.\nSpecifically, we introduce open-set auxiliary classes that are visually similar\nto existing ones, aiming to enhance representation learning for both head and\ntail classes. This forms the core contribution and insight of our approach. To\nautomate the curation of auxiliary data, we leverage large language models\n(LLMs) as knowledge bases to search for auxiliary categories and retrieve\nrelevant images through web crawling. To prevent the overwhelming presence of\nauxiliary classes from disrupting training, we introduce a neighbor-silencing\nloss that encourages the model to focus on class discrimination within the\ntarget dataset. During inference, the classifier weights for auxiliary\ncategories are masked out, leaving only the target class weights for use.\nExtensive experiments and ablation studies on three standard long-tail\nbenchmarks demonstrate the effectiveness of our approach, notably outperforming\nstrong baseline methods that use the same amount of data. The code will be made\npublicly available.\n","authors":["Shizhen Zhao","Xin Wen","Jiahui Liu","Chuofan Ma","Chunfeng Yuan","Xiaojuan Qi"],"pdf_url":"https://arxiv.org/pdf/2410.15980v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15971v1","updated":"2024-10-21T12:58:19Z","published":"2024-10-21T12:58:19Z","title":"Zero-Shot Scene Reconstruction from Single Images with Deep Prior\n  Assembly","summary":"  Large language and vision models have been leading a revolution in visual\ncomputing. By greatly scaling up sizes of data and model parameters, the large\nmodels learn deep priors which lead to remarkable performance in various tasks.\nIn this work, we present deep prior assembly, a novel framework that assembles\ndiverse deep priors from large models for scene reconstruction from single\nimages in a zero-shot manner. We show that this challenging task can be done\nwithout extra knowledge but just simply generalizing one deep prior in one\nsub-task. To this end, we introduce novel methods related to poses, scales, and\nocclusion parsing which are keys to enable deep priors to work together in a\nrobust way. Deep prior assembly does not require any 3D or 2D data-driven\ntraining in the task and demonstrates superior performance in generalizing\npriors to open-world scenes. We conduct evaluations on various datasets, and\nreport analysis, numerical and visual comparisons with the latest methods to\nshow our superiority. Project page:\nhttps://junshengzhou.github.io/DeepPriorAssembly.\n","authors":["Junsheng Zhou","Yu-Shen Liu","Zhizhong Han"],"pdf_url":"https://arxiv.org/pdf/2410.15971v1.pdf","comment":"To appear at NeurIPS 2024. Project page:\n  https://junshengzhou.github.io/DeepPriorAssembly"},{"id":"http://arxiv.org/abs/2405.17991v2","updated":"2024-10-21T12:53:21Z","published":"2024-05-28T09:23:14Z","title":"VeLoRA: Memory Efficient Training using Rank-1 Sub-Token Projections","summary":"  Large language models (LLMs) have recently emerged as powerful tools for\ntackling many language-processing tasks. Despite their success, training and\nfine-tuning these models is still far too computationally and memory intensive.\nIn this paper, we identify and characterise the important components needed for\neffective model convergence using gradient descent. In doing so we find that\nthe intermediate activations used to implement backpropagation can be\nexcessively compressed without incurring any degradation in performance. This\nresult leads us to a cheap and memory-efficient algorithm for both fine-tuning\nand pre-training LLMs. The proposed algorithm simply divides the tokens up into\nsmaller sub-tokens before projecting them onto a fixed 1-dimensional subspace\nduring the forward pass. These features are then coarsely reconstructed during\nthe backward pass to implement the update rules. We confirm the effectiveness\nof our algorithm as being complimentary to many state-of-the-art PEFT methods\non the VTAB-1k fine-tuning benchmark. Furthermore, we outperform QLoRA for\nfine-tuning LLaMA and show competitive performance against other\nmemory-efficient pre-training methods on the large-scale C4 dataset.\n","authors":["Roy Miles","Pradyumna Reddy","Ismail Elezi","Jiankang Deng"],"pdf_url":"https://arxiv.org/pdf/2405.17991v2.pdf","comment":"NeurIPS 2024. Code available at https://github.com/roymiles/VeLoRA"},{"id":"http://arxiv.org/abs/2410.15961v1","updated":"2024-10-21T12:47:36Z","published":"2024-10-21T12:47:36Z","title":"A Paradigm Shift in Mouza Map Vectorization: A Human-Machine\n  Collaboration Approach","summary":"  Efficient vectorization of hand-drawn cadastral maps, such as Mouza maps in\nBangladesh, poses a significant challenge due to their complex structures.\nCurrent manual digitization methods are time-consuming and labor-intensive. Our\nstudy proposes a semi-automated approach to streamline the digitization\nprocess, saving both time and human resources. Our methodology focuses on\nseparating the plot boundaries and plot identifiers and applying our\ndigitization methodology to convert both of them into vectorized format. To\naccomplish full vectorization, Convolutional Neural Network (CNN) models are\nutilized for pre-processing and plot number detection along with our smoothing\nalgorithms based on the diversity of vector maps. The CNN models are trained\nwith our own labeled dataset, generated from the maps, and smoothing algorithms\nare introduced from the various observations of the map's vector formats.\nFurther human intervention remains essential for precision. We have evaluated\nour methods on several maps and provided both quantitative and qualitative\nresults with user study. The result demonstrates that our methodology\noutperforms the existing map digitization processes significantly.\n","authors":["Mahir Shahriar Dhrubo","Samira Akter","Anwarul Bashir Shuaib","Md Toki Tahmid","Zahid Hasan","A. B. M. Alim Al Islam"],"pdf_url":"https://arxiv.org/pdf/2410.15961v1.pdf","comment":"13 pages including reference, 14 figures, 4 tables"},{"id":"http://arxiv.org/abs/2410.15959v1","updated":"2024-10-21T12:43:54Z","published":"2024-10-21T12:43:54Z","title":"Diffusion Transformer Policy","summary":"  Recent large visual-language action models pretrained on diverse robot\ndatasets have demonstrated the potential for generalizing to new environments\nwith a few in-domain data. However, those approaches usually predict\ndiscretized or continuous actions by a small action head, which limits the\nability in handling diverse action spaces. In contrast, we model the continuous\naction with a large multi-modal diffusion transformer, dubbed as Diffusion\nTransformer Policy, in which we directly denoise action chunks by a large\ntransformer model rather than a small action head. By leveraging the scaling\ncapability of transformers, the proposed approach can effectively model\ncontinuous end-effector actions across large diverse robot datasets, and\nachieve better generalization performance. Extensive experiments demonstrate\nDiffusion Transformer Policy pretrained on diverse robot data can generalize to\ndifferent embodiments, including simulation environments like Maniskill2 and\nCalvin, as well as the real-world Franka arm. Specifically, without bells and\nwhistles, the proposed approach achieves state-of-the-art performance with only\na single third-view camera stream in the Calvin novel task setting (ABC->D),\nimproving the average number of tasks completed in a row of 5 to 3.6, and the\npretraining stage significantly facilitates the success sequence length on the\nCalvin by over 1.2. The code will be publicly available.\n","authors":["Zhi Hou","Tianyi Zhang","Yuwen Xiong","Hengjun Pu","Chengyang Zhao","Ronglei Tong","Yu Qiao","Jifeng Dai","Yuntao Chen"],"pdf_url":"https://arxiv.org/pdf/2410.15959v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.15957v1","updated":"2024-10-21T12:36:27Z","published":"2024-10-21T12:36:27Z","title":"CamI2V: Camera-Controlled Image-to-Video Diffusion Model","summary":"  Recently, camera pose, as a user-friendly and physics-related condition, has\nbeen introduced into text-to-video diffusion model for camera control. However,\nexisting methods simply inject camera conditions through a side input. These\napproaches neglect the inherent physical knowledge of camera pose, resulting in\nimprecise camera control, inconsistencies, and also poor interpretability. In\nthis paper, we emphasize the necessity of integrating explicit physical\nconstraints into model design. Epipolar attention is proposed for modeling all\ncross-frame relationships from a novel perspective of noised condition. This\nensures that features are aggregated from corresponding epipolar lines in all\nnoised frames, overcoming the limitations of current attention mechanisms in\ntracking displaced features across frames, especially when features move\nsignificantly with the camera and become obscured by noise. Additionally, we\nintroduce register tokens to handle cases without intersections between frames,\ncommonly caused by rapid camera movements, dynamic objects, or occlusions. To\nsupport image-to-video, we propose the multiple guidance scale to allow for\nprecise control for image, text, and camera, respectively. Furthermore, we\nestablish a more robust and reproducible evaluation pipeline to solve the\ninaccuracy and instability of existing camera control measurement. We achieve a\n25.5\\% improvement in camera controllability on RealEstate10K while maintaining\nstrong generalization to out-of-domain images. Only 24GB and 12GB are required\nfor training and inference, respectively. We plan to release checkpoints, along\nwith training and evaluation codes. Dynamic videos are best viewed at\n\\url{https://zgctroy.github.io/CamI2V}.\n","authors":["Guangcong Zheng","Teng Li","Rui Jiang","Yehao Lu","Tao Wu","Xi Li"],"pdf_url":"https://arxiv.org/pdf/2410.15957v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15947v1","updated":"2024-10-21T12:26:53Z","published":"2024-10-21T12:26:53Z","title":"AI-Driven Approaches for Glaucoma Detection -- A Comprehensive Review","summary":"  The diagnosis of glaucoma plays a critical role in the management and\ntreatment of this vision-threatening disease. Glaucoma is a group of eye\ndiseases that cause blindness by damaging the optic nerve at the back of the\neye. Often called \"silent thief of sight\", it exhibits no symptoms during the\nearly stages. Therefore, early detection is crucial to prevent vision loss.\nWith the rise of Artificial Intelligence (AI), particularly Deep Learning (DL)\ntechniques, Computer-Aided Diagnosis (CADx) systems have emerged as promising\ntools to assist clinicians in accurately diagnosing glaucoma early. This paper\naims to provide a comprehensive overview of AI techniques utilized in CADx\nsystems for glaucoma diagnosis. Through a detailed analysis of current\nliterature, we identify key gaps and challenges in these systems, emphasizing\nthe need for improved safety, reliability, interpretability, and\nexplainability. By identifying research gaps, we aim to advance the field of\nCADx systems especially for the early diagnosis of glaucoma, in order to\nprevent any potential loss of vision.\n","authors":["Yuki Hagiwara","Octavia-Andreaa Ciora","Maureen Monnet","Gino Lancho","Jeanette Miriam Lorenz"],"pdf_url":"https://arxiv.org/pdf/2410.15947v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15941v1","updated":"2024-10-21T12:13:43Z","published":"2024-10-21T12:13:43Z","title":"MBPU: A Plug-and-Play State Space Model for Point Cloud Upsamping with\n  Fast Point Rendering","summary":"  The task of point cloud upsampling (PCU) is to generate dense and uniform\npoint clouds from sparse input captured by 3D sensors like LiDAR, holding\npotential applications in real yet is still a challenging task. Existing deep\nlearning-based methods have shown significant achievements in this field.\nHowever, they still face limitations in effectively handling long sequences and\naddressing the issue of shrinkage artifacts around the surface of the point\ncloud. Inspired by the newly proposed Mamba, in this paper, we introduce a\nnetwork named MBPU built on top of the Mamba architecture, which performs well\nin long sequence modeling, especially for large-scale point cloud upsampling,\nand achieves fast convergence speed. Moreover, MBPU is an arbitrary-scale\nupsampling framework as the predictor of point distance in the point refinement\nphase. At the same time, we simultaneously predict the 3D position shift and 1D\npoint-to-point distance as regression quantities to constrain the global\nfeatures while ensuring the accuracy of local details. We also introduce a fast\ndifferentiable renderer to further enhance the fidelity of the upsampled point\ncloud and reduce artifacts. It is noted that, by the merits of our fast point\nrendering, MBPU yields high-quality upsampled point clouds by effectively\neliminating surface noise. Extensive experiments have demonstrated that our\nMBPU outperforms other off-the-shelf methods in terms of point cloud\nupsampling, especially for large-scale point clouds.\n","authors":["Jiayi Song","Weidong Yang","Zhijun Li","Wen-Ming Chen","Ben Fei"],"pdf_url":"https://arxiv.org/pdf/2410.15941v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15932v1","updated":"2024-10-21T12:00:52Z","published":"2024-10-21T12:00:52Z","title":"Focus on BEV: Self-calibrated Cycle View Transformation for Monocular\n  Birds-Eye-View Segmentation","summary":"  Birds-Eye-View (BEV) segmentation aims to establish a spatial mapping from\nthe perspective view to the top view and estimate the semantic maps from\nmonocular images. Recent studies have encountered difficulties in view\ntransformation due to the disruption of BEV-agnostic features in image space.\nTo tackle this issue, we propose a novel FocusBEV framework consisting of $(i)$\na self-calibrated cross view transformation module to suppress the BEV-agnostic\nimage areas and focus on the BEV-relevant areas in the view transformation\nstage, $(ii)$ a plug-and-play ego-motion-based temporal fusion module to\nexploit the spatiotemporal structure consistency in BEV space with a memory\nbank, and $(iii)$ an occupancy-agnostic IoU loss to mitigate both semantic and\npositional uncertainties. Experimental evidence demonstrates that our approach\nachieves new state-of-the-art on two popular benchmarks,\\ie, 29.2\\% mIoU on\nnuScenes and 35.2\\% mIoU on Argoverse.\n","authors":["Jiawei Zhao","Qixing Jiang","Xuede Li","Junfeng Luo"],"pdf_url":"https://arxiv.org/pdf/2410.15932v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.07255v3","updated":"2024-10-21T11:57:29Z","published":"2024-06-11T13:34:57Z","title":"Towards Realistic Data Generation for Real-World Super-Resolution","summary":"  Existing image super-resolution (SR) techniques often fail to generalize\neffectively in complex real-world settings due to the significant divergence\nbetween training data and practical scenarios. To address this challenge,\nprevious efforts have either manually simulated intricate physical-based\ndegradations or utilized learning-based techniques, yet these approaches remain\ninadequate for producing large-scale, realistic, and diverse data\nsimultaneously. In this paper, we introduce a novel Realistic Decoupled Data\nGenerator (RealDGen), an unsupervised learning data generation framework\ndesigned for real-world super-resolution. We meticulously develop content and\ndegradation extraction strategies, which are integrated into a novel\ncontent-degradation decoupled diffusion model to create realistic\nlow-resolution images from unpaired real LR and HR images. Extensive\nexperiments demonstrate that RealDGen excels in generating large-scale,\nhigh-quality paired data that mirrors real-world degradations, significantly\nadvancing the performance of popular SR models on various real-world\nbenchmarks.\n","authors":["Long Peng","Wenbo Li","Renjing Pei","Jingjing Ren","Yang Wang","Yang Cao","Zheng-Jun Zha"],"pdf_url":"https://arxiv.org/pdf/2406.07255v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15927v1","updated":"2024-10-21T11:55:06Z","published":"2024-10-21T11:55:06Z","title":"GReFEL: Geometry-Aware Reliable Facial Expression Learning under Bias\n  and Imbalanced Data Distribution","summary":"  Reliable facial expression learning (FEL) involves the effective learning of\ndistinctive facial expression characteristics for more reliable, unbiased and\naccurate predictions in real-life settings. However, current systems struggle\nwith FEL tasks because of the variance in people's facial expressions due to\ntheir unique facial structures, movements, tones, and demographics. Biased and\nimbalanced datasets compound this challenge, leading to wrong and biased\nprediction labels. To tackle these, we introduce GReFEL, leveraging Vision\nTransformers and a facial geometry-aware anchor-based reliability balancing\nmodule to combat imbalanced data distributions, bias, and uncertainty in facial\nexpression learning. Integrating local and global data with anchors that learn\ndifferent facial data points and structural features, our approach adjusts\nbiased and mislabeled emotions caused by intra-class disparity, inter-class\nsimilarity, and scale sensitivity, resulting in comprehensive, accurate, and\nreliable facial expression predictions. Our model outperforms current\nstate-of-the-art methodologies, as demonstrated by extensive experiments on\nvarious datasets.\n","authors":["Azmine Toushik Wasi","Taki Hasan Rafi","Raima Islam","Karlo Serbetar","Dong Kyu Chae"],"pdf_url":"https://arxiv.org/pdf/2410.15927v1.pdf","comment":"ACCV 2024. Extended version of ARBEx (arXiv:2305.01486)"},{"id":"http://arxiv.org/abs/2410.15926v1","updated":"2024-10-21T11:54:53Z","published":"2024-10-21T11:54:53Z","title":"Mitigating Object Hallucination via Concentric Causal Attention","summary":"  Recent Large Vision Language Models (LVLMs) present remarkable zero-shot\nconversational and reasoning capabilities given multimodal queries.\nNevertheless, they suffer from object hallucination, a phenomenon where LVLMs\nare prone to generate textual responses not factually aligned with image\ninputs. Our pilot study reveals that object hallucination is closely tied with\nRotary Position Encoding (RoPE), a widely adopted positional dependency\nmodeling design in existing LVLMs. Due to the long-term decay in RoPE, LVLMs\ntend to hallucinate more when relevant visual cues are distant from instruction\ntokens in the multimodal input sequence. Additionally, we observe a similar\neffect when reversing the sequential order of visual tokens during multimodal\nalignment. Our tests indicate that long-term decay in RoPE poses challenges to\nLVLMs while capturing visual-instruction interactions across long distances. We\npropose Concentric Causal Attention (CCA), a simple yet effective positional\nalignment strategy that mitigates the impact of RoPE long-term decay in LVLMs\nby naturally reducing relative distance between visual and instruction tokens.\nWith CCA, visual tokens can better interact with instruction tokens, thereby\nenhancing model's perception capability and alleviating object hallucination.\nWithout bells and whistles, our positional alignment method surpasses existing\nhallucination mitigation strategies by large margins on multiple object\nhallucination benchmarks.\n","authors":["Yun Xing","Yiheng Li","Ivan Laptev","Shijian Lu"],"pdf_url":"https://arxiv.org/pdf/2410.15926v1.pdf","comment":"To appear at NeurIPS 2024. Code is available at\n  https://github.com/xing0047/cca-llava"},{"id":"http://arxiv.org/abs/2408.11958v2","updated":"2024-10-21T11:49:56Z","published":"2024-08-21T19:25:03Z","title":"CARLA Drone: Monocular 3D Object Detection from a Different Perspective","summary":"  Existing techniques for monocular 3D detection have a serious restriction.\nThey tend to perform well only on a limited set of benchmarks, faring well\neither on ego-centric car views or on traffic camera views, but rarely on both.\nTo encourage progress, this work advocates for an extended evaluation of 3D\ndetection frameworks across different camera perspectives. We make two key\ncontributions. First, we introduce the CARLA Drone dataset, CDrone. Simulating\ndrone views, it substantially expands the diversity of camera perspectives in\nexisting benchmarks. Despite its synthetic nature, CDrone represents a\nreal-world challenge. To show this, we confirm that previous techniques\nstruggle to perform well both on CDrone and a real-world 3D drone dataset.\nSecond, we develop an effective data augmentation pipeline called GroundMix.\nIts distinguishing element is the use of the ground for creating 3D-consistent\naugmentation of a training image. GroundMix significantly boosts the detection\naccuracy of a lightweight one-stage detector. In our expanded evaluation, we\nachieve the average precision on par with or substantially higher than the\nprevious state of the art across all tested datasets.\n","authors":["Johannes Meier","Luca Scalerandi","Oussema Dhaouadi","Jacques Kaiser","Nikita Araslanov","Daniel Cremers"],"pdf_url":"https://arxiv.org/pdf/2408.11958v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15919v1","updated":"2024-10-21T11:49:10Z","published":"2024-10-21T11:49:10Z","title":"Are Large-scale Soft Labels Necessary for Large-scale Dataset\n  Distillation?","summary":"  In ImageNet-condensation, the storage for auxiliary soft labels exceeds that\nof the condensed dataset by over 30 times. However, are large-scale soft labels\nnecessary for large-scale dataset distillation? In this paper, we first\ndiscover that the high within-class similarity in condensed datasets\nnecessitates the use of large-scale soft labels. This high within-class\nsimilarity can be attributed to the fact that previous methods use samples from\ndifferent classes to construct a single batch for batch normalization (BN)\nmatching. To reduce the within-class similarity, we introduce class-wise\nsupervision during the image synthesizing process by batching the samples\nwithin classes, instead of across classes. As a result, we can increase\nwithin-class diversity and reduce the size of required soft labels. A key\nbenefit of improved image diversity is that soft label compression can be\nachieved through simple random pruning, eliminating the need for complex\nrule-based strategies. Experiments validate our discoveries. For example, when\ncondensing ImageNet-1K to 200 images per class, our approach compresses the\nrequired soft labels from 113 GB to 2.8 GB (40x compression) with a 2.6%\nperformance gain. Code is available at:\nhttps://github.com/he-y/soft-label-pruning-for-dataset-distillation\n","authors":["Lingao Xiao","Yang He"],"pdf_url":"https://arxiv.org/pdf/2410.15919v1.pdf","comment":"Accepted by Neurips 2024"},{"id":"http://arxiv.org/abs/2410.15916v1","updated":"2024-10-21T11:46:28Z","published":"2024-10-21T11:46:28Z","title":"Leveraging CORAL-Correlation Consistency Network for Semi-Supervised\n  Left Atrium MRI Segmentation","summary":"  Semi-supervised learning (SSL) has been widely used to learn from both a few\nlabeled images and many unlabeled images to overcome the scarcity of labeled\nsamples in medical image segmentation. Most current SSL-based segmentation\nmethods use pixel values directly to identify similar features in labeled and\nunlabeled data. They usually fail to accurately capture the intricate\nattachment structures in the left atrium, such as the areas of inconsistent\ndensity or exhibit outward curvatures, adding to the complexity of the task. In\nthis paper, we delve into this issue and introduce an effective solution,\nCORAL(Correlation-Aligned)-Correlation Consistency Network (CORN), to capture\nthe global structure shape and local details of Left Atrium. Diverging from\nprevious methods focused on each local pixel value, the CORAL-Correlation\nConsistency Module (CCM) in the CORN leverages second-order statistical\ninformation to capture global structural features by minimizing the\ndistribution discrepancy between labeled and unlabeled samples in feature\nspace. Yet, direct construction of features from unlabeled data frequently\nresults in ``Sample Selection Bias'', leading to flawed supervision. We thus\nfurther propose the Dynamic Feature Pool (DFP) for the CCM, which utilizes a\nconfidence-based filtering strategy to remove incorrectly selected features and\nregularize both teacher and student models by constraining the similarity\nmatrix to be consistent. Extensive experiments on the Left Atrium dataset have\nshown that the proposed CORN outperforms previous state-of-the-art\nsemi-supervised learning methods.\n","authors":["Xinze Li","Runlin Huang","Zhenghao Wu","Bohan Yang","Wentao Fan","Chengzhang Zhu","Weifeng Su"],"pdf_url":"https://arxiv.org/pdf/2410.15916v1.pdf","comment":"5 pages, 3 figures, Accepted by 2024 IEEE International Conference on\n  Bioinformatics and Biomedicine (BIBM 2024)"},{"id":"http://arxiv.org/abs/2403.17633v4","updated":"2024-10-21T11:34:27Z","published":"2024-03-26T12:08:14Z","title":"UADA3D: Unsupervised Adversarial Domain Adaptation for 3D Object\n  Detection with Sparse LiDAR and Large Domain Gaps","summary":"  In this study, we address a gap in existing unsupervised domain adaptation\napproaches on LiDAR-based 3D object detection, which have predominantly\nconcentrated on adapting between established, high-density autonomous driving\ndatasets. We focus on sparser point clouds, capturing scenarios from different\nperspectives: not just from vehicles on the road but also from mobile robots on\nsidewalks, which encounter significantly different environmental conditions and\nsensor configurations. We introduce Unsupervised Adversarial Domain Adaptation\nfor 3D Object Detection (UADA3D). UADA3D does not depend on pre-trained source\nmodels or teacher-student architectures. Instead, it uses an adversarial\napproach to directly learn domain-invariant features. We demonstrate its\nefficacy in various adaptation scenarios, showing significant improvements in\nboth self-driving car and mobile robot domains. Our code is open-source and\nwill be available soon.\n","authors":["Maciej K Wozniak","Mattias Hansson","Marko Thiel","Patric Jensfelt"],"pdf_url":"https://arxiv.org/pdf/2403.17633v4.pdf","comment":"Accepted for IEEE RA-L 2024"},{"id":"http://arxiv.org/abs/2410.15909v1","updated":"2024-10-21T11:32:46Z","published":"2024-10-21T11:32:46Z","title":"Hybrid Architecture for Real-Time Video Anomaly Detection: Integrating\n  Spatial and Temporal Analysis","summary":"  We propose a new architecture for real-time anomaly detection in video data,\ninspired by human behavior by combining spatial and temporal analyses. This\napproach uses two distinct models: for temporal analysis, a recurrent\nconvolutional network (CNN + RNN) is employed, associating VGG19 and a GRU to\nprocess video sequences. Regarding spatial analysis, it is performed using\nYOLOv7 to analyze individual images. These two analyses can be carried out\neither in parallel, with a final prediction that combines the results of both\nanalyses, or in series, where the spatial analysis enriches the data before the\ntemporal analysis. In this article, we will compare these two architectural\nconfigurations with each other, to evaluate the effectiveness of our hybrid\napproach in video anomaly detection.\n","authors":["Fabien Poirier"],"pdf_url":"https://arxiv.org/pdf/2410.15909v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15907v1","updated":"2024-10-21T11:29:35Z","published":"2024-10-21T11:29:35Z","title":"Seismic Phase Picking","summary":"  Seismic phase picking, which aims to determine the arrival time of P- and\nS-waves according to seismic waveforms, is fundamental to earthquake\nmonitoring. Generally, manual phase picking is trustworthy, but with the\nincreasing number of worldwide stations and seismic monitors, it becomes more\nchallenging for human to complete the task comprehensively. In this work, we\nexplore multiple ways to do automatic phase picking, including traditional and\nlearning-based methods.\n","authors":["Yuchen Wang","Ruihuan Wang"],"pdf_url":"https://arxiv.org/pdf/2410.15907v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07758v2","updated":"2024-10-21T11:12:38Z","published":"2024-10-10T09:37:33Z","title":"HeightFormer: A Semantic Alignment Monocular 3D Object Detection Method\n  from Roadside Perspective","summary":"  The on-board 3D object detection technology has received extensive attention\nas a critical technology for autonomous driving, while few studies have focused\non applying roadside sensors in 3D traffic object detection. Existing studies\nachieve the projection of 2D image features to 3D features through height\nestimation based on the frustum. However, they did not consider the height\nalignment and the extraction efficiency of bird's-eye-view features. We propose\na novel 3D object detection framework integrating Spatial Former and Voxel\nPooling Former to enhance 2D-to-3D projection based on height estimation.\nExtensive experiments were conducted using the Rope3D and DAIR-V2X-I dataset,\nand the results demonstrated the outperformance of the proposed algorithm in\nthe detection of both vehicles and cyclists. These results indicate that the\nalgorithm is robust and generalized under various detection scenarios.\nImproving the accuracy of 3D object detection on the roadside is conducive to\nbuilding a safe and trustworthy intelligent transportation system of\nvehicle-road coordination and promoting the large-scale application of\nautonomous driving. The code and pre-trained models will be released on\nhttps://anonymous.4open.science/r/HeightFormer.\n","authors":["Pei Liu","Zihao Zhang","Haipeng Liu","Nanfang Zheng","Meixin Zhu","Ziyuan Pu"],"pdf_url":"https://arxiv.org/pdf/2410.07758v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15891v1","updated":"2024-10-21T11:10:07Z","published":"2024-10-21T11:10:07Z","title":"TexPro: Text-guided PBR Texturing with Procedural Material Modeling","summary":"  In this paper, we present TexPro, a novel method for high-fidelity material\ngeneration for input 3D meshes given text prompts. Unlike existing\ntext-conditioned texture generation methods that typically generate RGB\ntextures with baked lighting, TexPro is able to produce diverse texture maps\nvia procedural material modeling, which enables physical-based rendering,\nrelighting, and additional benefits inherent to procedural materials.\nSpecifically, we first generate multi-view reference images given the input\ntextual prompt by employing the latest text-to-image model. We then derive\ntexture maps through a rendering-based optimization with recent differentiable\nprocedural materials. To this end, we design several techniques to handle the\nmisalignment between the generated multi-view images and 3D meshes, and\nintroduce a novel material agent that enhances material classification and\nmatching by exploring both part-level understanding and object-aware material\nreasoning. Experiments demonstrate the superiority of the proposed method over\nexisting SOTAs and its capability of relighting.\n","authors":["Ziqiang Dang","Wenqi Dong","Zesong Yang","Bangbang Yang","Liang Li","Yuewen Ma","Zhaopeng Cui"],"pdf_url":"https://arxiv.org/pdf/2410.15891v1.pdf","comment":"In submission. Supplementary material is included at the end of the\n  main paper (5 pages, 2 figures)"},{"id":"http://arxiv.org/abs/2410.15886v1","updated":"2024-10-21T11:04:58Z","published":"2024-10-21T11:04:58Z","title":"Foundation Models for Slide-level Cancer Subtyping in Digital Pathology","summary":"  Since the emergence of the ImageNet dataset, the pretraining and fine-tuning\napproach has become widely adopted in computer vision due to the ability of\nImageNet-pretrained models to learn a wide variety of visual features. However,\na significant challenge arises when adapting these models to domain-specific\nfields, such as digital pathology, due to substantial gaps between domains. To\naddress this limitation, foundation models (FM) have been trained on\nlarge-scale in-domain datasets to learn the intricate features of\nhistopathology images. In cancer diagnosis, whole-slide image (WSI) prediction\nis essential for patient prognosis, and multiple instance learning (MIL) has\nbeen implemented to handle the giga-pixel size of WSI. As MIL frameworks rely\non patch-level feature aggregation, this work aims to compare the performance\nof various feature extractors developed under different pretraining strategies\nfor cancer subtyping on WSI under a MIL framework. Results demonstrate the\nability of foundation models to surpass ImageNet-pretrained models for the\nprediction of six skin cancer subtypes\n","authors":["Pablo Meseguer","Rocío del Amor","Adrian Colomer","Valery Naranjo"],"pdf_url":"https://arxiv.org/pdf/2410.15886v1.pdf","comment":"Manuscript accepted for oral presentation at Decision Science\n  Allieance -INternational Summer Conference (DSA-ISC) 2024 held on Valencia,\n  Spain"},{"id":"http://arxiv.org/abs/2408.17433v2","updated":"2024-10-21T11:01:46Z","published":"2024-08-30T17:35:06Z","title":"DARES: Depth Anything in Robotic Endoscopic Surgery with Self-supervised\n  Vector-LoRA of the Foundation Model","summary":"  Robotic-assisted surgery (RAS) relies on accurate depth estimation for 3D\nreconstruction and visualization. While foundation models like Depth Anything\nModels (DAM) show promise, directly applying them to surgery often yields\nsuboptimal results. Fully fine-tuning on limited surgical data can cause\noverfitting and catastrophic forgetting, compromising model robustness and\ngeneralization. Although Low-Rank Adaptation (LoRA) addresses some adaptation\nissues, its uniform parameter distribution neglects the inherent feature\nhierarchy, where earlier layers, learning more general features, require more\nparameters than later ones. To tackle this issue, we introduce Depth Anything\nin Robotic Endoscopic Surgery (DARES), a novel approach that employs a new\nadaptation technique, Vector Low-Rank Adaptation (Vector-LoRA) on the DAM V2 to\nperform self-supervised monocular depth estimation in RAS scenes. To enhance\nlearning efficiency, we introduce Vector-LoRA by integrating more parameters in\nearlier layers and gradually decreasing parameters in later layers. We also\ndesign a reprojection loss based on the multi-scale SSIM error to enhance depth\nperception by better tailoring the foundation model to the specific\nrequirements of the surgical environment. The proposed method is validated on\nthe SCARED dataset and demonstrates superior performance over recent\nstate-of-the-art self-supervised monocular depth estimation techniques,\nachieving an improvement of 13.3% in the absolute relative error metric. The\ncode and pre-trained weights are available at\nhttps://github.com/mobarakol/DARES.\n","authors":["Mona Sheikh Zeinoddin","Chiara Lena","Jiongqi Qu","Luca Carlini","Mattia Magro","Seunghoi Kim","Elena De Momi","Sophia Bano","Matthew Grech-Sollars","Evangelos Mazomenos","Daniel C. Alexander","Danail Stoyanov","Matthew J. Clarkson","Mobarakol Islam"],"pdf_url":"https://arxiv.org/pdf/2408.17433v2.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2410.15882v1","updated":"2024-10-21T11:01:44Z","published":"2024-10-21T11:01:44Z","title":"Distributed Learning for UAV Swarms","summary":"  Unmanned Aerial Vehicle (UAV) swarms are increasingly deployed in dynamic,\ndata-rich environments for applications such as environmental monitoring and\nsurveillance. These scenarios demand efficient data processing while\nmaintaining privacy and security, making Federated Learning (FL) a promising\nsolution. FL allows UAVs to collaboratively train global models without sharing\nraw data, but challenges arise due to the non-Independent and Identically\nDistributed (non-IID) nature of the data collected by UAVs. In this study, we\nshow an integration of the state-of-the-art FL methods to UAV Swarm application\nand invetigate the performance of multiple aggregation methods (namely FedAvg,\nFedProx, FedOpt, and MOON) with a particular focus on tackling non-IID on a\nvariety of datasets, specifically MNIST for baseline performance, CIFAR10 for\nnatural object classification, EuroSAT for environment monitoring, and CelebA\nfor surveillance. These algorithms were selected to cover improved techniques\non both client-side updates and global aggregation. Results show that while all\nalgorithms perform comparably on IID data, their performance deteriorates\nsignificantly under non-IID conditions. FedProx demonstrated the most stable\noverall performance, emphasising the importance of regularising local updates\nin non-IID environments to mitigate drastic deviations in local models.\n","authors":["Chen Hu","Hanchi Ren","Jingjing Deng","Xianghua Xie"],"pdf_url":"https://arxiv.org/pdf/2410.15882v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15881v1","updated":"2024-10-21T11:01:20Z","published":"2024-10-21T11:01:20Z","title":"MI-VisionShot: Few-shot adaptation of vision-language models for\n  slide-level classification of histopathological images","summary":"  Vision-language supervision has made remarkable strides in learning visual\nrepresentations from textual guidance. In digital pathology, vision-language\nmodels (VLM), pre-trained on curated datasets of histological image-captions,\nhave been adapted to downstream tasks, such as region of interest\nclassification. Zero-shot transfer for slide-level prediction has been\nformulated by MI-Zero, but it exhibits high variability depending on the\ntextual prompts. Inspired by prototypical learning, we propose MI-VisionShot, a\ntraining-free adaptation method on top of VLMs to predict slide-level labels in\nfew-shot learning scenarios. Our framework takes advantage of the excellent\nrepresentation learning of VLM to create prototype-based classifiers under a\nmultiple-instance setting by retrieving the most discriminative patches within\neach slide. Experimentation through different settings shows the ability of\nMI-VisionShot to surpass zero-shot transfer with lower variability, even in\nlow-shot scenarios. Code coming soon at\nthttps://github.com/cvblab/MIVisionShot.\n","authors":["Pablo Meseguer","Rocío del Amor","Valery Naranjo"],"pdf_url":"https://arxiv.org/pdf/2410.15881v1.pdf","comment":"Manuscript accepted for oral presentation at KES-InnovationInMedicine\n  2024 held on Madeira, Portugal"},{"id":"http://arxiv.org/abs/2404.07989v3","updated":"2024-10-21T10:54:55Z","published":"2024-04-11T17:59:45Z","title":"Any2Point: Empowering Any-modality Large Models for Efficient 3D\n  Understanding","summary":"  Large foundation models have recently emerged as a prominent focus of\ninterest, attaining superior performance in widespread scenarios. Due to the\nscarcity of 3D data, many efforts have been made to adapt pre-trained\ntransformers from vision to 3D domains. However, such 2D-to-3D approaches are\nstill limited, due to the potential loss of spatial geometries and high\ncomputation cost. More importantly, their frameworks are mainly designed for 2D\nmodels, lacking a general any-to-3D paradigm. In this paper, we introduce\nAny2Point, a parameter-efficient method to empower any-modality large models\n(vision, language, audio) for 3D understanding. Given a frozen transformer from\nany source modality, we propose a 3D-to-any (1D or 2D) virtual projection\nstrategy that correlates the input 3D points to the original 1D or 2D positions\nwithin the source modality. This mechanism enables us to assign each 3D token\nwith a positional encoding paired with the pre-trained model, which avoids 3D\ngeometry loss caused by the true projection and better motivates the\ntransformer for 3D learning with 1D/2D positional priors. Then, within each\ntransformer block, we insert an any-to-3D guided adapter module for\nparameter-efficient fine-tuning. The adapter incorporates prior spatial\nknowledge from the source modality to guide the local feature aggregation of 3D\ntokens, compelling the semantic adaption of any-modality transformers. We\nconduct extensive experiments to showcase the effectiveness and efficiency of\nour method. Code and models are released at\nhttps://github.com/Ivan-Tang-3D/Any2Point.\n","authors":["Yiwen Tang","Ray Zhang","Jiaming Liu","Zoey Guo","Dong Wang","Zhigang Wang","Bin Zhao","Shanghang Zhang","Peng Gao","Hongsheng Li","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2404.07989v3.pdf","comment":"Code and models are released at\n  https://github.com/Ivan-Tang-3D/Any2Point"},{"id":"http://arxiv.org/abs/2410.15866v1","updated":"2024-10-21T10:50:00Z","published":"2024-10-21T10:50:00Z","title":"Visual Motif Identification: Elaboration of a Curated Comparative\n  Dataset and Classification Methods","summary":"  In cinema, visual motifs are recurrent iconographic compositions that carry\nartistic or aesthetic significance. Their use throughout the history of visual\narts and media is interesting to researchers and filmmakers alike. Our goal in\nthis work is to recognise and classify these motifs by proposing a new machine\nlearning model that uses a custom dataset to that end. We show how features\nextracted from a CLIP model can be leveraged by using a shallow network and an\nappropriate loss to classify images into 20 different motifs, with surprisingly\ngood results: an $F_1$-score of 0.91 on our test set. We also present several\nablation studies justifying the input features, architecture and\nhyperparameters used.\n","authors":["Adam Phillips","Daniel Grandes Rodriguez","Miriam Sánchez-Manzano","Alan Salvadó","Manuel Garin","Gloria Haro","Coloma Ballester"],"pdf_url":"https://arxiv.org/pdf/2410.15866v1.pdf","comment":"17 pages, 11 figures, one table, to be published in the conference\n  proceedings of ECCV 2024"},{"id":"http://arxiv.org/abs/2310.03059v8","updated":"2024-10-21T10:49:59Z","published":"2023-10-04T16:49:36Z","title":"Point-PEFT: Parameter-Efficient Fine-Tuning for 3D Pre-trained Models","summary":"  The popularity of pre-trained large models has revolutionized downstream\ntasks across diverse fields, such as language, vision, and multi-modality. To\nminimize the adaption cost for downstream tasks, many Parameter-Efficient\nFine-Tuning (PEFT) techniques are proposed for language and 2D image\npre-trained models. However, the specialized PEFT method for 3D pre-trained\nmodels is still under-explored. To this end, we introduce Point-PEFT, a novel\nframework for adapting point cloud pre-trained models with minimal learnable\nparameters. Specifically, for a pre-trained 3D model, we freeze most of its\nparameters, and only tune the newly added PEFT modules on downstream tasks,\nwhich consist of a Point-prior Prompt and a Geometry-aware Adapter. The\nPoint-prior Prompt adopts a set of learnable prompt tokens, for which we\npropose to construct a memory bank with domain-specific knowledge, and utilize\na parameter-free attention to enhance the prompt tokens. The Geometry-aware\nAdapter aims to aggregate point cloud features within spatial neighborhoods to\ncapture fine-grained geometric information through local interactions.\nExtensive experiments indicate that our Point-PEFT can achieve better\nperformance than the full fine-tuning on various downstream tasks, while using\nonly 5% of the trainable parameters, demonstrating the efficiency and\neffectiveness of our approach. Code is released at\nhttps://github.com/Ivan-Tang-3D/Point-PEFT.\n","authors":["Yiwen Tang","Ray Zhang","Zoey Guo","Dong Wang","Zhigang Wang","Bin Zhao","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2310.03059v8.pdf","comment":"The specialized PEFT framework for 3D pre-trained models, which\n  achieves competitive performance to full fine-tuning, and significantly\n  reduces the computational resources. Project page:\n  https://github.com/Ivan-Tang-3D/Point-PEFT"},{"id":"http://arxiv.org/abs/2410.15851v1","updated":"2024-10-21T10:27:57Z","published":"2024-10-21T10:27:57Z","title":"R2I-rPPG: A Robust Region of Interest Selection Method for Remote\n  Photoplethysmography to Extract Heart Rate","summary":"  The COVID-19 pandemic has underscored the need for low-cost, scalable\napproaches to measuring contactless vital signs, either during initial triage\nat a healthcare facility or virtual telemedicine visits. Remote\nphotoplethysmography (rPPG) can accurately estimate heart rate (HR) when\napplied to close-up videos of healthy volunteers in well-lit laboratory\nsettings. However, results from such highly optimized laboratory studies may\nnot be readily translated to healthcare settings. One significant barrier to\nthe practical application of rPPG in health care is the accurate localization\nof the region of interest (ROI). Clinical or telemedicine visits may involve\nsub-optimal lighting, movement artifacts, variable camera angle, and subject\ndistance. This paper presents an rPPG ROI selection method based on 3D facial\nlandmarks and patient head yaw angle. We then demonstrate the robustness of\nthis ROI selection method when coupled to the Plane-Orthogonal-to-Skin (POS)\nrPPG method when applied to videos of patients presenting to an Emergency\nDepartment for respiratory complaints. Our results demonstrate the\neffectiveness of our proposed approach in improving the accuracy and robustness\nof rPPG in a challenging clinical environment.\n","authors":["Sandeep Nagar","Mark Hasegawa-Johnson","David G. Beiser","Narendra Ahuja"],"pdf_url":"https://arxiv.org/pdf/2410.15851v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2410.15847v1","updated":"2024-10-21T10:19:45Z","published":"2024-10-21T10:19:45Z","title":"Random Token Fusion for Multi-View Medical Diagnosis","summary":"  In multi-view medical diagnosis, deep learning-based models often fuse\ninformation from different imaging perspectives to improve diagnostic\nperformance. However, existing approaches are prone to overfitting and rely\nheavily on view-specific features, which can lead to trivial solutions. In this\nwork, we introduce Random Token Fusion (RTF), a novel technique designed to\nenhance multi-view medical image analysis using vision transformers. By\nintegrating randomness into the feature fusion process during training, RTF\naddresses the issue of overfitting and enhances the robustness and accuracy of\ndiagnostic models without incurring any additional cost at inference. We\nvalidate our approach on standard mammography and chest X-ray benchmark\ndatasets. Through extensive experiments, we demonstrate that RTF consistently\nimproves the performance of existing fusion methods, paving the way for a new\ngeneration of multi-view medical foundation models.\n","authors":["Jingyu Guo","Christos Matsoukas","Fredrik Strand","Kevin Smith"],"pdf_url":"https://arxiv.org/pdf/2410.15847v1.pdf","comment":"Originally published at the NeurIPS 2024 Workshop on Advancements In\n  Medical Foundation Models: Explainability, Robustness, Security, and Beyond\n  (AIM-FM)"},{"id":"http://arxiv.org/abs/2410.12284v2","updated":"2024-10-21T10:11:11Z","published":"2024-10-16T06:43:02Z","title":"Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical\n  Decision-Support Setting","summary":"  The growing capabilities of AI models are leading to their wider use,\nincluding in safety-critical domains. Explainable AI (XAI) aims to make these\nmodels safer to use by making their inference process more transparent.\nHowever, current explainability methods are seldom evaluated in the way they\nare intended to be used: by real-world end users. To address this, we conducted\na large-scale user study with 85 healthcare practitioners in the context of\nhuman-AI collaborative chest X-ray analysis. We evaluated three types of\nexplanations: visual explanations (saliency maps), natural language\nexplanations, and a combination of both modalities. We specifically examined\nhow different explanation types influence users depending on whether the AI\nadvice and explanations are factually correct. We find that text-based\nexplanations lead to significant over-reliance, which is alleviated by\ncombining them with saliency maps. We also observe that the quality of\nexplanations, that is, how much factually correct information they entail, and\nhow much this aligns with AI correctness, significantly impacts the usefulness\nof the different explanation types.\n","authors":["Maxime Kayser","Bayar Menzat","Cornelius Emde","Bogdan Bercean","Alex Novak","Abdala Espinosa","Bartlomiej W. Papiez","Susanne Gaube","Thomas Lukasiewicz","Oana-Maria Camburu"],"pdf_url":"https://arxiv.org/pdf/2410.12284v2.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.15833v1","updated":"2024-10-21T09:50:17Z","published":"2024-10-21T09:50:17Z","title":"LiOn-XA: Unsupervised Domain Adaptation via LiDAR-Only Cross-Modal\n  Adversarial Training","summary":"  In this paper, we propose LiOn-XA, an unsupervised domain adaptation (UDA)\napproach that combines LiDAR-Only Cross-Modal (X) learning with Adversarial\ntraining for 3D LiDAR point cloud semantic segmentation to bridge the domain\ngap arising from environmental and sensor setup changes. Unlike existing works\nthat exploit multiple data modalities like point clouds and RGB image data, we\naddress UDA in scenarios where RGB images might not be available and show that\ntwo distinct LiDAR data representations can learn from each other for UDA. More\nspecifically, we leverage 3D voxelized point clouds to preserve important\ngeometric structure in combination with 2D projection-based range images that\nprovide information such as object orientations or surfaces. To further align\nthe feature space between both domains, we apply adversarial training using\nboth features and predictions of both 2D and 3D neural networks. Our\nexperiments on 3 real-to-real adaptation scenarios demonstrate the\neffectiveness of our approach, achieving new state-of-the-art performance when\ncompared to previous uni- and multi-model UDA methods. Our source code is\npublicly available at https://github.com/JensLe97/lion-xa.\n","authors":["Thomas Kreutz","Jens Lemke","Max Mühlhäuser","Alejandro Sanchez Guinea"],"pdf_url":"https://arxiv.org/pdf/2410.15833v1.pdf","comment":"Preprint, Paper has been accepted at IROS2024"},{"id":"http://arxiv.org/abs/2403.05846v2","updated":"2024-10-21T09:38:03Z","published":"2024-03-09T09:11:49Z","title":"Diffusion Lens: Interpreting Text Encoders in Text-to-Image Pipelines","summary":"  Text-to-image diffusion models (T2I) use a latent representation of a text\nprompt to guide the image generation process. However, the process by which the\nencoder produces the text representation is unknown. We propose the Diffusion\nLens, a method for analyzing the text encoder of T2I models by generating\nimages from its intermediate representations. Using the Diffusion Lens, we\nperform an extensive analysis of two recent T2I models. Exploring compound\nprompts, we find that complex scenes describing multiple objects are composed\nprogressively and more slowly compared to simple scenes; Exploring knowledge\nretrieval, we find that representation of uncommon concepts requires further\ncomputation compared to common concepts, and that knowledge retrieval is\ngradual across layers. Overall, our findings provide valuable insights into the\ntext encoder component in T2I pipelines.\n","authors":["Michael Toker","Hadas Orgad","Mor Ventura","Dana Arad","Yonatan Belinkov"],"pdf_url":"https://arxiv.org/pdf/2403.05846v2.pdf","comment":"Published in: ACL 2024 Project webpage:\n  tokeron.github.io/DiffusionLensWeb"},{"id":"http://arxiv.org/abs/2410.15819v1","updated":"2024-10-21T09:35:57Z","published":"2024-10-21T09:35:57Z","title":"LiMTR: Time Series Motion Prediction for Diverse Road Users through\n  Multimodal Feature Integration","summary":"  Predicting the behavior of road users accurately is crucial to enable the\nsafe operation of autonomous vehicles in urban or densely populated areas.\nTherefore, there has been a growing interest in time series motion prediction\nresearch, leading to significant advancements in state-of-the-art techniques in\nrecent years. However, the potential of using LiDAR data to capture more\ndetailed local features, such as a person's gaze or posture, remains largely\nunexplored. To address this, we develop a novel multimodal approach for motion\nprediction based on the PointNet foundation model architecture, incorporating\nlocal LiDAR features. Evaluation on the Waymo Open Dataset shows a performance\nimprovement of 6.20% and 1.58% in minADE and mAP respectively, when integrated\nand compared with the previous state-of-the-art MTR. We open-source the code of\nour LiMTR model.\n","authors":["Camiel Oerlemans","Bram Grooten","Michiel Braat","Alaa Alassi","Emilia Silvas","Decebal Constantin Mocanu"],"pdf_url":"https://arxiv.org/pdf/2410.15819v1.pdf","comment":"Accepted at the NeurIPS 2024 workshop Time Series in the Age of Large\n  Models. Code available at https://github.com/Cing2/LiMTR"},{"id":"http://arxiv.org/abs/2410.15814v1","updated":"2024-10-21T09:28:42Z","published":"2024-10-21T09:28:42Z","title":"Kaninfradet3D:A Road-side Camera-LiDAR Fusion 3D Perception Model based\n  on Nonlinear Feature Extraction and Intrinsic Correlation","summary":"  With the development of AI-assisted driving, numerous methods have emerged\nfor ego-vehicle 3D perception tasks, but there has been limited research on\nroadside perception. With its ability to provide a global view and a broader\nsensing range, the roadside perspective is worth developing. LiDAR provides\nprecise three-dimensional spatial information, while cameras offer semantic\ninformation. These two modalities are complementary in 3D detection. However,\nadding camera data does not increase accuracy in some studies since the\ninformation extraction and fusion procedure is not sufficiently reliable.\nRecently, Kolmogorov-Arnold Networks (KANs) have been proposed as replacements\nfor MLPs, which are better suited for high-dimensional, complex data. Both the\ncamera and the LiDAR provide high-dimensional information, and employing KANs\nshould enhance the extraction of valuable features to produce better fusion\noutcomes. This paper proposes Kaninfradet3D, which optimizes the feature\nextraction and fusion modules. To extract features from complex\nhigh-dimensional data, the model's encoder and fuser modules were improved\nusing KAN Layers. Cross-attention was applied to enhance feature fusion, and\nvisual comparisons verified that camera features were more evenly integrated.\nThis addressed the issue of camera features being abnormally concentrated,\nnegatively impacting fusion. Compared to the benchmark, our approach shows\nimprovements of +9.87 mAP and +10.64 mAP in the two viewpoints of the TUMTraf\nIntersection Dataset and an improvement of +1.40 mAP in the roadside end of the\nTUMTraf V2X Cooperative Perception Dataset. The results indicate that\nKaninfradet3D can effectively fuse features, demonstrating the potential of\napplying KANs in roadside perception tasks.\n","authors":["Pei Liu","Nanfang Zheng","Yiqun Li","Junlan Chen","Ziyuan Pu"],"pdf_url":"https://arxiv.org/pdf/2410.15814v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15812v1","updated":"2024-10-21T09:27:51Z","published":"2024-10-21T09:27:51Z","title":"FusionLungNet: Multi-scale Fusion Convolution with Refinement Network\n  for Lung CT Image Segmentation","summary":"  Early detection of lung cancer is crucial as it increases the chances of\nsuccessful treatment. Automatic lung image segmentation assists doctors in\nidentifying diseases such as lung cancer, COVID-19, and respiratory disorders.\nHowever, lung segmentation is challenging due to overlapping features like\nvascular and bronchial structures, along with pixel-level fusion of brightness,\ncolor, and texture. New lung segmentation methods face difficulties in\nidentifying long-range relationships between image components, reliance on\nconvolution operations that may not capture all critical features, and the\ncomplex structures of the lungs. Furthermore, semantic gaps between feature\nmaps can hinder the integration of relevant information, reducing model\naccuracy. Skip connections can also limit the decoder's access to complete\ninformation, resulting in partial information loss during encoding. To overcome\nthese challenges, we propose a hybrid approach using the FusionLungNet network,\nwhich has a multi-level structure with key components, including the ResNet-50\nencoder, Channel-wise Aggregation Attention (CAA) module, Multi-scale Feature\nFusion (MFF) block, self refinement (SR) module, and multiple decoders. The\nrefinement sub-network uses convolutional neural networks for image\npost-processing to improve quality. Our method employs a combination of loss\nfunctions, including SSIM, IOU, and focal loss, to optimize image\nreconstruction quality. We created and publicly released a new dataset for lung\nsegmentation called LungSegDB, including 1800 CT images from the LIDC-IDRI\ndataset (dataset version 1) and 700 images from the Chest CT Cancer Images from\nKaggle dataset (dataset version 2). Our method achieved an IOU score of 98.04,\noutperforming existing methods and demonstrating significant improvements in\nsegmentation accuracy. https://github.com/sadjadrz/FusionLungNet\n","authors":["Sadjad Rezvani","Mansoor Fateh","Yeganeh Jalali","Amirreza Fateh"],"pdf_url":"https://arxiv.org/pdf/2410.15812v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15811v1","updated":"2024-10-21T09:25:49Z","published":"2024-10-21T09:25:49Z","title":"Data-Efficient CLIP-Powered Dual-Branch Networks for Source-Free\n  Unsupervised Domain Adaptation","summary":"  Source-Free Unsupervised Domain Adaptation (SF-UDA) aims to transfer a\nmodel's performance from a labeled source domain to an unlabeled target domain\nwithout direct access to source samples, addressing data privacy issues.\nHowever, most existing SF-UDA approaches assume the availability of abundant\nsource domain samples, which is often impractical due to the high cost of data\nannotation. In this paper, we explore a more challenging scenario where direct\naccess to source domain samples is restricted, and the source domain contains\nonly a few samples. To tackle the dual challenges of limited source data and\nprivacy concerns, we introduce a data-efficient, CLIP-powered dual-branch\nnetwork (CDBN in short). We design a cross-modal dual-branch network that\nintegrates source domain class semantics into the unsupervised fine-tuning of\nthe target domain. It preserves the class information from the source domain\nwhile enhancing the model's generalization to the target domain. Additionally,\nwe propose an unsupervised optimization strategy driven by accurate\nclassification and diversity, which aims to retain the classification\ncapability learned from the source domain while producing more confident and\ndiverse predictions in the target domain. Extensive experiments across 31\ntransfer tasks on 7 public datasets demonstrate that our approach achieves\nstate-of-the-art performance compared to existing methods.\n","authors":["Yongguang Li","Yueqi Cao","Jindong Li","Qi Wang","Shengsheng Wang"],"pdf_url":"https://arxiv.org/pdf/2410.15811v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15802v1","updated":"2024-10-21T09:20:33Z","published":"2024-10-21T09:20:33Z","title":"Assisted Physical Interaction: Autonomous Aerial Robots with Neural\n  Network Detection, Navigation, and Safety Layers","summary":"  The paper introduces a novel framework for safe and autonomous aerial\nphysical interaction in industrial settings. It comprises two main components:\na neural network-based target detection system enhanced with edge computing for\nreduced onboard computational load, and a control barrier function (CBF)-based\ncontroller for safe and precise maneuvering. The target detection system is\ntrained on a dataset under challenging visual conditions and evaluated for\naccuracy across various unseen data with changing lighting conditions. Depth\nfeatures are utilized for target pose estimation, with the entire detection\nframework offloaded into low-latency edge computing. The CBF-based controller\nenables the UAV to converge safely to the target for precise contact. Simulated\nevaluations of both the controller and target detection are presented,\nalongside an analysis of real-world detection performance.\n","authors":["Andrea Berra","Viswa Narayanan Sankaranarayanan","Achilleas Santi Seisa","Julien Mellet","Udayanga G. W. K. N. Gamage","Sumeet Gajanan Satpute","Fabio Ruggiero","Vincenzo Lippiello","Silvia Tolu","Matteo Fumagalli","George Nikolakopoulos","Miguel Ángel Trujillo Soto","Guillermo Heredia"],"pdf_url":"https://arxiv.org/pdf/2410.15802v1.pdf","comment":"8 pages,14 figures, ICUAS 2024"},{"id":"http://arxiv.org/abs/2410.13571v2","updated":"2024-10-21T09:15:37Z","published":"2024-10-17T14:07:46Z","title":"DriveDreamer4D: World Models Are Effective Data Machines for 4D Driving\n  Scene Representation","summary":"  Closed-loop simulation is essential for advancing end-to-end autonomous\ndriving systems. Contemporary sensor simulation methods, such as NeRF and 3DGS,\nrely predominantly on conditions closely aligned with training data\ndistributions, which are largely confined to forward-driving scenarios.\nConsequently, these methods face limitations when rendering complex maneuvers\n(e.g., lane change, acceleration, deceleration). Recent advancements in\nautonomous-driving world models have demonstrated the potential to generate\ndiverse driving videos. However, these approaches remain constrained to 2D\nvideo generation, inherently lacking the spatiotemporal coherence required to\ncapture intricacies of dynamic driving environments. In this paper, we\nintroduce DriveDreamer4D, which enhances 4D driving scene representation\nleveraging world model priors. Specifically, we utilize the world model as a\ndata machine to synthesize novel trajectory videos based on real-world driving\ndata. Notably, we explicitly leverage structured conditions to control the\nspatial-temporal consistency of foreground and background elements, thus the\ngenerated data adheres closely to traffic constraints. To our knowledge,\nDriveDreamer4D is the first to utilize video generation models for improving 4D\nreconstruction in driving scenarios. Experimental results reveal that\nDriveDreamer4D significantly enhances generation quality under novel trajectory\nviews, achieving a relative improvement in FID by 24.5%, 39.0%, and 10.5%\ncompared to PVG, S3Gaussian, and Deformable-GS. Moreover, DriveDreamer4D\nmarkedly enhances the spatiotemporal coherence of driving agents, which is\nverified by a comprehensive user study and the relative increases of 20.3%,\n42.0%, and 13.7% in the NTA-IoU metric.\n","authors":["Guosheng Zhao","Chaojun Ni","Xiaofeng Wang","Zheng Zhu","Xueyang Zhang","Yida Wang","Guan Huang","Xinze Chen","Boyuan Wang","Youyi Zhang","Wenjun Mei","Xingang Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13571v2.pdf","comment":"Project Page: https://drivedreamer4d.github.io"},{"id":"http://arxiv.org/abs/2409.07825v3","updated":"2024-10-21T09:14:47Z","published":"2024-09-12T08:15:39Z","title":"Deep Multimodal Learning with Missing Modality: A Survey","summary":"  During multimodal model training and testing, certain data modalities may be\nabsent due to sensor limitations, cost constraints, privacy concerns, or data\nloss, negatively affecting performance. Multimodal learning techniques designed\nto handle missing modalities can mitigate this by ensuring model robustness\neven when some modalities are unavailable. This survey reviews recent progress\nin Multimodal Learning with Missing Modality (MLMM), focusing on deep learning\nmethods. It provides the first comprehensive survey that covers the motivation\nand distinctions between MLMM and standard multimodal learning setups, followed\nby a detailed analysis of current methods, applications, and datasets,\nconcluding with challenges and future directions.\n","authors":["Renjie Wu","Hu Wang","Hsiang-Ting Chen","Gustavo Carneiro"],"pdf_url":"https://arxiv.org/pdf/2409.07825v3.pdf","comment":"Submitted to ACM Computing Surveys"},{"id":"http://arxiv.org/abs/2410.15794v1","updated":"2024-10-21T09:06:13Z","published":"2024-10-21T09:06:13Z","title":"Habaek: High-performance water segmentation through dataset expansion\n  and inductive bias optimization","summary":"  Water segmentation is critical to disaster response and water resource\nmanagement. Authorities may employ high-resolution photography to monitor\nrivers, lakes, and reservoirs, allowing for more proactive management in\nagriculture, industry, and conservation. Deep learning has improved flood\nmonitoring by allowing models like CNNs, U-Nets, and transformers to handle\nlarge volumes of satellite and aerial data. However, these models usually have\nsignificant processing requirements, limiting their usage in real-time\napplications. This research proposes upgrading the SegFormer model for water\nsegmentation by data augmentation with datasets such as ADE20K and RIWA to\nboost generalization. We examine how inductive bias affects attention-based\nmodels and discover that SegFormer performs better on bigger datasets. To\nfurther demonstrate the function of data augmentation, Low-Rank Adaptation\n(LoRA) is used to lower processing complexity while preserving accuracy. We\nshow that the suggested Habaek model outperforms current models in\nsegmentation, with an Intersection over Union (IoU) ranging from 0.91986 to\n0.94397. In terms of F1-score, recall, accuracy, and precision, Habaek performs\nbetter than rival models, indicating its potential for real-world applications.\nThis study highlights the need to enhance structures and include datasets for\neffective water segmentation.\n","authors":["Hanseon Joo","Eunji Lee","Minjong Cheon"],"pdf_url":"https://arxiv.org/pdf/2410.15794v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15792v1","updated":"2024-10-21T09:02:40Z","published":"2024-10-21T09:02:40Z","title":"WildOcc: A Benchmark for Off-Road 3D Semantic Occupancy Prediction","summary":"  3D semantic occupancy prediction is an essential part of autonomous driving,\nfocusing on capturing the geometric details of scenes. Off-road environments\nare rich in geometric information, therefore it is suitable for 3D semantic\noccupancy prediction tasks to reconstruct such scenes. However, most of\nresearches concentrate on on-road environments, and few methods are designed\nfor off-road 3D semantic occupancy prediction due to the lack of relevant\ndatasets and benchmarks. In response to this gap, we introduce WildOcc, to our\nknowledge, the first benchmark to provide dense occupancy annotations for\noff-road 3D semantic occupancy prediction tasks. A ground truth generation\npipeline is proposed in this paper, which employs a coarse-to-fine\nreconstruction to achieve a more realistic result. Moreover, we introduce a\nmulti-modal 3D semantic occupancy prediction framework, which fuses\nspatio-temporal information from multi-frame images and point clouds at voxel\nlevel. In addition, a cross-modality distillation function is introduced, which\ntransfers geometric knowledge from point clouds to image features.\n","authors":["Heng Zhai","Jilin Mei","Chen Min","Liang Chen","Fangzhou Zhao","Yu Hu"],"pdf_url":"https://arxiv.org/pdf/2410.15792v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.20648v2","updated":"2024-10-21T08:52:10Z","published":"2024-05-31T07:30:24Z","title":"Shotluck Holmes: A Family of Efficient Small-Scale Large Language Vision\n  Models For Video Captioning and Summarization","summary":"  Video is an increasingly prominent and information-dense medium, yet it poses\nsubstantial challenges for language models. A typical video consists of a\nsequence of shorter segments, or shots, that collectively form a coherent\nnarrative. Each shot is analogous to a word in a sentence where multiple data\nstreams of information (such as visual and auditory data) must be processed\nsimultaneously. Comprehension of the entire video requires not only\nunderstanding the visual-audio information of each shot but also requires that\nthe model links the ideas between each shot to generate a larger,\nall-encompassing story. Despite significant progress in the field, current\nworks often overlook videos' more granular shot-by-shot semantic information.\nIn this project, we propose a family of efficient large language vision models\n(LLVMs) to boost video summarization and captioning called Shotluck Holmes. By\nleveraging better pretraining and data collection strategies, we extend the\nabilities of existing small LLVMs from being able to understand a picture to\nbeing able to understand a sequence of frames. Specifically, we show that\nShotluck Holmes achieves better performance than state-of-the-art results on\nthe Shot2Story video captioning and summary task with significantly smaller and\nmore computationally efficient models.\n","authors":["Richard Luo","Austin Peng","Adithya Vasudev","Rishabh Jain"],"pdf_url":"https://arxiv.org/pdf/2405.20648v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15780v1","updated":"2024-10-21T08:45:26Z","published":"2024-10-21T08:45:26Z","title":"An Efficient System for Automatic Map Storytelling -- A Case Study on\n  Historical Maps","summary":"  Historical maps provide valuable information and knowledge about the past.\nHowever, as they often feature non-standard projections, hand-drawn styles, and\nartistic elements, it is challenging for non-experts to identify and interpret\nthem. While existing image captioning methods have achieved remarkable success\non natural images, their performance on maps is suboptimal as maps are\nunderrepresented in their pre-training process. Despite the recent advance of\nGPT-4 in text recognition and map captioning, it still has a limited\nunderstanding of maps, as its performance wanes when texts (e.g., titles and\nlegends) in maps are missing or inaccurate. Besides, it is inefficient or even\nimpractical to fine-tune the model with users' own datasets. To address these\nproblems, we propose a novel and lightweight map-captioning counterpart.\nSpecifically, we fine-tune the state-of-the-art vision-language model CLIP to\ngenerate captions relevant to historical maps and enrich the captions with\nGPT-3.5 to tell a brief story regarding where, what, when and why of a given\nmap. We propose a novel decision tree architecture to only generate captions\nrelevant to the specified map type. Our system shows invariance to text\nalterations in maps. The system can be easily adapted and extended to other map\ntypes and scaled to a larger map captioning system. The code is open-sourced at\nhttps://github.com/claudaff/automatic-map-storytelling.\n","authors":["Ziyi Liu","Claudio Affolter","Sidi Wu","Yizi Chen","Lorenz Hurni"],"pdf_url":"https://arxiv.org/pdf/2410.15780v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15778v1","updated":"2024-10-21T08:42:30Z","published":"2024-10-21T08:42:30Z","title":"Reducing Hallucinations in Vision-Language Models via Latent Space\n  Steering","summary":"  Hallucination poses a challenge to the deployment of large vision-language\nmodels (LVLMs) in applications. Unlike in large language models (LLMs),\nhallucination in LVLMs often arises from misalignments between visual inputs\nand textual outputs. This paper investigates the underlying mechanisms of\nhallucination, focusing on the unique structure of LVLMs that distinguishes\nthem from large language models (LLMs). We identify that hallucinations often\narise from the sensitivity of text decoders to vision inputs, a natural\nphenomenon when image encoders and text decoders are pre-trained separately.\nInspired by this, we introduce Visual and Textual Intervention (VTI), a novel\ntechnique designed to reduce hallucinations by steering latent space\nrepresentations during inference to enhance the stability of vision features.\nAs a task-agnostic test-time intervention, VTI can be easily applied to any\nproblem without additional cost. Extensive experiments demonstrate that it can\neffectively reduce hallucinations and outperform baseline methods across\nmultiple metrics, highlighting the critical role of vision feature stability in\nLVLMs.\n","authors":["Sheng Liu","Haotian Ye","James Zou"],"pdf_url":"https://arxiv.org/pdf/2410.15778v1.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2410.15774v1","updated":"2024-10-21T08:36:25Z","published":"2024-10-21T08:36:25Z","title":"Generalizing Motion Planners with Mixture of Experts for Autonomous\n  Driving","summary":"  Large real-world driving datasets have sparked significant research into\nvarious aspects of data-driven motion planners for autonomous driving. These\ninclude data augmentation, model architecture, reward design, training\nstrategies, and planner pipelines. These planners promise better\ngeneralizations on complicated and few-shot cases than previous methods.\nHowever, experiment results show that many of these approaches produce limited\ngeneralization abilities in planning performance due to overly complex designs\nor training paradigms. In this paper, we review and benchmark previous methods\nfocusing on generalizations. The experimental results indicate that as models\nare appropriately scaled, many design elements become redundant. We introduce\nStateTransformer-2 (STR2), a scalable, decoder-only motion planner that uses a\nVision Transformer (ViT) encoder and a mixture-of-experts (MoE) causal\nTransformer architecture. The MoE backbone addresses modality collapse and\nreward balancing by expert routing during training. Extensive experiments on\nthe NuPlan dataset show that our method generalizes better than previous\napproaches across different test sets and closed-loop simulations. Furthermore,\nwe assess its scalability on billions of real-world urban driving scenarios,\ndemonstrating consistent accuracy improvements as both data and model size\ngrow.\n","authors":["Qiao Sun","Huimin Wang","Jiahao Zhan","Fan Nie","Xin Wen","Leimeng Xu","Kun Zhan","Peng Jia","Xianpeng Lang","Hang Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.15774v1.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.15768v1","updated":"2024-10-21T08:28:11Z","published":"2024-10-21T08:28:11Z","title":"Learning to Synthesize Graphics Programs for Geometric Artworks","summary":"  Creating and understanding art has long been a hallmark of human ability.\nWhen presented with finished digital artwork, professional graphic artists can\nintuitively deconstruct and replicate it using various drawing tools, such as\nthe line tool, paint bucket, and layer features, including opacity and blending\nmodes. While most recent research in this field has focused on art generation,\nproposing a range of methods, these often rely on the concept of artwork being\nrepresented as a final image. To bridge the gap between pixel-level results and\nthe actual drawing process, we present an approach that treats a set of drawing\ntools as executable programs. This method predicts a sequence of steps to\nachieve the final image, allowing for understandable and resolution-independent\nreproductions under the usage of a set of drawing commands. Our experiments\ndemonstrate that our program synthesizer, Art2Prog, can comprehensively\nunderstand complex input images and reproduce them using high-quality\nexecutable programs. The experimental results evidence the potential of\nmachines to grasp higher-level information from images and generate compact\nprogram-level descriptions.\n","authors":["Qi Bing","Chaoyi Zhang","Weidong Cai"],"pdf_url":"https://arxiv.org/pdf/2410.15768v1.pdf","comment":"ICPR 2024"},{"id":"http://arxiv.org/abs/2410.15767v1","updated":"2024-10-21T08:27:13Z","published":"2024-10-21T08:27:13Z","title":"Improving Instance Optimization in Deformable Image Registration with\n  Gradient Projection","summary":"  Deformable image registration is inherently a multi-objective optimization\n(MOO) problem, requiring a delicate balance between image similarity and\ndeformation regularity. These conflicting objectives often lead to poor\noptimization outcomes, such as being trapped in unsatisfactory local minima or\nexperiencing slow convergence. Deep learning methods have recently gained\npopularity in this domain due to their efficiency in processing large datasets\nand achieving high accuracy. However, they often underperform during test time\ncompared to traditional optimization techniques, which further explore\niterative, instance-specific gradient-based optimization. This performance gap\nis more pronounced when a distribution shift between training and test data\nexists. To address this issue, we focus on the instance optimization (IO)\nparadigm, which involves additional optimization for test-time instances based\non a pre-trained model. IO effectively combines the generalization capabilities\nof deep learning with the fine-tuning advantages of instance-specific\noptimization. Within this framework, we emphasize the use of gradient\nprojection to mitigate conflicting updates in MOO. This technique projects\nconflicting gradients into a common space, better aligning the dual objectives\nand enhancing optimization stability. We validate our method using a\nstate-of-the-art foundation model on the 3D Brain inter-subject registration\ntask (LUMIR) from the Learn2Reg 2024 Challenge. Our results show significant\nimprovements over standard gradient descent, leading to more accurate and\nreliable registration results.\n","authors":["Yi Zhang","Yidong Zhao","Qian Tao"],"pdf_url":"https://arxiv.org/pdf/2410.15767v1.pdf","comment":"L2R 2024 Challenge Paper"},{"id":"http://arxiv.org/abs/2410.15766v1","updated":"2024-10-21T08:24:46Z","published":"2024-10-21T08:24:46Z","title":"How Important are Data Augmentations to Close the Domain Gap for Object\n  Detection in Orbit?","summary":"  We investigate the efficacy of data augmentations to close the domain gap in\nspaceborne computer vision, crucial for autonomous operations like on-orbit\nservicing. As the use of computer vision in space increases, challenges such as\nhostile illumination and low signal-to-noise ratios significantly hinder\nperformance. While learning-based algorithms show promising results, their\nadoption is limited by the need for extensive annotated training data and the\ndomain gap that arises from differences between synthesized and real-world\nimagery. This study explores domain generalization in terms of data\naugmentations -- classical color and geometric transformations, corruptions,\nand noise -- to enhance model performance across the domain gap. To this end,\nwe conduct an large scale experiment using a hyperparameter optimization\npipeline that samples hundreds of different configurations and searches for the\nbest set to bridge the domain gap. As a reference task, we use 2D object\ndetection and evaluate on the SPEED+ dataset that contains real\nhardware-in-the-loop satellite images in its test set. Moreover, we evaluate\nfour popular object detectors, including Mask R-CNN, Faster R-CNN, YOLO-v7, and\nthe open set detector GroundingDINO, and highlight their trade-offs between\nperformance, inference speed, and training time. Our results underscore the\nvital role of data augmentations in bridging the domain gap, improving model\nperformance, robustness, and reliability for critical space applications. As a\nresult, we propose two novel data augmentations specifically developed to\nemulate the visual effects observed in orbital imagery. We conclude by\nrecommending the most effective augmentations for advancing computer vision in\nchallenging orbital environments. Code for training detectors and\nhyperparameter search will be made publicly available.\n","authors":["Maximilian Ulmer","Leonard Klüpfel","Maximilian Durner","Rudolph Triebel"],"pdf_url":"https://arxiv.org/pdf/2410.15766v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15760v1","updated":"2024-10-21T08:20:19Z","published":"2024-10-21T08:20:19Z","title":"DeepIcon: A Hierarchical Network for Layer-wise Icon Vectorization","summary":"  In contrast to the well-established technique of rasterization, vectorization\nof images poses a significant challenge in the field of computer graphics.\nRecent learning-based methods for converting raster images to vector formats\nfrequently suffer from incomplete shapes, redundant path prediction, and a lack\nof accuracy in preserving the semantics of the original content. These\nshortcomings severely hinder the utility of these methods for further editing\nand manipulation of images. To address these challenges, we present DeepIcon, a\nnovel hierarchical image vectorization network specifically tailored for\ngenerating variable-length icon vector graphics based on the raster image\ninput. Our experimental results indicate that DeepIcon can efficiently produce\nScalable Vector Graphics (SVGs) directly from raster images, bypassing the need\nfor a differentiable rasterizer while also demonstrating a profound\nunderstanding of the image contents.\n","authors":["Qi Bing","Chaoyi Zhang","Weidong Cai"],"pdf_url":"https://arxiv.org/pdf/2410.15760v1.pdf","comment":"Accepted as Oral Presentation at DICTA 2024"},{"id":"http://arxiv.org/abs/2408.10188v4","updated":"2024-10-21T08:12:42Z","published":"2024-08-19T17:48:08Z","title":"LongVILA: Scaling Long-Context Visual Language Models for Long Videos","summary":"  Long-context capability is critical for multi-modal foundation models,\nespecially for long video understanding. We introduce LongVILA, a full-stack\nsolution for long-context visual-language models \\qinghao{by co-designing the\nalgorithm and system. For model training, we upgrade existing VLMs to support\nlong video understanding by incorporating two additional stages, {\\em i.e.},\nlong context extension and long video supervised fine-tuning. However, training\non long video is computationally and memory intensive. We introduce the\nlong-context Multi-Modal Sequence Parallelism (MM-SP) system that efficiently\nparallelizes long video training and inference, enabling 2M context length\ntraining on 256 GPUs without any gradient checkpointing. LongVILA efficiently\nextends the number of video frames of VILA from 8 to 2048, improving the long\nvideo captioning score from 2.00 to 3.26 (out of 5), achieving 99.8% accuracy\nin 6,000-frame (more than 1 million tokens) video needle-in-a-haystack.\nLongVILA-7B demonstrates strong accuracy on the VideoMME benchmark, i.e., 61.8%\nwith subtitle. Besides, MM-SP is 2.1x - 5.7x faster than ring style sequence\nparallelism and 1.1x - 1.4x faster than Megatron with a hybrid context and\ntensor parallelism. Moreover, it seamlessly integrates with Hugging Face\nTransformers.\n","authors":["Fuzhao Xue","Yukang Chen","Dacheng Li","Qinghao Hu","Ligeng Zhu","Xiuyu Li","Yunhao Fang","Haotian Tang","Shang Yang","Zhijian Liu","Ethan He","Hongxu Yin","Pavlo Molchanov","Jan Kautz","Linxi Fan","Yuke Zhu","Yao Lu","Song Han"],"pdf_url":"https://arxiv.org/pdf/2408.10188v4.pdf","comment":"Code and models are available at\n  https://github.com/NVlabs/VILA/blob/main/LongVILA.md"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2410.16270v1","updated":"2024-10-21T17:59:50Z","published":"2024-10-21T17:59:50Z","title":"Reflection-Bench: probing AI intelligence with reflection","summary":"  The ability to adapt beliefs or behaviors in response to unexpected outcomes,\nreflection, is fundamental to intelligent systems' interaction with the world.\nFrom a cognitive science perspective, this serves as a core principle of\nintelligence applicable to both human and AI systems. To address the debate on\nthe intelligence of large language models (LLMs), we propose Reflection-Bench,\na comprehensive benchmark comprising 7 tasks spanning core cognitive functions\ncrucial for reflection, including perception, memory, belief updating,\ndecision-making, prediction, counterfactual thinking, and meta-reflection. We\nevaluate the performances of 13 prominent LLMs such as OpenAI o1, GPT-4, Claude\n3.5 Sonnet, etc. The results indicate that current LLMs still lack satisfactory\nreflection ability. We discuss the underlying causes of these results and\nsuggest potential avenues for future research. In conclusion, Reflection-Bench\noffers both evaluation tools and inspiration for developing AI capable of\nreliably interacting with the environment. Our data and code are available at\nhttps://github.com/YabYum/ReflectionBench.\n","authors":["Lingyu Li","Yixu Wang","Haiquan Zhao","Shuqi Kong","Yan Teng","Chunbo Li","Yingchun Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16270v1.pdf","comment":"11 pages, 7 figures, 2 tables"},{"id":"http://arxiv.org/abs/2406.08472v2","updated":"2024-10-21T17:59:13Z","published":"2024-06-12T17:56:31Z","title":"RILe: Reinforced Imitation Learning","summary":"  Reinforcement Learning has achieved significant success in generating complex\nbehavior but often requires extensive reward function engineering. Adversarial\nvariants of Imitation Learning and Inverse Reinforcement Learning offer an\nalternative by learning policies from expert demonstrations via a\ndiscriminator. However, these methods struggle in complex tasks where randomly\nsampling expert-like behaviors is challenging. This limitation stems from their\nreliance on policy-agnostic discriminators, which provide insufficient guidance\nfor agent improvement, especially as task complexity increases and expert\nbehavior becomes more distinct. We introduce RILe (Reinforced Imitation\nLearning environment), a novel trainer-student system that learns a dynamic\nreward function based on the student's performance and alignment with expert\ndemonstrations. In RILe, the student learns an action policy while the trainer,\nusing reinforcement learning, continuously updates itself via the\ndiscriminator's feedback to optimize the alignment between the student and the\nexpert. The trainer optimizes for long-term cumulative rewards from the\ndiscriminator, enabling it to provide nuanced feedback that accounts for the\ncomplexity of the task and the student's current capabilities. This approach\nallows for greater exploration of agent actions by providing graduated feedback\nrather than binary expert/non-expert classifications. By reducing dependence on\npolicy-agnostic discriminators, RILe enables better performance in complex\nsettings where traditional methods falter, outperforming existing methods by 2x\nin complex simulated robot-locomotion tasks.\n","authors":["Mert Albaba","Sammy Christen","Thomas Langarek","Christoph Gebhardt","Otmar Hilliges","Michael J. Black"],"pdf_url":"https://arxiv.org/pdf/2406.08472v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16267v1","updated":"2024-10-21T17:59:11Z","published":"2024-10-21T17:59:11Z","title":"xGen-MM-Vid (BLIP-3-Video): You Only Need 32 Tokens to Represent a Video\n  Even in VLMs","summary":"  We present xGen-MM-Vid (BLIP-3-Video): a multimodal language model for\nvideos, particularly designed to efficiently capture temporal information over\nmultiple frames. BLIP-3-Video takes advantage of the 'temporal encoder' in\naddition to the conventional visual tokenizer, which maps a sequence of tokens\nover multiple frames into a compact set of visual tokens. This enables\nBLIP3-Video to use much fewer visual tokens than its competing models (e.g., 32\nvs. 4608 tokens). We explore different types of temporal encoders, including\nlearnable spatio-temporal pooling as well as sequential models like Token\nTuring Machines. We experimentally confirm that BLIP-3-Video obtains video\nquestion-answering accuracies comparable to much larger state-of-the-art models\n(e.g., 34B), while being much smaller (i.e., 4B) and more efficient by using\nfewer visual tokens. The project website is at\nhttps://www.salesforceairesearch.com/opensource/xGen-MM-Vid/index.html\n","authors":["Michael S. Ryoo","Honglu Zhou","Shrikant Kendre","Can Qin","Le Xue","Manli Shu","Silvio Savarese","Ran Xu","Caiming Xiong","Juan Carlos Niebles"],"pdf_url":"https://arxiv.org/pdf/2410.16267v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16266v1","updated":"2024-10-21T17:59:09Z","published":"2024-10-21T17:59:09Z","title":"3DGS-Enhancer: Enhancing Unbounded 3D Gaussian Splatting with\n  View-consistent 2D Diffusion Priors","summary":"  Novel-view synthesis aims to generate novel views of a scene from multiple\ninput images or videos, and recent advancements like 3D Gaussian splatting\n(3DGS) have achieved notable success in producing photorealistic renderings\nwith efficient pipelines. However, generating high-quality novel views under\nchallenging settings, such as sparse input views, remains difficult due to\ninsufficient information in under-sampled areas, often resulting in noticeable\nartifacts. This paper presents 3DGS-Enhancer, a novel pipeline for enhancing\nthe representation quality of 3DGS representations. We leverage 2D video\ndiffusion priors to address the challenging 3D view consistency problem,\nreformulating it as achieving temporal consistency within a video generation\nprocess. 3DGS-Enhancer restores view-consistent latent features of rendered\nnovel views and integrates them with the input views through a spatial-temporal\ndecoder. The enhanced views are then used to fine-tune the initial 3DGS model,\nsignificantly improving its rendering performance. Extensive experiments on\nlarge-scale datasets of unbounded scenes demonstrate that 3DGS-Enhancer yields\nsuperior reconstruction performance and high-fidelity rendering results\ncompared to state-of-the-art methods. The project webpage is\nhttps://xiliu8006.github.io/3DGS-Enhancer-project .\n","authors":["Xi Liu","Chaoyi Zhou","Siyu Huang"],"pdf_url":"https://arxiv.org/pdf/2410.16266v1.pdf","comment":"Accepted by NeurIPS 2024 Spotlight"},{"id":"http://arxiv.org/abs/2410.16256v1","updated":"2024-10-21T17:56:51Z","published":"2024-10-21T17:56:51Z","title":"CompassJudger-1: All-in-one Judge Model Helps Model Evaluation and\n  Evolution","summary":"  Efficient and accurate evaluation is crucial for the continuous improvement\nof large language models (LLMs). Among various assessment methods, subjective\nevaluation has garnered significant attention due to its superior alignment\nwith real-world usage scenarios and human preferences. However, human-based\nevaluations are costly and lack reproducibility, making precise automated\nevaluators (judgers) vital in this process. In this report, we introduce\n\\textbf{CompassJudger-1}, the first open-source \\textbf{all-in-one} judge LLM.\nCompassJudger-1 is a general-purpose LLM that demonstrates remarkable\nversatility. It is capable of: 1. Performing unitary scoring and two-model\ncomparisons as a reward model; 2. Conducting evaluations according to specified\nformats; 3. Generating critiques; 4. Executing diverse tasks like a general\nLLM. To assess the evaluation capabilities of different judge models under a\nunified setting, we have also established \\textbf{JudgerBench}, a new benchmark\nthat encompasses various subjective evaluation tasks and covers a wide range of\ntopics. CompassJudger-1 offers a comprehensive solution for various evaluation\ntasks while maintaining the flexibility to adapt to diverse requirements. Both\nCompassJudger and JudgerBench are released and available to the research\ncommunity athttps://github.com/open-compass/CompassJudger. We believe that by\nopen-sourcing these tools, we can foster collaboration and accelerate progress\nin LLM evaluation methodologies.\n","authors":["Maosong Cao","Alexander Lam","Haodong Duan","Hongwei Liu","Songyang Zhang","Kai Chen"],"pdf_url":"https://arxiv.org/pdf/2410.16256v1.pdf","comment":"Technical Report, Code and Models:\n  https://github.com/open-compass/CompassJudger"},{"id":"http://arxiv.org/abs/2410.16239v1","updated":"2024-10-21T17:42:41Z","published":"2024-10-21T17:42:41Z","title":"MoRE: Multi-Modal Contrastive Pre-training with Transformers on X-Rays,\n  ECGs, and Diagnostic Report","summary":"  In this paper, we introduce a novel Multi-Modal Contrastive Pre-training\nFramework that synergistically combines X-rays, electrocardiograms (ECGs), and\nradiology/cardiology reports. Our approach leverages transformers to encode\nthese diverse modalities into a unified representation space, aiming to enhance\ndiagnostic accuracy and facilitate comprehensive patient assessments. We\nutilize LoRA-Peft to significantly reduce trainable parameters in the LLM and\nincorporate recent linear attention dropping strategy in the Vision\nTransformer(ViT) for smoother attention. Furthermore, we provide novel\nmultimodal attention explanations and retrieval for our model. To the best of\nour knowledge, we are the first to propose an integrated model that combines\nX-ray, ECG, and Radiology/Cardiology Report with this approach. By utilizing\ncontrastive loss, MoRE effectively aligns modality-specific features into a\ncoherent embedding, which supports various downstream tasks such as zero-shot\nclassification and multimodal retrieval. Employing our proposed methodology, we\nachieve state-of-the-art (SOTA) on the Mimic-IV, CheXpert, Edema Severity, and\nPtbXl downstream datasets, surpassing existing multimodal approaches. Our\nproposed framework shows significant improvements in capturing intricate\ninter-modal relationships and its robustness in medical diagnosis that\nestablishes a framework for future research in multimodal learning in the\nhealthcare sector.\n","authors":["Samrajya Thapa","Koushik Howlader","Subhankar Bhattacharjee","Wei le"],"pdf_url":"https://arxiv.org/pdf/2410.16239v1.pdf","comment":"10 pages, 5 figures, 9 tables. Supplementary detail in Appendix. Code\n  made available in Github for reproducibility"},{"id":"http://arxiv.org/abs/2410.16232v1","updated":"2024-10-21T17:39:49Z","published":"2024-10-21T17:39:49Z","title":"Sketch2Code: Evaluating Vision-Language Models for Interactive Web\n  Design Prototyping","summary":"  Sketches are a natural and accessible medium for UI designers to\nconceptualize early-stage ideas. However, existing research on UI/UX automation\noften requires high-fidelity inputs like Figma designs or detailed screenshots,\nlimiting accessibility and impeding efficient design iteration. To bridge this\ngap, we introduce Sketch2Code, a benchmark that evaluates state-of-the-art\nVision Language Models (VLMs) on automating the conversion of rudimentary\nsketches into webpage prototypes. Beyond end-to-end benchmarking, Sketch2Code\nsupports interactive agent evaluation that mimics real-world design workflows,\nwhere a VLM-based agent iteratively refines its generations by communicating\nwith a simulated user, either passively receiving feedback instructions or\nproactively asking clarification questions. We comprehensively analyze ten\ncommercial and open-source models, showing that Sketch2Code is challenging for\nexisting VLMs; even the most capable models struggle to accurately interpret\nsketches and formulate effective questions that lead to steady improvement.\nNevertheless, a user study with UI/UX experts reveals a significant preference\nfor proactive question-asking over passive feedback reception, highlighting the\nneed to develop more effective paradigms for multi-turn conversational agents.\n","authors":["Ryan Li","Yanzhe Zhang","Diyi Yang"],"pdf_url":"https://arxiv.org/pdf/2410.16232v1.pdf","comment":"preprint, 9 pages"},{"id":"http://arxiv.org/abs/2408.17355v2","updated":"2024-10-21T17:27:00Z","published":"2024-08-30T15:39:34Z","title":"Bidirectional Decoding: Improving Action Chunking via Closed-Loop\n  Resampling","summary":"  Predicting and executing a sequence of actions without intermediate\nreplanning, known as action chunking, is increasingly used in robot learning\nfrom human demonstrations. Yet, its reported effects on the learned policy are\ninconsistent: some studies find it crucial for achieving strong results, while\nothers observe decreased performance. In this paper, we first dissect how\naction chunking impacts the divergence between a learner and a demonstrator. We\nfind that action chunking allows the learner to better capture the temporal\ndependencies in demonstrations but at the cost of reduced reactivity in\nstochastic environments. To address this tradeoff, we propose Bidirectional\nDecoding (BID), a test-time inference algorithm that bridges action chunking\nwith closed-loop operations. BID samples multiple predictions at each time step\nand searches for the optimal one based on two criteria: (i) backward coherence,\nwhich favors samples that align with previous decisions; (ii) forward contrast,\nwhich seeks samples of high likelihood for future plans. By coupling decisions\nwithin and across action chunks, BID promotes consistency over time while\nmaintaining reactivity to unexpected changes. Experimental results show that\nBID boosts the performance of two state-of-the-art generative policies across\nseven simulation benchmarks and two real-world tasks. Code and videos are\navailable at https://bid-robot.github.io.\n","authors":["Yuejiang Liu","Jubayer Ibn Hamid","Annie Xie","Yoonho Lee","Maximilian Du","Chelsea Finn"],"pdf_url":"https://arxiv.org/pdf/2408.17355v2.pdf","comment":"Project website: https://bid-robot.github.io/"},{"id":"http://arxiv.org/abs/2410.16215v1","updated":"2024-10-21T17:16:13Z","published":"2024-10-21T17:16:13Z","title":"Pre-training Distillation for Large Language Models: A Design Space\n  Exploration","summary":"  Knowledge distillation (KD) aims to transfer knowledge from a large teacher\nmodel to a smaller student model. Previous work applying KD in the field of\nlarge language models (LLMs) typically focused on the post-training phase,\nwhere the student LLM learns directly from instructions and corresponding\nresponses generated by the teacher model. In this paper, we extend KD to the\npre-training phase of LLMs, named pre-training distillation (PD). We first\nconduct a preliminary experiment using GLM-4-9B as the teacher LLM to distill a\n1.9B parameter student LLM, validating the effectiveness of PD. Considering the\nkey impact factors of distillation, we systematically explore the design space\nof pre-training distillation across four aspects: logits processing, loss\nselection, scaling law, and offline or online logits. We conduct extensive\nexperiments to explore the design space of pre-training distillation and find\nbetter configurations and interesting conclusions, such as larger student LLMs\ngenerally benefiting more from pre-training distillation, while a larger\nteacher LLM does not necessarily guarantee better results. We hope our\nexploration of the design space will inform future practices in pre-training\ndistillation.\n","authors":["Hao Peng","Xin Lv","Yushi Bai","Zijun Yao","Jiajie Zhang","Lei Hou","Juanzi Li"],"pdf_url":"https://arxiv.org/pdf/2410.16215v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16212v1","updated":"2024-10-21T17:12:06Z","published":"2024-10-21T17:12:06Z","title":"Comprehensive benchmarking of large language models for RNA secondary\n  structure prediction","summary":"  Inspired by the success of large language models (LLM) for DNA and proteins,\nseveral LLM for RNA have been developed recently. RNA-LLM uses large datasets\nof RNA sequences to learn, in a self-supervised way, how to represent each RNA\nbase with a semantically rich numerical vector. This is done under the\nhypothesis that obtaining high-quality RNA representations can enhance\ndata-costly downstream tasks. Among them, predicting the secondary structure is\na fundamental task for uncovering RNA functional mechanisms. In this work we\npresent a comprehensive experimental analysis of several pre-trained RNA-LLM,\ncomparing them for the RNA secondary structure prediction task in an unified\ndeep learning framework. The RNA-LLM were assessed with increasing\ngeneralization difficulty on benchmark datasets. Results showed that two LLM\nclearly outperform the other models, and revealed significant challenges for\ngeneralization in low-homology scenarios.\n","authors":["L. I. Zablocki","L. A. Bugnon","M. Gerard","L. Di Persia","G. Stegmayer","D. H. Milone"],"pdf_url":"https://arxiv.org/pdf/2410.16212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16208v1","updated":"2024-10-21T17:11:21Z","published":"2024-10-21T17:11:21Z","title":"Compute-Constrained Data Selection","summary":"  Data selection can reduce the amount of training data needed to finetune\nLLMs; however, the efficacy of data selection scales directly with its compute.\nMotivated by the practical challenge of compute-constrained finetuning, we\nconsider the setting in which both the cost of selecting data and training are\nbudgeted for. We first formalize the problem of data selection with a\ncost-aware utility function, and model the data selection problem as trading\noff initial-selection cost for training gain. We run a comprehensive sweep of\nexperiments across multiple tasks, varying compute budget by scaling finetuning\ntokens, model sizes, and data selection compute. These experiments show the\nvalidity of this model in real-world experiments. Interestingly we find that\nmany powerful data selection methods are almost never compute-optimal, and that\ncheaper data selection alternatives dominate both from a theoretical and\nempirical perspective.\n","authors":["Junjie Oscar Yin","Alexander M. Rush"],"pdf_url":"https://arxiv.org/pdf/2410.16208v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19323v2","updated":"2024-10-21T17:05:15Z","published":"2024-05-29T17:54:22Z","title":"Are Large Language Models Chameleons? An Attempt to Simulate Social\n  Surveys","summary":"  Can large language models (LLMs) simulate social surveys? To answer this\nquestion, we conducted millions of simulations in which LLMs were asked to\nanswer subjective questions. A comparison of different LLM responses with the\nEuropean Social Survey (ESS) data suggests that the effect of prompts on bias\nand variability is fundamental, highlighting major cultural, age, and gender\nbiases. We further discussed statistical methods for measuring the difference\nbetween LLM answers and survey data and proposed a novel measure inspired by\nJaccard similarity, as LLM-generated responses are likely to have a smaller\nvariance. Our experiments also reveal that it is important to analyze the\nrobustness and variability of prompts before using LLMs to simulate social\nsurveys, as their imitation abilities are approximate at best.\n","authors":["Mingmeng Geng","Sihong He","Roberto Trotta"],"pdf_url":"https://arxiv.org/pdf/2405.19323v2.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2410.16198v1","updated":"2024-10-21T17:00:06Z","published":"2024-10-21T17:00:06Z","title":"Improve Vision Language Model Chain-of-thought Reasoning","summary":"  Chain-of-thought (CoT) reasoning in vision language models (VLMs) is crucial\nfor improving interpretability and trustworthiness. However, current training\nrecipes lack robust CoT reasoning data, relying on datasets dominated by short\nannotations with minimal rationales. In this work, we show that training VLM on\nshort answers does not generalize well to reasoning tasks that require more\ndetailed responses. To address this, we propose a two-fold approach. First, we\ndistill rationales from GPT-4o model to enrich the training data and fine-tune\nVLMs, boosting their CoT performance. Second, we apply reinforcement learning\nto further calibrate reasoning quality. Specifically, we construct positive\n(correct) and negative (incorrect) pairs of model-generated reasoning chains,\nby comparing their predictions with annotated short answers. Using this\npairwise data, we apply the Direct Preference Optimization algorithm to refine\nthe model's reasoning abilities. Our experiments demonstrate significant\nimprovements in CoT reasoning on benchmark datasets and better generalization\nto direct answer prediction as well. This work emphasizes the importance of\nincorporating detailed rationales in training and leveraging reinforcement\nlearning to strengthen the reasoning capabilities of VLMs.\n","authors":["Ruohong Zhang","Bowen Zhang","Yanghao Li","Haotian Zhang","Zhiqing Sun","Zhe Gan","Yinfei Yang","Ruoming Pang","Yiming Yang"],"pdf_url":"https://arxiv.org/pdf/2410.16198v1.pdf","comment":"10 pages + appendix"},{"id":"http://arxiv.org/abs/2410.16196v1","updated":"2024-10-21T16:59:25Z","published":"2024-10-21T16:59:25Z","title":"Information for Conversation Generation: Proposals Utilising Knowledge\n  Graphs","summary":"  LLMs are frequently used tools for conversational generation. Without\nadditional information LLMs can generate lower quality responses due to lacking\nrelevant content and hallucinations, as well as the perception of poor\nemotional capability, and an inability to maintain a consistent character.\nKnowledge graphs are commonly used forms of external knowledge and may provide\nsolutions to these challenges. This paper introduces three proposals, utilizing\nknowledge graphs to enhance LLM generation. Firstly, dynamic knowledge graph\nembeddings and recommendation could allow for the integration of new\ninformation and the selection of relevant knowledge for response generation.\nSecondly, storing entities with emotional values as additional features may\nprovide knowledge that is better emotionally aligned with the user input.\nThirdly, integrating character information through narrative bubbles would\nmaintain character consistency, as well as introducing a structure that would\nreadily incorporate new information.\n","authors":["Alex Clay","Ernesto Jiménez-Ruiz"],"pdf_url":"https://arxiv.org/pdf/2410.16196v1.pdf","comment":"7 pages with citations, 1 figure, accepted to the ISWC 2024 Special\n  Session"},{"id":"http://arxiv.org/abs/2406.13791v3","updated":"2024-10-21T16:55:31Z","published":"2024-06-19T19:35:14Z","title":"IoT-Based Preventive Mental Health Using Knowledge Graphs and Standards\n  for Better Well-Being","summary":"  Sustainable Development Goals (SDGs) give the UN a road map for development\nwith Agenda 2030 as a target. SDG3 \"Good Health and Well-Being\" ensures healthy\nlives and promotes well-being for all ages. Digital technologies can support\nSDG3. Burnout and even depression could be reduced by encouraging better\npreventive health. Due to the lack of patient knowledge and focus to take care\nof their health, it is necessary to help patients before it is too late. New\ntrends such as positive psychology and mindfulness are highly encouraged in the\nUSA. Digital Twins (DTs) can help with the continuous monitoring of emotion\nusing physiological signals (e.g., collected via wearables). DTs facilitate\nmonitoring and provide constant health insight to improve quality of life and\nwell-being with better personalization. Healthcare DTs challenges are\nstandardizing data formats, communication protocols, and data exchange\nmechanisms. As an example, ISO has the ISO/IEC JTC 1/SC 41 Internet of Things\n(IoT) and DTs Working Group, with standards such as \"ISO/IEC 21823-3:2021 IoT -\nInteroperability for IoT Systems - Part 3 Semantic interoperability\", \"ISO/IEC\nCD 30178 - IoT - Data format, value and coding\". To achieve those data\nintegration and knowledge challenges, we designed the Mental Health Knowledge\nGraph (ontology and dataset) to boost mental health. As an example, explicit\nknowledge is described such as chocolate contains magnesium which is\nrecommended for depression. The Knowledge Graph (KG) acquires knowledge from\nontology-based mental health projects classified within the LOV4IoT ontology\ncatalog (Emotion, Depression, and Mental Health). Furthermore, the KG is mapped\nto standards when possible. Standards from ETSI SmartM2M can be used such as\nSAREF4EHAW to represent medical devices and sensors, but also ITU/WHO, ISO,\nW3C, NIST, and IEEE standards relevant to mental health can be considered.\n","authors":["Amelie Gyrard","Seyedali Mohammadi","Manas Gaur","Antonio Kung"],"pdf_url":"https://arxiv.org/pdf/2406.13791v3.pdf","comment":"20 pages, Book chapter, Smart Technologies for Achieving Good Health\n  and Well-Being: Towards Sustainable Development Goal, Taylor & Francis"},{"id":"http://arxiv.org/abs/2409.18169v3","updated":"2024-10-21T16:51:22Z","published":"2024-09-26T17:55:22Z","title":"Harmful Fine-tuning Attacks and Defenses for Large Language Models: A\n  Survey","summary":"  Recent research demonstrates that the nascent fine-tuning-as-a-service\nbusiness model exposes serious safety concerns -- fine-tuning over a few\nharmful data uploaded by the users can compromise the safety alignment of the\nmodel. The attack, known as harmful fine-tuning, has raised a broad research\ninterest among the community. However, as the attack is still new, \\textbf{we\nobserve from our miserable submission experience that there are general\nmisunderstandings within the research community.} We in this paper aim to clear\nsome common concerns for the attack setting, and formally establish the\nresearch problem. Specifically, we first present the threat model of the\nproblem, and introduce the harmful fine-tuning attack and its variants. Then we\nsystematically survey the existing literature on attacks/defenses/mechanical\nanalysis of the problem. Finally, we outline future research directions that\nmight contribute to the development of the field. Additionally, we present a\nlist of questions of interest, which might be useful to refer to when reviewers\nin the peer review process question the realism of the\nexperiment/attack/defense setting. A curated list of relevant papers is\nmaintained and made accessible at:\n\\url{https://github.com/git-disl/awesome_LLM-harmful-fine-tuning-papers}.\n","authors":["Tiansheng Huang","Sihao Hu","Fatih Ilhan","Selim Furkan Tekin","Ling Liu"],"pdf_url":"https://arxiv.org/pdf/2409.18169v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16170v1","updated":"2024-10-21T16:35:58Z","published":"2024-10-21T16:35:58Z","title":"Learning How to Vote With Principles: Axiomatic Insights Into the\n  Collective Decisions of Neural Networks","summary":"  Can neural networks be applied in voting theory, while satisfying the need\nfor transparency in collective decisions? We propose axiomatic deep voting: a\nframework to build and evaluate neural networks that aggregate preferences,\nusing the well-established axiomatic method of voting theory. Our findings are:\n(1) Neural networks, despite being highly accurate, often fail to align with\nthe core axioms of voting rules, revealing a disconnect between mimicking\noutcomes and reasoning. (2) Training with axiom-specific data does not enhance\nalignment with those axioms. (3) By solely optimizing axiom satisfaction,\nneural networks can synthesize new voting rules that often surpass and\nsubstantially differ from existing ones. This offers insights for both fields:\nFor AI, important concepts like bias and value-alignment are studied in a\nmathematically rigorous way; for voting theory, new areas of the space of\nvoting rules are explored.\n","authors":["Levin Hornischer","Zoi Terzopoulou"],"pdf_url":"https://arxiv.org/pdf/2410.16170v1.pdf","comment":"15 pages, 8 figures, 7 tables"},{"id":"http://arxiv.org/abs/2405.16195v2","updated":"2024-10-21T16:32:24Z","published":"2024-05-25T11:57:43Z","title":"Adaptive $Q$-Network: On-the-fly Target Selection for Deep Reinforcement\n  Learning","summary":"  Deep Reinforcement Learning (RL) is well known for being highly sensitive to\nhyperparameters, requiring practitioners substantial efforts to optimize them\nfor the problem at hand. This also limits the applicability of RL in real-world\nscenarios. In recent years, the field of automated Reinforcement Learning\n(AutoRL) has grown in popularity by trying to address this issue. However,\nthese approaches typically hinge on additional samples to select\nwell-performing hyperparameters, hindering sample-efficiency and practicality.\nFurthermore, most AutoRL methods are heavily based on already existing AutoML\nmethods, which were originally developed neglecting the additional challenges\ninherent to RL due to its non-stationarities. In this work, we propose a new\napproach for AutoRL, called Adaptive $Q$-Network (AdaQN), that is tailored to\nRL to take into account the non-stationarity of the optimization procedure\nwithout requiring additional samples. AdaQN learns several $Q$-functions, each\none trained with different hyperparameters, which are updated online using the\n$Q$-function with the smallest approximation error as a shared target. Our\nselection scheme simultaneously handles different hyperparameters while coping\nwith the non-stationarity induced by the RL optimization procedure and being\northogonal to any critic-based RL algorithm. We demonstrate that AdaQN is\ntheoretically sound and empirically validate it in MuJoCo control problems and\nAtari $2600$ games, showing benefits in sample-efficiency, overall performance,\nrobustness to stochasticity and training stability.\n","authors":["Théo Vincent","Fabian Wahren","Jan Peters","Boris Belousov","Carlo D'Eramo"],"pdf_url":"https://arxiv.org/pdf/2405.16195v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.16164v1","updated":"2024-10-21T16:31:16Z","published":"2024-10-21T16:31:16Z","title":"GenAI Assisting Medical Training","summary":"  Medical procedures such as venipuncture and cannulation are essential for\nnurses and require precise skills. Learning this skill, in turn, is a challenge\nfor educators due to the number of teachers per class and the complexity of the\ntask. The study aims to help students with skill acquisition and alleviate the\neducator's workload by integrating generative AI methods to provide real-time\nfeedback on medical procedures such as venipuncture and cannulation.\n","authors":["Stefan Fritsch","Matthias Tschoepe","Vitor Fortes Rey","Lars Krupp","Agnes Gruenerbl","Eloise Monger","Sarah Travenna"],"pdf_url":"https://arxiv.org/pdf/2410.16164v1.pdf","comment":"2 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.16152v1","updated":"2024-10-21T16:19:34Z","published":"2024-10-21T16:19:34Z","title":"Warped Diffusion: Solving Video Inverse Problems with Image Diffusion\n  Models","summary":"  Using image models naively for solving inverse video problems often suffers\nfrom flickering, texture-sticking, and temporal inconsistency in generated\nvideos. To tackle these problems, in this paper, we view frames as continuous\nfunctions in the 2D space, and videos as a sequence of continuous warping\ntransformations between different frames. This perspective allows us to train\nfunction space diffusion models only on images and utilize them to solve\ntemporally correlated inverse problems. The function space diffusion models\nneed to be equivariant with respect to the underlying spatial transformations.\nTo ensure temporal consistency, we introduce a simple post-hoc test-time\nguidance towards (self)-equivariant solutions. Our method allows us to deploy\nstate-of-the-art latent diffusion models such as Stable Diffusion XL to solve\nvideo inverse problems. We demonstrate the effectiveness of our method for\nvideo inpainting and $8\\times$ video super-resolution, outperforming existing\ntechniques based on noise transformations. We provide generated video results:\nhttps://giannisdaras.github.io/warped\\_diffusion.github.io/.\n","authors":["Giannis Daras","Weili Nie","Karsten Kreis","Alex Dimakis","Morteza Mardani","Nikola Borislavov Kovachki","Arash Vahdat"],"pdf_url":"https://arxiv.org/pdf/2410.16152v1.pdf","comment":"Accepted in NeurIPS 2024"},{"id":"http://arxiv.org/abs/2405.18406v2","updated":"2024-10-21T16:18:37Z","published":"2024-05-28T17:46:36Z","title":"RACCooN: A Versatile Instructional Video Editing Framework with\n  Auto-Generated Narratives","summary":"  Recent video generative models primarily rely on carefully written text\nprompts for specific tasks, like inpainting or style editing. They require\nlabor-intensive textual descriptions for input videos, hindering their\nflexibility to adapt personal/raw videos to user specifications. This paper\nproposes RACCooN, a versatile and user-friendly video-to-paragraph-to-video\ngenerative framework that supports multiple video editing capabilities such as\nremoval, addition, and modification, through a unified pipeline. RACCooN\nconsists of two principal stages: Video-to-Paragraph (V2P) and\nParagraph-to-Video (P2V). In the V2P stage, we automatically describe video\nscenes in well-structured natural language, capturing both the holistic context\nand focused object details. Subsequently, in the P2V stage, users can\noptionally refine these descriptions to guide the video diffusion model,\nenabling various modifications to the input video, such as removing, changing\nsubjects, and/or adding new objects. The proposed approach stands out from\nother methods through several significant contributions: (1) RACCooN suggests a\nmulti-granular spatiotemporal pooling strategy to generate well-structured\nvideo descriptions, capturing both the broad context and object details without\nrequiring complex human annotations, simplifying precise video content editing\nbased on text for users. (2) Our video generative model incorporates\nauto-generated narratives or instructions to enhance the quality and accuracy\nof the generated content. (3) RACCooN also plans to imagine new objects in a\ngiven video, so users simply prompt the model to receive a detailed video\nediting plan for complex video editing. The proposed framework demonstrates\nimpressive versatile capabilities in video-to-paragraph generation, video\ncontent editing, and can be incorporated into other SoTA video generative\nmodels for further enhancement.\n","authors":["Jaehong Yoon","Shoubin Yu","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2405.18406v2.pdf","comment":"The first two authors contribute equally. Project Page:\n  https://raccoon-mllm-gen.github.io/"},{"id":"http://arxiv.org/abs/2410.16151v1","updated":"2024-10-21T16:18:31Z","published":"2024-10-21T16:18:31Z","title":"Small Contributions, Small Networks: Efficient Neural Network Pruning\n  Based on Relative Importance","summary":"  Recent advancements have scaled neural networks to unprecedented sizes,\nachieving remarkable performance across a wide range of tasks. However,\ndeploying these large-scale models on resource-constrained devices poses\nsignificant challenges due to substantial storage and computational\nrequirements. Neural network pruning has emerged as an effective technique to\nmitigate these limitations by reducing model size and complexity. In this\npaper, we introduce an intuitive and interpretable pruning method based on\nactivation statistics, rooted in information theory and statistical analysis.\nOur approach leverages the statistical properties of neuron activations to\nidentify and remove weights with minimal contributions to neuron outputs.\nSpecifically, we build a distribution of weight contributions across the\ndataset and utilize its parameters to guide the pruning process. Furthermore,\nwe propose a Pruning-aware Training strategy that incorporates an additional\nregularization term to enhance the effectiveness of our pruning method.\nExtensive experiments on multiple datasets and network architectures\ndemonstrate that our method consistently outperforms several baseline and\nstate-of-the-art pruning techniques.\n","authors":["Mostafa Hussien","Mahmoud Afifi","Kim Khoa Nguyen","Mohamed Cheriet"],"pdf_url":"https://arxiv.org/pdf/2410.16151v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16148v1","updated":"2024-10-21T16:17:22Z","published":"2024-10-21T16:17:22Z","title":"PODTILE: Facilitating Podcast Episode Browsing with Auto-generated\n  Chapters","summary":"  Listeners of long-form talk-audio content, such as podcast episodes, often\nfind it challenging to understand the overall structure and locate relevant\nsections. A practical solution is to divide episodes into\nchapters--semantically coherent segments labeled with titles and timestamps.\nSince most episodes on our platform at Spotify currently lack creator-provided\nchapters, automating the creation of chapters is essential. Scaling the\nchapterization of podcast episodes presents unique challenges. First, episodes\ntend to be less structured than written texts, featuring spontaneous\ndiscussions with nuanced transitions. Second, the transcripts are usually\nlengthy, averaging about 16,000 tokens, which necessitates efficient processing\nthat can preserve context. To address these challenges, we introduce PODTILE, a\nfine-tuned encoder-decoder transformer to segment conversational data. The\nmodel simultaneously generates chapter transitions and titles for the input\ntranscript. To preserve context, each input text is augmented with global\ncontext, including the episode's title, description, and previous chapter\ntitles. In our intrinsic evaluation, PODTILE achieved an 11% improvement in\nROUGE score over the strongest baseline. Additionally, we provide insights into\nthe practical benefits of auto-generated chapters for listeners navigating\nepisode content. Our findings indicate that auto-generated chapters serve as a\nuseful tool for engaging with less popular podcasts. Finally, we present\nempirical evidence that using chapter titles can enhance effectiveness of\nsparse retrieval in search tasks.\n","authors":["Azin Ghazimatin","Ekaterina Garmash","Gustavo Penha","Kristen Sheets","Martin Achenbach","Oguz Semerci","Remi Galvez","Marcus Tannenberg","Sahitya Mantravadi","Divya Narayanan","Ofeliya Kalaydzhyan","Douglas Cole","Ben Carterette","Ann Clifton","Paul N. Bennett","Claudia Hauff","Mounia Lalmas"],"pdf_url":"https://arxiv.org/pdf/2410.16148v1.pdf","comment":"9 pages, 4 figures, CIKM industry track 2024"},{"id":"http://arxiv.org/abs/2410.16136v1","updated":"2024-10-21T16:01:39Z","published":"2024-10-21T16:01:39Z","title":"Modeling dynamic neural activity by combining naturalistic video stimuli\n  and stimulus-independent latent factors","summary":"  Understanding how the brain processes dynamic natural stimuli remains a\nfundamental challenge in neuroscience. Current dynamic neural encoding models\neither take stimuli as input but ignore shared variability in neural responses,\nor they model this variability by deriving latent embeddings from neural\nresponses or behavior while ignoring the visual input. To address this gap, we\npropose a probabilistic model that incorporates video inputs along with\nstimulus-independent latent factors to capture variability in neuronal\nresponses, predicting a joint distribution for the entire population. After\ntraining and testing our model on mouse V1 neuronal responses, we found that it\noutperforms video-only models in terms of log-likelihood and achieves further\nimprovements when conditioned on responses from other neurons. Furthermore, we\nfind that the learned latent factors strongly correlate with mouse behavior,\nalthough the model was trained without behavior data.\n","authors":["Finn Schmidt","Suhas Shrinivasan","Polina Turishcheva","Fabian H. Sinz"],"pdf_url":"https://arxiv.org/pdf/2410.16136v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16135v1","updated":"2024-10-21T16:00:04Z","published":"2024-10-21T16:00:04Z","title":"Beyond 2:4: exploring V:N:M sparsity for efficient transformer inference\n  on GPUs","summary":"  To date, 2:4 sparsity has stood as the only sparse pattern that can be\naccelerated using sparse tensor cores on GPUs. In practice, 2:4 sparsity often\npossesses low actual speedups ($\\leq 1.3$) and requires fixed sparse ratios,\nmeaning that other ratios, such as 4:8, 8:16, or those exceeding 50% sparsity,\ndo not incur any speedups on GPUs. Recent studies suggest that V:N:M sparsity\nis promising in addressing these limitations of 2:4 sparsity. However,\nregarding accuracy, the effects of V:N:M sparsity on broader Transformer\nmodels, such as vision Transformers and large language models (LLMs), are\nlargely unexamined. Moreover, Some specific issues related to V:N:M sparsity,\nsuch as how to select appropriate V and M values, remain unresolved. In this\nstudy, we thoroughly investigate the application of V:N:M sparsity in vision\nmodels and LLMs across multiple tasks, from pertaining to downstream tasks. We\npropose three key approaches to enhance the applicability and accuracy of\nV:N:M-sparse Transformers, including heuristic V and M selection,\nV:N:M-specific channel permutation, and three-staged LoRA training techniques.\nExperimental results show that, with our methods, the DeiT-small achieves\nlossless accuracy at 64:2:5 sparsity, while the DeiT-base maintains accuracy\neven at 64:2:8 sparsity. In addition, the fine-tuned LLama2-7B at 64:2:5\nsparsity performs comparably or better than training-free 2:4 sparse\nalternatives on downstream tasks. More importantly, V:N:M-sparse Transformers\noffer a wider range of speedup-accuracy trade-offs compared to 2:4 sparsity.\nOverall, our exploration largely facilitates the V:N:M sparsity to act as a\ntruly effective acceleration solution for Transformers in cost-sensitive\ninference scenarios.\n","authors":["Kang Zhao","Tao Yuan","Han Bao","Zhenfeng Su","Chang Gao","Zhaofeng Sun","Zichen Liang","Liping Jing","Jianfei Chen"],"pdf_url":"https://arxiv.org/pdf/2410.16135v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.14134v2","updated":"2024-10-21T15:59:18Z","published":"2024-08-26T09:29:56Z","title":"Exploring the Potential of Large Language Models for Heterophilic Graphs","summary":"  Large language models (LLMs) have presented significant opportunities to\nenhance various machine learning applications, including graph neural networks\n(GNNs). By leveraging the vast open-world knowledge within LLMs, we can more\neffectively interpret and utilize textual data to better characterize\nheterophilic graphs, where neighboring nodes often have different labels.\nHowever, existing approaches for heterophilic graphs overlook the rich textual\ndata associated with nodes, which could unlock deeper insights into their\nheterophilic contexts. In this work, we explore the potential of LLMs for\nmodeling heterophilic graphs and propose a novel two-stage framework:\nLLM-enhanced edge discriminator and LLM-guided edge reweighting. In the first\nstage, we fine-tune the LLM to better identify homophilic and heterophilic\nedges based on the textual content of their nodes. In the second stage, we\nadaptively manage message propagation in GNNs for different edge types based on\nnode features, structures, and heterophilic or homophilic characteristics. To\ncope with the computational demands when deploying LLMs in practical scenarios,\nwe further explore model distillation techniques to fine-tune smaller, more\nefficient models that maintain competitive performance. Extensive experiments\nvalidate the effectiveness of our framework, demonstrating the feasibility of\nusing LLMs to enhance node classification on heterophilic graphs.\n","authors":["Yuxia Wu","Shujie Li","Yuan Fang","Chuan Shi"],"pdf_url":"https://arxiv.org/pdf/2408.14134v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2409.13761v2","updated":"2024-10-21T15:59:18Z","published":"2024-09-16T18:46:24Z","title":"Do Large Language Models Need a Content Delivery Network?","summary":"  As the use of large language models (LLMs) expands rapidly, so does the range\nof knowledge needed to supplement various LLM queries. Thus, enabling flexible\nand efficient injection of new knowledge in LLM inference is critical. Three\nhigh-level options exist: (i) embedding the knowledge in LLM's weights (i.e.,\nfine-tuning), (ii) including the knowledge as a part of LLM's text input (i.e.,\nin-context learning), or (iii) injecting the KV caches of the new knowledge to\nLLM during prefill. This paper argues that, although fine-tuning and in-context\nlearning are popular, using KV caches as the medium of knowledge could\nsimultaneously enable more modular management of knowledge injection and more\nefficient LLM serving with low cost and fast response. To realize these\nbenefits, we envision a Knowledge Delivery Network (KDN), a new system\ncomponent in LLM services that dynamically optimizes the storage, transfer, and\ncomposition of KV cache across LLM engines and other compute and storage\nresources. We believe that, just like content delivery networks (CDNs), such as\nAkamai, enabled the success of the Internet ecosystem through their efficient\ndata delivery, KDNs will be critical to the success of LLM applications through\ntheir efficient knowledge delivery. We have open-sourced a KDN prototype at\nhttps://github.com/LMCache/LMCache.\n","authors":["Yihua Cheng","Kuntai Du","Jiayi Yao","Junchen Jiang"],"pdf_url":"https://arxiv.org/pdf/2409.13761v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13502v2","updated":"2024-10-21T15:58:30Z","published":"2024-10-17T12:48:14Z","title":"MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily\n  Complex Proofs","summary":"  Large language models (LLMs) can solve arithmetic word problems with high\naccuracy, but little is known about how well they generalize to problems that\nare more complex than the ones on which they have been trained. Empirical\ninvestigations of such questions are impeded by two major flaws of current\nevaluations: (i) much of the evaluation data is contaminated, in the sense that\nit has already been seen during training, and (ii) benchmark datasets do not\ncapture how problem proofs may be arbitrarily complex in various ways. As a\nstep towards addressing these issues, we present a framework for evaluating\nLLMs on problems with arbitrarily complex arithmetic proofs, called MathGAP.\nMathGAP generates problems that follow fixed proof specifications -- along with\nchain-of-thought reasoning annotations -- enabling systematic studies on\ngeneralization with respect to arithmetic proof complexity. We apply MathGAP to\nanalyze how in-context learning interacts with generalization to problems that\nhave more complex proofs. We find that among the models tested, most show a\nsignificant decrease in performance as proofs get deeper and wider. This effect\nis more pronounced in complex, nonlinear proof structures, which are\nchallenging even for GPT-4o. Surprisingly, providing in-context examples from\nthe same distribution as the test set is not always beneficial for performance.\nIn particular, zero-shot prompting as well as demonstrating a diverse range of\nexamples that are less complex than the test data sometimes yield similar or\nhigher accuracies.\n","authors":["Andreas Opedal","Haruki Shirakami","Bernhard Schölkopf","Abulhair Saparov","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2410.13502v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2407.00299v4","updated":"2024-10-21T15:56:23Z","published":"2024-06-29T03:37:29Z","title":"Human-Agent Joint Learning for Efficient Robot Manipulation Skill\n  Acquisition","summary":"  Employing a teleoperation system for gathering demonstrations offers the\npotential for more efficient learning of robot manipulation. However,\nteleoperating a robot arm equipped with a dexterous hand or gripper, via a\nteleoperation system presents inherent challenges due to the task's high\ndimensionality, complexity of motion, and differences between physiological\nstructures. In this study, we introduce a novel system for joint learning\nbetween human operators and robots, that enables human operators to share\ncontrol of a robot end-effector with a learned assistive agent, simplifies the\ndata collection process, and facilitates simultaneous human demonstration\ncollection and robot manipulation training. As data accumulates, the assistive\nagent gradually learns. Consequently, less human effort and attention are\nrequired, enhancing the efficiency of the data collection process. It also\nallows the human operator to adjust the control ratio to achieve a trade-off\nbetween manual and automated control. We conducted experiments in both\nsimulated environments and physical real-world settings. Through user studies\nand quantitative evaluations, it is evident that the proposed system could\nenhance data collection efficiency and reduce the need for human adaptation\nwhile ensuring the collected data is of sufficient quality for downstream\ntasks. \\textit{For more details, please refer to our webpage\nhttps://norweig1an.github.io/HAJL.github.io/.\n","authors":["Shengcheng Luo","Quanquan Peng","Jun Lv","Kaiwen Hong","Katherine Rose Driggs-Campbell","Cewu Lu","Yong-Lu Li"],"pdf_url":"https://arxiv.org/pdf/2407.00299v4.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.16132v1","updated":"2024-10-21T15:56:17Z","published":"2024-10-21T15:56:17Z","title":"A Data-driven Crowd Simulation Framework Integrating Physics-informed\n  Machine Learning with Navigation Potential Fields","summary":"  Traditional rule-based physical models are limited by their reliance on\nsingular physical formulas and parameters, making it difficult to effectively\ntackle the intricate tasks associated with crowd simulation. Recent research\nhas introduced deep learning methods to tackle these issues, but most current\napproaches focus primarily on generating pedestrian trajectories, often lacking\ninterpretability and failing to provide real-time dynamic simulations.To\naddress the aforementioned issues, we propose a novel data-driven crowd\nsimulation framework that integrates Physics-informed Machine Learning (PIML)\nwith navigation potential fields. Our approach leverages the strengths of both\nphysical models and PIML. Specifically, we design an innovative\nPhysics-informed Spatio-temporal Graph Convolutional Network (PI-STGCN) as a\ndata-driven module to predict pedestrian movement trends based on crowd\nspatio-temporal data. Additionally, we construct a physical model of navigation\npotential fields based on flow field theory to guide pedestrian movements,\nthereby reinforcing physical constraints during the simulation. In our\nframework, navigation potential fields are dynamically computed and updated\nbased on the movement trends predicted by the PI-STGCN, while the updated crowd\ndynamics, guided by these fields, subsequently feed back into the PI-STGCN.\nComparative experiments on two publicly available large-scale real-world\ndatasets across five scenes demonstrate that our proposed framework outperforms\nexisting rule-based methods in accuracy and fidelity. The similarity between\nsimulated and actual pedestrian trajectories increases by 10.8%, while the\naverage error is reduced by 4%. Moreover, our framework exhibits greater\nadaptability and better interpretability compared to methods that rely solely\non deep learning for trajectory generation.\n","authors":["Runkang Guo","Bin Chen","Qi Zhang","Yong Zhao","Xiao Wang","Zhengqiu Zhu"],"pdf_url":"https://arxiv.org/pdf/2410.16132v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16128v1","updated":"2024-10-21T15:55:04Z","published":"2024-10-21T15:55:04Z","title":"SMART: Self-learning Meta-strategy Agent for Reasoning Tasks","summary":"  Tasks requiring deductive reasoning, especially those involving multiple\nsteps, often demand adaptive strategies such as intermediate generation of\nrationales or programs, as no single approach is universally optimal. While\nLanguage Models (LMs) can enhance their outputs through iterative\nself-refinement and strategy adjustments, they frequently fail to apply the\nmost effective strategy in their first attempt. This inefficiency raises the\nquestion: Can LMs learn to select the optimal strategy in the first attempt,\nwithout a need for refinement? To address this challenge, we introduce SMART\n(Self-learning Meta-strategy Agent for Reasoning Tasks), a novel framework that\nenables LMs to autonomously learn and select the most effective strategies for\nvarious reasoning tasks. We model the strategy selection process as a Markov\nDecision Process and leverage reinforcement learning-driven continuous\nself-improvement to allow the model to find the suitable strategy to solve a\ngiven task. Unlike traditional self-refinement methods that rely on multiple\ninference passes or external feedback, SMART allows an LM to internalize the\noutcomes of its own reasoning processes and adjust its strategy accordingly,\naiming for correct solutions on the first attempt. Our experiments across\nvarious reasoning datasets and with different model architectures demonstrate\nthat SMART significantly enhances the ability of models to choose optimal\nstrategies without external guidance (+15 points on the GSM8K dataset). By\nachieving higher accuracy with a single inference pass, SMART not only improves\nperformance but also reduces computational costs for refinement-based\nstrategies, paving the way for more efficient and intelligent reasoning in LMs.\n","authors":["Rongxing Liu","Kumar Shridhar","Manish Prajapat","Patrick Xia","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2410.16128v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16119v1","updated":"2024-10-21T15:47:03Z","published":"2024-10-21T15:47:03Z","title":"SeaDAG: Semi-autoregressive Diffusion for Conditional Directed Acyclic\n  Graph Generation","summary":"  We introduce SeaDAG, a semi-autoregressive diffusion model for conditional\ngeneration of Directed Acyclic Graphs (DAGs). Considering their inherent\nlayer-wise structure, we simulate layer-wise autoregressive generation by\ndesigning different denoising speed for different layers. Unlike conventional\nautoregressive generation that lacks a global graph structure view, our method\nmaintains a complete graph structure at each diffusion step, enabling\noperations such as property control that require the full graph structure.\nLeveraging this capability, we evaluate the DAG properties during training by\nemploying a graph property decoder. We explicitly train the model to learn\ngraph conditioning with a condition loss, which enhances the diffusion model's\ncapacity to generate graphs that are both realistic and aligned with specified\nproperties. We evaluate our method on two representative conditional DAG\ngeneration tasks: (1) circuit generation from truth tables, where precise DAG\nstructures are crucial for realizing circuit functionality, and (2) molecule\ngeneration based on quantum properties. Our approach demonstrates promising\nresults, generating high-quality and realistic DAGs that closely align with\ngiven conditions.\n","authors":["Xinyi Zhou","Xing Li","Yingzhao Lian","Yiwen Wang","Lei Chen","Mingxuan Yuan","Jianye Hao","Guangyong Chen","Pheng Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2410.16119v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16116v1","updated":"2024-10-21T15:42:47Z","published":"2024-10-21T15:42:47Z","title":"Multimodal Flare Forecasting with Deep Learning","summary":"  Solar flare forecasting mainly relies on photospheric magnetograms and\nassociated physical features to predict forthcoming flares. However, it is\nbelieved that flare initiation mechanisms often originate in the chromosphere\nand the lower corona. In this study, we employ deep learning as a purely\ndata-driven approach to compare the predictive capabilities of chromospheric\nand coronal UV and EUV emissions across different wavelengths with those of\nphotospheric line-of-sight magnetograms. Our findings indicate that individual\nEUV wavelengths can provide discriminatory power comparable or better to that\nof line-of-sight magnetograms. Moreover, we identify simple multimodal neural\nnetwork architectures that consistently outperform single-input models, showing\ncomplementarity between the flare precursors that can be extracted from the\ndistinct layers of the solar atmosphere. To mitigate potential biases from\nknown misattributions in Active Region flare catalogs, our models are trained\nand evaluated using full-disk images and a comprehensive flare event catalog at\nthe full-disk level. We introduce a deep-learning architecture suited for\nextracting temporal features from full-disk videos.\n","authors":["Grégoire Francisco","Sabrina Guastavino","Teresa Barata","João Fernandes","Dario Del Moro"],"pdf_url":"https://arxiv.org/pdf/2410.16116v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16105v1","updated":"2024-10-21T15:34:33Z","published":"2024-10-21T15:34:33Z","title":"Addressing Spectral Bias of Deep Neural Networks by Multi-Grade Deep\n  Learning","summary":"  Deep neural networks (DNNs) suffer from the spectral bias, wherein DNNs\ntypically exhibit a tendency to prioritize the learning of lower-frequency\ncomponents of a function, struggling to capture its high-frequency features.\nThis paper is to address this issue. Notice that a function having only low\nfrequency components may be well-represented by a shallow neural network (SNN),\na network having only a few layers. By observing that composition of low\nfrequency functions can effectively approximate a high-frequency function, we\npropose to learn a function containing high-frequency components by composing\nseveral SNNs, each of which learns certain low-frequency information from the\ngiven data. We implement the proposed idea by exploiting the multi-grade deep\nlearning (MGDL) model, a recently introduced model that trains a DNN\nincrementally, grade by grade, a current grade learning from the residue of the\nprevious grade only an SNN composed with the SNNs trained in the preceding\ngrades as features. We apply MGDL to synthetic, manifold, colored images, and\nMNIST datasets, all characterized by presence of high-frequency features. Our\nstudy reveals that MGDL excels at representing functions containing\nhigh-frequency information. Specifically, the neural networks learned in each\ngrade adeptly capture some low-frequency information, allowing their\ncompositions with SNNs learned in the previous grades effectively representing\nthe high-frequency features. Our experimental results underscore the efficacy\nof MGDL in addressing the spectral bias inherent in DNNs. By leveraging MGDL,\nwe offer insights into overcoming spectral bias limitation of DNNs, thereby\nenhancing the performance and applicability of deep learning models in tasks\nrequiring the representation of high-frequency information. This study confirms\nthat the proposed method offers a promising solution to address the spectral\nbias of DNNs.\n","authors":["Ronglong Fang","Yuesheng Xu"],"pdf_url":"https://arxiv.org/pdf/2410.16105v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.06955v3","updated":"2024-10-21T15:26:26Z","published":"2024-02-10T13:51:09Z","title":"Feature Mapping in Physics-Informed Neural Networks (PINNs)","summary":"  In this paper, the training dynamics of PINNs with a feature mapping layer\nvia the limiting Conjugate Kernel and Neural Tangent Kernel is investigated,\nshedding light on the convergence of PINNs; Although the commonly used\nFourier-based feature mapping has achieved great success, we show its\ninadequacy in some physics scenarios. Via these two scopes, we propose\nconditionally positive definite Radial Basis Function as a better alternative.\nLastly, we explore the feature mapping numerically in wide neural networks. Our\nempirical results reveal the efficacy of our method in diverse forward and\ninverse problem sets. Composing feature functions is found to be a practical\nway to address the expressivity and generalisability trade-off, viz., tuning\nthe bandwidth of the kernels and the surjectivity of the feature mapping\nfunction. This simple technique can be implemented for coordinate inputs and\nbenefits the broader PINNs research.\n","authors":["Chengxi Zeng","Tilo Burghardt","Alberto M Gambaruto"],"pdf_url":"https://arxiv.org/pdf/2402.06955v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14485v8","updated":"2024-10-21T15:24:04Z","published":"2024-06-20T16:48:14Z","title":"Proceedings of The second international workshop on eXplainable AI for\n  the Arts (XAIxArts)","summary":"  This second international workshop on explainable AI for the Arts (XAIxArts)\nbrought together a community of researchers in HCI, Interaction Design, AI,\nexplainable AI (XAI), and digital arts to explore the role of XAI for the Arts.\nWorkshop held at the 16th ACM Conference on Creativity and Cognition (C&C\n2024), Chicago, USA.\n","authors":["Nick Bryan-Kinns","Corey Ford","Shuoyang Zheng","Helen Kennedy","Alan Chamberlain","Makayla Lewis","Drew Hemment","Zijin Li","Qiong Wu","Lanxi Xiao","Gus Xia","Jeba Rezwana","Michael Clemens","Gabriel Vigliensoni"],"pdf_url":"https://arxiv.org/pdf/2406.14485v8.pdf","comment":"Proceedings of The second international workshop on eXplainable AI\n  for the Arts (XAIxArts)"},{"id":"http://arxiv.org/abs/2410.13203v2","updated":"2024-10-21T15:21:56Z","published":"2024-10-17T04:10:36Z","title":"TabSeq: A Framework for Deep Learning on Tabular Data via Sequential\n  Ordering","summary":"  Effective analysis of tabular data still poses a significant problem in deep\nlearning, mainly because features in tabular datasets are often heterogeneous\nand have different levels of relevance. This work introduces TabSeq, a novel\nframework for the sequential ordering of features, addressing the vital\nnecessity to optimize the learning process. Features are not always equally\ninformative, and for certain deep learning models, their random arrangement can\nhinder the model's learning capacity. Finding the optimum sequence order for\nsuch features could improve the deep learning models' learning process. The\nnovel feature ordering technique we provide in this work is based on clustering\nand incorporates both local ordering and global ordering. It is designed to be\nused with a multi-head attention mechanism in a denoising autoencoder network.\nOur framework uses clustering to align comparable features and improve data\norganization. Multi-head attention focuses on essential characteristics,\nwhereas the denoising autoencoder highlights important aspects by rebuilding\nfrom distorted inputs. This method improves the capability to learn from\ntabular data while lowering redundancy. Our research, demonstrating improved\nperformance through appropriate feature sequence rearrangement using raw\nantibody microarray and two other real-world biomedical datasets, validates the\nimpact of feature ordering. These results demonstrate that feature ordering can\nbe a viable approach to improved deep learning of tabular data.\n","authors":["Al Zadid Sultan Bin Habib","Kesheng Wang","Mary-Anne Hartley","Gianfranco Doretto","Donald A. Adjeroh"],"pdf_url":"https://arxiv.org/pdf/2410.13203v2.pdf","comment":"This paper has been accepted for presentation at the 27th\n  International Conference on Pattern Recognition (ICPR 2024) in Kolkata, India"},{"id":"http://arxiv.org/abs/2410.16091v1","updated":"2024-10-21T15:13:17Z","published":"2024-10-21T15:13:17Z","title":"Neural Quantum Propagators for Driven-Dissipative Quantum Dynamics","summary":"  Describing the dynamics of strong-laser driven open quantum systems is a very\nchallenging task that requires the solution of highly involved equations of\nmotion. While machine learning techniques are being applied with some success\nto simulate the time evolution of individual quantum states, their use to\napproximate time-dependent operators (that can evolve various states) remains\nlargely unexplored. In this work, we develop driven neural quantum propagators\n(NQP), a universal neural network framework that solves driven-dissipative\nquantum dynamics by approximating propagators rather than wavefunctions or\ndensity matrices. NQP can handle arbitrary initial quantum states, adapt to\nvarious external fields, and simulate long-time dynamics, even when trained on\nfar shorter time windows. Furthermore, by appropriately configuring the\nexternal fields, our trained NQP can be transferred to systems governed by\ndifferent Hamiltonians. We demonstrate the effectiveness of our approach by\nstudying the spin-boson and the three-state transition Gamma models.\n","authors":["Jiaji Zhang","Carlos L. Benavides-Riveros","Lipeng Chen"],"pdf_url":"https://arxiv.org/pdf/2410.16091v1.pdf","comment":"7 pages, comment are welcome!"},{"id":"http://arxiv.org/abs/2410.16089v1","updated":"2024-10-21T15:12:37Z","published":"2024-10-21T15:12:37Z","title":"Multi-Sensor Fusion for UAV Classification Based on Feature Maps of\n  Image and Radar Data","summary":"  The unique cost, flexibility, speed, and efficiency of modern UAVs make them\nan attractive choice in many applications in contemporary society. This,\nhowever, causes an ever-increasing number of reported malicious or accidental\nincidents, rendering the need for the development of UAV detection and\nclassification mechanisms essential. We propose a methodology for developing a\nsystem that fuses already processed multi-sensor data into a new Deep Neural\nNetwork to increase its classification accuracy towards UAV detection. The DNN\nmodel fuses high-level features extracted from individual object detection and\nclassification models associated with thermal, optronic, and radar data.\nAdditionally, emphasis is given to the model's Convolutional Neural Network\n(CNN) based architecture that combines the features of the three sensor\nmodalities by stacking the extracted image features of the thermal and optronic\nsensor achieving higher classification accuracy than each sensor alone.\n","authors":["Nikos Sakellariou","Antonios Lalas","Konstantinos Votis","Dimitrios Tzovaras"],"pdf_url":"https://arxiv.org/pdf/2410.16089v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.16088v1","updated":"2024-10-21T15:12:20Z","published":"2024-10-21T15:12:20Z","title":"Fine-Tuning LLMs for Reliable Medical Question-Answering Services","summary":"  We present an advanced approach to medical question-answering (QA) services,\nusing fine-tuned Large Language Models (LLMs) to improve the accuracy and\nreliability of healthcare information. Our study focuses on optimizing models\nlike LLaMA-2 and Mistral, which have shown great promise in delivering precise,\nreliable medical answers. By leveraging comprehensive datasets, we applied\nfine-tuning techniques such as rsDoRA+ and ReRAG. rsDoRA+ enhances model\nperformance through a combination of decomposed model weights, varied learning\nrates for low-rank matrices, and rank stabilization, leading to improved\nefficiency. ReRAG, which integrates retrieval on demand and question rewriting,\nfurther refines the accuracy of the responses. This approach enables healthcare\nproviders to access fast, dependable information, aiding in more efficient\ndecision-making and fostering greater patient trust. Our work highlights the\npotential of fine-tuned LLMs to significantly improve the quality and\naccessibility of medical information services, ultimately contributing to\nbetter healthcare outcomes for all.\n","authors":["Ali Anaissi","Ali Braytee","Junaid Akram"],"pdf_url":"https://arxiv.org/pdf/2410.16088v1.pdf","comment":"8 pages, 10 figures, accepted and to be published in the proceedings\n  of 2024 IEEE International Conference on Data Mining Workshops (ICDMW)"},{"id":"http://arxiv.org/abs/2410.16083v1","updated":"2024-10-21T15:02:30Z","published":"2024-10-21T15:02:30Z","title":"Critical Example Mining for Vehicle Trajectory Prediction using\n  Flow-based Generative Models","summary":"  Precise trajectory prediction in complex driving scenarios is essential for\nautonomous vehicles. In practice, different driving scenarios present varying\nlevels of difficulty for trajectory prediction models. However, most existing\nresearch focuses on the average precision of prediction results, while ignoring\nthe underlying distribution of the input scenarios. This paper proposes a\ncritical example mining method that utilizes a data-driven approach to estimate\nthe rareness of the trajectories. By combining the rareness estimation of\nobservations with whole trajectories, the proposed method effectively\nidentifies a subset of data that is relatively hard to predict BEFORE feeding\nthem to a specific prediction model. The experimental results show that the\nmined subset has higher prediction error when applied to different downstream\nprediction models, which reaches +108.1% error (greater than two times compared\nto the average on dataset) when mining 5% samples. Further analysis indicates\nthat the mined critical examples include uncommon cases such as sudden brake\nand cancelled lane-change, which helps to better understand and improve the\nperformance of prediction models.\n","authors":["Zhezhang Ding","Huijing Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.16083v1.pdf","comment":"8 pages,6 figures"},{"id":"http://arxiv.org/abs/2410.16070v1","updated":"2024-10-21T14:48:35Z","published":"2024-10-21T14:48:35Z","title":"On-Device LLMs for SMEs: Challenges and Opportunities","summary":"  This paper presents a systematic review of the infrastructure requirements\nfor deploying Large Language Models (LLMs) on-device within the context of\nsmall and medium-sized enterprises (SMEs), focusing on both hardware and\nsoftware perspectives. From the hardware viewpoint, we discuss the utilization\nof processing units like GPUs and TPUs, efficient memory and storage solutions,\nand strategies for effective deployment, addressing the challenges of limited\ncomputational resources typical in SME settings. From the software perspective,\nwe explore framework compatibility, operating system optimization, and the use\nof specialized libraries tailored for resource-constrained environments. The\nreview is structured to first identify the unique challenges faced by SMEs in\ndeploying LLMs on-device, followed by an exploration of the opportunities that\nboth hardware innovations and software adaptations offer to overcome these\nobstacles. Such a structured review provides practical insights, contributing\nsignificantly to the community by enhancing the technological resilience of\nSMEs in integrating LLMs.\n","authors":["Jeremy Stephen Gabriel Yee Zhi Wen","Pai Chet Ng","Zhengkui Wang","Ian McLoughlin","Aik Beng Ng","Simon See"],"pdf_url":"https://arxiv.org/pdf/2410.16070v1.pdf","comment":"9 pages, 1 figure. The work is supported by the SIT-NVIDIA Joint AI\n  Centre"},{"id":"http://arxiv.org/abs/2410.16063v1","updated":"2024-10-21T14:44:08Z","published":"2024-10-21T14:44:08Z","title":"Integrated Image-Text Based on Semi-supervised Learning for Small Sample\n  Instance Segmentation","summary":"  Small sample instance segmentation is a very challenging task, and many\nexisting methods follow the training strategy of meta-learning which pre-train\nmodels on support set and fine-tune on query set. The pre-training phase, which\nis highly task related, requires a significant amount of additional training\ntime and the selection of datasets with close proximity to ensure\neffectiveness. The article proposes a novel small sample instance segmentation\nsolution from the perspective of maximizing the utilization of existing\ninformation without increasing annotation burden and training costs. The\nproposed method designs two modules to address the problems encountered in\nsmall sample instance segmentation. First, it helps the model fully utilize\nunlabeled data by learning to generate pseudo labels, increasing the number of\navailable samples. Second, by integrating the features of text and image, more\naccurate classification results can be obtained. These two modules are suitable\nfor box-free and box-dependent frameworks. In the way, the proposed method not\nonly improves the performance of small sample instance segmentation, but also\ngreatly reduce reliance on pre-training. We have conducted experiments in three\ndatasets from different scenes: on land, underwater and under microscope. As\nevidenced by our experiments, integrated image-text corrects the confidence of\nclassification, and pseudo labels help the model obtain preciser masks. All the\nresults demonstrate the effectiveness and superiority of our method.\n","authors":["Ruting Chi","Zhiyi Huang","Yuexing Han"],"pdf_url":"https://arxiv.org/pdf/2410.16063v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09940v2","updated":"2024-10-21T14:36:35Z","published":"2024-10-13T17:51:21Z","title":"Generalized Group Data Attribution","summary":"  Data Attribution (DA) methods quantify the influence of individual training\ndata points on model outputs and have broad applications such as\nexplainability, data selection, and noisy label identification. However,\nexisting DA methods are often computationally intensive, limiting their\napplicability to large-scale machine learning models. To address this\nchallenge, we introduce the Generalized Group Data Attribution (GGDA)\nframework, which computationally simplifies DA by attributing to groups of\ntraining points instead of individual ones. GGDA is a general framework that\nsubsumes existing attribution methods and can be applied to new DA techniques\nas they emerge. It allows users to optimize the trade-off between efficiency\nand fidelity based on their needs. Our empirical results demonstrate that GGDA\napplied to popular DA methods such as Influence Functions, TracIn, and TRAK\nresults in upto 10x-50x speedups over standard DA methods while gracefully\ntrading off attribution fidelity. For downstream applications such as dataset\npruning and noisy label identification, we demonstrate that GGDA significantly\nimproves computational efficiency and maintains effectiveness, enabling\npractical applications in large-scale machine learning scenarios that were\npreviously infeasible.\n","authors":["Dan Ley","Suraj Srinivas","Shichang Zhang","Gili Rusak","Himabindu Lakkaraju"],"pdf_url":"https://arxiv.org/pdf/2410.09940v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.04684v2","updated":"2024-10-21T14:21:59Z","published":"2023-12-07T20:36:10Z","title":"Latent Skill Discovery for Chain-of-Thought Reasoning","summary":"  Chain-of-thought (CoT) prompting is a popular in-context learning (ICL)\napproach for large language models (LLMs), especially when tackling complex\nreasoning tasks. Traditional ICL approaches construct prompts using examples\nthat contain questions similar to the input question. However, CoT prompting,\nwhich includes crucial intermediate reasoning steps (rationales) within its\nexamples, necessitates selecting examples based on these rationales rather than\nthe questions themselves. Existing methods require human experts or pre-trained\nLLMs to describe the skill, a high-level abstraction of rationales, to guide\nthe selection. These methods, however, are often costly and difficult to scale.\nInstead, this paper introduces a new approach named Latent Reasoning Skills\n(LaRS) that employs unsupervised learning to create a latent space\nrepresentation of rationales, with a latent variable called a reasoning skill.\nConcurrently, LaRS learns a reasoning policy to determine the required\nreasoning skill for a given question. Then the ICL examples are selected by\naligning the reasoning skills between past examples and the question. This\napproach is theoretically grounded and compute-efficient, eliminating the need\nfor auxiliary LLM inference or manual prompt design. Empirical results\ndemonstrate that LaRS consistently outperforms SOTA skill-based selection\nmethods, processing example banks four times faster, reducing LLM inferences\nduring the selection stage by half, and showing greater robustness to\nsub-optimal example banks.\n","authors":["Zifan Xu","Haozhu Wang","Dmitriy Bespalov","Xuan Wang","Peter Stone","Yanjun Qi"],"pdf_url":"https://arxiv.org/pdf/2312.04684v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.09478v2","updated":"2024-10-21T14:15:30Z","published":"2024-09-14T16:39:17Z","title":"From FDG to PSMA: A Hitchhiker's Guide to Multitracer, Multicenter\n  Lesion Segmentation in PET/CT Imaging","summary":"  Automated lesion segmentation in PET/CT scans is crucial for improving\nclinical workflows and advancing cancer diagnostics. However, the task is\nchallenging due to physiological variability, different tracers used in PET\nimaging, and diverse imaging protocols across medical centers. To address this,\nthe autoPET series was created to challenge researchers to develop algorithms\nthat generalize across diverse PET/CT environments. This paper presents our\nsolution for the autoPET III challenge, targeting multitracer, multicenter\ngeneralization using the nnU-Net framework with the ResEncL architecture. Key\ntechniques include misalignment data augmentation and multi-modal pretraining\nacross CT, MR, and PET datasets to provide an initial anatomical understanding.\nWe incorporate organ supervision as a multitask approach, enabling the model to\ndistinguish between physiological uptake and tracer-specific patterns, which is\nparticularly beneficial in cases where no lesions are present. Compared to the\ndefault nnU-Net, which achieved a Dice score of 57.61, or the larger ResEncL\n(65.31) our model significantly improved performance with a Dice score of\n68.40, alongside a reduction in false positive (FPvol: 7.82) and false negative\n(FNvol: 10.35) volumes. These results underscore the effectiveness of combining\nadvanced network design, augmentation, pretraining, and multitask learning for\nPET/CT lesion segmentation. After evaluation on the test set, our approach was\nawarded the first place in the model-centric category (Team LesionTracer). Code\nis publicly available at https://github.com/MIC-DKFZ/autopet-3-submission.\n","authors":["Maximilian Rokuss","Balint Kovacs","Yannick Kirchhoff","Shuhan Xiao","Constantin Ulrich","Klaus H. Maier-Hein","Fabian Isensee"],"pdf_url":"https://arxiv.org/pdf/2409.09478v2.pdf","comment":"Winning method of the autoPET III challenge (model-centric) - Team\n  LesionTracer"},{"id":"http://arxiv.org/abs/2410.16032v1","updated":"2024-10-21T14:06:53Z","published":"2024-10-21T14:06:53Z","title":"TimeMixer++: A General Time Series Pattern Machine for Universal\n  Predictive Analysis","summary":"  Time series analysis plays a critical role in numerous applications,\nsupporting tasks such as forecasting, classification, anomaly detection, and\nimputation. In this work, we present the time series pattern machine (TSPM), a\nmodel designed to excel in a broad range of time series tasks through powerful\nrepresentation and pattern extraction capabilities. Traditional time series\nmodels often struggle to capture universal patterns, limiting their\neffectiveness across diverse tasks. To address this, we define multiple scales\nin the time domain and various resolutions in the frequency domain, employing\nvarious mixing strategies to extract intricate, task-adaptive time series\npatterns. Specifically, we introduce a general-purpose TSPM that processes\nmulti-scale time series using (1) multi-resolution time imaging (MRTI), (2)\ntime image decomposition (TID), (3) multi-scale mixing (MCM), and (4)\nmulti-resolution mixing (MRM) to extract comprehensive temporal patterns. MRTI\ntransforms multi-scale time series into multi-resolution time images, capturing\npatterns across both temporal and frequency domains. TID leverages dual-axis\nattention to extract seasonal and trend patterns, while MCM hierarchically\naggregates these patterns across scales. MRM adaptively integrates all\nrepresentations across resolutions. This method achieves state-of-the-art\nperformance across 8 time series analytical tasks, consistently surpassing both\ngeneral-purpose and task-specific models. Our work marks a promising step\ntoward the next generation of TSPMs, paving the way for further advancements in\ntime series analysis.\n","authors":["Shiyu Wang","Jiawei Li","Xiaoming Shi","Zhou Ye","Baichuan Mo","Wenze Lin","Shengtong Ju","Zhixuan Chu","Ming Jin"],"pdf_url":"https://arxiv.org/pdf/2410.16032v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16024v1","updated":"2024-10-21T13:58:38Z","published":"2024-10-21T13:58:38Z","title":"A New Approach to Solving SMAC Task: Generating Decision Tree Code from\n  Large Language Models","summary":"  StarCraft Multi-Agent Challenge (SMAC) is one of the most commonly used\nexperimental environments in multi-agent reinforcement learning (MARL), where\nthe specific task is to control a set number of allied units to defeat enemy\nforces. Traditional MARL algorithms often require interacting with the\nenvironment for up to 1 million steps to train a model, and the resulting\npolicies are typically non-interpretable with weak transferability. In this\npaper, we propose a novel approach to solving SMAC tasks called LLM-SMAC. In\nour framework, agents leverage large language models (LLMs) to generate\ndecision tree code by providing task descriptions. The model is further\nself-reflection using feedback from the rewards provided by the environment. We\nconduct experiments in the SMAC and demonstrate that our method can produce\nhigh-quality, interpretable decision trees with minimal environmental\nexploration. Moreover, these models exhibit strong transferability,\nsuccessfully applying to similar SMAC environments without modification. We\nbelieve this approach offers a new direction for solving decision-making tasks\nin the future.\n","authors":["Yue Deng","Weiyu Ma","Yuxin Fan","Yin Zhang","Haifeng Zhang","Jian Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.16024v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.04202v6","updated":"2024-10-21T13:47:44Z","published":"2024-03-07T04:12:24Z","title":"Dynamics of Moral Behavior in Heterogeneous Populations of Learning\n  Agents","summary":"  Growing concerns about safety and alignment of AI systems highlight the\nimportance of embedding moral capabilities in artificial agents: a promising\nsolution is the use of learning from experience, i.e., Reinforcement Learning.\nIn multi-agent (social) environments, complex population-level phenomena may\nemerge from interactions between individual learning agents. Many of the\nexisting studies rely on simulated social dilemma environments to study the\ninteractions of independent learning agents; however, they tend to ignore the\nmoral heterogeneity that is likely to be present in societies of agents in\npractice. For example, at different points in time a single learning agent may\nface opponents who are consequentialist (i.e., focused on maximizing outcomes\nover time), norm-based (i.e., conforming to specific norms), or virtue-based\n(i.e., considering a combination of different virtues). The extent to which\nagents' co-development may be impacted by such moral heterogeneity in\npopulations is not well understood. In this paper, we present a study of the\nlearning dynamics of morally heterogeneous populations interacting in a social\ndilemma setting. Using an Iterated Prisoner's Dilemma environment with a\npartner selection mechanism, we investigate the extent to which the prevalence\nof diverse moral agents in populations affects individual agents' learning\nbehaviors and emergent population-level outcomes. We observe several types of\nnon-trivial interactions between pro-social and anti-social agents, and find\nthat certain types of moral agents are able to steer selfish agents towards\nmore cooperative behavior.\n","authors":["Elizaveta Tennant","Stephen Hailes","Mirco Musolesi"],"pdf_url":"https://arxiv.org/pdf/2403.04202v6.pdf","comment":"Presented at AIES 2024 (7th AAAI/ACM Conference on AI, Ethics, and\n  Society - San Jose, CA, USA)\n  https://ojs.aaai.org/index.php/AIES/article/view/31736"},{"id":"http://arxiv.org/abs/2410.16012v1","updated":"2024-10-21T13:43:02Z","published":"2024-10-21T13:43:02Z","title":"Massimo: Public Queue Monitoring and Management using Mass-Spring Model","summary":"  An efficient system of a queue control and regulation in public spaces is\nvery important in order to avoid the traffic jams and to improve the customer\nsatisfaction. This article offers a detailed road map based on a merger of\nintelligent systems and creating an efficient systems of queues in public\nplaces. Through the utilization of different technologies i.e. computer vision,\nmachine learning algorithms, deep learning our system provide accurate\ninformation about the place is crowded or not and the necessary efforts to be\ntaken.\n","authors":["Abhijeet Kumar","Unnati Singh","Rajdeep Chatterjee","Tathagata Bandyopadhyay"],"pdf_url":"https://arxiv.org/pdf/2410.16012v1.pdf","comment":"8 pages, 6 figures, 3 algorithms, 3 tables"},{"id":"http://arxiv.org/abs/2410.16011v1","updated":"2024-10-21T13:42:19Z","published":"2024-10-21T13:42:19Z","title":"CA*: Addressing Evaluation Pitfalls in Computation-Aware Latency for\n  Simultaneous Speech Translation","summary":"  Simultaneous speech translation (SimulST) systems must balance translation\nquality with response time, making latency measurement crucial for evaluating\ntheir real-world performance. However, there has been a longstanding belief\nthat current metrics yield unrealistically high latency measurements in\nunsegmented streaming settings. In this paper, we investigate this phenomenon,\nrevealing its root cause in a fundamental misconception underlying existing\nlatency evaluation approaches. We demonstrate that this issue affects not only\nstreaming but also segment-level latency evaluation across different metrics.\nFurthermore, we propose a modification to correctly measure computation-aware\nlatency for SimulST systems, addressing the limitations present in existing\nmetrics.\n","authors":["Xi Xu","Wenda Xu","Siqi Ouyang","Lei Li"],"pdf_url":"https://arxiv.org/pdf/2410.16011v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16008v1","updated":"2024-10-21T13:41:27Z","published":"2024-10-21T13:41:27Z","title":"Resilient Temporal GCN for Smart Grid State Estimation Under Topology\n  Inaccuracies","summary":"  State Estimation is a crucial task in power systems. Graph Neural Networks\nhave demonstrated significant potential in state estimation for power systems\nby effectively analyzing measurement data and capturing the complex\ninteractions and interrelations among the measurements through the system's\ngraph structure. However, the information about the system's graph structure\nmay be inaccurate due to noise, attack or lack of accurate information about\nthe topology of the system. This paper studies these scenarios under topology\nuncertainties and evaluates the impact of the topology uncertainties on the\nperformance of a Temporal Graph Convolutional Network (TGCN) for state\nestimation in power systems. In order to make the model resilient to topology\nuncertainties, modifications in the TGCN model are proposed to incorporate a\nknowledge graph, generated based on the measurement data. This knowledge graph\nsupports the assumed uncertain system graph. Two variations of the TGCN\narchitecture are introduced to integrate the knowledge graph, and their\nperformances are evaluated and compared to demonstrate improved resilience\nagainst topology uncertainties. The evaluation results indicate that while the\ntwo proposed architecture show different performance, they both improve the\nperformance of the TGCN state estimation under topology uncertainties.\n","authors":["Seyed Hamed Haghshenas","Mia Naeini"],"pdf_url":"https://arxiv.org/pdf/2410.16008v1.pdf","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2410.16007v1","updated":"2024-10-21T13:41:15Z","published":"2024-10-21T13:41:15Z","title":"Are Language Model Logits Calibrated?","summary":"  Some information is factual (e.g., \"Paris is in France\"), whereas other\ninformation is probabilistic (e.g., \"the coin flip will be a [Heads/Tails].\").\nWe believe that good Language Models (LMs) should understand and reflect this\nnuance. Our work investigates this by testing if LMs' output probabilities are\ncalibrated to their textual contexts. We define model \"calibration\" as the\ndegree to which the output probabilities of candidate tokens are aligned with\nthe relative likelihood that should be inferred from the given context. For\nexample, if the context concerns two equally likely options (e.g., heads or\ntails for a fair coin), the output probabilities should reflect this. Likewise,\ncontext that concerns non-uniformly likely events (e.g., rolling a six with a\ndie) should also be appropriately captured with proportionate output\nprobabilities. We find that even in simple settings the best LMs (1) are poorly\ncalibrated, and (2) have systematic biases (e.g., preferred colors and\nsensitivities to word orderings). For example, gpt-4o-mini often picks the\nfirst of two options presented in the prompt regardless of the options' implied\nlikelihood, whereas Llama-3.1-8B picks the second. Our other consistent finding\nis mode-collapse: Instruction-tuned models often over-allocate probability mass\non a single option. These systematic biases introduce non-intuitive model\nbehavior, making models harder for users to understand.\n","authors":["Charles Lovering","Michael Krumdick","Viet Dac Lai","Nilesh Kumar","Varshini Reddy","Rik Koncel-Kedziorski","Chris Tanner"],"pdf_url":"https://arxiv.org/pdf/2410.16007v1.pdf","comment":"10 pages (main), 24 pages (appendix), under review"},{"id":"http://arxiv.org/abs/2406.19705v5","updated":"2024-10-21T13:38:48Z","published":"2024-06-28T07:36:31Z","title":"DISCO: Efficient Diffusion Solver for Large-Scale Combinatorial\n  Optimization Problems","summary":"  Combinatorial Optimization (CO) problems are fundamentally important in\nnumerous real-world applications across diverse industries, characterized by\nentailing enormous solution space and demanding time-sensitive response.\nDespite recent advancements in neural solvers, their limited expressiveness\nstruggles to capture the multi-modal nature of CO landscapes. While some\nresearch has shifted towards diffusion models, these models still sample\nsolutions indiscriminately from the entire NP-complete solution space with\ntime-consuming denoising processes, which limit their practicality for large\nproblem scales. We propose DISCO, an efficient DIffusion Solver for large-scale\nCombinatorial Optimization problems that excels in both solution quality and\ninference speed. DISCO's efficacy is twofold: First, it enhances solution\nquality by constraining the sampling space to a more meaningful domain guided\nby solution residues, while preserving the multi-modal properties of the output\ndistributions. Second, it accelerates the denoising process through an\nanalytically solvable approach, enabling solution sampling with minimal\nreverse-time steps and significantly reducing inference time. DISCO delivers\nstrong performance on large-scale Traveling Salesman Problems and challenging\nMaximal Independent Set benchmarks, with inference time up to 5.28 times faster\nthan other diffusion alternatives. By incorporating a divide-and-conquer\nstrategy, DISCO can well generalize to solve unseen-scale problem instances,\neven surpassing models specifically trained for those scales.\n","authors":["Kexiong Yu","Hang Zhao","Yuhang Huang","Renjiao Yi","Kai Xu","Chenyang Zhu"],"pdf_url":"https://arxiv.org/pdf/2406.19705v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15998v1","updated":"2024-10-21T13:29:08Z","published":"2024-10-21T13:29:08Z","title":"1024m at SMM4H 2024: Tasks 3, 5 & 6 -- Ensembles of Transformers and\n  Large Language Models for Medical Text Classification","summary":"  Social media is a great source of data for users reporting information and\nregarding their health and how various things have had an effect on them. This\npaper presents various approaches using Transformers and Large Language Models\nand their ensembles, their performance along with advantages and drawbacks for\nvarious tasks of SMM4H'24 - Classifying texts on impact of nature and outdoor\nspaces on the author's mental health (Task 3), Binary classification of tweets\nreporting their children's health disorders like Asthma, Autism, ADHD and\nSpeech disorder (task 5), Binary classification of users self-reporting their\nage (task 6).\n","authors":["Ram Mohan Rao Kadiyala","M. V. P. Chandra Sekhara Rao"],"pdf_url":"https://arxiv.org/pdf/2410.15998v1.pdf","comment":"short paper , acl 2024"},{"id":"http://arxiv.org/abs/2404.10425v2","updated":"2024-10-21T13:28:20Z","published":"2024-04-16T09:43:58Z","title":"Optimizing BioTac Simulation for Realistic Tactile Perception","summary":"  Tactile sensing presents a promising opportunity for enhancing the\ninteraction capabilities of today's robots. BioTac is a commonly used tactile\nsensor that enables robots to perceive and respond to physical tactile stimuli.\nHowever, the sensor's non-linearity poses challenges in simulating its\nbehavior. In this paper, we first investigate a BioTac simulation that uses\ntemperature, force, and contact point positions to predict the sensor outputs.\nWe show that training with BioTac temperature readings does not yield accurate\nsensor output predictions during deployment. Consequently, we tested three\nalternative models, i.e., an XGBoost regressor, a neural network, and a\ntransformer encoder. We train these models without temperature readings and\nprovide a detailed investigation of the window size of the input vectors. We\ndemonstrate that we achieve statistically significant improvements over the\nbaseline network. Furthermore, our results reveal that the XGBoost regressor\nand transformer outperform traditional feed-forward neural networks in this\ntask. We make all our code and results available online on\nhttps://github.com/wzaielamri/Optimizing_BioTac_Simulation.\n","authors":["Wadhah Zai El Amri","Nicolás Navarro-Guerrero"],"pdf_url":"https://arxiv.org/pdf/2404.10425v2.pdf","comment":"12 pages (including appendix), Accepted at the International Joint\n  Conference on Neural Network (IJCNN) 2024, Yokohama, Japan. \\c{opyright} 2024\n  IEEE. Personal use of this material is permitted. Permission from IEEE must\n  be obtained for all other uses, in any current or future media... (We refer\n  to IEEE Copyrights)"},{"id":"http://arxiv.org/abs/2410.15990v1","updated":"2024-10-21T13:20:15Z","published":"2024-10-21T13:20:15Z","title":"Augmenting Legal Decision Support Systems with LLM-based NLI for\n  Analyzing Social Media Evidence","summary":"  This paper presents our system description and error analysis of our entry\nfor NLLP 2024 shared task on Legal Natural Language Inference (L-NLI)\n\\citep{hagag2024legallenssharedtask2024}. The task required classifying these\nrelationships as entailed, contradicted, or neutral, indicating any association\nbetween the review and the complaint. Our system emerged as the winning\nsubmission, significantly outperforming other entries with a substantial margin\nand demonstrating the effectiveness of our approach in legal text analysis. We\nprovide a detailed analysis of the strengths and limitations of each model and\napproach tested, along with a thorough error analysis and suggestions for\nfuture improvements. This paper aims to contribute to the growing field of\nlegal NLP by offering insights into advanced techniques for natural language\ninference in legal contexts, making it accessible to both experts and newcomers\nin the field.\n","authors":["Ram Mohan Rao Kadiyala","Siddartha Pullakhandam","Kanwal Mehreen","Subhasya Tippareddy","Ashay Srivastava"],"pdf_url":"https://arxiv.org/pdf/2410.15990v1.pdf","comment":"8 pages , accepted to emnlp 2024"},{"id":"http://arxiv.org/abs/2410.15987v1","updated":"2024-10-21T13:16:58Z","published":"2024-10-21T13:16:58Z","title":"Analyzing Closed-loop Training Techniques for Realistic Traffic Agent\n  Models in Autonomous Highway Driving Simulations","summary":"  Simulation plays a crucial role in the rapid development and safe deployment\nof autonomous vehicles. Realistic traffic agent models are indispensable for\nbridging the gap between simulation and the real world. Many existing\napproaches for imitating human behavior are based on learning from\ndemonstration. However, these approaches are often constrained by focusing on\nindividual training strategies. Therefore, to foster a broader understanding of\nrealistic traffic agent modeling, in this paper, we provide an extensive\ncomparative analysis of different training principles, with a focus on\nclosed-loop methods for highway driving simulation. We experimentally compare\n(i) open-loop vs. closed-loop multi-agent training, (ii) adversarial vs.\ndeterministic supervised training, (iii) the impact of reinforcement losses,\nand (iv) the impact of training alongside log-replayed agents to identify\nsuitable training techniques for realistic agent modeling. Furthermore, we\nidentify promising combinations of different closed-loop training methods.\n","authors":["Matthias Bitzer","Reinis Cimurs","Benjamin Coors","Johannes Goth","Sebastian Ziesche","Philipp Geiger","Maximilian Naumann"],"pdf_url":"https://arxiv.org/pdf/2410.15987v1.pdf","comment":"15 pages, 6 figures, 4 tables"},{"id":"http://arxiv.org/abs/2410.11786v2","updated":"2024-10-21T13:11:44Z","published":"2024-10-15T17:05:25Z","title":"Selection-p: Self-Supervised Task-Agnostic Prompt Compression for\n  Faithfulness and Transferability","summary":"  Large Language Models (LLMs) have demonstrated impressive capabilities in a\nwide range of natural language processing tasks when leveraging in-context\nlearning. To mitigate the additional computational and financial costs\nassociated with in-context learning, several prompt compression methods have\nbeen proposed to compress the in-context learning prompts. Despite their\nsuccess, these methods face challenges with transferability due to\nmodel-specific compression, or rely on external training data, such as GPT-4.\nIn this paper, we investigate the ability of LLMs to develop a unified\ncompression method that discretizes uninformative tokens, utilizing a\nself-supervised pre-training technique. By introducing a small number of\nparameters during the continual pre-training, the proposed Selection-p produces\na probability for each input token, indicating whether to preserve or discard\nit. Experiments show Selection-p achieves state-of-the-art performance across\nnumerous classification tasks, achieving compression rates of up to 10 times\nwhile experiencing only a marginal 0.8% decrease in performance. Moreover, it\nexhibits superior transferability to different models compared to prior work.\nAdditionally, we further analyze how Selection-p helps maintain performance on\nin-context learning with long contexts.\n","authors":["Tsz Ting Chung","Leyang Cui","Lemao Liu","Xinting Huang","Shuming Shi","Dit-Yan Yeung"],"pdf_url":"https://arxiv.org/pdf/2410.11786v2.pdf","comment":"14 pages, 5 figures, 10 tables, EMNLP 2024 Findings"},{"id":"http://arxiv.org/abs/2410.15978v1","updated":"2024-10-21T13:05:33Z","published":"2024-10-21T13:05:33Z","title":"PROMPTHEUS: A Human-Centered Pipeline to Streamline SLRs with LLMs","summary":"  The growing volume of academic publications poses significant challenges for\nresearchers conducting timely and accurate Systematic Literature Reviews,\nparticularly in fast-evolving fields like artificial intelligence. This growth\nof academic literature also makes it increasingly difficult for lay people to\naccess scientific knowledge effectively, meaning academic literature is often\nmisrepresented in the popular press and, more broadly, in society. Traditional\nSLR methods are labor-intensive and error-prone, and they struggle to keep up\nwith the rapid pace of new research. To address these issues, we developed\n\\textit{PROMPTHEUS}: an AI-driven pipeline solution that automates the SLR\nprocess using Large Language Models. We aimed to enhance efficiency by reducing\nthe manual workload while maintaining the precision and coherence required for\ncomprehensive literature synthesis. PROMPTHEUS automates key stages of the SLR\nprocess, including systematic search, data extraction, topic modeling using\nBERTopic, and summarization with transformer models. Evaluations conducted\nacross five research domains demonstrate that PROMPTHEUS reduces review time,\nachieves high precision, and provides coherent topic organization, offering a\nscalable and effective solution for conducting literature reviews in an\nincreasingly crowded research landscape. In addition, such tools may reduce the\nincreasing mistrust in science by making summarization more accessible to\nlaypeople.\n  The code for this project can be found on the GitHub repository at\nhttps://github.com/joaopftorres/PROMPTHEUS.git\n","authors":["João Pedro Fernandes Torres","Catherine Muligan","Joaquim Jorge","Catarina Moreira"],"pdf_url":"https://arxiv.org/pdf/2410.15978v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15977v1","updated":"2024-10-21T13:04:44Z","published":"2024-10-21T13:04:44Z","title":"Enabling Energy-Efficient Deployment of Large Language Models on\n  Memristor Crossbar: A Synergy of Large and Small","summary":"  Large language models (LLMs) have garnered substantial attention due to their\npromising applications in diverse domains. Nevertheless, the increasing size of\nLLMs comes with a significant surge in the computational requirements for\ntraining and deployment. Memristor crossbars have emerged as a promising\nsolution, which demonstrated a small footprint and remarkably high energy\nefficiency in computer vision (CV) models. Memristors possess higher density\ncompared to conventional memory technologies, making them highly suitable for\neffectively managing the extreme model size associated with LLMs. However,\ndeploying LLMs on memristor crossbars faces three major challenges. Firstly,\nthe size of LLMs increases rapidly, already surpassing the capabilities of\nstate-of-the-art memristor chips. Secondly, LLMs often incorporate multi-head\nattention blocks, which involve non-weight stationary multiplications that\ntraditional memristor crossbars cannot support. Third, while memristor\ncrossbars excel at performing linear operations, they are not capable of\nexecuting complex nonlinear operations in LLM such as softmax and layer\nnormalization. To address these challenges, we present a novel architecture for\nthe memristor crossbar that enables the deployment of state-of-the-art LLM on a\nsingle chip or package, eliminating the energy and time inefficiencies\nassociated with off-chip communication. Our testing on BERT_Large showed\nnegligible accuracy loss. Compared to traditional memristor crossbars, our\narchitecture achieves enhancements of up to 39X in area overhead and 18X in\nenergy consumption. Compared to modern TPU/GPU systems, our architecture\ndemonstrates at least a 68X reduction in the area-delay product and a\nsignificant 69% energy consumption reduction.\n","authors":["Zhehui Wang","Tao Luo","Cheng Liu","Weichen Liu","Rick Siow Mong Goh","Weng-Fai Wong"],"pdf_url":"https://arxiv.org/pdf/2410.15977v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15974v1","updated":"2024-10-21T13:00:09Z","published":"2024-10-21T13:00:09Z","title":"Large Language Models for Cross-lingual Emotion Detection","summary":"  This paper presents a detailed system description of our entry for the WASSA\n2024 Task 2, focused on cross-lingual emotion detection. We utilized a\ncombination of large language models (LLMs) and their ensembles to effectively\nunderstand and categorize emotions across different languages. Our approach not\nonly outperformed other submissions with a large margin, but also demonstrated\nthe strength of integrating multiple models to enhance performance.\nAdditionally, We conducted a thorough comparison of the benefits and\nlimitations of each model used. An error analysis is included along with\nsuggested areas for future improvement. This paper aims to offer a clear and\ncomprehensive understanding of advanced techniques in emotion detection, making\nit accessible even to those new to the field.\n","authors":["Ram Mohan Rao Kadiyala"],"pdf_url":"https://arxiv.org/pdf/2410.15974v1.pdf","comment":"6 pages , accepted to acl 2024"},{"id":"http://arxiv.org/abs/2410.15973v1","updated":"2024-10-21T12:59:58Z","published":"2024-10-21T12:59:58Z","title":"Karush-Kuhn-Tucker Condition-Trained Neural Networks (KKT Nets)","summary":"  This paper presents a novel approach to solving convex optimization problems\nby leveraging the fact that, under certain regularity conditions, any set of\nprimal or dual variables satisfying the Karush-Kuhn-Tucker (KKT) conditions is\nnecessary and sufficient for optimality. Similar to Theory-Trained Neural\nNetworks (TTNNs), the parameters of the convex optimization problem are input\nto the neural network, and the expected outputs are the optimal primal and dual\nvariables. A choice for the loss function in this case is a loss, which we\nrefer to as the KKT Loss, that measures how well the network's outputs satisfy\nthe KKT conditions. We demonstrate the effectiveness of this approach using a\nlinear program as an example. For this problem, we observe that minimizing the\nKKT Loss alone outperforms training the network with a weighted sum of the KKT\nLoss and a Data Loss (the mean-squared error between the ground truth optimal\nsolutions and the network's output). Moreover, minimizing only the Data Loss\nyields inferior results compared to those obtained by minimizing the KKT Loss.\nWhile the approach is promising, the obtained primal and dual solutions are not\nsufficiently close to the ground truth optimal solutions. In the future, we aim\nto develop improved models to obtain solutions closer to the ground truth and\nextend the approach to other problem classes.\n","authors":["Shreya Arvind","Rishabh Pomaje","Rajshekhar V Bhat"],"pdf_url":"https://arxiv.org/pdf/2410.15973v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.14038v3","updated":"2024-10-21T12:54:33Z","published":"2024-09-21T06:49:34Z","title":"OAEI-LLM: A Benchmark Dataset for Understanding Large Language Model\n  Hallucinations in Ontology Matching","summary":"  Hallucinations of large language models (LLMs) commonly occur in\ndomain-specific downstream tasks, with no exception in ontology matching (OM).\nThe prevalence of using LLMs for OM raises the need for benchmarks to better\nunderstand LLM hallucinations. The OAEI-LLM dataset is an extended version of\nthe Ontology Alignment Evaluation Initiative (OAEI) datasets that evaluate\nLLM-specific hallucinations in OM tasks. We outline the methodology used in\ndataset construction and schema extension, and provide examples of potential\nuse cases.\n","authors":["Zhangcheng Qiang","Kerry Taylor","Weiqing Wang","Jing Jiang"],"pdf_url":"https://arxiv.org/pdf/2409.14038v3.pdf","comment":"5 pages, 1 figure, 1 table"},{"id":"http://arxiv.org/abs/2405.17991v2","updated":"2024-10-21T12:53:21Z","published":"2024-05-28T09:23:14Z","title":"VeLoRA: Memory Efficient Training using Rank-1 Sub-Token Projections","summary":"  Large language models (LLMs) have recently emerged as powerful tools for\ntackling many language-processing tasks. Despite their success, training and\nfine-tuning these models is still far too computationally and memory intensive.\nIn this paper, we identify and characterise the important components needed for\neffective model convergence using gradient descent. In doing so we find that\nthe intermediate activations used to implement backpropagation can be\nexcessively compressed without incurring any degradation in performance. This\nresult leads us to a cheap and memory-efficient algorithm for both fine-tuning\nand pre-training LLMs. The proposed algorithm simply divides the tokens up into\nsmaller sub-tokens before projecting them onto a fixed 1-dimensional subspace\nduring the forward pass. These features are then coarsely reconstructed during\nthe backward pass to implement the update rules. We confirm the effectiveness\nof our algorithm as being complimentary to many state-of-the-art PEFT methods\non the VTAB-1k fine-tuning benchmark. Furthermore, we outperform QLoRA for\nfine-tuning LLaMA and show competitive performance against other\nmemory-efficient pre-training methods on the large-scale C4 dataset.\n","authors":["Roy Miles","Pradyumna Reddy","Ismail Elezi","Jiankang Deng"],"pdf_url":"https://arxiv.org/pdf/2405.17991v2.pdf","comment":"NeurIPS 2024. Code available at https://github.com/roymiles/VeLoRA"},{"id":"http://arxiv.org/abs/2410.15966v1","updated":"2024-10-21T12:52:03Z","published":"2024-10-21T12:52:03Z","title":"Self-Explained Keywords Empower Large Language Models for Code\n  Generation","summary":"  Large language models (LLMs) have achieved impressive performance in code\ngeneration. However, due to the long-tail distribution of LLMs' training data,\nlow-frequency terms are typically underrepresented in the training process.\nConsequently, LLMs often misunderstand or overlook problem-specific,\nlow-frequency keywords during code generation, compromising the accuracy of the\ngenerated code. To address this, we propose a novel technique named\nSEK(\\textbf{S}elf-\\textbf{E}xplained \\textbf{K}eywords), which empowers an LLM\nfor better code generation by extracting and explaining the key terms in the\nproblem description with the LLM itself and ranking them based on frequency.\nComprehensive experiments across three benchmarks, i.e., HumanEval(+), MBPP(+),\nand APPS, with five representative LLMs, show that SEK can significantly\nimprove LLMs in code generation, yielding substantial and consistent gains. For\ninstance, SEK improves the Pass@1 of DeepSeek-Coder-V2-Instruct from 85.4\\% to\n93.3\\% on the Humaneval benchmark. Further analysis confirms that SEK enables\nthe LLMs to shift their attention from low-frequency keywords to their\ncorresponding high-frequency counterparts.\n","authors":["Lishui Fan","Mouxiang Chen","Zhongxin Liu"],"pdf_url":"https://arxiv.org/pdf/2410.15966v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15962v1","updated":"2024-10-21T12:47:57Z","published":"2024-10-21T12:47:57Z","title":"Systematic Exploration of Dialogue Summarization Approaches for\n  Reproducibility, Comparative Assessment, and Methodological Innovations for\n  Advancing Natural Language Processing in Abstractive Summarization","summary":"  Reproducibility in scientific research, particularly within the realm of\nnatural language processing (NLP), is essential for validating and verifying\nthe robustness of experimental findings. This paper delves into the\nreproduction and evaluation of dialogue summarization models, focusing\nspecifically on the discrepancies observed between original studies and our\nreproduction efforts. Dialogue summarization is a critical aspect of NLP,\naiming to condense conversational content into concise and informative\nsummaries, thus aiding in efficient information retrieval and decision-making\nprocesses. Our research involved a thorough examination of several dialogue\nsummarization models using the AMI (Augmented Multi-party Interaction) dataset.\nThe models assessed include Hierarchical Memory Networks (HMNet) and various\nversions of Pointer-Generator Networks (PGN), namely PGN(DKE), PGN(DRD),\nPGN(DTS), and PGN(DALL). The primary objective was to evaluate the\ninformativeness and quality of the summaries generated by these models through\nhuman assessment, a method that introduces subjectivity and variability in the\nevaluation process. The analysis began with Dataset 1, where the sample\nstandard deviation of 0.656 indicated a moderate dispersion of data points\naround the mean.\n","authors":["Yugandhar Reddy Gogireddy","Jithendra Reddy Gogireddy"],"pdf_url":"https://arxiv.org/pdf/2410.15962v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15960v1","updated":"2024-10-21T12:45:10Z","published":"2024-10-21T12:45:10Z","title":"AI-Driven Innovations in Modern Cloud Computing","summary":"  The world has witnessed rapid technological transformation, past couple of\ndecades and with Advent of Cloud computing the landscape evolved exponentially\nleading to efficient and scalable application development. Now, the past couple\nof years the digital ecosystem has brought in numerous innovations with\nintegration of Artificial Intelligence commonly known as AI. This paper\nexplores how AI and cloud computing intersect to deliver transformative\ncapabilities for modernizing applications by providing services and\ninfrastructure. Harnessing the combined potential of both AI & Cloud\ntechnologies, technology providers can now exploit intelligent resource\nmanagement, predictive analytics, automated deployment & scaling with enhanced\nsecurity leading to offering innovative solutions to their customers.\nFurthermore, by leveraging such technologies of cloud & AI businesses can reap\nrich rewards in the form of reducing operational costs and improving service\ndelivery. This paper further addresses challenges associated such as data\nprivacy concerns and how it can be mitigated with robust AI governance\nframeworks.\n","authors":["Animesh Kumar"],"pdf_url":"https://arxiv.org/pdf/2410.15960v1.pdf","comment":"5 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.15956v1","updated":"2024-10-21T12:34:17Z","published":"2024-10-21T12:34:17Z","title":"Do Large Language Models Have an English Accent? Evaluating and\n  Improving the Naturalness of Multilingual LLMs","summary":"  Current Large Language Models (LLMs) are predominantly designed with English\nas the primary language, and even the few that are multilingual tend to exhibit\nstrong English-centric biases. Much like speakers who might produce awkward\nexpressions when learning a second language, LLMs often generate unnatural\noutputs in non-English languages, reflecting English-centric patterns in both\nvocabulary and grammar. Despite the importance of this issue, the naturalness\nof multilingual LLM outputs has received limited attention. In this paper, we\naddress this gap by introducing novel automatic corpus-level metrics to assess\nthe lexical and syntactic naturalness of LLM outputs in a multilingual context.\nUsing our new metrics, we evaluate state-of-the-art LLMs on a curated benchmark\nin French and Chinese, revealing a tendency towards English-influenced\npatterns. To mitigate this issue, we also propose a simple and effective\nalignment method to improve the naturalness of an LLM in a target language and\ndomain, achieving consistent improvements in naturalness without compromising\nthe performance on general-purpose benchmarks. Our work highlights the\nimportance of developing multilingual metrics, resources and methods for the\nnew wave of multilingual LLMs.\n","authors":["Yanzhu Guo","Simone Conia","Zelin Zhou","Min Li","Saloni Potdar","Henry Xiao"],"pdf_url":"https://arxiv.org/pdf/2410.15956v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15954v1","updated":"2024-10-21T12:34:02Z","published":"2024-10-21T12:34:02Z","title":"TS-ACL: A Time Series Analytic Continual Learning Framework for\n  Privacy-Preserving and Class-Incremental Pattern Recognition","summary":"  Class-incremental Learning (CIL) in Time Series Classification (TSC) aims to\nincrementally train models using the streaming time series data that arrives\ncontinuously. The main problem in this scenario is catastrophic forgetting,\ni.e., training models with new samples inevitably leads to the forgetting of\npreviously learned knowledge. Among existing methods, the replay-based methods\nachieve satisfactory performance but compromise privacy, while exemplar-free\nmethods protect privacy but suffer from low accuracy. However, more critically,\nowing to their reliance on gradient-based update techniques, these existing\nmethods fundamentally cannot solve the catastrophic forgetting problem. In TSC\nscenarios with continuously arriving data and temporally shifting\ndistributions, these methods become even less practical. In this paper, we\npropose a Time Series Analytic Continual Learning framework, called TS-ACL.\nInspired by analytical learning, TS-ACL transforms neural network updates into\ngradient-free linear regression problems, thereby fundamentally mitigating\ncatastrophic forgetting. Specifically, employing a pre-trained and frozen\nfeature extraction encoder, TS-ACL only needs to update its analytic classifier\nrecursively in a lightweight manner that is highly suitable for real-time\napplications and large-scale data processing. Additionally, we theoretically\ndemonstrate that the model obtained recursively through the TS-ACL is exactly\nequivalent to a model trained on the complete dataset in a centralized manner,\nthereby establishing the property of absolute knowledge memory. Extensive\nexperiments validate the superior performance of our TS-ACL.\n","authors":["Kejia Fan","Jiaxu Li","Songning Lai","Linpu Lv","Anfeng Liu","Jianheng Tang","Houbing Herbert Song","Huiping Zhuang"],"pdf_url":"https://arxiv.org/pdf/2410.15954v1.pdf","comment":"11 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2410.15952v1","updated":"2024-10-21T12:32:39Z","published":"2024-10-21T12:32:39Z","title":"User-centric evaluation of explainability of AI with and for humans: a\n  comprehensive empirical study","summary":"  This study is located in the Human-Centered Artificial Intelligence (HCAI)\nand focuses on the results of a user-centered assessment of commonly used\neXplainable Artificial Intelligence (XAI) algorithms, specifically\ninvestigating how humans understand and interact with the explanations provided\nby these algorithms. To achieve this, we employed a multi-disciplinary approach\nthat included state-of-the-art research methods from social sciences to measure\nthe comprehensibility of explanations generated by a state-of-the-art lachine\nlearning model, specifically the Gradient Boosting Classifier (XGBClassifier).\nWe conducted an extensive empirical user study involving interviews with 39\nparticipants from three different groups, each with varying expertise in data\nscience, data visualization, and domain-specific knowledge related to the\ndataset used for training the machine learning model. Participants were asked a\nseries of questions to assess their understanding of the model's explanations.\nTo ensure replicability, we built the model using a publicly available dataset\nfrom the UC Irvine Machine Learning Repository, focusing on edible and\nnon-edible mushrooms. Our findings reveal limitations in existing XAI methods\nand confirm the need for new design principles and evaluation techniques that\naddress the specific information needs and user perspectives of different\nclasses of AI stakeholders. We believe that the results of our research and the\ncross-disciplinary methodology we developed can be successfully adapted to\nvarious data types and user profiles, thus promoting dialogue and address\nopportunities in HCAI research. To support this, we are making the data\nresulting from our study publicly available.\n","authors":["Szymon Bobek","Paloma Korycińska","Monika Krakowska","Maciej Mozolewski","Dorota Rak","Magdalena Zych","Magdalena Wójcik","Grzegorz J. Nalepa"],"pdf_url":"https://arxiv.org/pdf/2410.15952v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15951v1","updated":"2024-10-21T12:32:17Z","published":"2024-10-21T12:32:17Z","title":"Redefining Finance: The Influence of Artificial Intelligence (AI) and\n  Machine Learning (ML)","summary":"  With rapid transformation of technologies, the fusion of Artificial\nIntelligence (AI) and Machine Learning (ML) in finance is disrupting the entire\necosystem and operations which were followed for decades. The current landscape\nis where decisions are increasingly data-driven by financial institutions with\nan appetite for automation while mitigating risks. The segments of financial\ninstitutions which are getting heavily influenced are retail banking, wealth\nmanagement, corporate banking & payment ecosystem. The solution ranges from\nonboarding the customers all the way fraud detection & prevention to enhancing\nthe customer services. Financial Institutes are leap frogging with integration\nof Artificial Intelligence and Machine Learning in mainstream applications and\nenhancing operational efficiency through advanced predictive analytics,\nextending personalized customer experiences, and automation to minimize risk\nwith fraud detection techniques. However, with Adoption of AI & ML, it is\nimperative that the financial institute also needs to address ethical and\nregulatory challenges, by putting in place robust governance frameworks and\nresponsible AI practices.\n","authors":["Animesh Kumar"],"pdf_url":"https://arxiv.org/pdf/2410.15951v1.pdf","comment":"10 pages, 1 figure"},{"id":"http://arxiv.org/abs/2410.15947v1","updated":"2024-10-21T12:26:53Z","published":"2024-10-21T12:26:53Z","title":"AI-Driven Approaches for Glaucoma Detection -- A Comprehensive Review","summary":"  The diagnosis of glaucoma plays a critical role in the management and\ntreatment of this vision-threatening disease. Glaucoma is a group of eye\ndiseases that cause blindness by damaging the optic nerve at the back of the\neye. Often called \"silent thief of sight\", it exhibits no symptoms during the\nearly stages. Therefore, early detection is crucial to prevent vision loss.\nWith the rise of Artificial Intelligence (AI), particularly Deep Learning (DL)\ntechniques, Computer-Aided Diagnosis (CADx) systems have emerged as promising\ntools to assist clinicians in accurately diagnosing glaucoma early. This paper\naims to provide a comprehensive overview of AI techniques utilized in CADx\nsystems for glaucoma diagnosis. Through a detailed analysis of current\nliterature, we identify key gaps and challenges in these systems, emphasizing\nthe need for improved safety, reliability, interpretability, and\nexplainability. By identifying research gaps, we aim to advance the field of\nCADx systems especially for the early diagnosis of glaucoma, in order to\nprevent any potential loss of vision.\n","authors":["Yuki Hagiwara","Octavia-Andreaa Ciora","Maureen Monnet","Gino Lancho","Jeanette Miriam Lorenz"],"pdf_url":"https://arxiv.org/pdf/2410.15947v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15944v1","updated":"2024-10-21T12:21:49Z","published":"2024-10-21T12:21:49Z","title":"Developing Retrieval Augmented Generation (RAG) based LLM Systems from\n  PDFs: An Experience Report","summary":"  This paper presents an experience report on the development of Retrieval\nAugmented Generation (RAG) systems using PDF documents as the primary data\nsource. The RAG architecture combines generative capabilities of Large Language\nModels (LLMs) with the precision of information retrieval. This approach has\nthe potential to redefine how we interact with and augment both structured and\nunstructured knowledge in generative models to enhance transparency, accuracy,\nand contextuality of responses. The paper details the end-to-end pipeline, from\ndata collection, preprocessing, to retrieval indexing and response generation,\nhighlighting technical challenges and practical solutions. We aim to offer\ninsights to researchers and practitioners developing similar systems using two\ndistinct approaches: OpenAI's Assistant API with GPT Series and Llama's\nopen-source models. The practical implications of this research lie in\nenhancing the reliability of generative AI systems in various sectors where\ndomain-specific knowledge and real-time information retrieval is important. The\nPython code used in this work is also available at:\nhttps://github.com/GPT-Laboratory/RAG-LLM-Development-Guidebook-from-PDFs.\n","authors":["Ayman Asad Khan","Md Toufique Hasan","Kai Kristian Kemell","Jussi Rasku","Pekka Abrahamsson"],"pdf_url":"https://arxiv.org/pdf/2410.15944v1.pdf","comment":"36 pages, 8 figures, 2 tables, and python code snippets"},{"id":"http://arxiv.org/abs/2309.06223v3","updated":"2024-10-21T12:11:52Z","published":"2023-09-12T13:42:20Z","title":"Compiled Models, Built-In Exploits: Uncovering Pervasive Bit-Flip Attack\n  Surfaces in DNN Executables","summary":"  Bit-flip attacks (BFAs) can manipulate deep neural networks (DNNs). For\nhigh-level DNN models running on deep learning (DL) frameworks like PyTorch,\nextensive BFAs have been used to flip bits in model weights and shown\neffective. Defenses have also been proposed to guard model weights. However,\nDNNs are increasingly compiled into DNN executables by DL compilers to leverage\nhardware primitives. These executables manifest distinct computation paradigms;\nexisting research fails to accurately capture and expose the BFA surfaces on\nDNN executables.\n  To this end, we launch the first systematic study of BFAs on DNN executables.\nPrior BFAs are limited to attacking model weights and assume a strong whitebox\nattacker with full knowledge of victim model weights, which is unrealistic as\nweights are often confidential. In contrast, we find that BFAs on DNN\nexecutables can achieve high effectiveness by exploiting the model structure\n(usually stored in the executable code), which only requires knowing the (often\npublic) model structure. Importantly, such structure-based BFAs are pervasive,\ntransferable, and more severe in DNN executables. They also slip past existing\ndefenses.\n  To demonstrate the new attack surfaces, we assume a weak and more realistic\nattacker with no knowledge of victim model weights. We design an automated tool\nto identify vulnerable bits in victim executables with high confidence (70% vs.\nbaseline 2%). We show on DDR4 DRAM that only 1.4 flips on average are needed to\nfully downgrade the accuracy of victim models, including quantized ones which\ncould require 23x more flips previously, to random guesses. We comprehensively\nevaluate 16 DNN executables, covering large-scale models trained on\ncommonly-used datasets compiled by the two most popular DL compilers. Our\nfinding calls for incorporating security mechanisms in future DNN compilation\ntoolchains.\n","authors":["Yanzuo Chen","Zhibo Liu","Yuanyuan Yuan","Sihang Hu","Tianxiang Li","Shuai Wang"],"pdf_url":"https://arxiv.org/pdf/2309.06223v3.pdf","comment":"Accepted by NDSS 2025"},{"id":"http://arxiv.org/abs/2410.15930v1","updated":"2024-10-21T11:59:14Z","published":"2024-10-21T11:59:14Z","title":"Centrality-aware Product Retrieval and Ranking","summary":"  This paper addresses the challenge of improving user experience on e-commerce\nplatforms by enhancing product ranking relevant to users' search queries.\nAmbiguity and complexity of user queries often lead to a mismatch between the\nuser's intent and retrieved product titles or documents. Recent approaches have\nproposed the use of Transformer-based models, which need millions of annotated\nquery-title pairs during the pre-training stage, and this data often does not\ntake user intent into account. To tackle this, we curate samples from existing\ndatasets at eBay, manually annotated with buyer-centric relevance scores and\ncentrality scores, which reflect how well the product title matches the users'\nintent. We introduce a User-intent Centrality Optimization (UCO) approach for\nexisting models, which optimises for the user intent in semantic product\nsearch. To that end, we propose a dual-loss based optimisation to handle hard\nnegatives, i.e., product titles that are semantically relevant but do not\nreflect the user's intent. Our contributions include curating challenging\nevaluation sets and implementing UCO, resulting in significant product ranking\nefficiency improvements observed for different evaluation metrics. Our work\naims to ensure that the most buyer-centric titles for a query are ranked\nhigher, thereby, enhancing the user experience on e-commerce platforms.\n","authors":["Hadeel Saadany","Swapnil Bhosale","Samarth Agrawal","Diptesh Kanojia","Constantin Orasan","Zhe Wu"],"pdf_url":"https://arxiv.org/pdf/2410.15930v1.pdf","comment":"EMNLP 2024: Industry track"},{"id":"http://arxiv.org/abs/2410.15927v1","updated":"2024-10-21T11:55:06Z","published":"2024-10-21T11:55:06Z","title":"GReFEL: Geometry-Aware Reliable Facial Expression Learning under Bias\n  and Imbalanced Data Distribution","summary":"  Reliable facial expression learning (FEL) involves the effective learning of\ndistinctive facial expression characteristics for more reliable, unbiased and\naccurate predictions in real-life settings. However, current systems struggle\nwith FEL tasks because of the variance in people's facial expressions due to\ntheir unique facial structures, movements, tones, and demographics. Biased and\nimbalanced datasets compound this challenge, leading to wrong and biased\nprediction labels. To tackle these, we introduce GReFEL, leveraging Vision\nTransformers and a facial geometry-aware anchor-based reliability balancing\nmodule to combat imbalanced data distributions, bias, and uncertainty in facial\nexpression learning. Integrating local and global data with anchors that learn\ndifferent facial data points and structural features, our approach adjusts\nbiased and mislabeled emotions caused by intra-class disparity, inter-class\nsimilarity, and scale sensitivity, resulting in comprehensive, accurate, and\nreliable facial expression predictions. Our model outperforms current\nstate-of-the-art methodologies, as demonstrated by extensive experiments on\nvarious datasets.\n","authors":["Azmine Toushik Wasi","Taki Hasan Rafi","Raima Islam","Karlo Serbetar","Dong Kyu Chae"],"pdf_url":"https://arxiv.org/pdf/2410.15927v1.pdf","comment":"ACCV 2024. Extended version of ARBEx (arXiv:2305.01486)"},{"id":"http://arxiv.org/abs/2402.08958v2","updated":"2024-10-21T11:49:53Z","published":"2024-02-14T05:58:43Z","title":"Towards Next-Level Post-Training Quantization of Hyper-Scale\n  Transformers","summary":"  With the increasing complexity of generative AI models, post-training\nquantization (PTQ) has emerged as a promising solution for deploying\nhyper-scale models on edge devices such as mobile and TVs. Existing PTQ\nschemes, however, consume considerable time and resources, which could be a\nbottleneck in real situations where frequent model updates and multiple\nhyperparameter tunings are required. As a cost-effective alternative,\nlearning-free PTQ schemes have been proposed. However, the performance is\nsomewhat limited because they cannot consider the inter-layer dependency within\nthe attention module, which is a significant feature of Transformers. In this\npaper, we thus propose a novel PTQ algorithm that balances accuracy and\nefficiency. The key idea of the proposed algorithm called aespa is to perform\nquantization layer-wise for efficiency while targeting attention-wise\nreconstruction to consider the cross-layer dependency. Through extensive\nexperiments on various language models and complexity analysis, we demonstrate\nthat aespa is accurate and efficient in quantizing Transformer models.\n","authors":["Junhan Kim","Chungman Lee","Eulrang Cho","Kyungphil Park","Ho-young Kim","Joonyoung Kim","Yongkweon Jeon"],"pdf_url":"https://arxiv.org/pdf/2402.08958v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.15912v1","updated":"2024-10-21T11:35:33Z","published":"2024-10-21T11:35:33Z","title":"Bench4Merge: A Comprehensive Benchmark for Merging in Realistic Dense\n  Traffic with Micro-Interactive Vehicles","summary":"  While the capabilities of autonomous driving have advanced rapidly, merging\ninto dense traffic remains a significant challenge, many motion planning\nmethods for this scenario have been proposed but it is hard to evaluate them.\nMost existing closed-loop simulators rely on rule-based controls for other\nvehicles, which results in a lack of diversity and randomness, thus failing to\naccurately assess the motion planning capabilities in highly interactive\nscenarios. Moreover, traditional evaluation metrics are insufficient for\ncomprehensively evaluating the performance of merging in dense traffic. In\nresponse, we proposed a closed-loop evaluation benchmark for assessing motion\nplanning capabilities in merging scenarios. Our approach involves other\nvehicles trained in large scale datasets with micro-behavioral characteristics\nthat significantly enhance the complexity and diversity. Additionally, we have\nrestructured the evaluation mechanism by leveraging large language models to\nassess each autonomous vehicle merging onto the main road. Extensive\nexperiments have demonstrated the advanced nature of this evaluation benchmark.\nThrough this benchmark, we have obtained an evaluation of existing methods and\nidentified common issues. The environment and vehicle motion planning models we\nhave designed can be accessed at\nhttps://anonymous.4open.science/r/Bench4Merge-EB5D\n","authors":["Zhengming Wang","Junli Wang","Pengfei Li","Zhaohan Li","Peng Li","Yilun Chen"],"pdf_url":"https://arxiv.org/pdf/2410.15912v1.pdf","comment":"6 pages, 7 figures, IEEE international conference on robotics and\n  automation"},{"id":"http://arxiv.org/abs/2403.17633v4","updated":"2024-10-21T11:34:27Z","published":"2024-03-26T12:08:14Z","title":"UADA3D: Unsupervised Adversarial Domain Adaptation for 3D Object\n  Detection with Sparse LiDAR and Large Domain Gaps","summary":"  In this study, we address a gap in existing unsupervised domain adaptation\napproaches on LiDAR-based 3D object detection, which have predominantly\nconcentrated on adapting between established, high-density autonomous driving\ndatasets. We focus on sparser point clouds, capturing scenarios from different\nperspectives: not just from vehicles on the road but also from mobile robots on\nsidewalks, which encounter significantly different environmental conditions and\nsensor configurations. We introduce Unsupervised Adversarial Domain Adaptation\nfor 3D Object Detection (UADA3D). UADA3D does not depend on pre-trained source\nmodels or teacher-student architectures. Instead, it uses an adversarial\napproach to directly learn domain-invariant features. We demonstrate its\nefficacy in various adaptation scenarios, showing significant improvements in\nboth self-driving car and mobile robot domains. Our code is open-source and\nwill be available soon.\n","authors":["Maciej K Wozniak","Mattias Hansson","Marko Thiel","Patric Jensfelt"],"pdf_url":"https://arxiv.org/pdf/2403.17633v4.pdf","comment":"Accepted for IEEE RA-L 2024"},{"id":"http://arxiv.org/abs/2410.15910v1","updated":"2024-10-21T11:33:14Z","published":"2024-10-21T11:33:14Z","title":"Diverse Policies Recovering via Pointwise Mutual Information Weighted\n  Imitation Learning","summary":"  Recovering a spectrum of diverse policies from a set of expert trajectories\nis an important research topic in imitation learning. After determining a\nlatent style for a trajectory, previous diverse policies recovering methods\nusually employ a vanilla behavioral cloning learning objective conditioned on\nthe latent style, treating each state-action pair in the trajectory with equal\nimportance. Based on an observation that in many scenarios, behavioral styles\nare often highly relevant with only a subset of state-action pairs, this paper\npresents a new principled method in diverse polices recovery. In particular,\nafter inferring or assigning a latent style for a trajectory, we enhance the\nvanilla behavioral cloning by incorporating a weighting mechanism based on\npointwise mutual information. This additional weighting reflects the\nsignificance of each state-action pair's contribution to learning the style,\nthus allowing our method to focus on state-action pairs most representative of\nthat style. We provide theoretical justifications for our new objective, and\nextensive empirical evaluations confirm the effectiveness of our method in\nrecovering diverse policies from expert data.\n","authors":["Hanlin Yang","Jian Yao","Weiming Liu","Qing Wang","Hanmin Qin","Hansheng Kong","Kirk Tang","Jiechao Xiong","Chao Yu","Kai Li","Junliang Xing","Hongwu Chen","Juchao Zhuo","Qiang Fu","Yang Wei","Haobo Fu"],"pdf_url":"https://arxiv.org/pdf/2410.15910v1.pdf","comment":"18 pages, 6 figures"},{"id":"http://arxiv.org/abs/2408.15538v2","updated":"2024-10-21T11:32:57Z","published":"2024-08-28T05:11:16Z","title":"TrafficGamer: Reliable and Flexible Traffic Simulation for\n  Safety-Critical Scenarios with Game-Theoretic Oracles","summary":"  While modern Autonomous Vehicle (AV) systems can develop reliable driving\npolicies under regular traffic conditions, they frequently struggle with\nsafety-critical traffic scenarios. This difficulty primarily arises from the\nrarity of such scenarios in driving datasets and the complexities associated\nwith predictive modeling among multiple vehicles. To support the testing and\nrefinement of AV policies, simulating safety-critical traffic events is an\nessential challenge to be addressed. In this work, we introduce TrafficGamer,\nwhich facilitates game-theoretic traffic simulation by viewing common road\ndriving as a multi-agent game. In evaluating the empirical performance across\nvarious real-world datasets, TrafficGamer ensures both fidelity and\nexploitability of the simulated scenarios, guaranteeing that they not only\nstatically align with real-world traffic distribution but also efficiently\ncapture equilibriums for representing safety-critical scenarios involving\nmultiple agents. Additionally, the results demonstrate that TrafficGamer\nexhibits highly flexible simulation across various contexts. Specifically, we\ndemonstrate that the generated scenarios can dynamically adapt to equilibriums\nof varying tightness by configuring risk-sensitive constraints during\noptimization. To the best of our knowledge, TrafficGamer is the first simulator\ncapable of generating diverse traffic scenarios involving multiple agents. We\nhave provided a demo webpage for the project at\nhttps://qiaoguanren.github.io/trafficgamer-demo/.\n","authors":["Guanren Qiao","Guorui Quan","Jiawei Yu","Shujun Jia","Guiliang Liu"],"pdf_url":"https://arxiv.org/pdf/2408.15538v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14859v2","updated":"2024-10-21T11:25:48Z","published":"2024-03-21T22:08:44Z","title":"Log Probabilities Are a Reliable Estimate of Semantic Plausibility in\n  Base and Instruction-Tuned Language Models","summary":"  Semantic plausibility (e.g. knowing that \"the actor won the award\" is more\nlikely than \"the actor won the battle\") serves as an effective proxy for\ngeneral world knowledge. Language models (LMs) capture vast amounts of world\nknowledge by learning distributional patterns in text, accessible via log\nprobabilities (LogProbs) they assign to plausible vs. implausible outputs. The\nnew generation of instruction-tuned LMs can now also provide explicit estimates\nof plausibility via prompting. Here, we evaluate the effectiveness of LogProbs\nand basic prompting to measure semantic plausibility, both in single-sentence\nminimal pairs (Experiment 1) and short context-dependent scenarios (Experiment\n2). We find that (i) in both base and instruction-tuned LMs, LogProbs offers a\nmore reliable measure of semantic plausibility than direct zero-shot prompting,\nwhich yields inconsistent and often poor results; (ii) instruction-tuning\ngenerally does not alter the sensitivity of LogProbs to semantic plausibility\n(although sometimes decreases it); (iii) across models, context mostly\nmodulates LogProbs in expected ways, as measured by three novel metrics of\ncontext-sensitive plausibility and their match to explicit human plausibility\njudgments. We conclude that, even in the era of prompt-based evaluations,\nLogProbs constitute a useful metric of semantic plausibility, both in base and\ninstruction-tuned LMs.\n","authors":["Carina Kauf","Emmanuele Chersoni","Alessandro Lenci","Evelina Fedorenko","Anna A. Ivanova"],"pdf_url":"https://arxiv.org/pdf/2403.14859v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15897v1","updated":"2024-10-21T11:21:21Z","published":"2024-10-21T11:21:21Z","title":"IGMaxHS -- An Incremental MaxSAT Solver with Support for XOR Clauses","summary":"  Recently, a novel, MaxSAT-based method for error correction in quantum\ncomputing has been proposed that requires both incremental MaxSAT solving\ncapabilities and support for XOR constraints, but no dedicated MaxSAT solver\nfulfilling these criteria existed yet. We alleviate that and introduce IGMaxHS,\nwhich is based on the existing solvers iMaxHS and GaussMaxHS, but poses fewer\nrestrictions on the XOR constraints than GaussMaxHS. IGMaxHS is fuzz tested\nwith xwcnfuzz, an extension of wcnfuzz that can directly output XOR\nconstraints. As a result, IGMaxHS is the only solver that reported neither\nincorrect unsatisfiability verdicts nor invalid models nor incoherent cost\nmodel combinations in a final fuzz testing comparison of all three solvers with\n10000 instances. We detail the steps required for implementing Gaussian\nelimination on XOR constraints in CDCL SAT solvers, and extend the recently\nproposed re-entrant incremental MaxSAT solver application program interface to\nallow for incremental addition of XOR constraints. Finally, we show that\nIGMaxHS is capable of decoding quantum color codes through simulation with the\nMunich Quantum Toolkit.\n","authors":["Ole Lübke"],"pdf_url":"https://arxiv.org/pdf/2410.15897v1.pdf","comment":"Presented at the 15th International Workshop on Pragmatics of SAT\n  (PoS 2024, see https://www.pragmaticsofssat.org/2024/ )"},{"id":"http://arxiv.org/abs/2410.15889v1","updated":"2024-10-21T11:06:56Z","published":"2024-10-21T11:06:56Z","title":"Model Mimic Attack: Knowledge Distillation for Provably Transferable\n  Adversarial Examples","summary":"  The vulnerability of artificial neural networks to adversarial perturbations\nin the black-box setting is widely studied in the literature. The majority of\nattack methods to construct these perturbations suffer from an impractically\nlarge number of queries required to find an adversarial example. In this work,\nwe focus on knowledge distillation as an approach to conduct transfer-based\nblack-box adversarial attacks and propose an iterative training of the\nsurrogate model on an expanding dataset. This work is the first, to our\nknowledge, to provide provable guarantees on the success of knowledge\ndistillation-based attack on classification neural networks: we prove that if\nthe student model has enough learning capabilities, the attack on the teacher\nmodel is guaranteed to be found within the finite number of distillation\niterations.\n","authors":["Kirill Lukyanov","Andrew Perminov","Denis Turdakov","Mikhail Pautov"],"pdf_url":"https://arxiv.org/pdf/2410.15889v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10621v3","updated":"2024-10-21T11:06:06Z","published":"2024-06-15T12:48:00Z","title":"StrucText-Eval: Evaluating Large Language Model's Reasoning Ability in\n  Structure-Rich Text","summary":"  The effective utilization of structured data, integral to corporate data\nstrategies, has been challenged by the rise of large language models (LLMs)\ncapable of processing unstructured information. This shift prompts the\nquestion: can LLMs interpret structured data directly in its unstructured form?\nWe propose an automatic evaluation data generation method for assessing LLMs'\nreasoning capabilities on structure-rich text to explore this. Our approach\nsupports 8 structured languages and 29 tasks, generating data with adjustable\ncomplexity through controllable nesting and structural width. We introduce\nStrucText-Eval, a benchmark containing 5,800 pre-generated and annotated\nsamples designed to evaluate how well LLMs understand and reason through\nstructured text. StrucText-Eval is divided into two suites: a regular Test\nsuite (3,712 samples) and a Test-Hard suite (2,088 samples), the latter\nemphasizing the gap between human and model performance on more complex tasks.\nExperimental results show that while open-source LLMs achieve a maximum\naccuracy of 74.9\\% on the standard dataset, their performance drops\nsignificantly to 45.8\\% on the harder dataset. In contrast, human participants\nreach an accuracy of 92.6\\% on StrucText-Eval-Hard, highlighting LLMs' current\nlimitations in handling intricate structural information. The benchmark and\ngeneration codes are open sourced in\n\\url{https://github.com/MikeGu721/StrucText-Eval}\n","authors":["Zhouhong Gu","Haoning Ye","Xingzhou Chen","Zeyang Zhou","Hongwei Feng","Yanghua Xiao"],"pdf_url":"https://arxiv.org/pdf/2406.10621v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03615v2","updated":"2024-10-21T11:05:27Z","published":"2024-08-07T08:16:32Z","title":"Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in\n  Long-Horizon Tasks","summary":"  Building a general-purpose agent is a long-standing vision in the field of\nartificial intelligence. Existing agents have made remarkable progress in many\ndomains, yet they still struggle to complete long-horizon tasks in an open\nworld. We attribute this to the lack of necessary world knowledge and\nmultimodal experience that can guide agents through a variety of long-horizon\ntasks. In this paper, we propose a Hybrid Multimodal Memory module to address\nthe above challenges. It 1) transforms knowledge into Hierarchical Directed\nKnowledge Graph that allows agents to explicitly represent and learn world\nknowledge, and 2) summarises historical information into Abstracted Multimodal\nExperience Pool that provide agents with rich references for in-context\nlearning. On top of the Hybrid Multimodal Memory module, a multimodal agent,\nOptimus-1, is constructed with dedicated Knowledge-guided Planner and\nExperience-Driven Reflector, contributing to a better planning and reflection\nin the face of long-horizon tasks in Minecraft. Extensive experimental results\nshow that Optimus-1 significantly outperforms all existing agents on\nchallenging long-horizon task benchmarks, and exhibits near human-level\nperformance on many tasks. In addition, we introduce various Multimodal Large\nLanguage Models (MLLMs) as the backbone of Optimus-1. Experimental results show\nthat Optimus-1 exhibits strong generalization with the help of the Hybrid\nMultimodal Memory module, outperforming the GPT-4V baseline on many tasks.\n","authors":["Zaijing Li","Yuquan Xie","Rui Shao","Gongwei Chen","Dongmei Jiang","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2408.03615v2.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.15885v1","updated":"2024-10-21T11:02:42Z","published":"2024-10-21T11:02:42Z","title":"How to Build a Pre-trained Multimodal model for Simultaneously Chatting\n  and Decision-making?","summary":"  Existing large pre-trained models typically map text input to text output in\nan end-to-end manner, such as ChatGPT, or map a segment of text input to a\nhierarchy of action decisions, such as OpenVLA. However, humans can\nsimultaneously generate text and actions when receiving specific input signals.\nFor example, a driver can make precise driving decisions while conversing with\na friend in the passenger seat. Motivated by this observation, we consider the\nfollowing question in this work: is it possible to construct a pre-trained\nmodel that can provide both language interaction and precise decision-making\ncapabilities in dynamic open scenarios. We provide a definitive answer to this\nquestion by developing a new model architecture termed Visual Language Action\nmodel for Chatting and Decision Making (VLA4CD), and further demonstrating its\nperformance in challenging autonomous driving tasks. Specifically, we leverage\nLoRA to fine-tune a pre-trained LLM with data of multiple modalities covering\nlanguage, visual, and action. Unlike the existing LoRA operations used for LLM\nfine-tuning, we have designed new computational modules and training cost\nfunctions for VLA4CD. These designs enable VLA4CD to provide continuous-valued\naction decisions while outputting text responses. In contrast, existing LLMs\ncan only output text responses, and current VLA models can only output action\ndecisions. Moreover, these VLA models handle action data by discretizing and\nthen tokenizing the discretized actions, a method unsuitable for complex\ndecision-making tasks involving high-dimensional continuous-valued action\nvectors, such as autonomous driving. The experimental results on CARLA validate\nthat: (1) our proposed model construction method is effective; (2) compared to\nthe SOTA VLA model, VLA4CD can provide more accurate real-time decision-making\nwhile retaining the text interaction capability inherent to LLMs.\n","authors":["Zuojin Tang","Bin Hu","Chenyang Zhao","De Ma","Gang Pan","Bin Liu"],"pdf_url":"https://arxiv.org/pdf/2410.15885v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15884v1","updated":"2024-10-21T11:02:18Z","published":"2024-10-21T11:02:18Z","title":"Using GPT Models for Qualitative and Quantitative News Analytics in the\n  2024 US Presidental Election Process","summary":"  The paper considers an approach of using Google Search API and GPT-4o model\nfor qualitative and quantitative analyses of news through retrieval-augmented\ngeneration (RAG). This approach was applied to analyze news about the 2024 US\npresidential election process. Different news sources for different time\nperiods have been analyzed. Quantitative scores generated by GPT model have\nbeen analyzed using Bayesian regression to derive trend lines. The\ndistributions found for the regression parameters allow for the analysis of\nuncertainty in the election process. The obtained results demonstrate that\nusing the GPT models for news analysis, one can get informative analytics and\nprovide key insights that can be applied in further analyses of election\nprocesses.\n","authors":["Bohdan M. Pavlyshenko"],"pdf_url":"https://arxiv.org/pdf/2410.15884v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15881v1","updated":"2024-10-21T11:01:20Z","published":"2024-10-21T11:01:20Z","title":"MI-VisionShot: Few-shot adaptation of vision-language models for\n  slide-level classification of histopathological images","summary":"  Vision-language supervision has made remarkable strides in learning visual\nrepresentations from textual guidance. In digital pathology, vision-language\nmodels (VLM), pre-trained on curated datasets of histological image-captions,\nhave been adapted to downstream tasks, such as region of interest\nclassification. Zero-shot transfer for slide-level prediction has been\nformulated by MI-Zero, but it exhibits high variability depending on the\ntextual prompts. Inspired by prototypical learning, we propose MI-VisionShot, a\ntraining-free adaptation method on top of VLMs to predict slide-level labels in\nfew-shot learning scenarios. Our framework takes advantage of the excellent\nrepresentation learning of VLM to create prototype-based classifiers under a\nmultiple-instance setting by retrieving the most discriminative patches within\neach slide. Experimentation through different settings shows the ability of\nMI-VisionShot to surpass zero-shot transfer with lower variability, even in\nlow-shot scenarios. Code coming soon at\nthttps://github.com/cvblab/MIVisionShot.\n","authors":["Pablo Meseguer","Rocío del Amor","Valery Naranjo"],"pdf_url":"https://arxiv.org/pdf/2410.15881v1.pdf","comment":"Manuscript accepted for oral presentation at KES-InnovationInMedicine\n  2024 held on Madeira, Portugal"},{"id":"http://arxiv.org/abs/2410.15876v1","updated":"2024-10-21T10:57:45Z","published":"2024-10-21T10:57:45Z","title":"FlickerFusion: Intra-trajectory Domain Generalizing Multi-Agent RL","summary":"  Multi-agent reinforcement learning has demonstrated significant potential in\naddressing complex cooperative tasks across various real-world applications.\nHowever, existing MARL approaches often rely on the restrictive assumption that\nthe number of entities (e.g., agents, obstacles) remains constant between\ntraining and inference. This overlooks scenarios where entities are dynamically\nremoved or added during the inference trajectory -- a common occurrence in\nreal-world environments like search and rescue missions and dynamic combat\nsituations. In this paper, we tackle the challenge of intra-trajectory dynamic\nentity composition under zero-shot out-of-domain (OOD) generalization, where\nsuch dynamic changes cannot be anticipated beforehand. Our empirical studies\nreveal that existing MARL methods suffer significant performance degradation\nand increased uncertainty in these scenarios. In response, we propose\nFlickerFusion, a novel OOD generalization method that acts as a universally\napplicable augmentation technique for MARL backbone methods. Our results show\nthat FlickerFusion not only achieves superior inference rewards but also\nuniquely reduces uncertainty vis-\\`a-vis the backbone, compared to existing\nmethods. For standardized evaluation, we introduce MPEv2, an enhanced version\nof Multi Particle Environments (MPE), consisting of 12 benchmarks. Benchmarks,\nimplementations, and trained models are organized and open-sourced at\nflickerfusion305.github.io, accompanied by ample demo video renderings.\n","authors":["Woosung Koh","Wonbeen Oh","Siyeol Kim","Suhin Shin","Hyeongjin Kim","Jaein Jang","Junghyun Lee","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2410.15876v1.pdf","comment":"NeurIPS '24 Open-World Agents Workshop"},{"id":"http://arxiv.org/abs/2410.04133v2","updated":"2024-10-21T10:56:37Z","published":"2024-10-05T12:12:02Z","title":"An Electrocardiogram Foundation Model Built on over 10 Million\n  Recordings with External Evaluation across Multiple Domains","summary":"  Artificial intelligence (AI) has demonstrated significant potential in ECG\nanalysis and cardiovascular disease assessment. Recently, foundation models\nhave played a remarkable role in advancing medical AI. The development of an\nECG foundation model holds the promise of elevating AI-ECG research to new\nheights. However, building such a model faces several challenges, including\ninsufficient database sample sizes and inadequate generalization across\nmultiple domains. Additionally, there is a notable performance gap between\nsingle-lead and multi-lead ECG analyses. We introduced an ECG Foundation Model\n(ECGFounder), a general-purpose model that leverages real-world ECG annotations\nfrom cardiology experts to broaden the diagnostic capabilities of ECG analysis.\nECGFounder was trained on over 10 million ECGs with 150 label categories from\nthe Harvard-Emory ECG Database, enabling comprehensive cardiovascular disease\ndiagnosis through ECG analysis. The model is designed to be both an effective\nout-of-the-box solution, and a to be fine-tunable for downstream tasks,\nmaximizing usability. Importantly, we extended its application to lower rank\nECGs, and arbitrary single-lead ECGs in particular. ECGFounder is applicable to\nsupporting various downstream tasks in mobile monitoring scenarios.\nExperimental results demonstrate that ECGFounder achieves expert-level\nperformance on internal validation sets, with AUROC exceeding 0.95 for eighty\ndiagnoses. It also shows strong classification performance and generalization\nacross various diagnoses on external validation sets. When fine-tuned,\nECGFounder outperforms baseline models in demographic analysis, clinical event\ndetection, and cross-modality cardiac rhythm diagnosis. The trained model and\ndata will be publicly released upon publication through the bdsp.io. Our code\nis available at https://github.com/bdsp-core/ECGFounder\n","authors":["Jun Li","Aaron Aguirre","Junior Moura","Che Liu","Lanhai Zhong","Chenxi Sun","Gari Clifford","Brandon Westover","Shenda Hong"],"pdf_url":"https://arxiv.org/pdf/2410.04133v2.pdf","comment":"working in progress"},{"id":"http://arxiv.org/abs/2404.07989v3","updated":"2024-10-21T10:54:55Z","published":"2024-04-11T17:59:45Z","title":"Any2Point: Empowering Any-modality Large Models for Efficient 3D\n  Understanding","summary":"  Large foundation models have recently emerged as a prominent focus of\ninterest, attaining superior performance in widespread scenarios. Due to the\nscarcity of 3D data, many efforts have been made to adapt pre-trained\ntransformers from vision to 3D domains. However, such 2D-to-3D approaches are\nstill limited, due to the potential loss of spatial geometries and high\ncomputation cost. More importantly, their frameworks are mainly designed for 2D\nmodels, lacking a general any-to-3D paradigm. In this paper, we introduce\nAny2Point, a parameter-efficient method to empower any-modality large models\n(vision, language, audio) for 3D understanding. Given a frozen transformer from\nany source modality, we propose a 3D-to-any (1D or 2D) virtual projection\nstrategy that correlates the input 3D points to the original 1D or 2D positions\nwithin the source modality. This mechanism enables us to assign each 3D token\nwith a positional encoding paired with the pre-trained model, which avoids 3D\ngeometry loss caused by the true projection and better motivates the\ntransformer for 3D learning with 1D/2D positional priors. Then, within each\ntransformer block, we insert an any-to-3D guided adapter module for\nparameter-efficient fine-tuning. The adapter incorporates prior spatial\nknowledge from the source modality to guide the local feature aggregation of 3D\ntokens, compelling the semantic adaption of any-modality transformers. We\nconduct extensive experiments to showcase the effectiveness and efficiency of\nour method. Code and models are released at\nhttps://github.com/Ivan-Tang-3D/Any2Point.\n","authors":["Yiwen Tang","Ray Zhang","Jiaming Liu","Zoey Guo","Dong Wang","Zhigang Wang","Bin Zhao","Shanghang Zhang","Peng Gao","Hongsheng Li","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2404.07989v3.pdf","comment":"Code and models are released at\n  https://github.com/Ivan-Tang-3D/Any2Point"},{"id":"http://arxiv.org/abs/2310.03059v8","updated":"2024-10-21T10:49:59Z","published":"2023-10-04T16:49:36Z","title":"Point-PEFT: Parameter-Efficient Fine-Tuning for 3D Pre-trained Models","summary":"  The popularity of pre-trained large models has revolutionized downstream\ntasks across diverse fields, such as language, vision, and multi-modality. To\nminimize the adaption cost for downstream tasks, many Parameter-Efficient\nFine-Tuning (PEFT) techniques are proposed for language and 2D image\npre-trained models. However, the specialized PEFT method for 3D pre-trained\nmodels is still under-explored. To this end, we introduce Point-PEFT, a novel\nframework for adapting point cloud pre-trained models with minimal learnable\nparameters. Specifically, for a pre-trained 3D model, we freeze most of its\nparameters, and only tune the newly added PEFT modules on downstream tasks,\nwhich consist of a Point-prior Prompt and a Geometry-aware Adapter. The\nPoint-prior Prompt adopts a set of learnable prompt tokens, for which we\npropose to construct a memory bank with domain-specific knowledge, and utilize\na parameter-free attention to enhance the prompt tokens. The Geometry-aware\nAdapter aims to aggregate point cloud features within spatial neighborhoods to\ncapture fine-grained geometric information through local interactions.\nExtensive experiments indicate that our Point-PEFT can achieve better\nperformance than the full fine-tuning on various downstream tasks, while using\nonly 5% of the trainable parameters, demonstrating the efficiency and\neffectiveness of our approach. Code is released at\nhttps://github.com/Ivan-Tang-3D/Point-PEFT.\n","authors":["Yiwen Tang","Ray Zhang","Zoey Guo","Dong Wang","Zhigang Wang","Bin Zhao","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2310.03059v8.pdf","comment":"The specialized PEFT framework for 3D pre-trained models, which\n  achieves competitive performance to full fine-tuning, and significantly\n  reduces the computational resources. Project page:\n  https://github.com/Ivan-Tang-3D/Point-PEFT"},{"id":"http://arxiv.org/abs/2410.15859v1","updated":"2024-10-21T10:39:05Z","published":"2024-10-21T10:39:05Z","title":"Mesa-Extrapolation: A Weave Position Encoding Method for Enhanced\n  Extrapolation in LLMs","summary":"  Large language models (LLMs), although having revolutionized many fields,\nstill suffer from the challenging extrapolation problem, where the inference\nability of LLMs sharply declines beyond their max training lengths. In this\nwork, we conduct a theoretical analysis to better understand why No Position\nEncoding (NoPE) fails outside its effective range, as well as examining the\npower of Position Encoding (PE) in this context. Our findings reveal that with\nmeticulous weave position, PE can indeed be extended beyond effective range.\nOur theorems establish that LLMs equipped with weave PE can achieve improved\nextrapolation performance without additional cost. Furthermore, we introduce a\nnovel weave PE method, Mesa-Extrapolation, which utilizes a chunk-based\ntriangular attention matrix and applies Stair PE to manage the final chunk.\nThis method not only retains competitive performance but also offers\nsubstantial benefits such as significantly reduced memory demand and faster\ninference speed. Extensive experiments validate the effectiveness of\nMesa-Extrapolation, demonstrating its potential as a scalable solution to\nenhancing LLMs applicative reach.\n","authors":["Xin Ma","Yang Liu","Jingjing Liu","Xiaoxu Ma"],"pdf_url":"https://arxiv.org/pdf/2410.15859v1.pdf","comment":"accepted by NeurIPS 2024. arXiv admin note: text overlap with\n  arXiv:2305.19466 by other authors"},{"id":"http://arxiv.org/abs/2410.15847v1","updated":"2024-10-21T10:19:45Z","published":"2024-10-21T10:19:45Z","title":"Random Token Fusion for Multi-View Medical Diagnosis","summary":"  In multi-view medical diagnosis, deep learning-based models often fuse\ninformation from different imaging perspectives to improve diagnostic\nperformance. However, existing approaches are prone to overfitting and rely\nheavily on view-specific features, which can lead to trivial solutions. In this\nwork, we introduce Random Token Fusion (RTF), a novel technique designed to\nenhance multi-view medical image analysis using vision transformers. By\nintegrating randomness into the feature fusion process during training, RTF\naddresses the issue of overfitting and enhances the robustness and accuracy of\ndiagnostic models without incurring any additional cost at inference. We\nvalidate our approach on standard mammography and chest X-ray benchmark\ndatasets. Through extensive experiments, we demonstrate that RTF consistently\nimproves the performance of existing fusion methods, paving the way for a new\ngeneration of multi-view medical foundation models.\n","authors":["Jingyu Guo","Christos Matsoukas","Fredrik Strand","Kevin Smith"],"pdf_url":"https://arxiv.org/pdf/2410.15847v1.pdf","comment":"Originally published at the NeurIPS 2024 Workshop on Advancements In\n  Medical Foundation Models: Explainability, Robustness, Security, and Beyond\n  (AIM-FM)"},{"id":"http://arxiv.org/abs/2410.15837v1","updated":"2024-10-21T09:57:42Z","published":"2024-10-21T09:57:42Z","title":"Long-distance Geomagnetic Navigation in GNSS-denied Environments with\n  Deep Reinforcement Learning","summary":"  Geomagnetic navigation has drawn increasing attention with its capacity in\nnavigating through complex environments and its independence from external\nnavigation services like global navigation satellite systems (GNSS). Existing\nstudies on geomagnetic navigation, i.e., matching navigation and bionic\nnavigation, rely on pre-stored map or extensive searches, leading to limited\napplicability or reduced navigation efficiency in unexplored areas. To address\nthe issues with geomagnetic navigation in areas where GNSS is unavailable, this\npaper develops a deep reinforcement learning (DRL)-based mechanism, especially\nfor long-distance geomagnetic navigation. The designed mechanism trains an\nagent to learn and gain the magnetoreception capacity for geomagnetic\nnavigation, rather than using any pre-stored map or extensive and expensive\nsearching approaches. Particularly, we integrate the geomagnetic gradient-based\nparallel approach into geomagnetic navigation. This integration mitigates the\nover-exploration of the learning agent by adjusting the geomagnetic gradient,\nsuch that the obtained gradient is aligned towards the destination. We explore\nthe effectiveness of the proposed approach via detailed numerical simulations,\nwhere we implement twin delayed deep deterministic policy gradient (TD3) in\nrealizing the proposed approach. The results demonstrate that our approach\noutperforms existing metaheuristic and bionic navigation methods in\nlong-distance missions under diverse navigation conditions.\n","authors":["Wenqi Bai","Xiaohui Zhang","Shiliang Zhang","Songnan Yang","Yushuai Li","Tingwen Huang"],"pdf_url":"https://arxiv.org/pdf/2410.15837v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15828v1","updated":"2024-10-21T09:46:37Z","published":"2024-10-21T09:46:37Z","title":"LLM4GRN: Discovering Causal Gene Regulatory Networks with LLMs --\n  Evaluation through Synthetic Data Generation","summary":"  Gene regulatory networks (GRNs) represent the causal relationships between\ntranscription factors (TFs) and target genes in single-cell RNA sequencing\n(scRNA-seq) data. Understanding these networks is crucial for uncovering\ndisease mechanisms and identifying therapeutic targets. In this work, we\ninvestigate the potential of large language models (LLMs) for GRN discovery,\nleveraging their learned biological knowledge alone or in combination with\ntraditional statistical methods. We develop a task-based evaluation strategy to\naddress the challenge of unavailable ground truth causal graphs. Specifically,\nwe use the GRNs suggested by LLMs to guide causal synthetic data generation and\ncompare the resulting data against the original dataset. Our statistical and\nbiological assessments show that LLMs can support statistical modeling and data\nsynthesis for biological research.\n","authors":["Tejumade Afonja","Ivaxi Sheth","Ruta Binkyte","Waqar Hanif","Thomas Ulas","Matthias Becker","Mario Fritz"],"pdf_url":"https://arxiv.org/pdf/2410.15828v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15821v1","updated":"2024-10-21T09:39:09Z","published":"2024-10-21T09:39:09Z","title":"The effect of fine-tuning on language model toxicity","summary":"  Fine-tuning language models has become increasingly popular following the\nproliferation of open models and improvements in cost-effective parameter\nefficient fine-tuning. However, fine-tuning can influence model properties such\nas safety. We assess how fine-tuning can impact different open models'\npropensity to output toxic content. We assess the impacts of fine-tuning Gemma,\nLlama, and Phi models on toxicity through three experiments. We compare how\ntoxicity is reduced by model developers during instruction-tuning. We show that\nsmall amounts of parameter-efficient fine-tuning on developer-tuned models via\nlow-rank adaptation on a non-adversarial dataset can significantly alter these\nresults across models. Finally, we highlight the impact of this in the wild,\ndemonstrating how toxicity rates of models fine-tuned by community contributors\ncan deviate in hard-to-predict ways.\n","authors":["Will Hawkins","Brent Mittelstadt","Chris Russell"],"pdf_url":"https://arxiv.org/pdf/2410.15821v1.pdf","comment":"To be presented at NeurIPS 2024 Safe Generative AI Workshop"},{"id":"http://arxiv.org/abs/2402.04494v2","updated":"2024-10-21T09:37:12Z","published":"2024-02-07T00:36:24Z","title":"Amortized Planning with Large-Scale Transformers: A Case Study on Chess","summary":"  This paper uses chess, a landmark planning problem in AI, to assess\ntransformers' performance on a planning task where memorization is futile\n$\\unicode{x2013}$ even at a large scale. To this end, we release ChessBench, a\nlarge-scale benchmark dataset of 10 million chess games with legal move and\nvalue annotations (15 billion data points) provided by Stockfish 16, the\nstate-of-the-art chess engine. We train transformers with up to 270 million\nparameters on ChessBench via supervised learning and perform extensive\nablations to assess the impact of dataset size, model size, architecture type,\nand different prediction targets (state-values, action-values, and behavioral\ncloning). Our largest models learn to predict action-values for novel boards\nquite accurately, implying highly non-trivial generalization. Despite\nperforming no explicit search, our resulting chess policy solves challenging\nchess puzzles and achieves a surprisingly strong Lichess blitz Elo of 2895\nagainst humans (grandmaster level). We also compare to Leela Chess Zero and\nAlphaZero (trained without supervision via self-play) with and without search.\nWe show that, although a remarkably good approximation of Stockfish's\nsearch-based algorithm can be distilled into large-scale transformers via\nsupervised learning, perfect distillation is still beyond reach, thus making\nChessBench well-suited for future research.\n","authors":["Anian Ruoss","Grégoire Delétang","Sourabh Medapati","Jordi Grau-Moya","Li Kevin Wenliang","Elliot Catt","John Reid","Cannada A. Lewis","Joel Veness","Tim Genewein"],"pdf_url":"https://arxiv.org/pdf/2402.04494v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15859v1","updated":"2024-10-21T10:39:05Z","published":"2024-10-21T10:39:05Z","title":"Mesa-Extrapolation: A Weave Position Encoding Method for Enhanced\n  Extrapolation in LLMs","summary":"  Large language models (LLMs), although having revolutionized many fields,\nstill suffer from the challenging extrapolation problem, where the inference\nability of LLMs sharply declines beyond their max training lengths. In this\nwork, we conduct a theoretical analysis to better understand why No Position\nEncoding (NoPE) fails outside its effective range, as well as examining the\npower of Position Encoding (PE) in this context. Our findings reveal that with\nmeticulous weave position, PE can indeed be extended beyond effective range.\nOur theorems establish that LLMs equipped with weave PE can achieve improved\nextrapolation performance without additional cost. Furthermore, we introduce a\nnovel weave PE method, Mesa-Extrapolation, which utilizes a chunk-based\ntriangular attention matrix and applies Stair PE to manage the final chunk.\nThis method not only retains competitive performance but also offers\nsubstantial benefits such as significantly reduced memory demand and faster\ninference speed. Extensive experiments validate the effectiveness of\nMesa-Extrapolation, demonstrating its potential as a scalable solution to\nenhancing LLMs applicative reach.\n","authors":["Xin Ma","Yang Liu","Jingjing Liu","Xiaoxu Ma"],"pdf_url":"https://arxiv.org/pdf/2410.15859v1.pdf","comment":"accepted by NeurIPS 2024"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2406.08472v2","updated":"2024-10-21T17:59:13Z","published":"2024-06-12T17:56:31Z","title":"RILe: Reinforced Imitation Learning","summary":"  Reinforcement Learning has achieved significant success in generating complex\nbehavior but often requires extensive reward function engineering. Adversarial\nvariants of Imitation Learning and Inverse Reinforcement Learning offer an\nalternative by learning policies from expert demonstrations via a\ndiscriminator. However, these methods struggle in complex tasks where randomly\nsampling expert-like behaviors is challenging. This limitation stems from their\nreliance on policy-agnostic discriminators, which provide insufficient guidance\nfor agent improvement, especially as task complexity increases and expert\nbehavior becomes more distinct. We introduce RILe (Reinforced Imitation\nLearning environment), a novel trainer-student system that learns a dynamic\nreward function based on the student's performance and alignment with expert\ndemonstrations. In RILe, the student learns an action policy while the trainer,\nusing reinforcement learning, continuously updates itself via the\ndiscriminator's feedback to optimize the alignment between the student and the\nexpert. The trainer optimizes for long-term cumulative rewards from the\ndiscriminator, enabling it to provide nuanced feedback that accounts for the\ncomplexity of the task and the student's current capabilities. This approach\nallows for greater exploration of agent actions by providing graduated feedback\nrather than binary expert/non-expert classifications. By reducing dependence on\npolicy-agnostic discriminators, RILe enables better performance in complex\nsettings where traditional methods falter, outperforming existing methods by 2x\nin complex simulated robot-locomotion tasks.\n","authors":["Mert Albaba","Sammy Christen","Thomas Langarek","Christoph Gebhardt","Otmar Hilliges","Michael J. Black"],"pdf_url":"https://arxiv.org/pdf/2406.08472v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16267v1","updated":"2024-10-21T17:59:11Z","published":"2024-10-21T17:59:11Z","title":"xGen-MM-Vid (BLIP-3-Video): You Only Need 32 Tokens to Represent a Video\n  Even in VLMs","summary":"  We present xGen-MM-Vid (BLIP-3-Video): a multimodal language model for\nvideos, particularly designed to efficiently capture temporal information over\nmultiple frames. BLIP-3-Video takes advantage of the 'temporal encoder' in\naddition to the conventional visual tokenizer, which maps a sequence of tokens\nover multiple frames into a compact set of visual tokens. This enables\nBLIP3-Video to use much fewer visual tokens than its competing models (e.g., 32\nvs. 4608 tokens). We explore different types of temporal encoders, including\nlearnable spatio-temporal pooling as well as sequential models like Token\nTuring Machines. We experimentally confirm that BLIP-3-Video obtains video\nquestion-answering accuracies comparable to much larger state-of-the-art models\n(e.g., 34B), while being much smaller (i.e., 4B) and more efficient by using\nfewer visual tokens. The project website is at\nhttps://www.salesforceairesearch.com/opensource/xGen-MM-Vid/index.html\n","authors":["Michael S. Ryoo","Honglu Zhou","Shrikant Kendre","Can Qin","Le Xue","Manli Shu","Silvio Savarese","Ran Xu","Caiming Xiong","Juan Carlos Niebles"],"pdf_url":"https://arxiv.org/pdf/2410.16267v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16255v1","updated":"2024-10-21T17:56:47Z","published":"2024-10-21T17:56:47Z","title":"Revisiting Deep Feature Reconstruction for Logical and Structural\n  Industrial Anomaly Detection","summary":"  Industrial anomaly detection is crucial for quality control and predictive\nmaintenance, but it presents challenges due to limited training data, diverse\nanomaly types, and external factors that alter object appearances. Existing\nmethods commonly detect structural anomalies, such as dents and scratches, by\nleveraging multi-scale features from image patches extracted through deep\npre-trained networks. However, significant memory and computational demands\noften limit their practical application. Additionally, detecting logical\nanomalies-such as images with missing or excess elements-requires an\nunderstanding of spatial relationships that traditional patch-based methods\nfail to capture. In this work, we address these limitations by focusing on Deep\nFeature Reconstruction (DFR), a memory- and compute-efficient approach for\ndetecting structural anomalies. We further enhance DFR into a unified\nframework, called ULSAD, which is capable of detecting both structural and\nlogical anomalies. Specifically, we refine the DFR training objective to\nimprove performance in structural anomaly detection, while introducing an\nattention-based loss mechanism using a global autoencoder-like network to\nhandle logical anomaly detection. Our empirical evaluation across five\nbenchmark datasets demonstrates the performance of ULSAD in detecting and\nlocalizing both structural and logical anomalies, outperforming eight\nstate-of-the-art methods. An extensive ablation study further highlights the\ncontribution of each component to the overall performance improvement. Our code\nis available at https://github.com/sukanyapatra1997/ULSAD-2024.git\n","authors":["Sukanya Patra","Souhaib Ben Taieb"],"pdf_url":"https://arxiv.org/pdf/2410.16255v1.pdf","comment":"Accepted in Transactions on Machine Learning Research (TMLR). Link to\n  OpenReview: https://openreview.net/forum?id=kdTC4ktHPD"},{"id":"http://arxiv.org/abs/2410.16253v1","updated":"2024-10-21T17:56:09Z","published":"2024-10-21T17:56:09Z","title":"Distribution Learning with Valid Outputs Beyond the Worst-Case","summary":"  Generative models at times produce \"invalid\" outputs, such as images with\ngeneration artifacts and unnatural sounds. Validity-constrained distribution\nlearning attempts to address this problem by requiring that the learned\ndistribution have a provably small fraction of its mass in invalid parts of\nspace -- something which standard loss minimization does not always ensure. To\nthis end, a learner in this model can guide the learning via \"validity\nqueries\", which allow it to ascertain the validity of individual examples.\nPrior work on this problem takes a worst-case stance, showing that proper\nlearning requires an exponential number of validity queries, and demonstrating\nan improper algorithm which -- while generating guarantees in a wide-range of\nsettings -- makes an atypical polynomial number of validity queries. In this\nwork, we take a first step towards characterizing regimes where guaranteeing\nvalidity is easier than in the worst-case. We show that when the data\ndistribution lies in the model class and the log-loss is minimized, the number\nof samples required to ensure validity has a weak dependence on the validity\nrequirement. Additionally, we show that when the validity region belongs to a\nVC-class, a limited number of validity queries are often sufficient.\n","authors":["Nick Rittler","Kamalika Chaudhuri"],"pdf_url":"https://arxiv.org/pdf/2410.16253v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16247v1","updated":"2024-10-21T17:52:01Z","published":"2024-10-21T17:52:01Z","title":"Implicit Regularization for Tubal Tensor Factorizations via Gradient\n  Descent","summary":"  We provide a rigorous analysis of implicit regularization in an\noverparametrized tensor factorization problem beyond the lazy training regime.\nFor matrix factorization problems, this phenomenon has been studied in a number\nof works. A particular challenge has been to design universal initialization\nstrategies which provably lead to implicit regularization in gradient-descent\nmethods. At the same time, it has been argued by Cohen et. al. 2016 that more\ngeneral classes of neural networks can be captured by considering tensor\nfactorizations. However, in the tensor case, implicit regularization has only\nbeen rigorously established for gradient flow or in the lazy training regime.\nIn this paper, we prove the first tensor result of its kind for gradient\ndescent rather than gradient flow. We focus on the tubal tensor product and the\nassociated notion of low tubal rank, encouraged by the relevance of this model\nfor image data. We establish that gradient descent in an overparametrized\ntensor factorization model with a small random initialization exhibits an\nimplicit bias towards solutions of low tubal rank. Our theoretical findings are\nillustrated in an extensive set of numerical simulations show-casing the\ndynamics predicted by our theory as well as the crucial role of using a small\nrandom initialization.\n","authors":["Santhosh Karnik","Anna Veselovska","Mark Iwen","Felix Krahmer"],"pdf_url":"https://arxiv.org/pdf/2410.16247v1.pdf","comment":"58 pages, 4 figures"},{"id":"http://arxiv.org/abs/2405.21042v2","updated":"2024-10-21T17:50:10Z","published":"2024-05-31T17:33:07Z","title":"Comparing the information content of probabilistic representation spaces","summary":"  Probabilistic representation spaces convey information about a dataset, and\nto understand the effects of factors such as training loss and network\narchitecture, we seek to compare the information content of such spaces.\nHowever, most existing methods to compare representation spaces assume\nrepresentations are points, and neglect the distributional nature of\nprobabilistic representations. Here, instead of building upon point-based\nmeasures of comparison, we build upon classic methods from literature on hard\nclustering. We generalize two information-theoretic methods of comparing hard\nclustering assignments to be applicable to general probabilistic representation\nspaces. We then propose a practical method of estimation that is based on\nfingerprinting a representation space with a sample of the dataset and is\napplicable when the communicated information is only a handful of bits. With\nunsupervised disentanglement as a motivating problem, we find information\nfragments that are repeatedly contained in individual latent dimensions in VAE\nand InfoGAN ensembles. Then, by comparing the full latent spaces of models, we\nfind highly consistent information content across datasets, methods, and\nhyperparameters, even though there is often a point during training with\nsubstantial variety across repeat runs. Finally, we leverage the\ndifferentiability of the proposed method and perform model fusion by\nsynthesizing the information content of multiple weak learners, each incapable\nof representing the global structure of a dataset. Across the case studies, the\ndirect comparison of information content provides a natural basis for\nunderstanding the processing of information.\n","authors":["Kieran A. Murphy","Sam Dillavou","Dani S. Bassett"],"pdf_url":"https://arxiv.org/pdf/2405.21042v2.pdf","comment":"Code:\n  https://github.com/murphyka/representation-space-info-comparison"},{"id":"http://arxiv.org/abs/2410.16239v1","updated":"2024-10-21T17:42:41Z","published":"2024-10-21T17:42:41Z","title":"MoRE: Multi-Modal Contrastive Pre-training with Transformers on X-Rays,\n  ECGs, and Diagnostic Report","summary":"  In this paper, we introduce a novel Multi-Modal Contrastive Pre-training\nFramework that synergistically combines X-rays, electrocardiograms (ECGs), and\nradiology/cardiology reports. Our approach leverages transformers to encode\nthese diverse modalities into a unified representation space, aiming to enhance\ndiagnostic accuracy and facilitate comprehensive patient assessments. We\nutilize LoRA-Peft to significantly reduce trainable parameters in the LLM and\nincorporate recent linear attention dropping strategy in the Vision\nTransformer(ViT) for smoother attention. Furthermore, we provide novel\nmultimodal attention explanations and retrieval for our model. To the best of\nour knowledge, we are the first to propose an integrated model that combines\nX-ray, ECG, and Radiology/Cardiology Report with this approach. By utilizing\ncontrastive loss, MoRE effectively aligns modality-specific features into a\ncoherent embedding, which supports various downstream tasks such as zero-shot\nclassification and multimodal retrieval. Employing our proposed methodology, we\nachieve state-of-the-art (SOTA) on the Mimic-IV, CheXpert, Edema Severity, and\nPtbXl downstream datasets, surpassing existing multimodal approaches. Our\nproposed framework shows significant improvements in capturing intricate\ninter-modal relationships and its robustness in medical diagnosis that\nestablishes a framework for future research in multimodal learning in the\nhealthcare sector.\n","authors":["Samrajya Thapa","Koushik Howlader","Subhankar Bhattacharjee","Wei le"],"pdf_url":"https://arxiv.org/pdf/2410.16239v1.pdf","comment":"10 pages, 5 figures, 9 tables. Supplementary detail in Appendix. Code\n  made available in Github for reproducibility"},{"id":"http://arxiv.org/abs/2405.12235v6","updated":"2024-10-21T17:34:08Z","published":"2024-05-14T23:50:01Z","title":"Hypergraph: A Unified and Uniform Definition with Application to\n  Chemical Hypergraph and More","summary":"  The conventional definition of hypergraph has two major issues: (1) there is\nnot a standard definition of directed hypergraph and (2) there is not a formal\ndefinition of nested hypergraph. To resolve these issues, we propose a new\ndefinition of hypergraph that unifies the concepts of undirected, directed and\nnested hypergraphs, and that is uniform in using hyperedge as a single\nconstruct for representing high-order correlations among things, i.e., nodes\nand hyperedges. Specifically, we define a hyperedge to be a simple hyperedge, a\nnesting hyperedge, or a directed hyperedge. With this new definition, a\nhypergraph is nested if it has nesting hyperedge(s), and is directed if it has\ndirected hyperedge(s). Otherwise, a hypergraph is a simple hypergraph. The\nuniformity and power of this new definition, with visualization, should\nfacilitate the use of hypergraph for representing (hierarchical) high-order\ncorrelations in general and chemical systems in particular. Graph has been\nwidely used as a mathematical structure for machine learning on molecular\nstructures and 3D molecular geometries. However, graph has a major limitation:\nit can represent only pairwise correlations between nodes. Hypergraph extends\ngraph with high-order correlations among nodes. This extension is significant\nor essential for machine learning on chemical systems. For molecules, this is\nsignificant as it allows the direct, explicit representation of multicenter\nbonds and molecular substructures. For chemical reactions, this is essential\nsince most chemical reactions involve multiple participants. We propose the use\nof chemical hypergraph, a multilevel hypergraph with simple, nesting and\ndirected hyperedges, as a single mathematical structure for representing\nchemical systems. We apply the new definition of hypergraph to chemical\nhypergraph and, as simplified versions, molecular hypergraph and chemical\nreaction hypergraph.\n","authors":["Daniel T. Chang"],"pdf_url":"https://arxiv.org/pdf/2405.12235v6.pdf","comment":"arXiv admin note: text overlap with arXiv:2310.03623 by other authors"},{"id":"http://arxiv.org/abs/2410.16222v1","updated":"2024-10-21T17:27:01Z","published":"2024-10-21T17:27:01Z","title":"A Realistic Threat Model for Large Language Model Jailbreaks","summary":"  A plethora of jailbreaking attacks have been proposed to obtain harmful\nresponses from safety-tuned LLMs. In their original settings, these methods all\nlargely succeed in coercing the target output, but their attacks vary\nsubstantially in fluency and computational effort. In this work, we propose a\nunified threat model for the principled comparison of these methods. Our threat\nmodel combines constraints in perplexity, measuring how far a jailbreak\ndeviates from natural text, and computational budget, in total FLOPs. For the\nformer, we build an N-gram model on 1T tokens, which, in contrast to\nmodel-based perplexity, allows for an LLM-agnostic and inherently interpretable\nevaluation. We adapt popular attacks to this new, realistic threat model, with\nwhich we, for the first time, benchmark these attacks on equal footing. After a\nrigorous comparison, we not only find attack success rates against safety-tuned\nmodern models to be lower than previously presented but also find that attacks\nbased on discrete optimization significantly outperform recent LLM-based\nattacks. Being inherently interpretable, our threat model allows for a\ncomprehensive analysis and comparison of jailbreak attacks. We find that\neffective attacks exploit and abuse infrequent N-grams, either selecting\nN-grams absent from real-world text or rare ones, e.g. specific to code\ndatasets.\n","authors":["Valentyn Boreiko","Alexander Panfilov","Vaclav Voracek","Matthias Hein","Jonas Geiping"],"pdf_url":"https://arxiv.org/pdf/2410.16222v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.17355v2","updated":"2024-10-21T17:27:00Z","published":"2024-08-30T15:39:34Z","title":"Bidirectional Decoding: Improving Action Chunking via Closed-Loop\n  Resampling","summary":"  Predicting and executing a sequence of actions without intermediate\nreplanning, known as action chunking, is increasingly used in robot learning\nfrom human demonstrations. Yet, its reported effects on the learned policy are\ninconsistent: some studies find it crucial for achieving strong results, while\nothers observe decreased performance. In this paper, we first dissect how\naction chunking impacts the divergence between a learner and a demonstrator. We\nfind that action chunking allows the learner to better capture the temporal\ndependencies in demonstrations but at the cost of reduced reactivity in\nstochastic environments. To address this tradeoff, we propose Bidirectional\nDecoding (BID), a test-time inference algorithm that bridges action chunking\nwith closed-loop operations. BID samples multiple predictions at each time step\nand searches for the optimal one based on two criteria: (i) backward coherence,\nwhich favors samples that align with previous decisions; (ii) forward contrast,\nwhich seeks samples of high likelihood for future plans. By coupling decisions\nwithin and across action chunks, BID promotes consistency over time while\nmaintaining reactivity to unexpected changes. Experimental results show that\nBID boosts the performance of two state-of-the-art generative policies across\nseven simulation benchmarks and two real-world tasks. Code and videos are\navailable at https://bid-robot.github.io.\n","authors":["Yuejiang Liu","Jubayer Ibn Hamid","Annie Xie","Yoonho Lee","Maximilian Du","Chelsea Finn"],"pdf_url":"https://arxiv.org/pdf/2408.17355v2.pdf","comment":"Project website: https://bid-robot.github.io/"},{"id":"http://arxiv.org/abs/2406.01583v2","updated":"2024-10-21T17:25:44Z","published":"2024-06-03T17:58:43Z","title":"Decomposing and Interpreting Image Representations via Text in ViTs\n  Beyond CLIP","summary":"  Recent work has explored how individual components of the CLIP-ViT model\ncontribute to the final representation by leveraging the shared image-text\nrepresentation space of CLIP. These components, such as attention heads and\nMLPs, have been shown to capture distinct image features like shape, color or\ntexture. However, understanding the role of these components in arbitrary\nvision transformers (ViTs) is challenging. To this end, we introduce a general\nframework which can identify the roles of various components in ViTs beyond\nCLIP. Specifically, we (a) automate the decomposition of the final\nrepresentation into contributions from different model components, and (b)\nlinearly map these contributions to CLIP space to interpret them via text.\nAdditionally, we introduce a novel scoring function to rank components by their\nimportance with respect to specific features. Applying our framework to various\nViT variants (e.g. DeiT, DINO, DINOv2, Swin, MaxViT), we gain insights into the\nroles of different components concerning particular image features. These\ninsights facilitate applications such as image retrieval using text\ndescriptions or reference images, visualizing token importance heatmaps, and\nmitigating spurious correlations. We release our code to reproduce the\nexperiments at https://github.com/SriramB-98/vit-decompose\n","authors":["Sriram Balasubramanian","Samyadeep Basu","Soheil Feizi"],"pdf_url":"https://arxiv.org/pdf/2406.01583v2.pdf","comment":"NeurIPS 2024, 31 pages, 15 figures"},{"id":"http://arxiv.org/abs/2410.13714v2","updated":"2024-10-21T17:21:16Z","published":"2024-10-17T16:14:49Z","title":"Generation through the lens of learning theory","summary":"  We study generation through the lens of statistical learning theory. First,\nwe abstract and formalize the results of Gold [1967], Angluin [1979, 1980], and\nKleinberg and Mullainathan [2024] for language identification/generation in the\nlimit in terms of a binary hypothesis class defined over an abstract instance\nspace. Then, we formalize a different paradigm of generation studied by\nKleinberg and Mullainathan [2024], which we call ``uniform generation,\" and\nprovide a characterization of which hypothesis classes are uniformly\ngeneratable. As is standard in statistical learning theory, our\ncharacterization is in terms of the finiteness of a new combinatorial dimension\nwe call the Closure dimension. By doing so, we are able to compare\ngeneratability with predictability (captured via PAC and online learnability)\nand show that these two properties of hypothesis classes are\n\\emph{incompatible} - there are classes that are generatable but not\npredictable and vice versa.\n","authors":["Vinod Raman","Ambuj Tewari"],"pdf_url":"https://arxiv.org/pdf/2410.13714v2.pdf","comment":"Minor edits"},{"id":"http://arxiv.org/abs/2410.16212v1","updated":"2024-10-21T17:12:06Z","published":"2024-10-21T17:12:06Z","title":"Comprehensive benchmarking of large language models for RNA secondary\n  structure prediction","summary":"  Inspired by the success of large language models (LLM) for DNA and proteins,\nseveral LLM for RNA have been developed recently. RNA-LLM uses large datasets\nof RNA sequences to learn, in a self-supervised way, how to represent each RNA\nbase with a semantically rich numerical vector. This is done under the\nhypothesis that obtaining high-quality RNA representations can enhance\ndata-costly downstream tasks. Among them, predicting the secondary structure is\na fundamental task for uncovering RNA functional mechanisms. In this work we\npresent a comprehensive experimental analysis of several pre-trained RNA-LLM,\ncomparing them for the RNA secondary structure prediction task in an unified\ndeep learning framework. The RNA-LLM were assessed with increasing\ngeneralization difficulty on benchmark datasets. Results showed that two LLM\nclearly outperform the other models, and revealed significant challenges for\ngeneralization in low-homology scenarios.\n","authors":["L. I. Zablocki","L. A. Bugnon","M. Gerard","L. Di Persia","G. Stegmayer","D. H. Milone"],"pdf_url":"https://arxiv.org/pdf/2410.16212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16208v1","updated":"2024-10-21T17:11:21Z","published":"2024-10-21T17:11:21Z","title":"Compute-Constrained Data Selection","summary":"  Data selection can reduce the amount of training data needed to finetune\nLLMs; however, the efficacy of data selection scales directly with its compute.\nMotivated by the practical challenge of compute-constrained finetuning, we\nconsider the setting in which both the cost of selecting data and training are\nbudgeted for. We first formalize the problem of data selection with a\ncost-aware utility function, and model the data selection problem as trading\noff initial-selection cost for training gain. We run a comprehensive sweep of\nexperiments across multiple tasks, varying compute budget by scaling finetuning\ntokens, model sizes, and data selection compute. These experiments show the\nvalidity of this model in real-world experiments. Interestingly we find that\nmany powerful data selection methods are almost never compute-optimal, and that\ncheaper data selection alternatives dominate both from a theoretical and\nempirical perspective.\n","authors":["Junjie Oscar Yin","Alexander M. Rush"],"pdf_url":"https://arxiv.org/pdf/2410.16208v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16207v1","updated":"2024-10-21T17:10:43Z","published":"2024-10-21T17:10:43Z","title":"CoT-TL: Low-Resource Temporal Knowledge Representation of Planning\n  Instructions Using Chain-of-Thought Reasoning","summary":"  Autonomous agents often face the challenge of interpreting uncertain natural\nlanguage instructions for planning tasks. Representing these instructions as\nLinear Temporal Logic (LTL) enables planners to synthesize actionable plans. We\nintroduce CoT-TL, a data-efficient in-context learning framework for\ntranslating natural language specifications into LTL representations. CoT-TL\naddresses the limitations of large language models, which typically rely on\nextensive fine-tuning data, by extending chain-of-thought reasoning and\nsemantic roles to align with the requirements of formal logic creation. This\napproach enhances the transparency and rationale behind LTL generation,\nfostering user trust. CoT-TL achieves state-of-the-art accuracy across three\ndiverse datasets in low-data scenarios, outperforming existing methods without\nfine-tuning or intermediate translations. To improve reliability and minimize\nhallucinations, we incorporate model checking to validate the syntax of the\ngenerated LTL output. We further demonstrate CoT-TL's effectiveness through\nablation studies and evaluations on unseen LTL structures and formulas in a new\ndataset. Finally, we validate CoT-TL's practicality by integrating it into a\nQuadCopter for multi-step drone planning based on natural language\ninstructions.\n","authors":["Kumar Manas","Stefan Zwicklbauer","Adrian Paschke"],"pdf_url":"https://arxiv.org/pdf/2410.16207v1.pdf","comment":"Accepted for publication in Proceedings of the 2024 IEEE/RSJ\n  International Conference on Intelligent Robots and Systems (IROS 2024), Abu\n  Dhabi 14-18 October 2024"},{"id":"http://arxiv.org/abs/2410.16204v1","updated":"2024-10-21T17:05:50Z","published":"2024-10-21T17:05:50Z","title":"Systematic Review: Text Processing Algorithms in Machine Learning and\n  Deep Learning for Mental Health Detection on Social Media","summary":"  The global rise in depression necessitates innovative detection methods for\nearly intervention. Social media provides a unique opportunity to identify\ndepression through user-generated posts. This systematic review evaluates\nmachine learning (ML) models for depression detection on social media, focusing\non biases and methodological challenges throughout the ML lifecycle. A search\nof PubMed, IEEE Xplore, and Google Scholar identified 47 relevant studies\npublished after 2010. The Prediction model Risk Of Bias ASsessment Tool\n(PROBAST) was utilized to assess methodological quality and risk of bias.\nSignificant biases impacting model reliability and generalizability were found.\nThere is a predominant reliance on Twitter (63.8%) and English-language content\n(over 90%), with most studies focusing on users from the United States and\nEurope. Non-probability sampling methods (approximately 80%) limit\nrepresentativeness. Only 23% of studies explicitly addressed linguistic nuances\nlike negations, crucial for accurate sentiment analysis. Inconsistent\nhyperparameter tuning was observed, with only 27.7% properly tuning models.\nAbout 17% did not adequately partition data into training, validation, and test\nsets, risking overfitting. While 74.5% used appropriate evaluation metrics for\nimbalanced data, others relied on accuracy without addressing class imbalance,\npotentially skewing results. Reporting transparency varied, often lacking\ncritical methodological details. These findings highlight the need to diversify\ndata sources, standardize preprocessing protocols, ensure consistent model\ndevelopment practices, address class imbalance, and enhance reporting\ntransparency. By overcoming these challenges, future research can develop more\nrobust and generalizable ML models for depression detection on social media,\ncontributing to improved mental health outcomes globally.\n","authors":["Yuchen Cao","Jianglai Dai","Zhongyan Wang","Yeyubei Zhang","Xiaorui Shen","Yunchong Liu","Yexin Tian"],"pdf_url":"https://arxiv.org/pdf/2410.16204v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19323v2","updated":"2024-10-21T17:05:15Z","published":"2024-05-29T17:54:22Z","title":"Are Large Language Models Chameleons? An Attempt to Simulate Social\n  Surveys","summary":"  Can large language models (LLMs) simulate social surveys? To answer this\nquestion, we conducted millions of simulations in which LLMs were asked to\nanswer subjective questions. A comparison of different LLM responses with the\nEuropean Social Survey (ESS) data suggests that the effect of prompts on bias\nand variability is fundamental, highlighting major cultural, age, and gender\nbiases. We further discussed statistical methods for measuring the difference\nbetween LLM answers and survey data and proposed a novel measure inspired by\nJaccard similarity, as LLM-generated responses are likely to have a smaller\nvariance. Our experiments also reveal that it is important to analyze the\nrobustness and variability of prompts before using LLMs to simulate social\nsurveys, as their imitation abilities are approximate at best.\n","authors":["Mingmeng Geng","Sihong He","Roberto Trotta"],"pdf_url":"https://arxiv.org/pdf/2405.19323v2.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2410.16201v1","updated":"2024-10-21T17:03:20Z","published":"2024-10-21T17:03:20Z","title":"Theoretical Limitations of Ensembles in the Age of Overparameterization","summary":"  Classic tree-based ensembles generalize better than any single decision tree.\nIn contrast, recent empirical studies find that modern ensembles of\n(overparameterized) neural networks may not provide any inherent generalization\nadvantage over single but larger neural networks. This paper clarifies how\nmodern overparameterized ensembles differ from their classic underparameterized\ncounterparts, using ensembles of random feature (RF) regressors as a basis for\ndeveloping theory. In contrast to the underparameterized regime, where\nensembling typically induces regularization and increases generalization, we\nprove that infinite ensembles of overparameterized RF regressors become\npointwise equivalent to (single) infinite-width RF regressors. This\nequivalence, which is exact for ridgeless models and approximate for small\nridge penalties, implies that overparameterized ensembles and single large\nmodels exhibit nearly identical generalization. As a consequence, we can\ncharacterize the predictive variance amongst ensemble members, and demonstrate\nthat it quantifies the expected effects of increasing capacity rather than\ncapturing any conventional notion of uncertainty. Our results challenge common\nassumptions about the advantages of ensembles in overparameterized settings,\nprompting a reconsideration of how well intuitions from underparameterized\nensembles transfer to deep ensembles and the overparameterized regime.\n","authors":["Niclas Dern","John P. Cunningham","Geoff Pleiss"],"pdf_url":"https://arxiv.org/pdf/2410.16201v1.pdf","comment":"26 pages, 12 figures"},{"id":"http://arxiv.org/abs/2410.16195v1","updated":"2024-10-21T16:59:01Z","published":"2024-10-21T16:59:01Z","title":"A Trust-Region Method for Graphical Stein Variational Inference","summary":"  Stein variational inference (SVI) is a sample-based approximate Bayesian\ninference technique that generates a sample set by jointly optimizing the\nsamples' locations to minimize an information-theoretic measure of discrepancy\nwith the target probability distribution. SVI thus provides a fast and\nsignificantly more sample-efficient approach to Bayesian inference than\ntraditional (random-sampling-based) alternatives. However, the optimization\ntechniques employed in existing SVI methods struggle to address problems in\nwhich the target distribution is high-dimensional, poorly-conditioned, or\nnon-convex, which severely limits the range of their practical applicability.\nIn this paper, we propose a novel trust-region optimization approach for SVI\nthat successfully addresses each of these challenges. Our method builds upon\nprior work in SVI by leveraging conditional independences in the target\ndistribution (to achieve high-dimensional scaling) and second-order information\n(to address poor conditioning), while additionally providing an effective\nadaptive step control procedure, which is essential for ensuring convergence on\nchallenging non-convex optimization problems. Experimental results show our\nmethod achieves superior numerical performance, both in convergence rate and\nsample accuracy, and scales better in high-dimensional distributions, than\nprevious SVI techniques.\n","authors":["Liam Pavlovic","David M. Rosen"],"pdf_url":"https://arxiv.org/pdf/2410.16195v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.13791v3","updated":"2024-10-21T16:55:31Z","published":"2024-06-19T19:35:14Z","title":"IoT-Based Preventive Mental Health Using Knowledge Graphs and Standards\n  for Better Well-Being","summary":"  Sustainable Development Goals (SDGs) give the UN a road map for development\nwith Agenda 2030 as a target. SDG3 \"Good Health and Well-Being\" ensures healthy\nlives and promotes well-being for all ages. Digital technologies can support\nSDG3. Burnout and even depression could be reduced by encouraging better\npreventive health. Due to the lack of patient knowledge and focus to take care\nof their health, it is necessary to help patients before it is too late. New\ntrends such as positive psychology and mindfulness are highly encouraged in the\nUSA. Digital Twins (DTs) can help with the continuous monitoring of emotion\nusing physiological signals (e.g., collected via wearables). DTs facilitate\nmonitoring and provide constant health insight to improve quality of life and\nwell-being with better personalization. Healthcare DTs challenges are\nstandardizing data formats, communication protocols, and data exchange\nmechanisms. As an example, ISO has the ISO/IEC JTC 1/SC 41 Internet of Things\n(IoT) and DTs Working Group, with standards such as \"ISO/IEC 21823-3:2021 IoT -\nInteroperability for IoT Systems - Part 3 Semantic interoperability\", \"ISO/IEC\nCD 30178 - IoT - Data format, value and coding\". To achieve those data\nintegration and knowledge challenges, we designed the Mental Health Knowledge\nGraph (ontology and dataset) to boost mental health. As an example, explicit\nknowledge is described such as chocolate contains magnesium which is\nrecommended for depression. The Knowledge Graph (KG) acquires knowledge from\nontology-based mental health projects classified within the LOV4IoT ontology\ncatalog (Emotion, Depression, and Mental Health). Furthermore, the KG is mapped\nto standards when possible. Standards from ETSI SmartM2M can be used such as\nSAREF4EHAW to represent medical devices and sensors, but also ITU/WHO, ISO,\nW3C, NIST, and IEEE standards relevant to mental health can be considered.\n","authors":["Amelie Gyrard","Seyedali Mohammadi","Manas Gaur","Antonio Kung"],"pdf_url":"https://arxiv.org/pdf/2406.13791v3.pdf","comment":"20 pages, Book chapter, Smart Technologies for Achieving Good Health\n  and Well-Being: Towards Sustainable Development Goal, Taylor & Francis"},{"id":"http://arxiv.org/abs/2409.18169v3","updated":"2024-10-21T16:51:22Z","published":"2024-09-26T17:55:22Z","title":"Harmful Fine-tuning Attacks and Defenses for Large Language Models: A\n  Survey","summary":"  Recent research demonstrates that the nascent fine-tuning-as-a-service\nbusiness model exposes serious safety concerns -- fine-tuning over a few\nharmful data uploaded by the users can compromise the safety alignment of the\nmodel. The attack, known as harmful fine-tuning, has raised a broad research\ninterest among the community. However, as the attack is still new, \\textbf{we\nobserve from our miserable submission experience that there are general\nmisunderstandings within the research community.} We in this paper aim to clear\nsome common concerns for the attack setting, and formally establish the\nresearch problem. Specifically, we first present the threat model of the\nproblem, and introduce the harmful fine-tuning attack and its variants. Then we\nsystematically survey the existing literature on attacks/defenses/mechanical\nanalysis of the problem. Finally, we outline future research directions that\nmight contribute to the development of the field. Additionally, we present a\nlist of questions of interest, which might be useful to refer to when reviewers\nin the peer review process question the realism of the\nexperiment/attack/defense setting. A curated list of relevant papers is\nmaintained and made accessible at:\n\\url{https://github.com/git-disl/awesome_LLM-harmful-fine-tuning-papers}.\n","authors":["Tiansheng Huang","Sihao Hu","Fatih Ilhan","Selim Furkan Tekin","Ling Liu"],"pdf_url":"https://arxiv.org/pdf/2409.18169v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.20539v2","updated":"2024-10-21T16:44:58Z","published":"2024-05-30T23:31:25Z","title":"SleeperNets: Universal Backdoor Poisoning Attacks Against Reinforcement\n  Learning Agents","summary":"  Reinforcement learning (RL) is an actively growing field that is seeing\nincreased usage in real-world, safety-critical applications -- making it\nparamount to ensure the robustness of RL algorithms against adversarial\nattacks. In this work we explore a particularly stealthy form of training-time\nattacks against RL -- backdoor poisoning. Here the adversary intercepts the\ntraining of an RL agent with the goal of reliably inducing a particular action\nwhen the agent observes a pre-determined trigger at inference time. We uncover\ntheoretical limitations of prior work by proving their inability to generalize\nacross domains and MDPs. Motivated by this, we formulate a novel poisoning\nattack framework which interlinks the adversary's objectives with those of\nfinding an optimal policy -- guaranteeing attack success in the limit. Using\ninsights from our theoretical analysis we develop ``SleeperNets'' as a\nuniversal backdoor attack which exploits a newly proposed threat model and\nleverages dynamic reward poisoning techniques. We evaluate our attack in 6\nenvironments spanning multiple domains and demonstrate significant improvements\nin attack success over existing methods, while preserving benign episodic\nreturn.\n","authors":["Ethan Rathbun","Christopher Amato","Alina Oprea"],"pdf_url":"https://arxiv.org/pdf/2405.20539v2.pdf","comment":"23 pages, 14 figures, NeurIPS"},{"id":"http://arxiv.org/abs/2410.16179v1","updated":"2024-10-21T16:44:51Z","published":"2024-10-21T16:44:51Z","title":"MagicPIG: LSH Sampling for Efficient LLM Generation","summary":"  Large language models (LLMs) with long context windows have gained\nsignificant attention. However, the KV cache, stored to avoid re-computation,\nbecomes a bottleneck. Various dynamic sparse or TopK-based attention\napproximation methods have been proposed to leverage the common insight that\nattention is sparse. In this paper, we first show that TopK attention itself\nsuffers from quality degradation in certain downstream tasks because attention\nis not always as sparse as expected. Rather than selecting the keys and values\nwith the highest attention scores, sampling with theoretical guarantees can\nprovide a better estimation for attention output. To make the sampling-based\napproximation practical in LLM generation, we propose MagicPIG, a heterogeneous\nsystem based on Locality Sensitive Hashing (LSH). MagicPIG significantly\nreduces the workload of attention computation while preserving high accuracy\nfor diverse tasks. MagicPIG stores the LSH hash tables and runs the attention\ncomputation on the CPU, which allows it to serve longer contexts and larger\nbatch sizes with high approximation accuracy. MagicPIG can improve decoding\nthroughput by $1.9\\sim3.9\\times$ across various GPU hardware and achieve 110ms\ndecoding latency on a single RTX 4090 for Llama-3.1-8B-Instruct model with a\ncontext of 96k tokens. The code is available at\n\\url{https://github.com/Infini-AI-Lab/MagicPIG}.\n","authors":["Zhuoming Chen","Ranajoy Sadhukhan","Zihao Ye","Yang Zhou","Jianyu Zhang","Niklas Nolte","Yuandong Tian","Matthijs Douze","Leon Bottou","Zhihao Jia","Beidi Chen"],"pdf_url":"https://arxiv.org/pdf/2410.16179v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14540v2","updated":"2024-10-21T16:40:09Z","published":"2024-05-23T13:22:59Z","title":"This Too Shall Pass: Removing Stale Observations in Dynamic Bayesian\n  Optimization","summary":"  Bayesian Optimization (BO) has proven to be very successful at optimizing a\nstatic, noisy, costly-to-evaluate black-box function $f : \\mathcal{S} \\to\n\\mathbb{R}$. However, optimizing a black-box which is also a function of time\n(i.e., a dynamic function) $f : \\mathcal{S} \\times \\mathcal{T} \\to \\mathbb{R}$\nremains a challenge, since a dynamic Bayesian Optimization (DBO) algorithm has\nto keep track of the optimum over time. This changes the nature of the\noptimization problem in at least three aspects: (i) querying an arbitrary point\nin $\\mathcal{S} \\times \\mathcal{T}$ is impossible, (ii) past observations\nbecome less and less relevant for keeping track of the optimum as time goes by\nand (iii) the DBO algorithm must have a high sampling frequency so it can\ncollect enough relevant observations to keep track of the optimum through time.\nIn this paper, we design a Wasserstein distance-based criterion able to\nquantify the relevancy of an observation with respect to future predictions.\nThen, we leverage this criterion to build W-DBO, a DBO algorithm able to remove\nirrelevant observations from its dataset on the fly, thus maintaining\nsimultaneously a good predictive performance and a high sampling frequency,\neven in continuous-time optimization tasks with unknown horizon. Numerical\nexperiments establish the superiority of W-DBO, which outperforms\nstate-of-the-art methods by a comfortable margin.\n","authors":["Anthony Bardou","Patrick Thiran","Giovanni Ranieri"],"pdf_url":"https://arxiv.org/pdf/2405.14540v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.07059v2","updated":"2024-10-21T16:34:48Z","published":"2024-07-09T17:31:47Z","title":"Differentiable Optimization of Similarity Scores Between Models and\n  Brains","summary":"  How do we know if two systems - biological or artificial - process\ninformation in a similar way? Similarity measures such as linear regression,\nCentered Kernel Alignment (CKA), Normalized Bures Similarity (NBS), and angular\nProcrustes distance, are often used to quantify this similarity. However, it is\ncurrently unclear what drives high similarity scores and even what constitutes\na \"good\" score. Here, we introduce a novel tool to investigate these questions\nby differentiating through similarity measures to directly maximize the score.\nSurprisingly, we find that high similarity scores do not guarantee encoding\ntask-relevant information in a manner consistent with neural data; and this is\nparticularly acute for CKA and even some variations of cross-validated and\nregularized linear regression. We find no consistent threshold for a good\nsimilarity score - it depends on both the measure and the dataset. In addition,\nsynthetic datasets optimized to maximize similarity scores initially learn the\nhighest variance principal component of the target dataset, but some methods\nlike angular Procrustes capture lower variance dimensions much earlier than\nmethods like CKA. To shed light on this, we mathematically derive the\nsensitivity of CKA, angular Procrustes, and NBS to the variance of principal\ncomponent dimensions, and explain the emphasis CKA places on high variance\ncomponents. Finally, by jointly optimizing multiple similarity measures, we\ncharacterize their allowable ranges and reveal that some similarity measures\nare more constraining than others. While current measures offer a seemingly\nstraightforward way to quantify the similarity between neural systems, our work\nunderscores the need for careful interpretation. We hope the tools we developed\nwill be used by practitioners to better understand current and future\nsimilarity measures.\n","authors":["Nathan Cloos","Moufan Li","Markus Siegel","Scott L. Brincat","Earl K. Miller","Guangyu Robert Yang","Christopher J. Cueva"],"pdf_url":"https://arxiv.org/pdf/2407.07059v2.pdf","comment":"19 pages, 9 figures"},{"id":"http://arxiv.org/abs/2405.16195v2","updated":"2024-10-21T16:32:24Z","published":"2024-05-25T11:57:43Z","title":"Adaptive $Q$-Network: On-the-fly Target Selection for Deep Reinforcement\n  Learning","summary":"  Deep Reinforcement Learning (RL) is well known for being highly sensitive to\nhyperparameters, requiring practitioners substantial efforts to optimize them\nfor the problem at hand. This also limits the applicability of RL in real-world\nscenarios. In recent years, the field of automated Reinforcement Learning\n(AutoRL) has grown in popularity by trying to address this issue. However,\nthese approaches typically hinge on additional samples to select\nwell-performing hyperparameters, hindering sample-efficiency and practicality.\nFurthermore, most AutoRL methods are heavily based on already existing AutoML\nmethods, which were originally developed neglecting the additional challenges\ninherent to RL due to its non-stationarities. In this work, we propose a new\napproach for AutoRL, called Adaptive $Q$-Network (AdaQN), that is tailored to\nRL to take into account the non-stationarity of the optimization procedure\nwithout requiring additional samples. AdaQN learns several $Q$-functions, each\none trained with different hyperparameters, which are updated online using the\n$Q$-function with the smallest approximation error as a shared target. Our\nselection scheme simultaneously handles different hyperparameters while coping\nwith the non-stationarity induced by the RL optimization procedure and being\northogonal to any critic-based RL algorithm. We demonstrate that AdaQN is\ntheoretically sound and empirically validate it in MuJoCo control problems and\nAtari $2600$ games, showing benefits in sample-efficiency, overall performance,\nrobustness to stochasticity and training stability.\n","authors":["Théo Vincent","Fabian Wahren","Jan Peters","Boris Belousov","Carlo D'Eramo"],"pdf_url":"https://arxiv.org/pdf/2405.16195v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.13995v2","updated":"2024-10-21T16:27:48Z","published":"2024-10-17T19:50:28Z","title":"Adversarial Inception for Bounded Backdoor Poisoning in Deep\n  Reinforcement Learning","summary":"  Recent works have demonstrated the vulnerability of Deep Reinforcement\nLearning (DRL) algorithms against training-time, backdoor poisoning attacks.\nThese attacks induce pre-determined, adversarial behavior in the agent upon\nobserving a fixed trigger during deployment while allowing the agent to solve\nits intended task during training. Prior attacks rely on arbitrarily large\nperturbations to the agent's rewards to achieve both of these objectives -\nleaving them open to detection. Thus, in this work, we propose a new class of\nbackdoor attacks against DRL which achieve state of the art performance while\nminimally altering the agent's rewards. These \"inception\" attacks train the\nagent to associate the targeted adversarial behavior with high returns by\ninducing a disjunction between the agent's chosen action and the true action\nexecuted in the environment during training. We formally define these attacks\nand prove they can achieve both adversarial objectives. We then devise an\nonline inception attack which significantly out-performs prior attacks under\nbounded reward constraints.\n","authors":["Ethan Rathbun","Christopher Amato","Alina Oprea"],"pdf_url":"https://arxiv.org/pdf/2410.13995v2.pdf","comment":"10 pages, 5 figures, ICLR 2025"},{"id":"http://arxiv.org/abs/2410.16161v1","updated":"2024-10-21T16:25:14Z","published":"2024-10-21T16:25:14Z","title":"DMM: Distributed Matrix Mechanism for Differentially-Private Federated\n  Learning using Packed Secret Sharing","summary":"  Federated Learning (FL) has gained lots of traction recently, both in\nindustry and academia. In FL, a machine learning model is trained using data\nfrom various end-users arranged in committees across several rounds. Since such\ndata can often be sensitive, a primary challenge in FL is providing privacy\nwhile still retaining utility of the model. Differential Privacy (DP) has\nbecome the main measure of privacy in the FL setting. DP comes in two flavors:\ncentral and local. In the former, a centralized server is trusted to receive\nthe users' raw gradients from a training step, and then perturb their\naggregation with some noise before releasing the next version of the model. In\nthe latter (more private) setting, noise is applied on users' local devices,\nand only the aggregation of users' noisy gradients is revealed even to the\nserver. Great strides have been made in increasing the privacy-utility\ntrade-off in the central DP setting, by utilizing the so-called matrix\nmechanism. However, progress has been mostly stalled in the local DP setting.\nIn this work, we introduce the distributed matrix mechanism to achieve the\nbest-of-both-worlds; local DP and also better privacy-utility trade-off from\nthe matrix mechanism. We accomplish this by proposing a cryptographic protocol\nthat securely transfers sensitive values across rounds, which makes use of\npacked secret sharing. This protocol accommodates the dynamic participation of\nusers per training round required by FL, including those that may drop out from\nthe computation. We provide experiments which show that our mechanism indeed\nsignificantly improves the privacy-utility trade-off of FL models compared to\nprevious local DP mechanisms, with little added overhead.\n","authors":["Alexander Bienstock","Ujjwal Kumar","Antigoni Polychroniadou"],"pdf_url":"https://arxiv.org/pdf/2410.16161v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16159v1","updated":"2024-10-21T16:22:19Z","published":"2024-10-21T16:22:19Z","title":"Metric as Transform: Exploring beyond Affine Transform for Interpretable\n  Neural Network","summary":"  Artificial Neural Networks of varying architectures are generally paired with\naffine transformation at the core. However, we find dot product neurons with\nglobal influence less interpretable as compared to local influence of euclidean\ndistance (as used in Radial Basis Function Network). In this work, we explore\nthe generalization of dot product neurons to $l^p$-norm, metrics, and beyond.\nWe find that metrics as transform performs similarly to affine transform when\nused in MultiLayer Perceptron or Convolutional Neural Network. Moreover, we\nexplore various properties of Metrics, compare it with Affine, and present\nmultiple cases where metrics seem to provide better interpretability. We\ndevelop an interpretable local dictionary based Neural Networks and use it to\nunderstand and reject adversarial examples.\n","authors":["Suman Sapkota"],"pdf_url":"https://arxiv.org/pdf/2410.16159v1.pdf","comment":"22 pages, 20 figures, 3 tables"},{"id":"http://arxiv.org/abs/2410.16154v1","updated":"2024-10-21T16:21:09Z","published":"2024-10-21T16:21:09Z","title":"Unsupervised Replay Strategies for Continual Learning with Limited Data","summary":"  Artificial neural networks (ANNs) show limited performance with scarce or\nimbalanced training data and face challenges with continuous learning, such as\nforgetting previously learned data after new tasks training. In contrast, the\nhuman brain can learn continuously and from just a few examples. This research\nexplores the impact of 'sleep', an unsupervised phase incorporating stochastic\nactivation with local Hebbian learning rules, on ANNs trained incrementally\nwith limited and imbalanced datasets, specifically MNIST and Fashion MNIST. We\ndiscovered that introducing a sleep phase significantly enhanced accuracy in\nmodels trained with limited data. When a few tasks were trained sequentially,\nsleep replay not only rescued previously learned information that had been\ncatastrophically forgetting following new task training but often enhanced\nperformance in prior tasks, especially those trained with limited data. This\nstudy highlights the multifaceted role of sleep replay in augmenting learning\nefficiency and facilitating continual learning in ANNs.\n","authors":["Anthony Bazhenov","Pahan Dewasurendra","Giri P. Krishnan","Jean Erik Delanois"],"pdf_url":"https://arxiv.org/pdf/2410.16154v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16152v1","updated":"2024-10-21T16:19:34Z","published":"2024-10-21T16:19:34Z","title":"Warped Diffusion: Solving Video Inverse Problems with Image Diffusion\n  Models","summary":"  Using image models naively for solving inverse video problems often suffers\nfrom flickering, texture-sticking, and temporal inconsistency in generated\nvideos. To tackle these problems, in this paper, we view frames as continuous\nfunctions in the 2D space, and videos as a sequence of continuous warping\ntransformations between different frames. This perspective allows us to train\nfunction space diffusion models only on images and utilize them to solve\ntemporally correlated inverse problems. The function space diffusion models\nneed to be equivariant with respect to the underlying spatial transformations.\nTo ensure temporal consistency, we introduce a simple post-hoc test-time\nguidance towards (self)-equivariant solutions. Our method allows us to deploy\nstate-of-the-art latent diffusion models such as Stable Diffusion XL to solve\nvideo inverse problems. We demonstrate the effectiveness of our method for\nvideo inpainting and $8\\times$ video super-resolution, outperforming existing\ntechniques based on noise transformations. We provide generated video results:\nhttps://giannisdaras.github.io/warped\\_diffusion.github.io/.\n","authors":["Giannis Daras","Weili Nie","Karsten Kreis","Alex Dimakis","Morteza Mardani","Nikola Borislavov Kovachki","Arash Vahdat"],"pdf_url":"https://arxiv.org/pdf/2410.16152v1.pdf","comment":"Accepted in NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.16151v1","updated":"2024-10-21T16:18:31Z","published":"2024-10-21T16:18:31Z","title":"Small Contributions, Small Networks: Efficient Neural Network Pruning\n  Based on Relative Importance","summary":"  Recent advancements have scaled neural networks to unprecedented sizes,\nachieving remarkable performance across a wide range of tasks. However,\ndeploying these large-scale models on resource-constrained devices poses\nsignificant challenges due to substantial storage and computational\nrequirements. Neural network pruning has emerged as an effective technique to\nmitigate these limitations by reducing model size and complexity. In this\npaper, we introduce an intuitive and interpretable pruning method based on\nactivation statistics, rooted in information theory and statistical analysis.\nOur approach leverages the statistical properties of neuron activations to\nidentify and remove weights with minimal contributions to neuron outputs.\nSpecifically, we build a distribution of weight contributions across the\ndataset and utilize its parameters to guide the pruning process. Furthermore,\nwe propose a Pruning-aware Training strategy that incorporates an additional\nregularization term to enhance the effectiveness of our pruning method.\nExtensive experiments on multiple datasets and network architectures\ndemonstrate that our method consistently outperforms several baseline and\nstate-of-the-art pruning techniques.\n","authors":["Mostafa Hussien","Mahmoud Afifi","Kim Khoa Nguyen","Mohamed Cheriet"],"pdf_url":"https://arxiv.org/pdf/2410.16151v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16150v1","updated":"2024-10-21T16:18:19Z","published":"2024-10-21T16:18:19Z","title":"Modelling Structured Data Learning with Restricted Boltzmann Machines in\n  the Teacher-Student Setting","summary":"  Restricted Boltzmann machines (RBM) are generative models capable to learn\ndata with a rich underlying structure. We study the teacher-student setting\nwhere a student RBM learns structured data generated by a teacher RBM. The\namount of structure in the data is controlled by adjusting the number of hidden\nunits of the teacher and the correlations in the rows of the weights, a.k.a.\npatterns. In the absence of correlations, we validate the conjecture that the\nperformance is independent of the number of teacher patters and hidden units of\nthe student RBMs, and we argue that the teacher-student setting can be used as\na toy model for studying the lottery ticket hypothesis. Beyond this regime, we\nfind that the critical amount of data required to learn the teacher patterns\ndecreases with both their number and correlations. In both regimes, we find\nthat, even with an relatively large dataset, it becomes impossible to learn the\nteacher patterns if the inference temperature used for regularization is kept\ntoo low. In our framework, the student can learn teacher patterns one-to-one or\nmany-to-one, generalizing previous findings about the teacher-student setting\nwith two hidden units to any arbitrary finite number of hidden units.\n","authors":["Robin Thériault","Francesco Tosello","Daniele Tantari"],"pdf_url":"https://arxiv.org/pdf/2410.16150v1.pdf","comment":"51 pages, 21 figures"},{"id":"http://arxiv.org/abs/2410.16146v1","updated":"2024-10-21T16:17:01Z","published":"2024-10-21T16:17:01Z","title":"Towards Combating Frequency Simplicity-biased Learning for Domain\n  Generalization","summary":"  Domain generalization methods aim to learn transferable knowledge from source\ndomains that can generalize well to unseen target domains. Recent studies show\nthat neural networks frequently suffer from a simplicity-biased learning\nbehavior which leads to over-reliance on specific frequency sets, namely as\nfrequency shortcuts, instead of semantic information, resulting in poor\ngeneralization performance. Despite previous data augmentation techniques\nsuccessfully enhancing generalization performances, they intend to apply more\nfrequency shortcuts, thereby causing hallucinations of generalization\nimprovement. In this paper, we aim to prevent such learning behavior of\napplying frequency shortcuts from a data-driven perspective. Given the\ntheoretical justification of models' biased learning behavior on different\nspatial frequency components, which is based on the dataset frequency\nproperties, we argue that the learning behavior on various frequency components\ncould be manipulated by changing the dataset statistical structure in the\nFourier domain. Intuitively, as frequency shortcuts are hidden in the dominant\nand highly dependent frequencies of dataset structure, dynamically perturbating\nthe over-reliance frequency components could prevent the application of\nfrequency shortcuts. To this end, we propose two effective data augmentation\nmodules designed to collaboratively and adaptively adjust the frequency\ncharacteristic of the dataset, aiming to dynamically influence the learning\nbehavior of the model and ultimately serving as a strategy to mitigate shortcut\nlearning. Code is available at AdvFrequency\n(https://github.com/C0notSilly/AdvFrequency).\n","authors":["Xilin He","Jingyu Hu","Qinliang Lin","Cheng Luo","Weicheng Xie","Siyang Song","Muhammad Haris Khan","Linlin Shen"],"pdf_url":"https://arxiv.org/pdf/2410.16146v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.16138v1","updated":"2024-10-21T16:04:50Z","published":"2024-10-21T16:04:50Z","title":"Theoretical Insights into Line Graph Transformation on Graph Learning","summary":"  Line graph transformation has been widely studied in graph theory, where each\nnode in a line graph corresponds to an edge in the original graph. This has\ninspired a series of graph neural networks (GNNs) applied to transformed line\ngraphs, which have proven effective in various graph representation learning\ntasks. However, there is limited theoretical study on how line graph\ntransformation affects the expressivity of GNN models. In this study, we focus\non two types of graphs known to be challenging to the Weisfeiler-Leman (WL)\ntests: Cai-F\\\"urer-Immerman (CFI) graphs and strongly regular graphs, and show\nthat applying line graph transformation helps exclude these challenging graph\nproperties, thus potentially assist WL tests in distinguishing these graphs. We\nempirically validate our findings by conducting a series of experiments that\ncompare the accuracy and efficiency of graph isomorphism tests and GNNs on both\nline-transformed and original graphs across these graph structure types.\n","authors":["Fan Yang","Xingyue Huang"],"pdf_url":"https://arxiv.org/pdf/2410.16138v1.pdf","comment":"21 pages, code available at\n  https://github.com/lukeyf/graphs-and-lines"},{"id":"http://arxiv.org/abs/2410.16135v1","updated":"2024-10-21T16:00:04Z","published":"2024-10-21T16:00:04Z","title":"Beyond 2:4: exploring V:N:M sparsity for efficient transformer inference\n  on GPUs","summary":"  To date, 2:4 sparsity has stood as the only sparse pattern that can be\naccelerated using sparse tensor cores on GPUs. In practice, 2:4 sparsity often\npossesses low actual speedups ($\\leq 1.3$) and requires fixed sparse ratios,\nmeaning that other ratios, such as 4:8, 8:16, or those exceeding 50% sparsity,\ndo not incur any speedups on GPUs. Recent studies suggest that V:N:M sparsity\nis promising in addressing these limitations of 2:4 sparsity. However,\nregarding accuracy, the effects of V:N:M sparsity on broader Transformer\nmodels, such as vision Transformers and large language models (LLMs), are\nlargely unexamined. Moreover, Some specific issues related to V:N:M sparsity,\nsuch as how to select appropriate V and M values, remain unresolved. In this\nstudy, we thoroughly investigate the application of V:N:M sparsity in vision\nmodels and LLMs across multiple tasks, from pertaining to downstream tasks. We\npropose three key approaches to enhance the applicability and accuracy of\nV:N:M-sparse Transformers, including heuristic V and M selection,\nV:N:M-specific channel permutation, and three-staged LoRA training techniques.\nExperimental results show that, with our methods, the DeiT-small achieves\nlossless accuracy at 64:2:5 sparsity, while the DeiT-base maintains accuracy\neven at 64:2:8 sparsity. In addition, the fine-tuned LLama2-7B at 64:2:5\nsparsity performs comparably or better than training-free 2:4 sparse\nalternatives on downstream tasks. More importantly, V:N:M-sparse Transformers\noffer a wider range of speedup-accuracy trade-offs compared to 2:4 sparsity.\nOverall, our exploration largely facilitates the V:N:M sparsity to act as a\ntruly effective acceleration solution for Transformers in cost-sensitive\ninference scenarios.\n","authors":["Kang Zhao","Tao Yuan","Han Bao","Zhenfeng Su","Chang Gao","Zhaofeng Sun","Zichen Liang","Liping Jing","Jianfei Chen"],"pdf_url":"https://arxiv.org/pdf/2410.16135v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.14134v2","updated":"2024-10-21T15:59:18Z","published":"2024-08-26T09:29:56Z","title":"Exploring the Potential of Large Language Models for Heterophilic Graphs","summary":"  Large language models (LLMs) have presented significant opportunities to\nenhance various machine learning applications, including graph neural networks\n(GNNs). By leveraging the vast open-world knowledge within LLMs, we can more\neffectively interpret and utilize textual data to better characterize\nheterophilic graphs, where neighboring nodes often have different labels.\nHowever, existing approaches for heterophilic graphs overlook the rich textual\ndata associated with nodes, which could unlock deeper insights into their\nheterophilic contexts. In this work, we explore the potential of LLMs for\nmodeling heterophilic graphs and propose a novel two-stage framework:\nLLM-enhanced edge discriminator and LLM-guided edge reweighting. In the first\nstage, we fine-tune the LLM to better identify homophilic and heterophilic\nedges based on the textual content of their nodes. In the second stage, we\nadaptively manage message propagation in GNNs for different edge types based on\nnode features, structures, and heterophilic or homophilic characteristics. To\ncope with the computational demands when deploying LLMs in practical scenarios,\nwe further explore model distillation techniques to fine-tune smaller, more\nefficient models that maintain competitive performance. Extensive experiments\nvalidate the effectiveness of our framework, demonstrating the feasibility of\nusing LLMs to enhance node classification on heterophilic graphs.\n","authors":["Yuxia Wu","Shujie Li","Yuan Fang","Chuan Shi"],"pdf_url":"https://arxiv.org/pdf/2408.14134v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2410.13502v2","updated":"2024-10-21T15:58:30Z","published":"2024-10-17T12:48:14Z","title":"MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily\n  Complex Proofs","summary":"  Large language models (LLMs) can solve arithmetic word problems with high\naccuracy, but little is known about how well they generalize to problems that\nare more complex than the ones on which they have been trained. Empirical\ninvestigations of such questions are impeded by two major flaws of current\nevaluations: (i) much of the evaluation data is contaminated, in the sense that\nit has already been seen during training, and (ii) benchmark datasets do not\ncapture how problem proofs may be arbitrarily complex in various ways. As a\nstep towards addressing these issues, we present a framework for evaluating\nLLMs on problems with arbitrarily complex arithmetic proofs, called MathGAP.\nMathGAP generates problems that follow fixed proof specifications -- along with\nchain-of-thought reasoning annotations -- enabling systematic studies on\ngeneralization with respect to arithmetic proof complexity. We apply MathGAP to\nanalyze how in-context learning interacts with generalization to problems that\nhave more complex proofs. We find that among the models tested, most show a\nsignificant decrease in performance as proofs get deeper and wider. This effect\nis more pronounced in complex, nonlinear proof structures, which are\nchallenging even for GPT-4o. Surprisingly, providing in-context examples from\nthe same distribution as the test set is not always beneficial for performance.\nIn particular, zero-shot prompting as well as demonstrating a diverse range of\nexamples that are less complex than the test data sometimes yield similar or\nhigher accuracies.\n","authors":["Andreas Opedal","Haruki Shirakami","Bernhard Schölkopf","Abulhair Saparov","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2410.13502v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2407.00299v4","updated":"2024-10-21T15:56:23Z","published":"2024-06-29T03:37:29Z","title":"Human-Agent Joint Learning for Efficient Robot Manipulation Skill\n  Acquisition","summary":"  Employing a teleoperation system for gathering demonstrations offers the\npotential for more efficient learning of robot manipulation. However,\nteleoperating a robot arm equipped with a dexterous hand or gripper, via a\nteleoperation system presents inherent challenges due to the task's high\ndimensionality, complexity of motion, and differences between physiological\nstructures. In this study, we introduce a novel system for joint learning\nbetween human operators and robots, that enables human operators to share\ncontrol of a robot end-effector with a learned assistive agent, simplifies the\ndata collection process, and facilitates simultaneous human demonstration\ncollection and robot manipulation training. As data accumulates, the assistive\nagent gradually learns. Consequently, less human effort and attention are\nrequired, enhancing the efficiency of the data collection process. It also\nallows the human operator to adjust the control ratio to achieve a trade-off\nbetween manual and automated control. We conducted experiments in both\nsimulated environments and physical real-world settings. Through user studies\nand quantitative evaluations, it is evident that the proposed system could\nenhance data collection efficiency and reduce the need for human adaptation\nwhile ensuring the collected data is of sufficient quality for downstream\ntasks. \\textit{For more details, please refer to our webpage\nhttps://norweig1an.github.io/HAJL.github.io/.\n","authors":["Shengcheng Luo","Quanquan Peng","Jun Lv","Kaiwen Hong","Katherine Rose Driggs-Campbell","Cewu Lu","Yong-Lu Li"],"pdf_url":"https://arxiv.org/pdf/2407.00299v4.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.16128v1","updated":"2024-10-21T15:55:04Z","published":"2024-10-21T15:55:04Z","title":"SMART: Self-learning Meta-strategy Agent for Reasoning Tasks","summary":"  Tasks requiring deductive reasoning, especially those involving multiple\nsteps, often demand adaptive strategies such as intermediate generation of\nrationales or programs, as no single approach is universally optimal. While\nLanguage Models (LMs) can enhance their outputs through iterative\nself-refinement and strategy adjustments, they frequently fail to apply the\nmost effective strategy in their first attempt. This inefficiency raises the\nquestion: Can LMs learn to select the optimal strategy in the first attempt,\nwithout a need for refinement? To address this challenge, we introduce SMART\n(Self-learning Meta-strategy Agent for Reasoning Tasks), a novel framework that\nenables LMs to autonomously learn and select the most effective strategies for\nvarious reasoning tasks. We model the strategy selection process as a Markov\nDecision Process and leverage reinforcement learning-driven continuous\nself-improvement to allow the model to find the suitable strategy to solve a\ngiven task. Unlike traditional self-refinement methods that rely on multiple\ninference passes or external feedback, SMART allows an LM to internalize the\noutcomes of its own reasoning processes and adjust its strategy accordingly,\naiming for correct solutions on the first attempt. Our experiments across\nvarious reasoning datasets and with different model architectures demonstrate\nthat SMART significantly enhances the ability of models to choose optimal\nstrategies without external guidance (+15 points on the GSM8K dataset). By\nachieving higher accuracy with a single inference pass, SMART not only improves\nperformance but also reduces computational costs for refinement-based\nstrategies, paving the way for more efficient and intelligent reasoning in LMs.\n","authors":["Rongxing Liu","Kumar Shridhar","Manish Prajapat","Patrick Xia","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2410.16128v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16124v1","updated":"2024-10-21T15:51:30Z","published":"2024-10-21T15:51:30Z","title":"MNIST-Nd: a set of naturalistic datasets to benchmark clustering across\n  dimensions","summary":"  Driven by advances in recording technology, large-scale high-dimensional\ndatasets have emerged across many scientific disciplines. Especially in\nbiology, clustering is often used to gain insights into the structure of such\ndatasets, for instance to understand the organization of different cell types.\nHowever, clustering is known to scale poorly to high dimensions, even though\nthe exact impact of dimensionality is unclear as current benchmark datasets are\nmostly two-dimensional. Here we propose MNIST-Nd, a set of synthetic datasets\nthat share a key property of real-world datasets, namely that individual\nsamples are noisy and clusters do not perfectly separate. MNIST-Nd is obtained\nby training mixture variational autoencoders with 2 to 64 latent dimensions on\nMNIST, resulting in six datasets with comparable structure but varying\ndimensionality. It thus offers the chance to disentangle the impact of\ndimensionality on clustering. Preliminary common clustering algorithm\nbenchmarks on MNIST-Nd suggest that Leiden is the most robust for growing\ndimensions.\n","authors":["Polina Turishcheva","Laura Hansel","Martin Ritzert","Marissa A. Weis","Alexander S. Ecker"],"pdf_url":"https://arxiv.org/pdf/2410.16124v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16122v1","updated":"2024-10-21T15:50:04Z","published":"2024-10-21T15:50:04Z","title":"Integer linear programming for unsupervised training set selection in\n  molecular machine learning","summary":"  Integer linear programming (ILP) is an elegant approach to solve linear\noptimization problems, naturally described using integer decision variables.\nWithin the context of physics-inspired machine learning applied to chemistry,\nwe demonstrate the relevance of an ILP formulation to select molecular training\nsets for predictions of size-extensive properties. We show that our algorithm\noutperforms existing unsupervised training set selection approaches, especially\nwhen predicting properties of molecules larger than those present in the\ntraining set. We argue that the reason for the improved performance is due to\nthe selection that is based on the notion of local similarity (i.e., per-atom)\nand a unique ILP approach that finds optimal solutions efficiently. Altogether,\nthis work provides a practical algorithm to improve the performance of\nphysics-inspired machine learning models and offers insights into the\nconceptual differences with existing training set selection approaches.\n","authors":["Matthieu Haeberle","Puck van Gerwen","Ruben Laplaza","Ksenia R. Briling","Jan Weinreich","Friedrich Eisenbrand","Clemence Corminboeuf"],"pdf_url":"https://arxiv.org/pdf/2410.16122v1.pdf","comment":"31 pages + SI (15 pages)"},{"id":"http://arxiv.org/abs/2410.16121v1","updated":"2024-10-21T15:48:34Z","published":"2024-10-21T15:48:34Z","title":"Extracting Spatiotemporal Data from Gradients with Large Language Models","summary":"  Recent works show that sensitive user data can be reconstructed from gradient\nupdates, breaking the key privacy promise of federated learning. While success\nwas demonstrated primarily on image data, these methods do not directly\ntransfer to other domains, such as spatiotemporal data. To understand privacy\nrisks in spatiotemporal federated learning, we first propose Spatiotemporal\nGradient Inversion Attack (ST-GIA), a gradient attack algorithm tailored to\nspatiotemporal data that successfully reconstructs the original location from\ngradients. Furthermore, the absence of priors in attacks on spatiotemporal data\nhas hindered the accurate reconstruction of real client data. To address this\nlimitation, we propose ST-GIA+, which utilizes an auxiliary language model to\nguide the search for potential locations, thereby successfully reconstructing\nthe original data from gradients. In addition, we design an adaptive defense\nstrategy to mitigate gradient inversion attacks in spatiotemporal federated\nlearning. By dynamically adjusting the perturbation levels, we can offer\ntailored protection for varying rounds of training data, thereby achieving a\nbetter trade-off between privacy and utility than current state-of-the-art\nmethods. Through intensive experimental analysis on three real-world datasets,\nwe reveal that the proposed defense strategy can well preserve the utility of\nspatiotemporal federated learning with effective security protection.\n","authors":["Lele Zheng","Yang Cao","Renhe Jiang","Kenjiro Taura","Yulong Shen","Sheng Li","Masatoshi Yoshikawa"],"pdf_url":"https://arxiv.org/pdf/2410.16121v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2407.08529"},{"id":"http://arxiv.org/abs/2410.16119v1","updated":"2024-10-21T15:47:03Z","published":"2024-10-21T15:47:03Z","title":"SeaDAG: Semi-autoregressive Diffusion for Conditional Directed Acyclic\n  Graph Generation","summary":"  We introduce SeaDAG, a semi-autoregressive diffusion model for conditional\ngeneration of Directed Acyclic Graphs (DAGs). Considering their inherent\nlayer-wise structure, we simulate layer-wise autoregressive generation by\ndesigning different denoising speed for different layers. Unlike conventional\nautoregressive generation that lacks a global graph structure view, our method\nmaintains a complete graph structure at each diffusion step, enabling\noperations such as property control that require the full graph structure.\nLeveraging this capability, we evaluate the DAG properties during training by\nemploying a graph property decoder. We explicitly train the model to learn\ngraph conditioning with a condition loss, which enhances the diffusion model's\ncapacity to generate graphs that are both realistic and aligned with specified\nproperties. We evaluate our method on two representative conditional DAG\ngeneration tasks: (1) circuit generation from truth tables, where precise DAG\nstructures are crucial for realizing circuit functionality, and (2) molecule\ngeneration based on quantum properties. Our approach demonstrates promising\nresults, generating high-quality and realistic DAGs that closely align with\ngiven conditions.\n","authors":["Xinyi Zhou","Xing Li","Yingzhao Lian","Yiwen Wang","Lei Chen","Mingxuan Yuan","Jianye Hao","Guangyong Chen","Pheng Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2410.16119v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.02176v3","updated":"2024-10-21T15:37:16Z","published":"2024-06-04T10:12:09Z","title":"AROMA: Preserving Spatial Structure for Latent PDE Modeling with Local\n  Neural Fields","summary":"  We present AROMA (Attentive Reduced Order Model with Attention), a framework\ndesigned to enhance the modeling of partial differential equations (PDEs) using\nlocal neural fields. Our flexible encoder-decoder architecture can obtain\nsmooth latent representations of spatial physical fields from a variety of data\ntypes, including irregular-grid inputs and point clouds. This versatility\neliminates the need for patching and allows efficient processing of diverse\ngeometries. The sequential nature of our latent representation can be\ninterpreted spatially and permits the use of a conditional transformer for\nmodeling the temporal dynamics of PDEs. By employing a diffusion-based\nformulation, we achieve greater stability and enable longer rollouts compared\nto conventional MSE training. AROMA's superior performance in simulating 1D and\n2D equations underscores the efficacy of our approach in capturing complex\ndynamical behaviors.\n","authors":["Louis Serrano","Thomas X Wang","Etienne Le Naour","Jean-Noël Vittaut","Patrick Gallinari"],"pdf_url":"https://arxiv.org/pdf/2406.02176v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16106v1","updated":"2024-10-21T15:34:44Z","published":"2024-10-21T15:34:44Z","title":"Statistical Inference for Temporal Difference Learning with Linear\n  Function Approximation","summary":"  Statistical inference with finite-sample validity for the value function of a\ngiven policy in Markov decision processes (MDPs) is crucial for ensuring the\nreliability of reinforcement learning. Temporal Difference (TD) learning,\narguably the most widely used algorithm for policy evaluation, serves as a\nnatural framework for this purpose.In this paper, we study the consistency\nproperties of TD learning with Polyak-Ruppert averaging and linear function\napproximation, and obtain three significant improvements over existing results.\nFirst, we derive a novel sharp high-dimensional probability convergence\nguarantee that depends explicitly on the asymptotic variance and holds under\nweak conditions. We further establish refined high-dimensional Berry-Esseen\nbounds over the class of convex sets that guarantee faster rates than those in\nthe literature. Finally, we propose a plug-in estimator for the asymptotic\ncovariance matrix, designed for efficient online computation. These results\nenable the construction of confidence regions and simultaneous confidence\nintervals for the linear parameters of the value function, with guaranteed\nfinite-sample coverage. We demonstrate the applicability of our theoretical\nfindings through numerical experiments.\n","authors":["Weichen Wu","Gen Li","Yuting Wei","Alessandro Rinaldo"],"pdf_url":"https://arxiv.org/pdf/2410.16106v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16105v1","updated":"2024-10-21T15:34:33Z","published":"2024-10-21T15:34:33Z","title":"Addressing Spectral Bias of Deep Neural Networks by Multi-Grade Deep\n  Learning","summary":"  Deep neural networks (DNNs) suffer from the spectral bias, wherein DNNs\ntypically exhibit a tendency to prioritize the learning of lower-frequency\ncomponents of a function, struggling to capture its high-frequency features.\nThis paper is to address this issue. Notice that a function having only low\nfrequency components may be well-represented by a shallow neural network (SNN),\na network having only a few layers. By observing that composition of low\nfrequency functions can effectively approximate a high-frequency function, we\npropose to learn a function containing high-frequency components by composing\nseveral SNNs, each of which learns certain low-frequency information from the\ngiven data. We implement the proposed idea by exploiting the multi-grade deep\nlearning (MGDL) model, a recently introduced model that trains a DNN\nincrementally, grade by grade, a current grade learning from the residue of the\nprevious grade only an SNN composed with the SNNs trained in the preceding\ngrades as features. We apply MGDL to synthetic, manifold, colored images, and\nMNIST datasets, all characterized by presence of high-frequency features. Our\nstudy reveals that MGDL excels at representing functions containing\nhigh-frequency information. Specifically, the neural networks learned in each\ngrade adeptly capture some low-frequency information, allowing their\ncompositions with SNNs learned in the previous grades effectively representing\nthe high-frequency features. Our experimental results underscore the efficacy\nof MGDL in addressing the spectral bias inherent in DNNs. By leveraging MGDL,\nwe offer insights into overcoming spectral bias limitation of DNNs, thereby\nenhancing the performance and applicability of deep learning models in tasks\nrequiring the representation of high-frequency information. This study confirms\nthat the proposed method offers a promising solution to address the spectral\nbias of DNNs.\n","authors":["Ronglong Fang","Yuesheng Xu"],"pdf_url":"https://arxiv.org/pdf/2410.16105v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16103v1","updated":"2024-10-21T15:31:06Z","published":"2024-10-21T15:31:06Z","title":"LDAdam: Adaptive Optimization from Low-Dimensional Gradient Statistics","summary":"  We introduce LDAdam, a memory-efficient optimizer for training large models,\nthat performs adaptive optimization steps within lower dimensional subspaces,\nwhile consistently exploring the full parameter space during training. This\nstrategy keeps the optimizer's memory footprint to a fraction of the model\nsize. LDAdam relies on a new projection-aware update rule for the optimizer\nstates that allows for transitioning between subspaces, i.e., estimation of the\nstatistics of the projected gradients. To mitigate the errors due to low-rank\nprojection, LDAdam integrates a new generalized error feedback mechanism, which\nexplicitly accounts for both gradient and optimizer state compression. We prove\nthe convergence of LDAdam under standard assumptions, and show that LDAdam\nallows for accurate and efficient fine-tuning and pre-training of language\nmodels.\n","authors":["Thomas Robert","Mher Safaryan","Ionut-Vlad Modoranu","Dan Alistarh"],"pdf_url":"https://arxiv.org/pdf/2410.16103v1.pdf","comment":"36 pages"},{"id":"http://arxiv.org/abs/2410.16100v1","updated":"2024-10-21T15:27:18Z","published":"2024-10-21T15:27:18Z","title":"ExDBN: Exact learning of Dynamic Bayesian Networks","summary":"  Causal learning from data has received much attention in recent years. One\nway of capturing causal relationships is by utilizing Bayesian networks. There,\none recovers a weighted directed acyclic graph, in which random variables are\nrepresented by vertices, and the weights associated with each edge represent\nthe strengths of the causal relationships between them. This concept is\nextended to capture dynamic effects by introducing a dependency on past data,\nwhich may be captured by the structural equation model, which is utilized in\nthe present contribution to formulate a score-based learning approach. A\nmixed-integer quadratic program is formulated and an algorithmic solution\nproposed, in which the pre-generation of exponentially many acyclicity\nconstraints is avoided by utilizing the so-called branch-and-cut (\"lazy\nconstraint\") method. Comparing the novel approach to the state of the art, we\nshow that the proposed approach turns out to produce excellent results when\napplied to small and medium-sized synthetic instances of up to 25 time-series.\nLastly, two interesting applications in bio-science and finance, to which the\nmethod is directly applied, further stress the opportunities in developing\nhighly accurate, globally convergent solvers that can handle modest instances.\n","authors":["Pavel Rytíř","Aleš Wodecki","Georgios Korpas","Jakub Mareček"],"pdf_url":"https://arxiv.org/pdf/2410.16100v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2402.06955v3","updated":"2024-10-21T15:26:26Z","published":"2024-02-10T13:51:09Z","title":"Feature Mapping in Physics-Informed Neural Networks (PINNs)","summary":"  In this paper, the training dynamics of PINNs with a feature mapping layer\nvia the limiting Conjugate Kernel and Neural Tangent Kernel is investigated,\nshedding light on the convergence of PINNs; Although the commonly used\nFourier-based feature mapping has achieved great success, we show its\ninadequacy in some physics scenarios. Via these two scopes, we propose\nconditionally positive definite Radial Basis Function as a better alternative.\nLastly, we explore the feature mapping numerically in wide neural networks. Our\nempirical results reveal the efficacy of our method in diverse forward and\ninverse problem sets. Composing feature functions is found to be a practical\nway to address the expressivity and generalisability trade-off, viz., tuning\nthe bandwidth of the kernels and the surjectivity of the feature mapping\nfunction. This simple technique can be implemented for coordinate inputs and\nbenefits the broader PINNs research.\n","authors":["Chengxi Zeng","Tilo Burghardt","Alberto M Gambaruto"],"pdf_url":"https://arxiv.org/pdf/2402.06955v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.08160v3","updated":"2024-10-21T15:22:58Z","published":"2024-09-12T15:52:22Z","title":"On the Role of Context in Reading Time Prediction","summary":"  We present a new perspective on how readers integrate context during\nreal-time language comprehension. Our proposals build on surprisal theory,\nwhich posits that the processing effort of a linguistic unit (e.g., a word) is\nan affine function of its in-context information content. We first observe that\nsurprisal is only one out of many potential ways that a contextual predictor\ncan be derived from a language model. Another one is the pointwise mutual\ninformation (PMI) between a unit and its context, which turns out to yield the\nsame predictive power as surprisal when controlling for unigram frequency.\nMoreover, both PMI and surprisal are correlated with frequency. This means that\nneither PMI nor surprisal contains information about context alone. In response\nto this, we propose a technique where we project surprisal onto the orthogonal\ncomplement of frequency, yielding a new contextual predictor that is\nuncorrelated with frequency. Our experiments show that the proportion of\nvariance in reading times explained by context is a lot smaller when context is\nrepresented by the orthogonalized predictor. From an interpretability\nstandpoint, this indicates that previous studies may have overstated the role\nthat context has in predicting reading times.\n","authors":["Andreas Opedal","Eleanor Chodroff","Ryan Cotterell","Ethan Gotlieb Wilcox"],"pdf_url":"https://arxiv.org/pdf/2409.08160v3.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.13203v2","updated":"2024-10-21T15:21:56Z","published":"2024-10-17T04:10:36Z","title":"TabSeq: A Framework for Deep Learning on Tabular Data via Sequential\n  Ordering","summary":"  Effective analysis of tabular data still poses a significant problem in deep\nlearning, mainly because features in tabular datasets are often heterogeneous\nand have different levels of relevance. This work introduces TabSeq, a novel\nframework for the sequential ordering of features, addressing the vital\nnecessity to optimize the learning process. Features are not always equally\ninformative, and for certain deep learning models, their random arrangement can\nhinder the model's learning capacity. Finding the optimum sequence order for\nsuch features could improve the deep learning models' learning process. The\nnovel feature ordering technique we provide in this work is based on clustering\nand incorporates both local ordering and global ordering. It is designed to be\nused with a multi-head attention mechanism in a denoising autoencoder network.\nOur framework uses clustering to align comparable features and improve data\norganization. Multi-head attention focuses on essential characteristics,\nwhereas the denoising autoencoder highlights important aspects by rebuilding\nfrom distorted inputs. This method improves the capability to learn from\ntabular data while lowering redundancy. Our research, demonstrating improved\nperformance through appropriate feature sequence rearrangement using raw\nantibody microarray and two other real-world biomedical datasets, validates the\nimpact of feature ordering. These results demonstrate that feature ordering can\nbe a viable approach to improved deep learning of tabular data.\n","authors":["Al Zadid Sultan Bin Habib","Kesheng Wang","Mary-Anne Hartley","Gianfranco Doretto","Donald A. Adjeroh"],"pdf_url":"https://arxiv.org/pdf/2410.13203v2.pdf","comment":"This paper has been accepted for presentation at the 27th\n  International Conference on Pattern Recognition (ICPR 2024) in Kolkata, India"},{"id":"http://arxiv.org/abs/2408.08381v4","updated":"2024-10-21T15:18:39Z","published":"2024-08-15T18:54:31Z","title":"Pre-processing and Compression: Understanding Hidden Representation\n  Refinement Across Imaging Domains via Intrinsic Dimension","summary":"  In recent years, there has been interest in how geometric properties such as\nintrinsic dimension (ID) of a neural network's hidden representations change\nthrough its layers, and how such properties are predictive of important model\nbehavior such as generalization ability. However, evidence has begun to emerge\nthat such behavior can change significantly depending on the domain of the\nnetwork's training data, such as natural versus medical images. Here, we\nfurther this inquiry by exploring how the ID of a network's learned\nrepresentations changes through its layers, in essence, characterizing how the\nnetwork successively refines the information content of input data to be used\nfor predictions. Analyzing eleven natural and medical image datasets across six\nnetwork architectures, we find that how ID changes through the network differs\nnoticeably between natural and medical image models. Specifically, medical\nimage models peak in representation ID earlier in the network, implying a\ndifference in the image features and their abstractness that are typically used\nfor downstream tasks in these domains. Additionally, we discover a strong\ncorrelation of this peak representation ID with the ID of the data in its input\nspace, implying that the intrinsic information content of a model's learned\nrepresentations is guided by that of the data it was trained on. Overall, our\nfindings emphasize notable discrepancies in network behavior between natural\nand non-natural imaging domains regarding hidden representation information\ncontent, and provide further insights into how a network's learned features are\nshaped by its training data.\n","authors":["Nicholas Konz","Maciej A. Mazurowski"],"pdf_url":"https://arxiv.org/pdf/2408.08381v4.pdf","comment":"Published in NeurIPS 2024 Workshop on Scientific Methods for\n  Understanding Deep Learning (SciForDL)"},{"id":"http://arxiv.org/abs/2406.15819v2","updated":"2024-10-21T15:07:13Z","published":"2024-06-22T11:17:50Z","title":"Automatic AI Model Selection for Wireless Systems: Online Learning via\n  Digital Twinning","summary":"  In modern wireless network architectures, such as O-RAN, artificial\nintelligence (AI)-based applications are deployed at intelligent controllers to\ncarry out functionalities like scheduling or power control. The AI \"apps\" are\nselected on the basis of contextual information such as network conditions,\ntopology, traffic statistics, and design goals. The mapping between context and\nAI model parameters is ideally done in a zero-shot fashion via an automatic\nmodel selection (AMS) mapping that leverages only contextual information\nwithout requiring any current data. This paper introduces a general methodology\nfor the online optimization of AMS mappings. Optimizing an AMS mapping is\nchallenging, as it requires exposure to data collected from many different\ncontexts. Therefore, if carried out online, this initial optimization phase\nwould be extremely time consuming. A possible solution is to leverage a digital\ntwin of the physical system to generate synthetic data from multiple simulated\ncontexts. However, given that the simulator at the digital twin is imperfect, a\ndirect use of simulated data for the optimization of the AMS mapping would\nyield poor performance when tested in the real system. This paper proposes a\nnovel method for the online optimization of AMS mapping that corrects for the\nbias of the simulator by means of limited real data collected from the physical\nsystem. Experimental results for a graph neural network-based power control app\ndemonstrate the significant advantages of the proposed approach.\n","authors":["Qiushuo Hou","Matteo Zecchin","Sangwoo Park","Yunlong Cai","Guanding Yu","Kaushik Chowdhury","Osvaldo Simeone"],"pdf_url":"https://arxiv.org/pdf/2406.15819v2.pdf","comment":"submitted for a journal publication"},{"id":"http://arxiv.org/abs/2410.16077v1","updated":"2024-10-21T14:55:59Z","published":"2024-10-21T14:55:59Z","title":"CartesianMoE: Boosting Knowledge Sharing among Experts via Cartesian\n  Product Routing in Mixture-of-Experts","summary":"  Large language models (LLM) have been attracting much attention from the\ncommunity recently, due to their remarkable performance in all kinds of\ndownstream tasks. According to the well-known scaling law, scaling up a dense\nLLM enhances its capabilities, but also significantly increases the\ncomputational complexity. Mixture-of-Experts (MoE) models address that by\nallowing the model size to grow without substantially raising training or\ninference costs. Yet MoE models face challenges regarding knowledge sharing\namong experts, making their performance somehow sensitive to routing accuracy.\nTo tackle that, previous works introduced shared experts and combined their\noutputs with those of the top $K$ routed experts in an ``addition'' manner. In\nthis paper, inspired by collective matrix factorization to learn shared\nknowledge among data, we propose CartesianMoE, which implements more effective\nknowledge sharing among experts in more like a ``multiplication'' manner.\nExtensive experimental results indicate that CartesianMoE outperforms previous\nMoE models for building LLMs, in terms of both perplexity and downstream task\nperformance. And we also find that CartesianMoE achieves better expert routing\nrobustness.\n","authors":["Zhenpeng Su","Xing Wu","Zijia Lin","Yizhe Xiong","Minxuan Lv","Guangyuan Ma","Hui Chen","Songlin Hu","Guiguang Ding"],"pdf_url":"https://arxiv.org/pdf/2410.16077v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16073v1","updated":"2024-10-21T14:53:12Z","published":"2024-10-21T14:53:12Z","title":"On the Geometry of Regularization in Adversarial Training:\n  High-Dimensional Asymptotics and Generalization Bounds","summary":"  Regularization, whether explicit in terms of a penalty in the loss or\nimplicit in the choice of algorithm, is a cornerstone of modern machine\nlearning. Indeed, controlling the complexity of the model class is particularly\nimportant when data is scarce, noisy or contaminated, as it translates a\nstatistical belief on the underlying structure of the data. This work\ninvestigates the question of how to choose the regularization norm $\\lVert\n\\cdot \\rVert$ in the context of high-dimensional adversarial training for\nbinary classification. To this end, we first derive an exact asymptotic\ndescription of the robust, regularized empirical risk minimizer for various\ntypes of adversarial attacks and regularization norms (including non-$\\ell_p$\nnorms). We complement this analysis with a uniform convergence analysis,\nderiving bounds on the Rademacher Complexity for this class of problems.\nLeveraging our theoretical results, we quantitatively characterize the\nrelationship between perturbation size and the optimal choice of $\\lVert \\cdot\n\\rVert$, confirming the intuition that, in the data scarce regime, the type of\nregularization becomes increasingly important for adversarial training as\nperturbations grow in size.\n","authors":["Matteo Vilucchio","Nikolaos Tsilivis","Bruno Loureiro","Julia Kempe"],"pdf_url":"https://arxiv.org/pdf/2410.16073v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07012v2","updated":"2024-10-21T14:53:11Z","published":"2024-03-09T10:01:49Z","title":"A PID-Controlled Non-Negative Tensor Factorization Model for Analyzing\n  Missing Data in NILM","summary":"  With the growing demand for energy and increased environmental awareness,\nNon-Intrusive Load Monitoring (NILM) has become an essential tool in smart grid\nand energy management. By analyzing total power load data, NILM infers the\nenergy usage of individual appliances without the need for separate sensors,\nenabling real-time monitoring from a few locations. This approach helps users\nunderstand consumption patterns, enhance energy efficiency, and detect\nanomalies for effective energy management. However, NILM datasets often suffer\nfrom issues such as sensor failures and data loss, compromising data integrity,\nthereby impacting subsequent analysis and applications. Traditional imputation\nmethods, such as linear interpolation and matrix factorization, struggle with\nnonlinear relationships and are sensitive to sparse data, resulting in\ninformation loss. To address these challenges, this paper proposes a\nProportional-Integral-Derivative (PID) Controlled Non-Negative Latent\nFactorization of Tensor (PNLF) model, which dynamically adjusts parameter\ngradients to improve convergence, stability, and accuracy. Experimental results\nshow that the PNLF model significantly outperforms state-of-the-art tensor\ncompletion models in both accuracy and efficiency. By addressing data loss\nissues, this study enhances load disaggregation precision and optimizes energy\nmanagement, providing reliable data support for smart grid applications and\npolicy formulation.\n","authors":["DengYu Shi"],"pdf_url":"https://arxiv.org/pdf/2403.07012v2.pdf","comment":"13papegs 8figures"},{"id":"http://arxiv.org/abs/2410.09940v2","updated":"2024-10-21T14:36:35Z","published":"2024-10-13T17:51:21Z","title":"Generalized Group Data Attribution","summary":"  Data Attribution (DA) methods quantify the influence of individual training\ndata points on model outputs and have broad applications such as\nexplainability, data selection, and noisy label identification. However,\nexisting DA methods are often computationally intensive, limiting their\napplicability to large-scale machine learning models. To address this\nchallenge, we introduce the Generalized Group Data Attribution (GGDA)\nframework, which computationally simplifies DA by attributing to groups of\ntraining points instead of individual ones. GGDA is a general framework that\nsubsumes existing attribution methods and can be applied to new DA techniques\nas they emerge. It allows users to optimize the trade-off between efficiency\nand fidelity based on their needs. Our empirical results demonstrate that GGDA\napplied to popular DA methods such as Influence Functions, TracIn, and TRAK\nresults in upto 10x-50x speedups over standard DA methods while gracefully\ntrading off attribution fidelity. For downstream applications such as dataset\npruning and noisy label identification, we demonstrate that GGDA significantly\nimproves computational efficiency and maintains effectiveness, enabling\npractical applications in large-scale machine learning scenarios that were\npreviously infeasible.\n","authors":["Dan Ley","Suraj Srinivas","Shichang Zhang","Gili Rusak","Himabindu Lakkaraju"],"pdf_url":"https://arxiv.org/pdf/2410.09940v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.16705v4","updated":"2024-10-21T14:33:15Z","published":"2023-10-25T15:20:53Z","title":"Wasserstein Gradient Flow over Variational Parameter Space for\n  Variational Inference","summary":"  Variational inference (VI) can be cast as an optimization problem in which\nthe variational parameters are tuned to closely align a variational\ndistribution with the true posterior. The optimization task can be approached\nthrough vanilla gradient descent in black-box VI or natural-gradient descent in\nnatural-gradient VI. In this work, we reframe VI as the optimization of an\nobjective that concerns probability distributions defined over a\n\\textit{variational parameter space}. Subsequently, we propose Wasserstein\ngradient descent for tackling this optimization problem. Notably, the\noptimization techniques, namely black-box VI and natural-gradient VI, can be\nreinterpreted as specific instances of the proposed Wasserstein gradient\ndescent. To enhance the efficiency of optimization, we develop practical\nmethods for numerically solving the discrete gradient flows. We validate the\neffectiveness of the proposed methods through empirical experiments on a\nsynthetic dataset, supplemented by theoretical analyses.\n","authors":["Dai Hai Nguyen","Tetsuya Sakurai","Hiroshi Mamitsuka"],"pdf_url":"https://arxiv.org/pdf/2310.16705v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16052v1","updated":"2024-10-21T14:28:26Z","published":"2024-10-21T14:28:26Z","title":"Near-Optimal Algorithm for Non-Stationary Kernelized Bandits","summary":"  This paper studies a non-stationary kernelized bandit (KB) problem, also\ncalled time-varying Bayesian optimization, where one seeks to minimize the\nregret under an unknown reward function that varies over time. In particular,\nwe focus on a near-optimal algorithm whose regret upper bound matches the\nregret lower bound. For this goal, we show the first algorithm-independent\nregret lower bound for non-stationary KB with squared exponential and Mat\\'ern\nkernels, which reveals that an existing optimization-based KB algorithm with\nslight modification is near-optimal. However, this existing algorithm suffers\nfrom feasibility issues due to its huge computational cost. Therefore, we\npropose a novel near-optimal algorithm called restarting phased elimination\nwith random permutation (R-PERP), which bypasses the huge computational cost. A\ntechnical key point is the simple permutation procedures of query candidates,\nwhich enable us to derive a novel tighter confidence bound tailored to the\nnon-stationary problems.\n","authors":["Shogo Iwazaki","Shion Takeno"],"pdf_url":"https://arxiv.org/pdf/2410.16052v1.pdf","comment":"24 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.06446v2","updated":"2024-10-21T14:28:18Z","published":"2024-10-09T01:12:07Z","title":"Machine Unlearning in Forgettability Sequence","summary":"  Machine unlearning (MU) is becoming a promising paradigm to achieve the\n\"right to be forgotten\", where the training trace of any chosen data points\ncould be eliminated, while maintaining the model utility on general testing\nsamples after unlearning. With the advancement of forgetting research, many\nfundamental open questions remain unanswered: do different samples exhibit\nvarying levels of difficulty in being forgotten? Further, does the sequence in\nwhich samples are forgotten, determined by their respective difficulty levels,\ninfluence the performance of forgetting algorithms? In this paper, we identify\nkey factor affecting unlearning difficulty and the performance of unlearning\nalgorithms. We find that samples with higher privacy risks are more likely to\nbe unlearning, indicating that the unlearning difficulty varies among different\nsamples which motives a more precise unlearning mode. Built upon this insight,\nwe propose a general unlearning framework, dubbed RSU, which consists of\nRanking module and SeqUnlearn module.\n","authors":["Junjie Chen","Qian Chen","Jian Lou","Xiaoyu Zhang","Kai Wu","Zilong Wang"],"pdf_url":"https://arxiv.org/pdf/2410.06446v2.pdf","comment":"The senior authors of the draft are not fully convinced that the\n  novelty is significant enough for this submission compared to the latest\n  research progress in this area. Additionally, the senior authors have\n  identified writing issues. Based on these two reasons, we have decided to\n  withdraw the draft from arXiv"},{"id":"http://arxiv.org/abs/2410.16041v1","updated":"2024-10-21T14:14:29Z","published":"2024-10-21T14:14:29Z","title":"GFlowNets for Hamiltonian decomposition in groups of compatible\n  operators","summary":"  Quantum computing presents a promising alternative for the direct simulation\nof quantum systems with the potential to explore chemical problems beyond the\ncapabilities of classical methods. However, current quantum algorithms are\nconstrained by hardware limitations and the increased number of measurements\nrequired to achieve chemical accuracy. To address the measurement challenge,\ntechniques for grouping commuting and anti-commuting terms, driven by\nheuristics, have been developed to reduce the number of measurements needed in\nquantum algorithms on near-term quantum devices. In this work, we propose a\nprobabilistic framework using GFlowNets to group fully (FC) or qubit-wise\ncommuting (QWC) terms within a given Hamiltonian. The significance of this\napproach is demonstrated by the reduced number of measurements for the found\ngroupings; 51% and 67% reduction factors respectively for FC and QWC\npartitionings with respect to greedy coloring algorithms, highlighting the\npotential of GFlowNets for future applications in the measurement problem.\nFurthermore, the flexibility of our algorithm extends its applicability to\nother resource optimization problems in Hamiltonian simulation, such as circuit\ndesign.\n","authors":["Isaac L. Huidobro-Meezs","Jun Dai","Guillaume Rabusseau","Rodrigo A. Vargas-Hernández"],"pdf_url":"https://arxiv.org/pdf/2410.16041v1.pdf","comment":"8 pages, 2 figures. Accepted for Machine Learning and the Physical\n  Sciences Workshop, NeurIPS 2024. Submission Number: 167"},{"id":"http://arxiv.org/abs/2410.16032v1","updated":"2024-10-21T14:06:53Z","published":"2024-10-21T14:06:53Z","title":"TimeMixer++: A General Time Series Pattern Machine for Universal\n  Predictive Analysis","summary":"  Time series analysis plays a critical role in numerous applications,\nsupporting tasks such as forecasting, classification, anomaly detection, and\nimputation. In this work, we present the time series pattern machine (TSPM), a\nmodel designed to excel in a broad range of time series tasks through powerful\nrepresentation and pattern extraction capabilities. Traditional time series\nmodels often struggle to capture universal patterns, limiting their\neffectiveness across diverse tasks. To address this, we define multiple scales\nin the time domain and various resolutions in the frequency domain, employing\nvarious mixing strategies to extract intricate, task-adaptive time series\npatterns. Specifically, we introduce a general-purpose TSPM that processes\nmulti-scale time series using (1) multi-resolution time imaging (MRTI), (2)\ntime image decomposition (TID), (3) multi-scale mixing (MCM), and (4)\nmulti-resolution mixing (MRM) to extract comprehensive temporal patterns. MRTI\ntransforms multi-scale time series into multi-resolution time images, capturing\npatterns across both temporal and frequency domains. TID leverages dual-axis\nattention to extract seasonal and trend patterns, while MCM hierarchically\naggregates these patterns across scales. MRM adaptively integrates all\nrepresentations across resolutions. This method achieves state-of-the-art\nperformance across 8 time series analytical tasks, consistently surpassing both\ngeneral-purpose and task-specific models. Our work marks a promising step\ntoward the next generation of TSPMs, paving the way for further advancements in\ntime series analysis.\n","authors":["Shiyu Wang","Jiawei Li","Xiaoming Shi","Zhou Ye","Baichuan Mo","Wenze Lin","Shengtong Ju","Zhixuan Chu","Ming Jin"],"pdf_url":"https://arxiv.org/pdf/2410.16032v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16029v1","updated":"2024-10-21T14:05:06Z","published":"2024-10-21T14:05:06Z","title":"Natural GaLore: Accelerating GaLore for memory-efficient LLM Training\n  and Fine-tuning","summary":"  Training LLMs presents significant memory challenges due to growing size of\ndata, weights, and optimizer states. Techniques such as data and model\nparallelism, gradient checkpointing, and offloading strategies address this\nissue but are often infeasible due to hardware constraints. To mitigate memory\nusage, alternative methods like Parameter-Efficient-Fine-Tuning (PEFT) and\nGaLore approximate weights or optimizer states. PEFT methods, such as LoRA,\nhave gained popularity for fine-tuning LLMs, though they require a full-rank\nwarm start. In contrast, GaLore allows full-parameter learning while being more\nmemory-efficient. This work introduces Natural GaLore, a simple drop in\nreplacement for AdamW, which efficiently applies the inverse Empirical Fisher\nInformation Matrix to low-rank gradients using Woodbury's Identity. We\ndemonstrate that incorporating second-order information speeds up optimization\nsignificantly, especially when the iteration budget is limited. Empirical\npretraining on 60M, 130M, 350M, and 1.1B parameter Llama models on C4 data\ndemonstrate significantly lower perplexity over GaLore without additional\nmemory overhead. By fine-tuning RoBERTa on the GLUE benchmark using Natural\nGaLore, we demonstrate significant reduction in gap 86.05% vs 86.28% for\nfull-finetuning. Furthermore, fine-tuning the TinyLlama 1.1B model for function\ncalling using the TinyAgent framework shows that Natural GaLore achieving\n83.09% accuracy on the TinyAgent dataset, significantly outperforms 16-bit LoRA\nat 80.06% and even surpasses GPT4-Turbo by 4%, all while using 30% less memory.\n  All code to reproduce the results are available at:\nhttps://github.com/selfsupervised-ai/Natural-GaLore.git\n","authors":["Arijit Das"],"pdf_url":"https://arxiv.org/pdf/2410.16029v1.pdf","comment":"10 pages, 3 tables, 3 figures"},{"id":"http://arxiv.org/abs/2403.04202v6","updated":"2024-10-21T13:47:44Z","published":"2024-03-07T04:12:24Z","title":"Dynamics of Moral Behavior in Heterogeneous Populations of Learning\n  Agents","summary":"  Growing concerns about safety and alignment of AI systems highlight the\nimportance of embedding moral capabilities in artificial agents: a promising\nsolution is the use of learning from experience, i.e., Reinforcement Learning.\nIn multi-agent (social) environments, complex population-level phenomena may\nemerge from interactions between individual learning agents. Many of the\nexisting studies rely on simulated social dilemma environments to study the\ninteractions of independent learning agents; however, they tend to ignore the\nmoral heterogeneity that is likely to be present in societies of agents in\npractice. For example, at different points in time a single learning agent may\nface opponents who are consequentialist (i.e., focused on maximizing outcomes\nover time), norm-based (i.e., conforming to specific norms), or virtue-based\n(i.e., considering a combination of different virtues). The extent to which\nagents' co-development may be impacted by such moral heterogeneity in\npopulations is not well understood. In this paper, we present a study of the\nlearning dynamics of morally heterogeneous populations interacting in a social\ndilemma setting. Using an Iterated Prisoner's Dilemma environment with a\npartner selection mechanism, we investigate the extent to which the prevalence\nof diverse moral agents in populations affects individual agents' learning\nbehaviors and emergent population-level outcomes. We observe several types of\nnon-trivial interactions between pro-social and anti-social agents, and find\nthat certain types of moral agents are able to steer selfish agents towards\nmore cooperative behavior.\n","authors":["Elizaveta Tennant","Stephen Hailes","Mirco Musolesi"],"pdf_url":"https://arxiv.org/pdf/2403.04202v6.pdf","comment":"Presented at AIES 2024 (7th AAAI/ACM Conference on AI, Ethics, and\n  Society - San Jose, CA, USA)\n  https://ojs.aaai.org/index.php/AIES/article/view/31736"},{"id":"http://arxiv.org/abs/2410.16013v1","updated":"2024-10-21T13:45:02Z","published":"2024-10-21T13:45:02Z","title":"Information-Theoretic Minimax Regret Bounds for Reinforcement Learning\n  based on Duality","summary":"  We study agents acting in an unknown environment where the agent's goal is to\nfind a robust policy. We consider robust policies as policies that achieve high\ncumulative rewards for all possible environments. To this end, we consider\nagents minimizing the maximum regret over different environment parameters,\nleading to the study of minimax regret. This research focuses on deriving\ninformation-theoretic bounds for minimax regret in Markov Decision Processes\n(MDPs) with a finite time horizon. Building on concepts from supervised\nlearning, such as minimum excess risk (MER) and minimax excess risk, we use\nrecent bounds on the Bayesian regret to derive minimax regret bounds.\nSpecifically, we establish minimax theorems and use bounds on the Bayesian\nregret to perform minimax regret analysis using these minimax theorems. Our\ncontributions include defining a suitable minimax regret in the context of\nMDPs, finding information-theoretic bounds for it, and applying these bounds in\nvarious scenarios.\n","authors":["Raghav Bongole","Amaury Gouverneur","Borja Rodríguez-Gálvez","Tobias J. Oechtering","Mikael Skoglund"],"pdf_url":"https://arxiv.org/pdf/2410.16013v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16012v1","updated":"2024-10-21T13:43:02Z","published":"2024-10-21T13:43:02Z","title":"Massimo: Public Queue Monitoring and Management using Mass-Spring Model","summary":"  An efficient system of a queue control and regulation in public spaces is\nvery important in order to avoid the traffic jams and to improve the customer\nsatisfaction. This article offers a detailed road map based on a merger of\nintelligent systems and creating an efficient systems of queues in public\nplaces. Through the utilization of different technologies i.e. computer vision,\nmachine learning algorithms, deep learning our system provide accurate\ninformation about the place is crowded or not and the necessary efforts to be\ntaken.\n","authors":["Abhijeet Kumar","Unnati Singh","Rajdeep Chatterjee","Tathagata Bandyopadhyay"],"pdf_url":"https://arxiv.org/pdf/2410.16012v1.pdf","comment":"8 pages, 6 figures, 3 algorithms, 3 tables"},{"id":"http://arxiv.org/abs/2410.16008v1","updated":"2024-10-21T13:41:27Z","published":"2024-10-21T13:41:27Z","title":"Resilient Temporal GCN for Smart Grid State Estimation Under Topology\n  Inaccuracies","summary":"  State Estimation is a crucial task in power systems. Graph Neural Networks\nhave demonstrated significant potential in state estimation for power systems\nby effectively analyzing measurement data and capturing the complex\ninteractions and interrelations among the measurements through the system's\ngraph structure. However, the information about the system's graph structure\nmay be inaccurate due to noise, attack or lack of accurate information about\nthe topology of the system. This paper studies these scenarios under topology\nuncertainties and evaluates the impact of the topology uncertainties on the\nperformance of a Temporal Graph Convolutional Network (TGCN) for state\nestimation in power systems. In order to make the model resilient to topology\nuncertainties, modifications in the TGCN model are proposed to incorporate a\nknowledge graph, generated based on the measurement data. This knowledge graph\nsupports the assumed uncertain system graph. Two variations of the TGCN\narchitecture are introduced to integrate the knowledge graph, and their\nperformances are evaluated and compared to demonstrate improved resilience\nagainst topology uncertainties. The evaluation results indicate that while the\ntwo proposed architecture show different performance, they both improve the\nperformance of the TGCN state estimation under topology uncertainties.\n","authors":["Seyed Hamed Haghshenas","Mia Naeini"],"pdf_url":"https://arxiv.org/pdf/2410.16008v1.pdf","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2406.10576v2","updated":"2024-10-21T13:39:32Z","published":"2024-06-15T09:31:03Z","title":"Bypass Back-propagation: Optimization-based Structural Pruning for Large\n  Language Models via Policy Gradient","summary":"  In contrast to moderate-size neural network pruning, structural weight\npruning on the Large-Language Models (LLMs) imposes a novel challenge on the\nefficiency of the pruning algorithms, due to the heavy computation/memory\ndemands of the LLMs. Recent efficient LLM pruning methods typically operate at\nthe post-training phase without the expensive weight finetuning, however, their\npruning criteria often rely on heuristically hand-crafted metrics, potentially\nleading to suboptimal performance. We instead propose a novel\noptimization-based structural pruning that learns the pruning masks in a\nprobabilistic space directly by optimizing the loss of the pruned model. To\npreserve the efficiency, our method eliminates the back-propagation through the\nLLM per se during the optimization, requiring only the forward pass of the LLM.\nWe achieve this by learning an underlying Bernoulli distribution to sample\nbinary pruning masks, where we decouple the Bernoulli parameters from the LLM\nloss, thus facilitating an efficient optimization via a policy gradient\nestimator without back-propagation. As a result, our method is able to 1)\noperate at structural granularities of channels, heads, and layers, 2) support\nglobal and heterogeneous pruning (i.e., our method automatically determines\ndifferent redundancy for different layers), and 3) optionally initialize with a\nmetric-based method (for our Bernoulli distributions). Extensive experiments on\nLLaMA, LLaMA-2, LLaMA-3, Vicuna, and Mistral using the C4 and WikiText2\ndatasets demonstrate that our method operates for 2.7 hours with around 35GB\nmemory for the 13B models on a single A100 GPU, and our pruned models\noutperform the state-of-the-arts w.r.t. both perplexity and the majority of\nvarious zero-shot tasks. Codes will be released.\n","authors":["Yuan Gao","Zujing Liu","Weizhong Zhang","Bo Du","Gui-Song Xia"],"pdf_url":"https://arxiv.org/pdf/2406.10576v2.pdf","comment":"Initially submitted on June 15, 2024, this version mainly changed the\n  title, and added several experiments: such as 1) experiments on LLaMA-3,\n  Mistral, 2) additional baseline methods (i.e., Bosai -- Everybody Prune Now),\n  and 3) post-pruning finetuned performance (i.e., first prune then finetune)"},{"id":"http://arxiv.org/abs/2404.14212v4","updated":"2024-10-21T13:34:22Z","published":"2024-04-22T14:21:37Z","title":"Toward Routing River Water in Land Surface Models with Recurrent Neural\n  Networks","summary":"  Machine learning is playing an increasing role in hydrology, supplementing or\nreplacing physics-based models. One notable example is the use of recurrent\nneural networks (RNNs) for forecasting streamflow given observed precipitation\nand geographic characteristics. Training of such a model over the continental\nUnited States (CONUS) demonstrated that a single set of model parameters can be\nused across independent catchments, and that RNNs can outperform physics-based\nmodels. In this work, we take a next step and study the performance of RNNs for\nriver routing in land surface models (LSMs). Instead of observed precipitation,\nthe LSM-RNN uses instantaneous runoff calculated from physics-based models as\nan input. We train the model with data from river basins spanning the globe and\ntest using historical streamflow measurements. The model demonstrates skill at\ngeneralization across basins (predicting streamflow in catchments not used in\ntraining) and across time (predicting streamflow during years not used in\ntraining). We compare the predictions from the LSM-RNN to an existing\nphysics-based model calibrated with a similar dataset and find that the LSM-RNN\noutperforms the physics-based model. Our results show that RNNs are effective\nfor global streamflow prediction from runoff inputs and motivate the\ndevelopment of complete routing models that can capture nested sub-basis\nconnections.\n","authors":["Mauricio Lima","Katherine Deck","Oliver R. A. Dunbar","Tapio Schneider"],"pdf_url":"https://arxiv.org/pdf/2404.14212v4.pdf","comment":"32 pages, 11 figures; submitted in HESS (EGU) with CCBY license"},{"id":"http://arxiv.org/abs/2410.15998v1","updated":"2024-10-21T13:29:08Z","published":"2024-10-21T13:29:08Z","title":"1024m at SMM4H 2024: Tasks 3, 5 & 6 -- Ensembles of Transformers and\n  Large Language Models for Medical Text Classification","summary":"  Social media is a great source of data for users reporting information and\nregarding their health and how various things have had an effect on them. This\npaper presents various approaches using Transformers and Large Language Models\nand their ensembles, their performance along with advantages and drawbacks for\nvarious tasks of SMM4H'24 - Classifying texts on impact of nature and outdoor\nspaces on the author's mental health (Task 3), Binary classification of tweets\nreporting their children's health disorders like Asthma, Autism, ADHD and\nSpeech disorder (task 5), Binary classification of users self-reporting their\nage (task 6).\n","authors":["Ram Mohan Rao Kadiyala","M. V. P. Chandra Sekhara Rao"],"pdf_url":"https://arxiv.org/pdf/2410.15998v1.pdf","comment":"short paper , acl 2024"},{"id":"http://arxiv.org/abs/2410.15997v1","updated":"2024-10-21T13:28:28Z","published":"2024-10-21T13:28:28Z","title":"MultiRC: Joint Learning for Time Series Anomaly Prediction and Detection\n  with Multi-scale Reconstructive Contrast","summary":"  Many methods have been proposed for unsupervised time series anomaly\ndetection. Despite some progress, research on predicting future anomalies is\nstill relatively scarce. Predicting anomalies is particularly challenging due\nto the diverse reaction time and the lack of labeled data. To address these\nchallenges, we propose MultiRC to integrate reconstructive and contrastive\nlearning for joint learning of anomaly prediction and detection, with\nmulti-scale structure and adaptive dominant period mask to deal with the\ndiverse reaction time. MultiRC also generates negative samples to provide\nessential training momentum for the anomaly prediction tasks and prevent model\ndegradation. We evaluate seven benchmark datasets from different fields. For\nboth anomaly prediction and detection tasks, MultiRC outperforms existing\nstate-of-the-art methods.\n","authors":["Shiyan Hu","Kai Zhao","Xiangfei Qiu","Yang Shu","Jilin Hu","Bin Yang","Chenjuan Guo"],"pdf_url":"https://arxiv.org/pdf/2410.15997v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15990v1","updated":"2024-10-21T13:20:15Z","published":"2024-10-21T13:20:15Z","title":"Augmenting Legal Decision Support Systems with LLM-based NLI for\n  Analyzing Social Media Evidence","summary":"  This paper presents our system description and error analysis of our entry\nfor NLLP 2024 shared task on Legal Natural Language Inference (L-NLI)\n\\citep{hagag2024legallenssharedtask2024}. The task required classifying these\nrelationships as entailed, contradicted, or neutral, indicating any association\nbetween the review and the complaint. Our system emerged as the winning\nsubmission, significantly outperforming other entries with a substantial margin\nand demonstrating the effectiveness of our approach in legal text analysis. We\nprovide a detailed analysis of the strengths and limitations of each model and\napproach tested, along with a thorough error analysis and suggestions for\nfuture improvements. This paper aims to contribute to the growing field of\nlegal NLP by offering insights into advanced techniques for natural language\ninference in legal contexts, making it accessible to both experts and newcomers\nin the field.\n","authors":["Ram Mohan Rao Kadiyala","Siddartha Pullakhandam","Kanwal Mehreen","Subhasya Tippareddy","Ashay Srivastava"],"pdf_url":"https://arxiv.org/pdf/2410.15990v1.pdf","comment":"8 pages , accepted to emnlp 2024"},{"id":"http://arxiv.org/abs/2410.15987v1","updated":"2024-10-21T13:16:58Z","published":"2024-10-21T13:16:58Z","title":"Analyzing Closed-loop Training Techniques for Realistic Traffic Agent\n  Models in Autonomous Highway Driving Simulations","summary":"  Simulation plays a crucial role in the rapid development and safe deployment\nof autonomous vehicles. Realistic traffic agent models are indispensable for\nbridging the gap between simulation and the real world. Many existing\napproaches for imitating human behavior are based on learning from\ndemonstration. However, these approaches are often constrained by focusing on\nindividual training strategies. Therefore, to foster a broader understanding of\nrealistic traffic agent modeling, in this paper, we provide an extensive\ncomparative analysis of different training principles, with a focus on\nclosed-loop methods for highway driving simulation. We experimentally compare\n(i) open-loop vs. closed-loop multi-agent training, (ii) adversarial vs.\ndeterministic supervised training, (iii) the impact of reinforcement losses,\nand (iv) the impact of training alongside log-replayed agents to identify\nsuitable training techniques for realistic agent modeling. Furthermore, we\nidentify promising combinations of different closed-loop training methods.\n","authors":["Matthias Bitzer","Reinis Cimurs","Benjamin Coors","Johannes Goth","Sebastian Ziesche","Philipp Geiger","Maximilian Naumann"],"pdf_url":"https://arxiv.org/pdf/2410.15987v1.pdf","comment":"15 pages, 6 figures, 4 tables"},{"id":"http://arxiv.org/abs/2410.15986v1","updated":"2024-10-21T13:16:29Z","published":"2024-10-21T13:16:29Z","title":"A quantitative Robbins-Siegmund theorem","summary":"  The Robbins-Siegmund theorem is one of the most important results in\nstochastic optimization, where it is widely used to prove the convergence of\nstochastic algorithms. We provide a quantitative version of the theorem,\nestablishing a bound on how far one needs to look in order to locate a region\nof metastability in the sense of Tao. Our proof involves a metastable analogue\nof Doob's theorem for $L_1$-supermartingales along with a series of technical\nlemmas that make precise how quantitative information propagates through sums\nand products of stochastic processes. In this way, our paper establishes a\ngeneral methodology for finding metastable bounds for stochastic processes that\ncan be reduced to supermartingales, and therefore for obtaining quantitative\nconvergence information across a broad class of stochastic algorithms whose\nconvergence proof relies on some variation of the Robbins-Siegmund theorem. We\nconclude by discussing how our general quantitative result might be used in\npractice.\n","authors":["Morenikeji Neri","Thomas Powell"],"pdf_url":"https://arxiv.org/pdf/2410.15986v1.pdf","comment":"30 pages"},{"id":"http://arxiv.org/abs/2410.06003v3","updated":"2024-10-21T13:12:35Z","published":"2024-10-08T13:04:02Z","title":"Is the MMI Criterion Necessary for Interpretability? Degenerating\n  Non-causal Features to Plain Noise for Self-Rationalization","summary":"  An important line of research in the field of explainability is to extract a\nsmall subset of crucial rationales from the full input. The most widely used\ncriterion for rationale extraction is the maximum mutual information (MMI)\ncriterion. However, in certain datasets, there are spurious features\nnon-causally correlated with the label and also get high mutual information,\ncomplicating the loss landscape of MMI. Although some penalty-based methods\nhave been developed to penalize the spurious features (e.g., invariance\npenalty, intervention penalty, etc) to help MMI work better, these are merely\nremedial measures. In the optimization objectives of these methods, spurious\nfeatures are still distinguished from plain noise, which hinders the discovery\nof causal rationales. This paper aims to develop a new criterion that treats\nspurious features as plain noise, allowing the model to work on datasets rich\nin spurious features as if it were working on clean datasets, thereby making\nrationale extraction easier. We theoretically observe that removing either\nplain noise or spurious features from the input does not alter the conditional\ndistribution of the remaining components relative to the task label. However,\nsignificant changes in the conditional distribution occur only when causal\nfeatures are eliminated. Based on this discovery, the paper proposes a\ncriterion for \\textbf{M}aximizing the \\textbf{R}emaining \\textbf{D}iscrepancy\n(MRD). Experiments on six widely used datasets show that our MRD criterion\nimproves rationale quality (measured by the overlap with human-annotated\nrationales) by up to $10.4\\%$ as compared to several recent competitive MMI\nvariants. Code: \\url{https://github.com/jugechengzi/Rationalization-MRD}.\n","authors":["Wei Liu","Zhiying Deng","Zhongyu Niu","Jun Wang","Haozhao Wang","YuanKai Zhang","Ruixuan Li"],"pdf_url":"https://arxiv.org/pdf/2410.06003v3.pdf","comment":"Accepted at NeurIPS 2024. arXiv admin note: text overlap with\n  arXiv:2309.13391"},{"id":"http://arxiv.org/abs/2410.15982v1","updated":"2024-10-21T13:12:22Z","published":"2024-10-21T13:12:22Z","title":"State Estimation Using Sparse DEIM and Recurrent Neural Networks","summary":"  Discrete Empirical Interpolation Method (DEIM) estimates a function from its\npointwise incomplete observations. In particular, this method can be used to\nestimate the state of a dynamical system from observational data gathered by\nsensors. However, when the number of observations are limited, DEIM returns\nlarge estimation errors. Sparse DEIM (S-DEIM) was recently developed to address\nthis problem by introducing a kernel vector which previous DEIM-based methods\nhad ignored. Unfortunately, estimating the optimal kernel vector in S-DEIM is a\ndifficult task. Here, we introduce a data-driven method to estimate this kernel\nvector from sparse observational time series using recurrent neural networks.\nUsing numerical examples, we demonstrate that this machine learning approach\ntogether with S-DEIM leads to nearly optimal state estimations.\n","authors":["Mohammad Farazmand"],"pdf_url":"https://arxiv.org/pdf/2410.15982v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11786v2","updated":"2024-10-21T13:11:44Z","published":"2024-10-15T17:05:25Z","title":"Selection-p: Self-Supervised Task-Agnostic Prompt Compression for\n  Faithfulness and Transferability","summary":"  Large Language Models (LLMs) have demonstrated impressive capabilities in a\nwide range of natural language processing tasks when leveraging in-context\nlearning. To mitigate the additional computational and financial costs\nassociated with in-context learning, several prompt compression methods have\nbeen proposed to compress the in-context learning prompts. Despite their\nsuccess, these methods face challenges with transferability due to\nmodel-specific compression, or rely on external training data, such as GPT-4.\nIn this paper, we investigate the ability of LLMs to develop a unified\ncompression method that discretizes uninformative tokens, utilizing a\nself-supervised pre-training technique. By introducing a small number of\nparameters during the continual pre-training, the proposed Selection-p produces\na probability for each input token, indicating whether to preserve or discard\nit. Experiments show Selection-p achieves state-of-the-art performance across\nnumerous classification tasks, achieving compression rates of up to 10 times\nwhile experiencing only a marginal 0.8% decrease in performance. Moreover, it\nexhibits superior transferability to different models compared to prior work.\nAdditionally, we further analyze how Selection-p helps maintain performance on\nin-context learning with long contexts.\n","authors":["Tsz Ting Chung","Leyang Cui","Lemao Liu","Xinting Huang","Shuming Shi","Dit-Yan Yeung"],"pdf_url":"https://arxiv.org/pdf/2410.11786v2.pdf","comment":"14 pages, 5 figures, 10 tables, EMNLP 2024 Findings"},{"id":"http://arxiv.org/abs/2410.15981v1","updated":"2024-10-21T13:06:38Z","published":"2024-10-21T13:06:38Z","title":"Visual Representation Learning Guided By Multi-modal Prior Knowledge","summary":"  Despite the remarkable success of deep neural networks (DNNs) in computer\nvision, they fail to remain high-performing when facing distribution shifts\nbetween training and testing data. In this paper, we propose Knowledge-Guided\nVisual representation learning (KGV), a distribution-based learning approach\nleveraging multi-modal prior knowledge, to improve generalization under\ndistribution shift. We use prior knowledge from two distinct modalities: 1) a\nknowledge graph (KG) with hierarchical and association relationships; and 2)\ngenerated synthetic images of visual elements semantically represented in the\nKG. The respective embeddings are generated from the given modalities in a\ncommon latent space, i.e., visual embeddings from original and synthetic images\nas well as knowledge graph embeddings (KGEs). These embeddings are aligned via\na novel variant of translation-based KGE methods, where the node and relation\nembeddings of the KG are modeled as Gaussian distributions and translations\nrespectively. We claim that incorporating multi-model prior knowledge enables\nmore regularized learning of image representations. Thus, the models are able\nto better generalize across different data distributions. We evaluate KGV on\ndifferent image classification tasks with major or minor distribution shifts,\nnamely road sign classification across datasets from Germany, China, and\nRussia, image classification with the mini-ImageNet dataset and its variants,\nas well as the DVM-CAR dataset. The results demonstrate that KGV consistently\nexhibits higher accuracy and data efficiency than the baselines across all\nexperiments.\n","authors":["Hongkuan Zhou","Lavdim Halilaj","Sebastian Monka","Stefan Schmid","Yuqicheng Zhu","Bo Xiong","Steffen Staab"],"pdf_url":"https://arxiv.org/pdf/2410.15981v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15974v1","updated":"2024-10-21T13:00:09Z","published":"2024-10-21T13:00:09Z","title":"Large Language Models for Cross-lingual Emotion Detection","summary":"  This paper presents a detailed system description of our entry for the WASSA\n2024 Task 2, focused on cross-lingual emotion detection. We utilized a\ncombination of large language models (LLMs) and their ensembles to effectively\nunderstand and categorize emotions across different languages. Our approach not\nonly outperformed other submissions with a large margin, but also demonstrated\nthe strength of integrating multiple models to enhance performance.\nAdditionally, We conducted a thorough comparison of the benefits and\nlimitations of each model used. An error analysis is included along with\nsuggested areas for future improvement. This paper aims to offer a clear and\ncomprehensive understanding of advanced techniques in emotion detection, making\nit accessible even to those new to the field.\n","authors":["Ram Mohan Rao Kadiyala"],"pdf_url":"https://arxiv.org/pdf/2410.15974v1.pdf","comment":"6 pages , accepted to acl 2024"},{"id":"http://arxiv.org/abs/2410.15973v1","updated":"2024-10-21T12:59:58Z","published":"2024-10-21T12:59:58Z","title":"Karush-Kuhn-Tucker Condition-Trained Neural Networks (KKT Nets)","summary":"  This paper presents a novel approach to solving convex optimization problems\nby leveraging the fact that, under certain regularity conditions, any set of\nprimal or dual variables satisfying the Karush-Kuhn-Tucker (KKT) conditions is\nnecessary and sufficient for optimality. Similar to Theory-Trained Neural\nNetworks (TTNNs), the parameters of the convex optimization problem are input\nto the neural network, and the expected outputs are the optimal primal and dual\nvariables. A choice for the loss function in this case is a loss, which we\nrefer to as the KKT Loss, that measures how well the network's outputs satisfy\nthe KKT conditions. We demonstrate the effectiveness of this approach using a\nlinear program as an example. For this problem, we observe that minimizing the\nKKT Loss alone outperforms training the network with a weighted sum of the KKT\nLoss and a Data Loss (the mean-squared error between the ground truth optimal\nsolutions and the network's output). Moreover, minimizing only the Data Loss\nyields inferior results compared to those obtained by minimizing the KKT Loss.\nWhile the approach is promising, the obtained primal and dual solutions are not\nsufficiently close to the ground truth optimal solutions. In the future, we aim\nto develop improved models to obtain solutions closer to the ground truth and\nextend the approach to other problem classes.\n","authors":["Shreya Arvind","Rishabh Pomaje","Rajshekhar V Bhat"],"pdf_url":"https://arxiv.org/pdf/2410.15973v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15954v1","updated":"2024-10-21T12:34:02Z","published":"2024-10-21T12:34:02Z","title":"TS-ACL: A Time Series Analytic Continual Learning Framework for\n  Privacy-Preserving and Class-Incremental Pattern Recognition","summary":"  Class-incremental Learning (CIL) in Time Series Classification (TSC) aims to\nincrementally train models using the streaming time series data that arrives\ncontinuously. The main problem in this scenario is catastrophic forgetting,\ni.e., training models with new samples inevitably leads to the forgetting of\npreviously learned knowledge. Among existing methods, the replay-based methods\nachieve satisfactory performance but compromise privacy, while exemplar-free\nmethods protect privacy but suffer from low accuracy. However, more critically,\nowing to their reliance on gradient-based update techniques, these existing\nmethods fundamentally cannot solve the catastrophic forgetting problem. In TSC\nscenarios with continuously arriving data and temporally shifting\ndistributions, these methods become even less practical. In this paper, we\npropose a Time Series Analytic Continual Learning framework, called TS-ACL.\nInspired by analytical learning, TS-ACL transforms neural network updates into\ngradient-free linear regression problems, thereby fundamentally mitigating\ncatastrophic forgetting. Specifically, employing a pre-trained and frozen\nfeature extraction encoder, TS-ACL only needs to update its analytic classifier\nrecursively in a lightweight manner that is highly suitable for real-time\napplications and large-scale data processing. Additionally, we theoretically\ndemonstrate that the model obtained recursively through the TS-ACL is exactly\nequivalent to a model trained on the complete dataset in a centralized manner,\nthereby establishing the property of absolute knowledge memory. Extensive\nexperiments validate the superior performance of our TS-ACL.\n","authors":["Kejia Fan","Jiaxu Li","Songning Lai","Linpu Lv","Anfeng Liu","Jianheng Tang","Houbing Herbert Song","Huiping Zhuang"],"pdf_url":"https://arxiv.org/pdf/2410.15954v1.pdf","comment":"11 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2410.15952v1","updated":"2024-10-21T12:32:39Z","published":"2024-10-21T12:32:39Z","title":"User-centric evaluation of explainability of AI with and for humans: a\n  comprehensive empirical study","summary":"  This study is located in the Human-Centered Artificial Intelligence (HCAI)\nand focuses on the results of a user-centered assessment of commonly used\neXplainable Artificial Intelligence (XAI) algorithms, specifically\ninvestigating how humans understand and interact with the explanations provided\nby these algorithms. To achieve this, we employed a multi-disciplinary approach\nthat included state-of-the-art research methods from social sciences to measure\nthe comprehensibility of explanations generated by a state-of-the-art lachine\nlearning model, specifically the Gradient Boosting Classifier (XGBClassifier).\nWe conducted an extensive empirical user study involving interviews with 39\nparticipants from three different groups, each with varying expertise in data\nscience, data visualization, and domain-specific knowledge related to the\ndataset used for training the machine learning model. Participants were asked a\nseries of questions to assess their understanding of the model's explanations.\nTo ensure replicability, we built the model using a publicly available dataset\nfrom the UC Irvine Machine Learning Repository, focusing on edible and\nnon-edible mushrooms. Our findings reveal limitations in existing XAI methods\nand confirm the need for new design principles and evaluation techniques that\naddress the specific information needs and user perspectives of different\nclasses of AI stakeholders. We believe that the results of our research and the\ncross-disciplinary methodology we developed can be successfully adapted to\nvarious data types and user profiles, thus promoting dialogue and address\nopportunities in HCAI research. To support this, we are making the data\nresulting from our study publicly available.\n","authors":["Szymon Bobek","Paloma Korycińska","Monika Krakowska","Maciej Mozolewski","Dorota Rak","Magdalena Zych","Magdalena Wójcik","Grzegorz J. Nalepa"],"pdf_url":"https://arxiv.org/pdf/2410.15952v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15927v1","updated":"2024-10-21T11:55:06Z","published":"2024-10-21T11:55:06Z","title":"GReFEL: Geometry-Aware Reliable Facial Expression Learning under Bias\n  and Imbalanced Data Distribution","summary":"  Reliable facial expression learning (FEL) involves the effective learning of\ndistinctive facial expression characteristics for more reliable, unbiased and\naccurate predictions in real-life settings. However, current systems struggle\nwith FEL tasks because of the variance in people's facial expressions due to\ntheir unique facial structures, movements, tones, and demographics. Biased and\nimbalanced datasets compound this challenge, leading to wrong and biased\nprediction labels. To tackle these, we introduce GReFEL, leveraging Vision\nTransformers and a facial geometry-aware anchor-based reliability balancing\nmodule to combat imbalanced data distributions, bias, and uncertainty in facial\nexpression learning. Integrating local and global data with anchors that learn\ndifferent facial data points and structural features, our approach adjusts\nbiased and mislabeled emotions caused by intra-class disparity, inter-class\nsimilarity, and scale sensitivity, resulting in comprehensive, accurate, and\nreliable facial expression predictions. Our model outperforms current\nstate-of-the-art methodologies, as demonstrated by extensive experiments on\nvarious datasets.\n","authors":["Azmine Toushik Wasi","Taki Hasan Rafi","Raima Islam","Karlo Serbetar","Dong Kyu Chae"],"pdf_url":"https://arxiv.org/pdf/2410.15927v1.pdf","comment":"ACCV 2024. Extended version of ARBEx (arXiv:2305.01486)"},{"id":"http://arxiv.org/abs/2405.14468v2","updated":"2024-10-21T11:54:16Z","published":"2024-05-23T11:55:49Z","title":"Neural Collapse versus Low-rank Bias: Is Deep Neural Collapse Really\n  Optimal?","summary":"  Deep neural networks (DNNs) exhibit a surprising structure in their final\nlayer known as neural collapse (NC), and a growing body of works has currently\ninvestigated the propagation of neural collapse to earlier layers of DNNs -- a\nphenomenon called deep neural collapse (DNC). However, existing theoretical\nresults are restricted to special cases: linear models, only two layers or\nbinary classification. In contrast, we focus on non-linear models of arbitrary\ndepth in multi-class classification and reveal a surprising qualitative shift.\nAs soon as we go beyond two layers or two classes, DNC stops being optimal for\nthe deep unconstrained features model (DUFM) -- the standard theoretical\nframework for the analysis of collapse. The main culprit is a low-rank bias of\nmulti-layer regularization schemes: this bias leads to optimal solutions of\neven lower rank than the neural collapse. We support our theoretical findings\nwith experiments on both DUFM and real data, which show the emergence of the\nlow-rank structure in the solution found by gradient descent.\n","authors":["Peter Súkeník","Marco Mondelli","Christoph Lampert"],"pdf_url":"https://arxiv.org/pdf/2405.14468v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15923v1","updated":"2024-10-21T11:53:49Z","published":"2024-10-21T11:53:49Z","title":"Automatic Differentiation of Optimization Algorithms with Time-Varying\n  Updates","summary":"  Numerous Optimization Algorithms have a time-varying update rule thanks to,\nfor instance, a changing step size, momentum parameter or, Hessian\napproximation. In this paper, we apply unrolled or automatic differentiation to\na time-varying iterative process and provide convergence (rate) guarantees for\nthe resulting derivative iterates. We adapt these convergence results and apply\nthem to proximal gradient descent with variable step size and FISTA when\nsolving partly smooth problems. We confirm our findings numerically by solving\n$\\ell_1$ and $\\ell_2$-regularized linear and logisitc regression respectively.\nOur theoretical and numerical results show that the convergence rate of the\nalgorithm is reflected in its derivative iterates.\n","authors":["Sheheryar Mehmood","Peter Ochs"],"pdf_url":"https://arxiv.org/pdf/2410.15923v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.08958v2","updated":"2024-10-21T11:49:53Z","published":"2024-02-14T05:58:43Z","title":"Towards Next-Level Post-Training Quantization of Hyper-Scale\n  Transformers","summary":"  With the increasing complexity of generative AI models, post-training\nquantization (PTQ) has emerged as a promising solution for deploying\nhyper-scale models on edge devices such as mobile and TVs. Existing PTQ\nschemes, however, consume considerable time and resources, which could be a\nbottleneck in real situations where frequent model updates and multiple\nhyperparameter tunings are required. As a cost-effective alternative,\nlearning-free PTQ schemes have been proposed. However, the performance is\nsomewhat limited because they cannot consider the inter-layer dependency within\nthe attention module, which is a significant feature of Transformers. In this\npaper, we thus propose a novel PTQ algorithm that balances accuracy and\nefficiency. The key idea of the proposed algorithm called aespa is to perform\nquantization layer-wise for efficiency while targeting attention-wise\nreconstruction to consider the cross-layer dependency. Through extensive\nexperiments on various language models and complexity analysis, we demonstrate\nthat aespa is accurate and efficient in quantizing Transformer models.\n","authors":["Junhan Kim","Chungman Lee","Eulrang Cho","Kyungphil Park","Ho-young Kim","Joonyoung Kim","Yongkweon Jeon"],"pdf_url":"https://arxiv.org/pdf/2402.08958v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2310.07446v5","updated":"2024-10-21T11:45:04Z","published":"2023-10-11T12:48:45Z","title":"ProbTS: Benchmarking Point and Distributional Forecasting across Diverse\n  Prediction Horizons","summary":"  Delivering precise point and distributional forecasts across a spectrum of\nprediction horizons represents a significant and enduring challenge in the\napplication of time-series forecasting within various industries. Prior\nresearch on developing deep learning models for time-series forecasting has\noften concentrated on isolated aspects, such as long-term point forecasting or\nshort-term probabilistic estimations. This narrow focus may result in skewed\nmethodological choices and hinder the adaptability of these models to uncharted\nscenarios. While there is a rising trend in developing universal forecasting\nmodels, a thorough understanding of their advantages and drawbacks, especially\nregarding essential forecasting needs like point and distributional forecasts\nacross short and long horizons, is still lacking. In this paper, we present\nProbTS, a benchmark tool designed as a unified platform to evaluate these\nfundamental forecasting needs and to conduct a rigorous comparative analysis of\nnumerous cutting-edge studies from recent years. We dissect the distinctive\ndata characteristics arising from disparate forecasting requirements and\nelucidate how these characteristics can skew methodological preferences in\ntypical research trajectories, which often fail to fully accommodate essential\nforecasting needs. Building on this, we examine the latest models for universal\ntime-series forecasting and discover that our analyses of methodological\nstrengths and weaknesses are also applicable to these universal models.\nFinally, we outline the limitations inherent in current research and underscore\nseveral avenues for future exploration.\n","authors":["Jiawen Zhang","Xumeng Wen","Zhenwei Zhang","Shun Zheng","Jia Li","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2310.07446v5.pdf","comment":"NeurIPS 2024 Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2410.15910v1","updated":"2024-10-21T11:33:14Z","published":"2024-10-21T11:33:14Z","title":"Diverse Policies Recovering via Pointwise Mutual Information Weighted\n  Imitation Learning","summary":"  Recovering a spectrum of diverse policies from a set of expert trajectories\nis an important research topic in imitation learning. After determining a\nlatent style for a trajectory, previous diverse policies recovering methods\nusually employ a vanilla behavioral cloning learning objective conditioned on\nthe latent style, treating each state-action pair in the trajectory with equal\nimportance. Based on an observation that in many scenarios, behavioral styles\nare often highly relevant with only a subset of state-action pairs, this paper\npresents a new principled method in diverse polices recovery. In particular,\nafter inferring or assigning a latent style for a trajectory, we enhance the\nvanilla behavioral cloning by incorporating a weighting mechanism based on\npointwise mutual information. This additional weighting reflects the\nsignificance of each state-action pair's contribution to learning the style,\nthus allowing our method to focus on state-action pairs most representative of\nthat style. We provide theoretical justifications for our new objective, and\nextensive empirical evaluations confirm the effectiveness of our method in\nrecovering diverse policies from expert data.\n","authors":["Hanlin Yang","Jian Yao","Weiming Liu","Qing Wang","Hanmin Qin","Hansheng Kong","Kirk Tang","Jiechao Xiong","Chao Yu","Kai Li","Junliang Xing","Hongwu Chen","Juchao Zhuo","Qiang Fu","Yang Wei","Haobo Fu"],"pdf_url":"https://arxiv.org/pdf/2410.15910v1.pdf","comment":"18 pages, 6 figures"},{"id":"http://arxiv.org/abs/2405.02063v5","updated":"2024-10-21T11:26:32Z","published":"2024-05-03T12:48:21Z","title":"Few-sample Variational Inference of Bayesian Neural Networks with\n  Arbitrary Nonlinearities","summary":"  Bayesian Neural Networks (BNNs) extend traditional neural networks to provide\nuncertainties associated with their outputs. On the forward pass through a BNN,\npredictions (and their uncertainties) are made either by Monte Carlo sampling\nnetwork weights from the learned posterior or by analytically propagating\nstatistical moments through the network. Though flexible, Monte Carlo sampling\nis computationally expensive and can be infeasible or impractical under\nresource constraints or for large networks. While moment propagation can\nameliorate the computational costs of BNN inference, it can be difficult or\nimpossible for networks with arbitrary nonlinearities, thereby restricting the\npossible set of network layers permitted with such a scheme. In this work, we\ndemonstrate a simple yet effective approach for propagating statistical moments\nthrough arbitrary nonlinearities with only 3 deterministic samples, enabling\nfew-sample variational inference of BNNs without restricting the set of network\nlayers used. Furthermore, we leverage this approach to demonstrate a novel\nnonlinear activation function that we use to inject physics-informed prior\ninformation into output nodes of a BNN.\n","authors":["David J. Schodt"],"pdf_url":"https://arxiv.org/pdf/2405.02063v5.pdf","comment":"Comment 1: Fixed plot markers in figure 6 to match legend and to\n  improve grayscale appearance Comment 2: Fixed mistyped value for optimizer\n  learning rate"},{"id":"http://arxiv.org/abs/2410.15899v1","updated":"2024-10-21T11:23:23Z","published":"2024-10-21T11:23:23Z","title":"On the Design and Performance of Machine Learning Based Error Correcting\n  Decoders","summary":"  This paper analyzes the design and competitiveness of four neural network\n(NN) architectures recently proposed as decoders for forward error correction\n(FEC) codes. We first consider the so-called single-label neural network (SLNN)\nand the multi-label neural network (MLNN) decoders which have been reported to\nachieve near maximum likelihood (ML) performance. Here, we show analytically\nthat SLNN and MLNN decoders can always achieve ML performance, regardless of\nthe code dimensions -- although at the cost of computational complexity -- and\nno training is in fact required. We then turn our attention to two\ntransformer-based decoders: the error correction code transformer (ECCT) and\nthe cross-attention message passing transformer (CrossMPT). We compare their\nperformance against traditional decoders, and show that ordered statistics\ndecoding outperforms these transformer-based decoders. The results in this\npaper cast serious doubts on the application of NN-based FEC decoders in the\nshort and medium block length regime.\n","authors":["Yuncheng Yuan","Péter Scheepers","Lydia Tasiou","Yunus Can Gültekin","Federico Corradi","Alex Alvarado"],"pdf_url":"https://arxiv.org/pdf/2410.15899v1.pdf","comment":"6 pages, 4 figures, submitted for possible presentation in a\n  conference"},{"id":"http://arxiv.org/abs/2310.04539v3","updated":"2024-10-21T11:12:02Z","published":"2023-10-06T19:06:13Z","title":"Generating Less Certain Adversarial Examples Improves Robust\n  Generalization","summary":"  This paper revisits the robust overfitting phenomenon of adversarial\ntraining. Observing that models with better robust generalization performance\nare less certain in predicting adversarially generated training inputs, we\nargue that overconfidence in predicting adversarial examples is a potential\ncause. Therefore, we hypothesize that generating less certain adversarial\nexamples improves robust generalization, and propose a formal definition of\nadversarial certainty that captures the variance of the model's predicted\nlogits on adversarial examples. Our theoretical analysis of synthetic\ndistributions characterizes the connection between adversarial certainty and\nrobust generalization. Accordingly, built upon the notion of adversarial\ncertainty, we develop a general method to search for models that can generate\ntraining-time adversarial inputs with reduced certainty, while maintaining the\nmodel's capability in distinguishing adversarial examples. Extensive\nexperiments on image benchmarks demonstrate that our method effectively learns\nmodels with consistently improved robustness and mitigates robust overfitting,\nconfirming the importance of generating less certain adversarial examples for\nrobust generalization.\n","authors":["Minxing Zhang","Michael Backes","Xiao Zhang"],"pdf_url":"https://arxiv.org/pdf/2310.04539v3.pdf","comment":"Published in Transactions of Machine Learning Research (TMLR)"},{"id":"http://arxiv.org/abs/2408.13296v2","updated":"2024-10-21T11:10:00Z","published":"2024-08-23T14:48:02Z","title":"The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs: An\n  Exhaustive Review of Technologies, Research, Best Practices, Applied Research\n  Challenges and Opportunities","summary":"  This report examines the fine-tuning of Large Language Models (LLMs),\nintegrating theoretical insights with practical applications. It outlines the\nhistorical evolution of LLMs from traditional Natural Language Processing (NLP)\nmodels to their pivotal role in AI. A comparison of fine-tuning methodologies,\nincluding supervised, unsupervised, and instruction-based approaches,\nhighlights their applicability to different tasks. The report introduces a\nstructured seven-stage pipeline for fine-tuning LLMs, spanning data\npreparation, model initialization, hyperparameter tuning, and model deployment.\nEmphasis is placed on managing imbalanced datasets and optimization techniques.\nParameter-efficient methods like Low-Rank Adaptation (LoRA) and Half\nFine-Tuning are explored for balancing computational efficiency with\nperformance. Advanced techniques such as memory fine-tuning, Mixture of Experts\n(MoE), and Mixture of Agents (MoA) are discussed for leveraging specialized\nnetworks and multi-agent collaboration. The report also examines novel\napproaches like Proximal Policy Optimization (PPO) and Direct Preference\nOptimization (DPO), which align LLMs with human preferences, alongside pruning\nand routing optimizations to improve efficiency. Further sections cover\nvalidation frameworks, post-deployment monitoring, and inference optimization,\nwith attention to deploying LLMs on distributed and cloud-based platforms.\nEmerging areas such as multimodal LLMs, fine-tuning for audio and speech, and\nchallenges related to scalability, privacy, and accountability are also\naddressed. This report offers actionable insights for researchers and\npractitioners navigating LLM fine-tuning in an evolving landscape.\n","authors":["Venkatesh Balavadhani Parthasarathy","Ahtsham Zafar","Aafaq Khan","Arsalan Shahid"],"pdf_url":"https://arxiv.org/pdf/2408.13296v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15889v1","updated":"2024-10-21T11:06:56Z","published":"2024-10-21T11:06:56Z","title":"Model Mimic Attack: Knowledge Distillation for Provably Transferable\n  Adversarial Examples","summary":"  The vulnerability of artificial neural networks to adversarial perturbations\nin the black-box setting is widely studied in the literature. The majority of\nattack methods to construct these perturbations suffer from an impractically\nlarge number of queries required to find an adversarial example. In this work,\nwe focus on knowledge distillation as an approach to conduct transfer-based\nblack-box adversarial attacks and propose an iterative training of the\nsurrogate model on an expanding dataset. This work is the first, to our\nknowledge, to provide provable guarantees on the success of knowledge\ndistillation-based attack on classification neural networks: we prove that if\nthe student model has enough learning capabilities, the attack on the teacher\nmodel is guaranteed to be found within the finite number of distillation\niterations.\n","authors":["Kirill Lukyanov","Andrew Perminov","Denis Turdakov","Mikhail Pautov"],"pdf_url":"https://arxiv.org/pdf/2410.15889v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15884v1","updated":"2024-10-21T11:02:18Z","published":"2024-10-21T11:02:18Z","title":"Using GPT Models for Qualitative and Quantitative News Analytics in the\n  2024 US Presidental Election Process","summary":"  The paper considers an approach of using Google Search API and GPT-4o model\nfor qualitative and quantitative analyses of news through retrieval-augmented\ngeneration (RAG). This approach was applied to analyze news about the 2024 US\npresidential election process. Different news sources for different time\nperiods have been analyzed. Quantitative scores generated by GPT model have\nbeen analyzed using Bayesian regression to derive trend lines. The\ndistributions found for the regression parameters allow for the analysis of\nuncertainty in the election process. The obtained results demonstrate that\nusing the GPT models for news analysis, one can get informative analytics and\nprovide key insights that can be applied in further analyses of election\nprocesses.\n","authors":["Bohdan M. Pavlyshenko"],"pdf_url":"https://arxiv.org/pdf/2410.15884v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15882v1","updated":"2024-10-21T11:01:44Z","published":"2024-10-21T11:01:44Z","title":"Distributed Learning for UAV Swarms","summary":"  Unmanned Aerial Vehicle (UAV) swarms are increasingly deployed in dynamic,\ndata-rich environments for applications such as environmental monitoring and\nsurveillance. These scenarios demand efficient data processing while\nmaintaining privacy and security, making Federated Learning (FL) a promising\nsolution. FL allows UAVs to collaboratively train global models without sharing\nraw data, but challenges arise due to the non-Independent and Identically\nDistributed (non-IID) nature of the data collected by UAVs. In this study, we\nshow an integration of the state-of-the-art FL methods to UAV Swarm application\nand invetigate the performance of multiple aggregation methods (namely FedAvg,\nFedProx, FedOpt, and MOON) with a particular focus on tackling non-IID on a\nvariety of datasets, specifically MNIST for baseline performance, CIFAR10 for\nnatural object classification, EuroSAT for environment monitoring, and CelebA\nfor surveillance. These algorithms were selected to cover improved techniques\non both client-side updates and global aggregation. Results show that while all\nalgorithms perform comparably on IID data, their performance deteriorates\nsignificantly under non-IID conditions. FedProx demonstrated the most stable\noverall performance, emphasising the importance of regularising local updates\nin non-IID environments to mitigate drastic deviations in local models.\n","authors":["Chen Hu","Hanchi Ren","Jingjing Deng","Xianghua Xie"],"pdf_url":"https://arxiv.org/pdf/2410.15882v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15876v1","updated":"2024-10-21T10:57:45Z","published":"2024-10-21T10:57:45Z","title":"FlickerFusion: Intra-trajectory Domain Generalizing Multi-Agent RL","summary":"  Multi-agent reinforcement learning has demonstrated significant potential in\naddressing complex cooperative tasks across various real-world applications.\nHowever, existing MARL approaches often rely on the restrictive assumption that\nthe number of entities (e.g., agents, obstacles) remains constant between\ntraining and inference. This overlooks scenarios where entities are dynamically\nremoved or added during the inference trajectory -- a common occurrence in\nreal-world environments like search and rescue missions and dynamic combat\nsituations. In this paper, we tackle the challenge of intra-trajectory dynamic\nentity composition under zero-shot out-of-domain (OOD) generalization, where\nsuch dynamic changes cannot be anticipated beforehand. Our empirical studies\nreveal that existing MARL methods suffer significant performance degradation\nand increased uncertainty in these scenarios. In response, we propose\nFlickerFusion, a novel OOD generalization method that acts as a universally\napplicable augmentation technique for MARL backbone methods. Our results show\nthat FlickerFusion not only achieves superior inference rewards but also\nuniquely reduces uncertainty vis-\\`a-vis the backbone, compared to existing\nmethods. For standardized evaluation, we introduce MPEv2, an enhanced version\nof Multi Particle Environments (MPE), consisting of 12 benchmarks. Benchmarks,\nimplementations, and trained models are organized and open-sourced at\nflickerfusion305.github.io, accompanied by ample demo video renderings.\n","authors":["Woosung Koh","Wonbeen Oh","Siyeol Kim","Suhin Shin","Hyeongjin Kim","Jaein Jang","Junghyun Lee","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2410.15876v1.pdf","comment":"NeurIPS '24 Open-World Agents Workshop"},{"id":"http://arxiv.org/abs/2410.15875v1","updated":"2024-10-21T10:57:25Z","published":"2024-10-21T10:57:25Z","title":"Enabling Asymmetric Knowledge Transfer in Multi-Task Learning with\n  Self-Auxiliaries","summary":"  Knowledge transfer in multi-task learning is typically viewed as a dichotomy;\npositive transfer, which improves the performance of all tasks, or negative\ntransfer, which hinders the performance of all tasks. In this paper, we\ninvestigate the understudied problem of asymmetric task relationships, where\nknowledge transfer aids the learning of certain tasks while hindering the\nlearning of others. We propose an optimisation strategy that includes\nadditional cloned tasks named self-auxiliaries into the learning process to\nflexibly transfer knowledge between tasks asymmetrically. Our method can\nexploit asymmetric task relationships, benefiting from the positive transfer\ncomponent while avoiding the negative transfer component. We demonstrate that\nasymmetric knowledge transfer provides substantial improvements in performance\ncompared to existing multi-task optimisation strategies on benchmark computer\nvision problems.\n","authors":["Olivier Graffeuille","Yun Sing Koh","Joerg Wicker","Moritz Lehmann"],"pdf_url":"https://arxiv.org/pdf/2410.15875v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04133v2","updated":"2024-10-21T10:56:37Z","published":"2024-10-05T12:12:02Z","title":"An Electrocardiogram Foundation Model Built on over 10 Million\n  Recordings with External Evaluation across Multiple Domains","summary":"  Artificial intelligence (AI) has demonstrated significant potential in ECG\nanalysis and cardiovascular disease assessment. Recently, foundation models\nhave played a remarkable role in advancing medical AI. The development of an\nECG foundation model holds the promise of elevating AI-ECG research to new\nheights. However, building such a model faces several challenges, including\ninsufficient database sample sizes and inadequate generalization across\nmultiple domains. Additionally, there is a notable performance gap between\nsingle-lead and multi-lead ECG analyses. We introduced an ECG Foundation Model\n(ECGFounder), a general-purpose model that leverages real-world ECG annotations\nfrom cardiology experts to broaden the diagnostic capabilities of ECG analysis.\nECGFounder was trained on over 10 million ECGs with 150 label categories from\nthe Harvard-Emory ECG Database, enabling comprehensive cardiovascular disease\ndiagnosis through ECG analysis. The model is designed to be both an effective\nout-of-the-box solution, and a to be fine-tunable for downstream tasks,\nmaximizing usability. Importantly, we extended its application to lower rank\nECGs, and arbitrary single-lead ECGs in particular. ECGFounder is applicable to\nsupporting various downstream tasks in mobile monitoring scenarios.\nExperimental results demonstrate that ECGFounder achieves expert-level\nperformance on internal validation sets, with AUROC exceeding 0.95 for eighty\ndiagnoses. It also shows strong classification performance and generalization\nacross various diagnoses on external validation sets. When fine-tuned,\nECGFounder outperforms baseline models in demographic analysis, clinical event\ndetection, and cross-modality cardiac rhythm diagnosis. The trained model and\ndata will be publicly released upon publication through the bdsp.io. Our code\nis available at https://github.com/bdsp-core/ECGFounder\n","authors":["Jun Li","Aaron Aguirre","Junior Moura","Che Liu","Lanhai Zhong","Chenxi Sun","Gari Clifford","Brandon Westover","Shenda Hong"],"pdf_url":"https://arxiv.org/pdf/2410.04133v2.pdf","comment":"working in progress"},{"id":"http://arxiv.org/abs/2404.07989v3","updated":"2024-10-21T10:54:55Z","published":"2024-04-11T17:59:45Z","title":"Any2Point: Empowering Any-modality Large Models for Efficient 3D\n  Understanding","summary":"  Large foundation models have recently emerged as a prominent focus of\ninterest, attaining superior performance in widespread scenarios. Due to the\nscarcity of 3D data, many efforts have been made to adapt pre-trained\ntransformers from vision to 3D domains. However, such 2D-to-3D approaches are\nstill limited, due to the potential loss of spatial geometries and high\ncomputation cost. More importantly, their frameworks are mainly designed for 2D\nmodels, lacking a general any-to-3D paradigm. In this paper, we introduce\nAny2Point, a parameter-efficient method to empower any-modality large models\n(vision, language, audio) for 3D understanding. Given a frozen transformer from\nany source modality, we propose a 3D-to-any (1D or 2D) virtual projection\nstrategy that correlates the input 3D points to the original 1D or 2D positions\nwithin the source modality. This mechanism enables us to assign each 3D token\nwith a positional encoding paired with the pre-trained model, which avoids 3D\ngeometry loss caused by the true projection and better motivates the\ntransformer for 3D learning with 1D/2D positional priors. Then, within each\ntransformer block, we insert an any-to-3D guided adapter module for\nparameter-efficient fine-tuning. The adapter incorporates prior spatial\nknowledge from the source modality to guide the local feature aggregation of 3D\ntokens, compelling the semantic adaption of any-modality transformers. We\nconduct extensive experiments to showcase the effectiveness and efficiency of\nour method. Code and models are released at\nhttps://github.com/Ivan-Tang-3D/Any2Point.\n","authors":["Yiwen Tang","Ray Zhang","Jiaming Liu","Zoey Guo","Dong Wang","Zhigang Wang","Bin Zhao","Shanghang Zhang","Peng Gao","Hongsheng Li","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2404.07989v3.pdf","comment":"Code and models are released at\n  https://github.com/Ivan-Tang-3D/Any2Point"}]},"2024-10-20T00:00:00Z":{"Robotics":[{"id":"http://arxiv.org/abs/2410.15536v1","updated":"2024-10-20T23:33:06Z","published":"2024-10-20T23:33:06Z","title":"GRS: Generating Robotic Simulation Tasks from Real-World Images","summary":"  We introduce GRS (Generating Robotic Simulation tasks), a novel system to\naddress the challenge of real-to-sim in robotics, computer vision, and AR/VR.\nGRS enables the creation of digital twin simulations from single real-world\nRGB-D observations, complete with diverse, solvable tasks for virtual agent\ntraining. We use state-of-the-art vision-language models (VLMs) to achieve a\ncomprehensive real-to-sim pipeline. GRS operates in three stages: 1) scene\ncomprehension using SAM2 for object segmentation and VLMs for object\ndescription, 2) matching identified objects with simulation-ready assets, and\n3) generating contextually appropriate robotic tasks. Our approach ensures\nsimulations align with task specifications by generating test suites designed\nto verify adherence to the task specification. We introduce a router that\niteratively refines the simulation and test code to ensure the simulation is\nsolvable by a robot policy while remaining aligned to the task specification.\nOur experiments demonstrate the system's efficacy in accurately identifying\nobject correspondence, which allows us to generate task environments that\nclosely match input environments, and enhance automated simulation task\ngeneration through our novel router mechanism.\n","authors":["Alex Zook","Fan-Yun Sun","Josef Spjut","Valts Blukis","Stan Birchfield","Jonathan Tremblay"],"pdf_url":"https://arxiv.org/pdf/2410.15536v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.13707v2","updated":"2024-10-20T22:21:46Z","published":"2024-06-19T17:03:45Z","title":"Safety-Critical Formation Control of Non-Holonomic Multi-Robot Systems\n  in Communication-Limited Environments","summary":"  This paper presents a novel estimator-based safety-critical controller for\nformation control of non-holonomic mobile robots in communication-limited\nenvironments. The proposed decentralized framework integrates a robust state\nestimator with a formation tracking control law, addressing the challenges of\ninter-agent collision avoidance and disturbance attenuation in leader-follower\nformations using control barrier functions. The estimator's design accounts for\nboth constant and time-varying velocity profiles, enhancing the system's\nadaptability to dynamic scenarios. A closed-form solution for the tracking\ncontroller facilitates efficient implementation while maintaining formation\nintegrity. The incorporation of string stability metrics further reinforces the\nframework's resilience against propagating disturbances from predecessors.\nRigorous stability analysis using Lyapunov functions ensures the stability of\nestimation errors and the convergence of the formation to desired\nconfigurations. The effectiveness and robustness of the proposed approach are\nvalidated through numerical simulations of various maneuvers and realistic\nGazebo experiments involving formations in a warehouse environment. The results\ndemonstrate the controller's ability to maintain safety, achieve precise\nformation control, and mitigate disturbances in scenarios without inter-robot\ncommunication.\n","authors":["Vishrut Bohara","Siavash Farzan"],"pdf_url":"https://arxiv.org/pdf/2406.13707v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2410.15498v1","updated":"2024-10-20T20:30:35Z","published":"2024-10-20T20:30:35Z","title":"Quasi-Static Continuum Model of Octopus-Like Soft Robot Arm Under Water\n  Actuated by Twisted and Coiled Artificial Muscles (TCAMs)","summary":"  The current work is a qualitative study that aims to explore the\nimplementation of Twisted and Coiled Artificial Muscles (TCAMs) for actuating\nand replicating the bending motion of an octopus-like soft robot arm\nunderwater. Additionally, it investigates the impact of hydrostatic and dynamic\nforces from steady-state fluid flow on the arm's motion. The artificial muscles\nare lightweight and low-cost actuators that generate a high power-to-weight\nratio, producing tensile force up to 12,600 times their own weight, which is\nclose to the functionality of biological muscles. The \"extended\" Cosserat\ntheory of rods is employed to formulate a quasi-static continuum model of arm\nmotion, where the arm's cross-section is not only capable of rigid rotation but\nalso deforms within its plane. This planar deformation of the arm cross-section\naligns with the biological behavior of the octopus arm, where the stiffness of\nthe hydrostat is directly induced by the incompressibility of the tissues. In\nline with the main goal, a constitutive model is derived for the material of\nthe octopus arm to capture its characteristic behavior.\n","authors":["Amirreza Fahim Golestaneh","Venanzio Cichella","Caterina Lamuta"],"pdf_url":"https://arxiv.org/pdf/2410.15498v1.pdf","comment":"12 pages, Under review at the journal \"Robotics Reports\""},{"id":"http://arxiv.org/abs/2410.15489v1","updated":"2024-10-20T20:07:08Z","published":"2024-10-20T20:07:08Z","title":"Generative AI Agents in Autonomous Machines: A Safety Perspective","summary":"  The integration of Generative Artificial Intelligence (AI) into autonomous\nmachines represents a major paradigm shift in how these systems operate and\nunlocks new solutions to problems once deemed intractable. Although generative\nAI agents provide unparalleled capabilities, they also have unique safety\nconcerns. These challenges require robust safeguards, especially for autonomous\nmachines that operate in high-stakes environments. This work investigates the\nevolving safety requirements when generative models are integrated as agents\ninto physical autonomous machines, comparing these to safety considerations in\nless critical AI applications. We explore the challenges and opportunities to\nensure the safe deployment of generative AI-driven autonomous machines.\nFurthermore, we provide a forward-looking perspective on the future of\nAI-driven autonomous systems and emphasize the importance of evaluating and\ncommunicating safety risks. As an important step towards addressing these\nconcerns, we recommend the development and implementation of comprehensive\nsafety scorecards for the use of generative AI technologies in autonomous\nmachines.\n","authors":["Jason Jabbour","Vijay Janapa Reddi"],"pdf_url":"https://arxiv.org/pdf/2410.15489v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15486v1","updated":"2024-10-20T19:51:27Z","published":"2024-10-20T19:51:27Z","title":"Evaluating Transferable Emotion Expressions for Zoomorphic Social Robots\n  using VR Prototyping","summary":"  Zoomorphic robots have the potential to offer companionship and well-being as\naccessible, low-maintenance alternatives to pet ownership. Many such robots,\nhowever, feature limited emotional expression, restricting their potential for\nrich affective relationships with everyday domestic users. Additionally,\nexploring this design space using hardware prototyping is obstructed by\nphysical and logistical constraints. We leveraged virtual reality rapid\nprototyping with passive haptic interaction to conduct a broad mixed-methods\nevaluation of emotion expression modalities and participatory prototyping of\nmultimodal expressions. We found differences in recognisability, effectiveness\nand user empathy between modalities while highlighting the importance of facial\nexpressions and the benefits of combining animal-like and unambiguous\nmodalities. We use our findings to inform promising directions for the\naffective zoomorphic robot design and potential implementations via hardware\nmodification or augmented reality, then discuss how VR prototyping makes this\nfield more accessible to designers and researchers.\n","authors":["Shaun Macdonald","Robin Bretin","Salma ElSayed"],"pdf_url":"https://arxiv.org/pdf/2410.15486v1.pdf","comment":"10 pages, 9 figures, accepted to 23rd IEEE International Symposium on\n  Mixed and Augmented Reality (ISMAR 2024)"},{"id":"http://arxiv.org/abs/2410.15469v1","updated":"2024-10-20T18:51:17Z","published":"2024-10-20T18:51:17Z","title":"AssemblyComplete: 3D Combinatorial Construction with Deep Reinforcement\n  Learning","summary":"  A critical goal in robotics and autonomy is to teach robots to adapt to\nreal-world collaborative tasks, particularly in automatic assembly. The ability\nof a robot to understand the original intent of an incomplete assembly and\ncomplete missing features without human instruction is valuable but\nchallenging. This paper introduces 3D combinatorial assembly completion, which\nis demonstrated using combinatorial unit primitives (i.e., Lego bricks).\nCombinatorial assembly is challenging due to the possible assembly combinations\nand complex physical constraints (e.g., no brick collisions, structure\nstability, inventory constraints, etc.). To address these challenges, we\npropose a two-part deep reinforcement learning (DRL) framework that tackles\nteaching the robot to understand the objective of an incomplete assembly and\nlearning a construction policy to complete the assembly. The robot queries a\nstable object library to facilitate assembly inference and guide learning. In\naddition to the robot policy, an action mask is developed to rule out invalid\nactions that violate physical constraints for object-oriented construction. We\ndemonstrate the proposed framework's feasibility and robustness in a variety of\nassembly scenarios in which the robot satisfies real-life assembly with respect\nto both solution and runtime quality. Furthermore, results demonstrate that the\nproposed framework effectively infers and assembles incomplete structures for\nunseen and unique object types.\n","authors":["Alan Chen","Changliu Liu"],"pdf_url":"https://arxiv.org/pdf/2410.15469v1.pdf","comment":"Submitted to 2025 American Control Conference (ACC)"},{"id":"http://arxiv.org/abs/2410.15461v1","updated":"2024-10-20T18:24:00Z","published":"2024-10-20T18:24:00Z","title":"EVA: An Embodied World Model for Future Video Anticipation","summary":"  World models integrate raw data from various modalities, such as images and\nlanguage to simulate comprehensive interactions in the world, thereby\ndisplaying crucial roles in fields like mixed reality and robotics. Yet,\napplying the world model for accurate video prediction is quite challenging due\nto the complex and dynamic intentions of the various scenes in practice. In\nthis paper, inspired by the human rethinking process, we decompose the complex\nvideo prediction into four meta-tasks that enable the world model to handle\nthis issue in a more fine-grained manner. Alongside these tasks, we introduce a\nnew benchmark named Embodied Video Anticipation Benchmark (EVA-Bench) to\nprovide a well-rounded evaluation. EVA-Bench focused on evaluating the video\nprediction ability of human and robot actions, presenting significant\nchallenges for both the language model and the generation model. Targeting\nembodied video prediction, we propose the Embodied Video Anticipator (EVA), a\nunified framework aiming at video understanding and generation. EVA integrates\na video generation model with a visual language model, effectively combining\nreasoning capabilities with high-quality generation. Moreover, to enhance the\ngeneralization of our framework, we tailor-designed a multi-stage pretraining\nparadigm that adaptatively ensembles LoRA to produce high-fidelity results.\nExtensive experiments on EVA-Bench highlight the potential of EVA to\nsignificantly improve performance in embodied scenes, paving the way for\nlarge-scale pre-trained models in real-world prediction tasks.\n","authors":["Xiaowei Chi","Hengyuan Zhang","Chun-Kai Fan","Xingqun Qi","Rongyu Zhang","Anthony Chen","Chi-min Chan","Wei Xue","Wenhan Luo","Shanghang Zhang","Yike Guo"],"pdf_url":"https://arxiv.org/pdf/2410.15461v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.08588v2","updated":"2024-10-20T17:57:03Z","published":"2023-10-12T17:59:58Z","title":"Octopus: Embodied Vision-Language Programmer from Environmental Feedback","summary":"  Large vision-language models (VLMs) have achieved substantial progress in\nmultimodal perception and reasoning. When integrated into an embodied agent,\nexisting embodied VLM works either output detailed action sequences at the\nmanipulation level or only provide plans at an abstract level, leaving a gap\nbetween high-level planning and real-world manipulation. To bridge this gap, we\nintroduce Octopus, an embodied vision-language programmer that uses executable\ncode generation as a medium to connect planning and manipulation. Octopus is\ndesigned to 1) proficiently comprehend an agent's visual and textual task\nobjectives, 2) formulate intricate action sequences, and 3) generate executable\ncode. To facilitate Octopus model development, we introduce OctoVerse: a suite\nof environments tailored for benchmarking vision-based code generators on a\nwide spectrum of tasks, ranging from mundane daily chores in simulators to\nsophisticated interactions in complex video games such as Grand Theft Auto\n(GTA) and Minecraft. To train Octopus, we leverage GPT-4 to control an\nexplorative agent that generates training data, i.e., action blueprints and\ncorresponding executable code. We also collect feedback that enables an\nenhanced training scheme called Reinforcement Learning with Environmental\nFeedback (RLEF). Through a series of experiments, we demonstrate Octopus's\nfunctionality and present compelling results, showing that the proposed RLEF\nrefines the agent's decision-making. By open-sourcing our simulation\nenvironments, dataset, and model architecture, we aspire to ignite further\ninnovation and foster collaborative applications within the broader embodied AI\ncommunity.\n","authors":["Jingkang Yang","Yuhao Dong","Shuai Liu","Bo Li","Ziyue Wang","Chencheng Jiang","Haoran Tan","Jiamu Kang","Yuanhan Zhang","Kaiyang Zhou","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2310.08588v2.pdf","comment":"Project Page: https://choiszt.github.io/Octopus/, Codebase:\n  https://github.com/dongyh20/Octopus"},{"id":"http://arxiv.org/abs/2403.09900v4","updated":"2024-10-20T17:35:15Z","published":"2024-03-14T22:22:22Z","title":"DTG : Diffusion-based Trajectory Generation for Mapless Global\n  Navigation","summary":"  We present a novel end-to-end diffusion-based trajectory generation method,\nDTG, for mapless global navigation in challenging outdoor scenarios with\nocclusions and unstructured off-road features like grass, buildings, bushes,\netc. Given a distant goal, our approach computes a trajectory that satisfies\nthe following goals: (1) minimize the travel distance to the goal; (2) maximize\nthe traversability by choosing paths that do not lie in undesirable areas.\nSpecifically, we present a novel Conditional RNN(CRNN) for diffusion models to\nefficiently generate trajectories. Furthermore, we propose an adaptive training\nmethod that ensures that the diffusion model generates more traversable\ntrajectories. We evaluate our methods in various outdoor scenes and compare the\nperformance with other global navigation algorithms on a Husky robot. In\npractice, we observe at least a 15% improvement in traveling distance and\naround a 7% improvement in traversability.\n","authors":["Jing Liang","Amirreza Payandeh","Daeun Song","Xuesu Xiao","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2403.09900v4.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2409.00303v2","updated":"2024-10-20T17:24:26Z","published":"2024-08-31T00:00:39Z","title":"Rapid and Robust Trajectory Optimization for Humanoids","summary":"  Performing trajectory design for humanoid robots with high degrees of freedom\nis computationally challenging. The trajectory design process also often\ninvolves carefully selecting various hyperparameters and requires a good\ninitial guess which can further complicate the development process. This work\nintroduces a generalized gait optimization framework that directly generates\nsmooth and physically feasible trajectories. The proposed method demonstrates\nfaster and more robust convergence than existing techniques and explicitly\nincorporates closed-loop kinematic constraints that appear in many modern\nhumanoids. The method is implemented as an open-source C++ codebase which can\nbe found at https://roahmlab.github.io/RAPTOR/.\n","authors":["Bohao Zhang","Ram Vasudevan"],"pdf_url":"https://arxiv.org/pdf/2409.00303v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15443v1","updated":"2024-10-20T16:39:15Z","published":"2024-10-20T16:39:15Z","title":"Lie Theory Based Optimization for Unified State Planning of Mobile\n  Manipulators","summary":"  Mobile manipulators are finding use in numerous practical applications. The\ncurrent issues with mobile manipulation are the large state space owing to the\nmobile base and the challenge of modeling high degree of freedom systems. It is\ncritical to devise fast and accurate algorithms that generate smooth motion\nplans for such mobile manipulators. Existing techniques attempt to solve this\nproblem but focus on separating the motion of the base and manipulator. We\npropose an approach using Lie theory to find the inverse kinematic constraints\nby converting the kinematic model, created using screw coordinates, between its\nLie group and vector representation. An optimization function is devised to\nsolve for the desired joint states of the entire mobile manipulator. This\nallows the motion of the mobile base and manipulator to be planned and applied\nin unison resulting in a smooth and accurate motion plan. The performance of\nthe proposed state planner is validated on simulated mobile manipulators in an\nanalytical experiment. Our solver is available with further derivations and\nresults at https://github.com/peleito/slithers.\n","authors":["William Smith","Siddharth Singh","Julia Rudy","Yuxiang Guan"],"pdf_url":"https://arxiv.org/pdf/2410.15443v1.pdf","comment":"8 pages, 9 figures, conference submission"},{"id":"http://arxiv.org/abs/2410.15414v1","updated":"2024-10-20T15:11:04Z","published":"2024-10-20T15:11:04Z","title":"An Agile Large-Workspace Teleoperation Interface Based on Human Arm\n  Motion and Force Estimation","summary":"  Teleoperation can transfer human perception and cognition to a slave robot to\ncope with some complex tasks, in which the agility and flexibility of the\ninterface play an important role in mapping human intention to the robot. In\nthis paper, we developed an agile large-workspace teleoperation interface by\nestimating human arm behavior. Using the wearable sensor, namely the inertial\nmeasurement unit and surface electromyography armband, we can capture the human\narm motion and force information, thereby intuitively controlling the\nmanipulation of the robot. The control principle of our wearable interface\nincludes two parts: (1) the arm incremental kinematics and (2) the grasping\nrecognition. Moreover, we developed a teleoperation framework with a time\nsynchronization mechanism for the real-time application. We conducted\nexperimental comparisons with a versatile haptic device (Omega 7) to verify the\neffectiveness of our interface and framework. Seven subjects are invited to\ncomplete three different tasks: free motion, handover, and pick-and-place\naction (each task ten times), and the total number of tests is 420.\nObjectively, we used the task completion time and success rate to compare the\nperformance of the two interfaces quantitatively. In addition, to quantify the\noperator experience, we used the NASA Task Load Index to assess their\nsubjective feelings. The results showed that the proposed interface achieved a\ncompetitive performance with a better operating experience.\n","authors":["Jianhang Jia","Hao Zhou","Xin Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.15414v1.pdf","comment":"6 pages, 8 figures, accepted by 2024 IEEE International Conference on\n  Robotics and Biomimetics (IEEE ROBIO 2024)"},{"id":"http://arxiv.org/abs/2410.15398v1","updated":"2024-10-20T14:17:00Z","published":"2024-10-20T14:17:00Z","title":"Evaluation of Human-Robot Interfaces based on 2D/3D Visual and Haptic\n  Feedback for Aerial Manipulation","summary":"  Most telemanipulation systems for aerial robots provide the operator with\nonly 2D screen visual information. The lack of richer information about the\nrobot's status and environment can limit human awareness and, in turn, task\nperformance. While the pilot's experience can often compensate for this reduced\nflow of information, providing richer feedback is expected to reduce the\ncognitive workload and offer a more intuitive experience overall. This work\naims to understand the significance of providing additional pieces of\ninformation during aerial telemanipulation, namely (i) 3D immersive visual\nfeedback about the robot's surroundings through mixed reality (MR) and (ii) 3D\nhaptic feedback about the robot interaction with the environment. To do so, we\ndeveloped a human-robot interface able to provide this information. First, we\ndemonstrate its potential in a real-world manipulation task requiring\nsub-centimeter-level accuracy. Then, we evaluate the individual effect of MR\nvision and haptic feedback on both dexterity and workload through a human\nsubjects study involving a virtual block transportation task. Results show that\nboth 3D MR vision and haptic feedback improve the operator's dexterity in the\nconsidered teleoperated aerial interaction tasks. Nevertheless, pilot\nexperience remains the most significant factor.\n","authors":["Julien Mellet","Mike Allenspach","Eugenio Cuniato","Claudio Pacchierotti","Roland Siegwart","Marco Tognon"],"pdf_url":"https://arxiv.org/pdf/2410.15398v1.pdf","comment":"12 pages, 11 figures, journal paper"},{"id":"http://arxiv.org/abs/2410.15394v1","updated":"2024-10-20T13:49:44Z","published":"2024-10-20T13:49:44Z","title":"A Semi-decentralized and Variational-Equilibrium-Based Trajectory\n  Planner for Connected and Autonomous Vehicles","summary":"  This paper designs a novel trajectory planning approach to resolve the\ncomputational efficiency and safety problems in uncoordinated methods by\nexploiting vehicle-to-everything (V2X) technology. The trajectory planning for\nconnected and autonomous vehicles (CAVs) is formulated as a game with coupled\nsafety constraints. We then define interaction-fair trajectories and prove that\nthey correspond to the variational equilibrium (VE) of this game. We propose a\nsemi-decentralized planner for the vehicles to seek VE-based fair trajectories,\nwhich can significantly improve computational efficiency through parallel\ncomputing among CAVs and enhance the safety of planned trajectories by ensuring\nequilibrium concordance among CAVs. Finally, experimental results show the\nadvantages of the approach, including fast computation speed, high scalability,\nequilibrium concordance, and safety.\n","authors":["Zhengqin Liu","Jinlong Lei","Peng Yi"],"pdf_url":"https://arxiv.org/pdf/2410.15394v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15373v1","updated":"2024-10-20T12:13:45Z","published":"2024-10-20T12:13:45Z","title":"DynaVINS++: Robust Visual-Inertial State Estimator in Dynamic\n  Environments by Adaptive Truncated Least Squares and Stable State Recovery","summary":"  Despite extensive research in robust visual-inertial navigation\nsystems~(VINS) in dynamic environments, many approaches remain vulnerable to\nobjects that suddenly start moving, which are referred to as \\textit{abruptly\ndynamic objects}. In addition, most approaches have considered the effect of\ndynamic objects only at the feature association level. In this study, we\nobserved that the state estimation diverges when errors from false\ncorrespondences owing to moving objects incorrectly propagate into the IMU bias\nterms. To overcome these problems, we propose a robust VINS framework called\n\\mbox{\\textit{DynaVINS++}}, which employs a) adaptive truncated least square\nmethod that adaptively adjusts the truncation range using both feature\nassociation and IMU preintegration to effectively minimize the effect of the\ndynamic objects while reducing the computational cost, and b)~stable state\nrecovery with bias consistency check to correct misestimated IMU bias and to\nprevent the divergence caused by abruptly dynamic objects. As verified in both\npublic and real-world datasets, our approach shows promising performance in\ndynamic environments, including scenes with abruptly dynamic objects.\n","authors":["Seungwon Song","Hyungtae Lim","Alex Junho Lee","Hyun Myung"],"pdf_url":"https://arxiv.org/pdf/2410.15373v1.pdf","comment":"8 pages, 7 figures. S. Song, H. Lim, A. J. Lee and H. Myung,\n  \"DynaVINS++: Robust Visual-Inertial State Estimator in Dynamic Environments\n  by Adaptive Truncated Least Squares and Stable State Recovery,\" in IEEE\n  Robotics and Automation Letters, vol. 9, no. 10, pp. 9127-9134, Oct. 2024"},{"id":"http://arxiv.org/abs/2403.10940v3","updated":"2024-10-20T12:04:15Z","published":"2024-03-16T14:52:26Z","title":"ViSaRL: Visual Reinforcement Learning Guided by Human Saliency","summary":"  Training robots to perform complex control tasks from high-dimensional pixel\ninput using reinforcement learning (RL) is sample-inefficient, because image\nobservations are comprised primarily of task-irrelevant information. By\ncontrast, humans are able to visually attend to task-relevant objects and\nareas. Based on this insight, we introduce Visual Saliency-Guided Reinforcement\nLearning (ViSaRL). Using ViSaRL to learn visual representations significantly\nimproves the success rate, sample efficiency, and generalization of an RL agent\non diverse tasks including DeepMind Control benchmark, robot manipulation in\nsimulation and on a real robot. We present approaches for incorporating\nsaliency into both CNN and Transformer-based encoders. We show that visual\nrepresentations learned using ViSaRL are robust to various sources of visual\nperturbations including perceptual noise and scene variations. ViSaRL nearly\ndoubles success rate on the real-robot tasks compared to the baseline which\ndoes not use saliency.\n","authors":["Anthony Liang","Jesse Thomason","Erdem Bıyık"],"pdf_url":"https://arxiv.org/pdf/2403.10940v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15321v1","updated":"2024-10-20T07:31:07Z","published":"2024-10-20T07:31:07Z","title":"Integrated Design and Control of a Robotic Arm on a Quadcopter for\n  Enhanced Package Delivery","summary":"  This paper presents a comprehensive design process for the integration of a\nrobotic arm into a quadcopter, emphasizing the physical modeling, system\nintegration, and controller development. Utilizing SolidWorks for mechanical\ndesign and MATLAB Simscape for simulation and control, this study addresses the\nchallenges encountered in integrating the robotic arm with the drone,\nencompassing both mechanical and control aspects. Two types of controllers are\ndeveloped and analyzed: a Proportional-Integral-Derivative (PID) controller and\na Model Reference Adaptive Controller (MRAC). The design and tuning of these\ncontrollers are key components of this research, with the focus on their\napplication in package delivery tasks. Extensive simulations demonstrate the\nperformance of each controller, with PID controllers exhibiting superior\ntrajectory tracking and lower Root Mean Square (RMS) errors under various\npayload conditions. The results underscore the efficacy of PID control for\nstable flight and precise maneuvering, while highlighting adaptability of MRAC\nto changing dynamics.\n","authors":["Animesh Singh","Jason Hillyer","Fariba Ariaei","Hossein Jula"],"pdf_url":"https://arxiv.org/pdf/2410.15321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.13707v2","updated":"2024-10-20T05:23:35Z","published":"2023-09-24T17:40:19Z","title":"ORLA*: Mobile Manipulator-Based Object Rearrangement with Lazy A Star","summary":"  Effectively performing object rearrangement is an essential skill for mobile\nmanipulators, e.g., setting up a dinner table or organizing a desk. A key\nchallenge in such problems is deciding an appropriate manipulation order for\nobjects to effectively untangle dependencies between objects while considering\nthe necessary motions for realizing the manipulations (e.g., pick and place).\nTo our knowledge, computing time-optimal multi-object rearrangement solutions\nfor mobile manipulators remains a largely untapped research direction. In this\nresearch, we propose ORLA*, which leverages delayed (lazy) evaluation in\nsearching for a high-quality object pick and place sequence that considers both\nend-effector and mobile robot base travel. ORLA* also supports multi-layered\nrearrangement tasks considering pile stability using machine learning.\nEmploying an optimal solver for finding temporary locations for displacing\nobjects, ORLA* can achieve global optimality. Through extensive simulation and\nablation study, we confirm the effectiveness of ORLA* delivering quality\nsolutions for challenging rearrangement instances. Supplementary materials are\navailable at: https://gaokai15.github.io/ORLA-Star/\n","authors":["Kai Gao"," Zhaxizhuoma","Yan Ding","Shiqi Zhang","Jingjin Yu"],"pdf_url":"https://arxiv.org/pdf/2309.13707v2.pdf","comment":"Submitted to ICRA 2025"},{"id":"http://arxiv.org/abs/2410.15281v1","updated":"2024-10-20T04:36:19Z","published":"2024-10-20T04:36:19Z","title":"Large Language Models for Autonomous Driving (LLM4AD): Concept,\n  Benchmark, Simulation, and Real-Vehicle Experiment","summary":"  With the broader usage and highly successful development of Large Language\nModels (LLMs), there has been a growth of interest and demand for applying LLMs\nto autonomous driving technology. Driven by their natural language\nunderstanding and reasoning ability, LLMs have the potential to enhance various\naspects of autonomous driving systems, from perception and scene understanding\nto language interaction and decision-making. In this paper, we first introduce\nnovel concepts and approaches to designing LLMs for autonomous driving\n(LLM4AD). Then, we propose a comprehensive benchmark for evaluating the\ninstruction-following abilities of LLMs within the autonomous driving domain.\nFurthermore, we conduct a series of experiments on both simulation and\nreal-world vehicle platforms, thoroughly evaluating the performance and\npotential of our LLM4AD systems. Our research highlights the significant\npotential of LLMs to enhance various aspects of autonomous vehicle technology,\nfrom perception and scene understanding to language interaction and\ndecision-making.\n","authors":["Can Cui","Yunsheng Ma","Zichong Yang","Yupeng Zhou","Peiran Liu","Juanwu Lu","Lingxi Li","Yaobin Chen","Jitesh H. Panchal","Amr Abdelraouf","Rohit Gupta","Kyungtae Han","Ziran Wang"],"pdf_url":"https://arxiv.org/pdf/2410.15281v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12568v2","updated":"2024-10-20T04:35:34Z","published":"2024-10-16T13:43:00Z","title":"Robust RL with LLM-Driven Data Synthesis and Policy Adaptation for\n  Autonomous Driving","summary":"  The integration of Large Language Models (LLMs) into autonomous driving\nsystems demonstrates strong common sense and reasoning abilities, effectively\naddressing the pitfalls of purely data-driven methods. Current LLM-based agents\nrequire lengthy inference times and face challenges in interacting with\nreal-time autonomous driving environments. A key open question is whether we\ncan effectively leverage the knowledge from LLMs to train an efficient and\nrobust Reinforcement Learning (RL) agent. This paper introduces RAPID, a novel\n\\underline{\\textbf{R}}obust \\underline{\\textbf{A}}daptive\n\\underline{\\textbf{P}}olicy \\underline{\\textbf{I}}nfusion and\n\\underline{\\textbf{D}}istillation framework, which trains specialized\nmix-of-policy RL agents using data synthesized by an LLM-based driving agent\nand online adaptation. RAPID features three key designs: 1) utilization of\noffline data collected from an LLM agent to distil expert knowledge into RL\npolicies for faster real-time inference; 2) introduction of robust distillation\nin RL to inherit both performance and robustness from LLM-based teacher; and 3)\nemployment of a mix-of-policy approach for joint decision decoding with a\npolicy adapter. Through fine-tuning via online environment interaction, RAPID\nreduces the forgetting of LLM knowledge while maintaining adaptability to\ndifferent tasks. Extensive experiments demonstrate RAPID's capability to\neffectively integrate LLM knowledge into scaled-down RL policies in an\nefficient, adaptable, and robust way. Code and checkpoints will be made\npublicly available upon acceptance.\n","authors":["Sihao Wu","Jiaxu Liu","Xiangyu Yin","Guangliang Cheng","Xingyu Zhao","Meng Fang","Xinping Yi","Xiaowei Huang"],"pdf_url":"https://arxiv.org/pdf/2410.12568v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.10023v5","updated":"2024-10-20T03:09:04Z","published":"2023-10-16T02:51:24Z","title":"3D-BBS: Global Localization for 3D Point Cloud Scan Matching Using\n  Branch-and-Bound Algorithm","summary":"  This paper presents an accurate and fast 3D global localization method,\n3D-BBS, that extends the existing branch-and-bound (BnB)-based 2D scan matching\n(BBS) algorithm. To reduce memory consumption, we utilize a sparse hash table\nfor storing hierarchical 3D voxel maps. To improve the processing cost of BBS\nin 3D space, we propose an efficient roto-translational space branching.\nFurthermore, we devise a batched BnB algorithm to fully leverage GPU parallel\nprocessing. Through experiments in simulated and real environments, we\ndemonstrated that the 3D-BBS enabled accurate global localization with only a\n3D LiDAR scan roughly aligned in the gravity direction and a 3D pre-built map.\nThis method required only 878 msec on average to perform global localization\nand outperformed state-of-the-art global registration methods in terms of\naccuracy and processing speed.\n","authors":["Koki Aoki","Kenji Koide","Shuji Oishi","Masashi Yokozuka","Atsuhiko Banno","Junichi Meguro"],"pdf_url":"https://arxiv.org/pdf/2310.10023v5.pdf","comment":"IEEE International Conference on Robotics and Automation (ICRA2024)"},{"id":"http://arxiv.org/abs/2405.04702v2","updated":"2024-10-20T02:25:44Z","published":"2024-05-07T22:42:04Z","title":"Mitigating Side Effects in Multi-Agent Systems Using Blame Assignment","summary":"  When independently trained or designed robots are deployed in a shared\nenvironment, their combined actions can lead to unintended negative side\neffects (NSEs). To ensure safe and efficient operation, robots must optimize\ntask performance while minimizing the penalties associated with NSEs, balancing\nindividual objectives with collective impact. We model the problem of\nmitigating NSEs in a cooperative multi-agent system as a bi-objective\nlexicographic decentralized Markov decision process. We assume independence of\ntransitions and rewards with respect to the robots' tasks, but the joint NSE\npenalty creates a form of dependence in this setting. To improve scalability,\nthe joint NSE penalty is decomposed into individual penalties for each robot\nusing credit assignment, which facilitates decentralized policy computation. We\nempirically demonstrate, using mobile robots and in simulation, the\neffectiveness and scalability of our approach in mitigating NSEs.\n","authors":["Pulkit Rustagi","Sandhya Saisubramanian"],"pdf_url":"https://arxiv.org/pdf/2405.04702v2.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2306.09509v3","updated":"2024-10-20T01:41:59Z","published":"2023-06-15T21:06:54Z","title":"Granger Causal Interaction Skill Chains","summary":"  Reinforcement Learning (RL) has demonstrated promising results in learning\npolicies for complex tasks, but it often suffers from low sample efficiency and\nlimited transferability. Hierarchical RL (HRL) methods aim to address the\ndifficulty of learning long-horizon tasks by decomposing policies into skills,\nabstracting states, and reusing skills in new tasks. However, many HRL methods\nrequire some initial task success to discover useful skills, which\nparadoxically may be very unlikely without access to useful skills. On the\nother hand, reward-free HRL methods often need to learn far too many skills to\nachieve proper coverage in high-dimensional domains. In contrast, we introduce\nthe Chain of Interaction Skills (COInS) algorithm, which focuses on\ncontrollability in factored domains to identify a small number of task-agnostic\nskills that still permit a high degree of control. COInS uses learned detectors\nto identify interactions between state factors and then trains a chain of\nskills to control each of these factors successively. We evaluate COInS on a\nrobotic pushing task with obstacles -- a challenging domain where other RL and\nHRL methods fall short. We also demonstrate the transferability of skills\nlearned by COInS, using variants of Breakout, a common RL benchmark, and show\n2-3x improvement in both sample efficiency and final performance compared to\nstandard RL baselines.\n","authors":["Caleb Chuck","Kevin Black","Aditya Arjun","Yuke Zhu","Scott Niekum"],"pdf_url":"https://arxiv.org/pdf/2306.09509v3.pdf","comment":"Accepted TMLR 2024"},{"id":"http://arxiv.org/abs/2410.15243v1","updated":"2024-10-20T01:12:36Z","published":"2024-10-20T01:12:36Z","title":"An Image-Guided Robotic System for Transcranial Magnetic Stimulation:\n  System Development and Experimental Evaluation","summary":"  Transcranial magnetic stimulation (TMS) is a noninvasive medical procedure\nthat can modulate brain activity, and it is widely used in neuroscience and\nneurology research. Compared to manual operators, robots may improve the\noutcome of TMS due to their superior accuracy and repeatability. However, there\nhas not been a widely accepted standard protocol for performing robotic TMS\nusing fine-segmented brain images, resulting in arbitrary planned angles with\nrespect to the true boundaries of the modulated cortex. Given that the recent\nstudy in TMS simulation suggests a noticeable difference in outcomes when using\ndifferent anatomical details, cortical shape should play a more significant\nrole in deciding the optimal TMS coil pose. In this work, we introduce an\nimage-guided robotic system for TMS that focuses on (1) establishing\nstandardized planning methods and heuristics to define a reference (true zero)\nfor the coil poses and (2) solving the issue that the manual coil placement\nrequires expert hand-eye coordination which often leading to low repeatability\nof the experiments. To validate the design of our robotic system, a phantom\nstudy and a preliminary human subject study were performed. Our results show\nthat the robotic method can half the positional error and improve the\nrotational accuracy by up to two orders of magnitude. The accuracy is proven to\nbe repeatable because the standard deviation of multiple trials is lowered by\nan order of magnitude. The improved actuation accuracy successfully translates\nto the TMS application, with a higher and more stable induced voltage in\nmagnetic field sensors.\n","authors":["Yihao Liu","Jiaming Zhang","Letian Ai","Jing Tian","Shahriar Sefati","Huan Liu","Alejandro Martin-Gomez","Amir Kheradmand","Mehran Armand"],"pdf_url":"https://arxiv.org/pdf/2410.15243v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2410.13837v2","updated":"2024-10-20T00:23:14Z","published":"2024-10-17T17:55:05Z","title":"ORSO: Accelerating Reward Design via Online Reward Selection and Policy\n  Optimization","summary":"  Reward shaping is a critical component in reinforcement learning (RL),\nparticularly for complex tasks where sparse rewards can hinder learning. While\nshaping rewards have been introduced to provide additional guidance, selecting\neffective shaping functions remains challenging and computationally expensive.\nThis paper introduces Online Reward Selection and Policy Optimization (ORSO), a\nnovel approach that frames shaping reward selection as an online model\nselection problem. ORSO employs principled exploration strategies to\nautomatically identify promising shaping reward functions without human\nintervention, balancing exploration and exploitation with provable regret\nguarantees. We demonstrate ORSO's effectiveness across various continuous\ncontrol tasks using the Isaac Gym simulator. Compared to traditional methods\nthat fully evaluate each shaping reward function, ORSO significantly improves\nsample efficiency, reduces computational time, and consistently identifies\nhigh-quality reward functions that produce policies comparable to those\ngenerated by domain experts through hand-engineered rewards.\n","authors":["Chen Bo Calvin Zhang","Zhang-Wei Hong","Aldo Pacchiano","Pulkit Agrawal"],"pdf_url":"https://arxiv.org/pdf/2410.13837v2.pdf","comment":"preprint, 35 pages, 23 figures"}]},"2024-10-19T00:00:00Z":{"Robotics":[{"id":"http://arxiv.org/abs/2410.15185v1","updated":"2024-10-19T19:24:20Z","published":"2024-10-19T19:24:20Z","title":"Semantically Safe Robot Manipulation: From Semantic Scene Understanding\n  to Motion Safeguards","summary":"  Ensuring safe interactions in human-centric environments requires robots to\nunderstand and adhere to constraints recognized by humans as \"common sense\"\n(e.g., \"moving a cup of water above a laptop is unsafe as the water may spill\"\nor \"rotating a cup of water is unsafe as it can lead to pouring its content\").\nRecent advances in computer vision and machine learning have enabled robots to\nacquire a semantic understanding of and reason about their operating\nenvironments. While extensive literature on safe robot decision-making exists,\nsemantic understanding is rarely integrated into these formulations. In this\nwork, we propose a semantic safety filter framework to certify robot inputs\nwith respect to semantically defined constraints (e.g., unsafe spatial\nrelationships, behaviours, and poses) and geometrically defined constraints\n(e.g., environment-collision and self-collision constraints). In our proposed\napproach, given perception inputs, we build a semantic map of the 3D\nenvironment and leverage the contextual reasoning capabilities of large\nlanguage models to infer semantically unsafe conditions. These semantically\nunsafe conditions are then mapped to safe actions through a control barrier\ncertification formulation. We evaluated our semantic safety filter approach in\nteleoperated tabletop manipulation tasks and pick-and-place tasks,\ndemonstrating its effectiveness in incorporating semantic constraints to ensure\nsafe robot operation beyond collision avoidance.\n","authors":["Lukas Brunke","Yanni Zhang","Ralf Römer","Jack Naimer","Nikola Staykov","Siqi Zhou","Angela P. Schoellig"],"pdf_url":"https://arxiv.org/pdf/2410.15185v1.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.15178v1","updated":"2024-10-19T18:46:17Z","published":"2024-10-19T18:46:17Z","title":"Enhancing Robot Navigation Policies with Task-Specific Uncertainty\n  Management","summary":"  Robots performing navigation tasks in complex environments face significant\nchallenges due to uncertainty in state estimation. Effectively managing this\nuncertainty is crucial, but the optimal approach varies depending on the\nspecific details of the task: different tasks require varying levels of\nprecision in different regions of the environment. For instance, a robot\nnavigating a crowded space might need precise localization near obstacles but\ncan operate effectively with less precise state estimates in open areas. This\nvarying need for certainty in different parts of the environment, depending on\nthe task, calls for policies that can adapt their uncertainty management\nstrategies based on task-specific requirements. In this paper, we present a\nframework for integrating task-specific uncertainty requirements directly into\nnavigation policies. We introduce Task-Specific Uncertainty Map (TSUM), which\nrepresents acceptable levels of state estimation uncertainty across different\nregions of the operating environment for a given task. Using TSUM, we propose\nGeneralized Uncertainty Integration for Decision-Making and Execution (GUIDE),\na policy conditioning framework that incorporates these uncertainty\nrequirements into the robot's decision-making process. We find that\nconditioning policies on TSUMs provides an effective way to express\ntask-specific uncertainty requirements and enables the robot to reason about\nthe context-dependent value of certainty. We show how integrating GUIDE into\nreinforcement learning frameworks allows the agent to learn navigation policies\nwithout the need for explicit reward engineering to balance task completion and\nuncertainty management. We evaluate GUIDE on a variety of real-world navigation\ntasks and find that it demonstrates significant improvements in task completion\nrates compared to baselines. Evaluation videos can be found at\nhttps://guided-agents.github.io.\n","authors":["Gokul Puthumanaillam","Paulo Padrao","Jose Fuentes","Leonardo Bobadilla","Melkior Ornik"],"pdf_url":"https://arxiv.org/pdf/2410.15178v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.19992v2","updated":"2024-10-19T18:23:46Z","published":"2024-03-29T06:09:24Z","title":"MindArm: Mechanized Intelligent Non-Invasive Neuro-Driven Prosthetic Arm\n  System","summary":"  Currently, individuals with arm mobility impairments (referred to as\n\"patients\") face limited technological solutions due to two key challenges: (1)\nnon-invasive prosthetic devices are often prohibitively expensive and costly to\nmaintain, and (2) invasive solutions require high-risk, costly brain surgery,\nwhich can pose a health risk. Therefore, current technological solutions are\nnot accessible for all patients with different financial backgrounds. Toward\nthis, we propose a low-cost technological solution called MindArm, an\naffordable, non-invasive neuro-driven prosthetic arm system. MindArm employs a\ndeep neural network (DNN) to translate brain signals, captured by low-cost\nsurface electroencephalogram (EEG) electrodes, into prosthetic arm movements.\nUtilizing an Open Brain Computer Interface and UDP networking for signal\nprocessing, the system seamlessly controls arm motion. In the compute module,\nwe run a trained DNN model to interpret filtered micro-voltage brain signals,\nand then translate them into a prosthetic arm action via serial communication\nseamlessly. Experimental results from a fully functional prototype show high\naccuracy across three actions, with 91% for idle/stationary, 85% for handshake,\nand 84% for cup pickup. The system costs approximately $500-550, including $400\nfor the EEG headset and $100-150 for motors, 3D printing, and assembly,\noffering an affordable alternative for mind-controlled prosthetic devices.\n","authors":["Maha Nawaz","Abdul Basit","Muhammad Shafique"],"pdf_url":"https://arxiv.org/pdf/2403.19992v2.pdf","comment":"8 pages, 22 figures, Paper accepted at ICARCV 2024, funded by CAIR"},{"id":"http://arxiv.org/abs/2409.05289v2","updated":"2024-10-19T18:23:02Z","published":"2024-09-09T02:54:24Z","title":"Developing Path Planning with Behavioral Cloning and Proximal Policy\n  Optimization for Path-Tracking and Static Obstacle Nudging","summary":"  In autonomous driving, end-to-end methods utilizing Imitation Learning (IL)\nand Reinforcement Learning (RL) are becoming more and more common. However,\nthey do not involve explicit reasoning like classic robotics workflow and\nplanning with horizons, resulting in strategies implicit and myopic. In this\npaper, we introduce a path planning method that uses Behavioral Cloning (BC)\nfor path-tracking and Proximal Policy Optimization (PPO) for static obstacle\nnudging. It outputs lateral offset values to adjust the given reference\nwaypoints and performs modified path for different controllers. Experimental\nresults show that the algorithm can do path following that mimics the expert\nperformance of path-tracking controllers, and avoid collision to fixed\nobstacles. The method makes a good attempt at planning with learning-based\nmethods in path planning problems of autonomous driving.\n","authors":["Mingyan Zhou","Biao Wang","Xiatao Sun"],"pdf_url":"https://arxiv.org/pdf/2409.05289v2.pdf","comment":"6 pages, 8 figures"},{"id":"http://arxiv.org/abs/2407.03245v3","updated":"2024-10-19T14:56:17Z","published":"2024-07-03T16:16:41Z","title":"TieBot: Learning to Knot a Tie from Visual Demonstration through a\n  Real-to-Sim-to-Real Approach","summary":"  The tie-knotting task is highly challenging due to the tie's high deformation\nand long-horizon manipulation actions. This work presents TieBot, a\nReal-to-Sim-to-Real learning from visual demonstration system for the robots to\nlearn to knot a tie. We introduce the Hierarchical Feature Matching approach to\nestimate a sequence of tie's meshes from the demonstration video. With these\nestimated meshes used as subgoals, we first learn a teacher policy using\nprivileged information. Then, we learn a student policy with point cloud\nobservation by imitating teacher policy. Lastly, our pipeline applies learned\npolicy to real-world execution. We demonstrate the effectiveness of TieBot in\nsimulation and the real world. In the real-world experiment, a dual-arm robot\nsuccessfully knots a tie, achieving 50% success rate among 10 trials. Videos\ncan be found https://tiebots.github.io/.\n","authors":["Weikun Peng","Jun Lv","Yuwei Zeng","Haonan Chen","Siheng Zhao","Jichen Sun","Cewu Lu","Lin Shao"],"pdf_url":"https://arxiv.org/pdf/2407.03245v3.pdf","comment":"Accepted by CoRL 2024 as Oral presentation, camera-ready version"},{"id":"http://arxiv.org/abs/2410.15123v1","updated":"2024-10-19T14:38:29Z","published":"2024-10-19T14:38:29Z","title":"MeshDMP: Motion Planning on Discrete Manifolds using Dynamic Movement\n  Primitives","summary":"  An open problem in industrial automation is to reliably perform tasks\nrequiring in-contact movements with complex workpieces, as current solutions\nlack the ability to seamlessly adapt to the workpiece geometry. In this paper,\nwe propose a Learning from Demonstration approach that allows a robot\nmanipulator to learn and generalise motions across complex surfaces by\nleveraging differential mathematical operators on discrete manifolds to embed\ninformation on the geometry of the workpiece extracted from triangular meshes,\nand extend the Dynamic Movement Primitives (DMPs) framework to generate motions\non the mesh surfaces. We also propose an effective strategy to adapt the motion\nto different surfaces, by introducing an isometric transformation of the\nlearned forcing term. The resulting approach, namely MeshDMP, is evaluated both\nin simulation and real experiments, showing promising results in typical\nindustrial automation tasks like car surface polishing.\n","authors":["Matteo Dalle Vedove","Fares J. Abu-Dakka","Luigi Palopoli","Daniele Fontanelli","Matteo Saveriano"],"pdf_url":"https://arxiv.org/pdf/2410.15123v1.pdf","comment":"Submitted at the 2025 IEEE International Conference on Robotics and\n  Automation"},{"id":"http://arxiv.org/abs/2403.01450v3","updated":"2024-10-19T12:04:03Z","published":"2024-03-03T09:08:07Z","title":"Collision-Free Robot Navigation in Crowded Environments using Learning\n  based Convex Model Predictive Control","summary":"  Navigating robots safely and efficiently in crowded and complex environments\nremains a significant challenge. However, due to the dynamic and intricate\nnature of these settings, planning efficient and collision-free paths for\nrobots to track is particularly difficult. In this paper, we uniquely bridge\nthe robot's perception, decision-making and control processes by utilizing the\nconvex obstacle-free region computed from 2D LiDAR data. The overall pipeline\nis threefold: (1) We proposes a robot navigation framework that utilizes deep\nreinforcement learning (DRL), conceptualizing the observation as the convex\nobstacle-free region, a departure from general reliance on raw sensor inputs.\n(2) We design the action space, derived from the intersection of the robot's\nkinematic limits and the convex region, to enable efficient sampling of\ninherently collision-free reference points. These actions assists in guiding\nthe robot to move towards the goal and interact with other obstacles during\nnavigation. (3) We employ model predictive control (MPC) to track the\ntrajectory formed by the reference points while satisfying constraints imposed\nby the convex obstacle-free region and the robot's kinodynamic limits. The\neffectiveness of proposed improvements has been validated through two sets of\nablation studies and a comparative experiment against the Timed Elastic Band\n(TEB), demonstrating improved navigation performance in crowded and complex\nenvironments.\n","authors":["Zhuanglei Wen","Mingze Dong","Xiai Chen"],"pdf_url":"https://arxiv.org/pdf/2403.01450v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15068v1","updated":"2024-10-19T11:11:58Z","published":"2024-10-19T11:11:58Z","title":"A Cycle Ride to HDR: Semantics Aware Self-Supervised Framework for\n  Unpaired LDR-to-HDR Image Translation","summary":"  Low Dynamic Range (LDR) to High Dynamic Range (HDR) image translation is an\nimportant computer vision problem. There is a significant amount of research\nutilizing both conventional non-learning methods and modern data-driven\napproaches, focusing on using both single-exposed and multi-exposed LDR for HDR\nimage reconstruction. However, most current state-of-the-art methods require\nhigh-quality paired {LDR,HDR} datasets for model training. In addition, there\nis limited literature on using unpaired datasets for this task where the model\nlearns a mapping between domains, i.e., LDR to HDR. To address limitations of\ncurrent methods, such as the paired data constraint , as well as unwanted\nblurring and visual artifacts in the reconstructed HDR, we propose a method\nthat uses a modified cycle-consistent adversarial architecture and utilizes\nunpaired {LDR,HDR} datasets for training. The method introduces novel\ngenerators to address visual artifact removal and an encoder and loss to\naddress semantic consistency, another under-explored topic. The method achieves\nstate-of-the-art results across several benchmark datasets and reconstructs\nhigh-quality HDR images.\n","authors":["Hrishav Bakul Barua","Stefanov Kalin","Lemuel Lai En Che","Dhall Abhinav","Wong KokSheik","Krishnasamy Ganesh"],"pdf_url":"https://arxiv.org/pdf/2410.15068v1.pdf","comment":"Submitted to IEEE"},{"id":"http://arxiv.org/abs/2408.11966v2","updated":"2024-10-19T09:50:00Z","published":"2024-08-21T19:37:17Z","title":"Visual Localization in 3D Maps: Comparing Point Cloud, Mesh, and NeRF\n  Representations","summary":"  Recent advances in mapping techniques have enabled the creation of highly\naccurate dense 3D maps during robotic missions, such as point clouds, meshes,\nor NeRF-based representations. These developments present new opportunities for\nreusing these maps for localization. However, there remains a lack of a unified\napproach that can operate seamlessly across different map representations. This\npaper presents and evaluates a global visual localization system capable of\nlocalizing a single camera image across various 3D map representations built\nusing both visual and lidar sensing. Our system generates a database by\nsynthesizing novel views of the scene, creating RGB and depth image pairs.\nLeveraging the precise 3D geometric map, our method automatically defines\nrendering poses, reducing the number of database images while preserving\nretrieval performance. To bridge the domain gap between real query camera\nimages and synthetic database images, our approach utilizes learning-based\ndescriptors and feature detectors. We evaluate the system's performance through\nextensive real-world experiments conducted in both indoor and outdoor settings,\nassessing the effectiveness of each map representation and demonstrating its\nadvantages over traditional structure-from-motion (SfM) localization\napproaches. The results show that all three map representations can achieve\nconsistent localization success rates of 55% and higher across various\nenvironments. NeRF synthesized images show superior performance, localizing\nquery images at an average success rate of 72%. Furthermore, we demonstrate an\nadvantage over SfM-based approaches that our synthesized database enables\nlocalization in the reverse travel direction which is unseen during the mapping\nprocess. Our system, operating in real-time on a mobile laptop equipped with a\nGPU, achieves a processing rate of 1Hz.\n","authors":["Lintong Zhang","Yifu Tao","Jiarong Lin","Fu Zhang","Maurice Fallon"],"pdf_url":"https://arxiv.org/pdf/2408.11966v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.11084v3","updated":"2024-10-19T08:12:53Z","published":"2023-12-18T10:23:50Z","title":"Multi-Agent Reinforcement Learning for Connected and Automated Vehicles\n  Control: Recent Advancements and Future Prospects","summary":"  Connected and automated vehicles (CAVs) are considered a potential solution\nfor future transportation challenges, aiming to develop systems that are\nefficient, safe, and environmentally friendly. However, CAV control presents\nsignificant challenges due to the complexity of interconnectivity and\ncoordination required among vehicles. Multi-agent reinforcement learning\n(MARL), which has shown notable advancements in addressing complex problems in\nautonomous driving, robotics, and human-vehicle interaction, emerges as a\npromising tool to enhance CAV capabilities. Despite its potential, there is a\nnotable absence of current reviews on mainstream MARL algorithms for CAVs. To\nfill this gap, this paper offers a comprehensive review of MARL's application\nin CAV control. The paper begins with an introduction to MARL, explaining its\nunique advantages in handling complex and multi-agent scenarios. It then\npresents a detailed survey of MARL applications across various control\ndimensions for CAVs, including critical scenarios such as platooning control,\nlane-changing, and unsignalized intersections. Additionally, the paper reviews\nprominent simulation platforms essential for developing and testing MARL\nalgorithms. Lastly, it examines the current challenges in deploying MARL for\nCAV control, including macro-micro optimization, communication, mixed traffic,\nand sim-to-real challenges. Potential solutions discussed include hierarchical\nMARL, decentralized MARL, adaptive interactions, and offline MARL.\n","authors":["Min Hua","Dong Chen","Xinda Qi","Kun Jiang","Zemin Eitan Liu","Quan Zhou","Hongming Xu"],"pdf_url":"https://arxiv.org/pdf/2312.11084v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15030v1","updated":"2024-10-19T08:06:43Z","published":"2024-10-19T08:06:43Z","title":"Cutting-Edge Detection of Fatigue in Drivers: A Comparative Study of\n  Object Detection Models","summary":"  This research delves into the development of a fatigue detection system based\non modern object detection algorithms, particularly YOLO (You Only Look Once)\nmodels, including YOLOv5, YOLOv6, YOLOv7, and YOLOv8. By comparing the\nperformance of these models, we evaluate their effectiveness in real-time\ndetection of fatigue-related behavior in drivers. The study addresses\nchallenges like environmental variability and detection accuracy and suggests a\nroadmap for enhancing real-time detection. Experimental results demonstrate\nthat YOLOv8 offers superior performance, balancing accuracy with speed. Data\naugmentation techniques and model optimization have been key in enhancing\nsystem adaptability to various driving conditions.\n","authors":["Amelia Jones"],"pdf_url":"https://arxiv.org/pdf/2410.15030v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14989v1","updated":"2024-10-19T05:41:11Z","published":"2024-10-19T05:41:11Z","title":"AutoFPDesigner: Automated Flight Procedure Design Based on Multi-Agent\n  Large Language Model","summary":"  Current flight procedure design methods heavily rely on human-led design\nprocess, which is not only low auto-mation but also suffer from complex\nalgorithm modelling and poor generalization. To address these challenges, this\npaper proposes an agent-driven flight procedure design method based on large\nlanguage model, named Au-toFPDesigner, which utilizes multi-agent collaboration\nto complete procedure design. The method enables end-to-end automated design of\nperformance-based navigation (PBN) procedures. In this process, the user input\nthe design requirements in natural language, AutoFPDesigner models the flight\nprocedure design by loading the design speci-fications and utilizing tool\nlibraries complete the design. AutoFPDesigner allows users to oversee and\nseamlessly participate in the design process. Experimental results show that\nAutoFPDesigner ensures nearly 100% safety in the designed flight procedures and\nachieves 75% task completion rate, with good adaptability across different\ndesign tasks. AutoFPDesigner introduces a new paradigm for flight procedure\ndesign and represents a key step towards the automation of this process.\nKeywords: Flight Procedure Design; Large Language Model; Performance-Based\nNavigation (PBN); Multi Agent;\n","authors":["Longtao Zhu","Hongyu Yang","Ge Song","Xin Ma","Yanxin Zhang","Yulong Ji"],"pdf_url":"https://arxiv.org/pdf/2410.14989v1.pdf","comment":"21 pages, 18 figures, 5 tables"},{"id":"http://arxiv.org/abs/2410.14974v1","updated":"2024-10-19T04:37:01Z","published":"2024-10-19T04:37:01Z","title":"CAGE: Causal Attention Enables Data-Efficient Generalizable Robotic\n  Manipulation","summary":"  Generalization in robotic manipulation remains a critical challenge,\nparticularly when scaling to new environments with limited demonstrations. This\npaper introduces CAGE, a novel robotic manipulation policy designed to overcome\nthese generalization barriers by integrating a causal attention mechanism. CAGE\nutilizes the powerful feature extraction capabilities of the vision foundation\nmodel DINOv2, combined with LoRA fine-tuning for robust environment\nunderstanding. The policy further employs a causal Perceiver for effective\ntoken compression and a diffusion-based action prediction head with attention\nmechanisms to enhance task-specific fine-grained conditioning. With as few as\n50 demonstrations from a single training environment, CAGE achieves robust\ngeneralization across diverse visual changes in objects, backgrounds, and\nviewpoints. Extensive experiments validate that CAGE significantly outperforms\nexisting state-of-the-art RGB/RGB-D approaches in various manipulation tasks,\nespecially under large distribution shifts. In similar environments, CAGE\noffers an average of 42% increase in task completion rate. While all baselines\nfail to execute the task in unseen environments, CAGE manages to obtain a 43%\ncompletion rate and a 51% success rate in average, making a huge step towards\npractical deployment of robots in real-world settings. Project website:\ncage-policy.github.io.\n","authors":["Shangning Xia","Hongjie Fang","Hao-Shu Fang","Cewu Lu"],"pdf_url":"https://arxiv.org/pdf/2410.14974v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14972v1","updated":"2024-10-19T04:31:54Z","published":"2024-10-19T04:31:54Z","title":"MENTOR: Mixture-of-Experts Network with Task-Oriented Perturbation for\n  Visual Reinforcement Learning","summary":"  Visual deep reinforcement learning (RL) enables robots to acquire skills from\nvisual input for unstructured tasks. However, current algorithms suffer from\nlow sample efficiency, limiting their practical applicability. In this work, we\npresent MENTOR, a method that improves both the architecture and optimization\nof RL agents. Specifically, MENTOR replaces the standard multi-layer perceptron\n(MLP) with a mixture-of-experts (MoE) backbone, enhancing the agent's ability\nto handle complex tasks by leveraging modular expert learning to avoid gradient\nconflicts. Furthermore, MENTOR introduces a task-oriented perturbation\nmechanism, which heuristically samples perturbation candidates containing\ntask-relevant information, leading to more targeted and effective optimization.\nMENTOR outperforms state-of-the-art methods across three simulation domains --\nDeepMind Control Suite, Meta-World, and Adroit. Additionally, MENTOR achieves\nan average of 83% success rate on three challenging real-world robotic\nmanipulation tasks including peg insertion, cable routing, and tabletop golf,\nwhich significantly surpasses the success rate of 32% from the current\nstrongest model-free visual RL algorithm. These results underscore the\nimportance of sample efficiency in advancing visual RL for real-world robotics.\nExperimental videos are available at\nhttps://suninghuang19.github.io/mentor_page.\n","authors":["Suning Huang","Zheyu Zhang","Tianhai Liang","Yihan Xu","Zhehao Kou","Chenhao Lu","Guowei Xu","Zhengrong Xue","Huazhe Xu"],"pdf_url":"https://arxiv.org/pdf/2410.14972v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14968v1","updated":"2024-10-19T04:19:52Z","published":"2024-10-19T04:19:52Z","title":"AugInsert: Learning Robust Visual-Force Policies via Data Augmentation\n  for Object Assembly Tasks","summary":"  This paper primarily focuses on learning robust visual-force policies in the\ncontext of high-precision object assembly tasks. Specifically, we focus on the\ncontact phase of the assembly task where both objects (peg and hole) have made\ncontact and the objective lies in maneuvering the objects to complete the\nassembly. Moreover, we aim to learn contact-rich manipulation policies with\nmultisensory inputs on limited expert data by expanding human demonstrations\nvia online data augmentation. We develop a simulation environment with a\ndual-arm robot manipulator to evaluate the effect of augmented expert\ndemonstration data. Our focus is on evaluating the robustness of our model with\nrespect to certain task variations: grasp pose, peg/hole shape, object body\nshape, scene appearance, camera pose, and force-torque/proprioception noise. We\nshow that our proposed data augmentation method helps in learning a\nmultisensory manipulation policy that is robust to unseen instances of these\nvariations, particularly physical variations such as grasp pose. Additionally,\nour ablative studies show the significant contribution of force-torque data to\nthe robustness of our model. For additional experiments and qualitative\nresults, we refer to the project webpage at https://bit.ly/47skWXH .\n","authors":["Ryan Diaz","Adam Imdieke","Vivek Veeriah","Karthik Desingh"],"pdf_url":"https://arxiv.org/pdf/2410.14968v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14957v1","updated":"2024-10-19T03:08:10Z","published":"2024-10-19T03:08:10Z","title":"Offline-to-online Reinforcement Learning for Image-based Grasping with\n  Scarce Demonstrations","summary":"  Offline-to-online reinforcement learning (O2O RL) aims to obtain a\ncontinually improving policy as it interacts with the environment, while\nensuring the initial behaviour is satisficing. This satisficing behaviour is\nnecessary for robotic manipulation where random exploration can be costly due\nto catastrophic failures and time. O2O RL is especially compelling when we can\nonly obtain a scarce amount of (potentially suboptimal)\ndemonstrations$\\unicode{x2014}$a scenario where behavioural cloning (BC) is\nknown to suffer from distribution shift. Previous works have outlined the\nchallenges in applying O2O RL algorithms under the image-based environments. In\nthis work, we propose a novel O2O RL algorithm that can learn in a real-life\nimage-based robotic vacuum grasping task with a small number of demonstrations\nwhere BC fails majority of the time. The proposed algorithm replaces the target\nnetwork in off-policy actor-critic algorithms with a regularization technique\ninspired by neural tangent kernel. We demonstrate that the proposed algorithm\ncan reach above 90% success rate in under two hours of interaction time, with\nonly 50 human demonstrations, while BC and two commonly-used RL algorithms fail\nto achieve similar performance.\n","authors":["Bryan Chan","Anson Leung","James Bergstra"],"pdf_url":"https://arxiv.org/pdf/2410.14957v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14947v1","updated":"2024-10-19T02:34:13Z","published":"2024-10-19T02:34:13Z","title":"Optimally Solving Colored Generalized Sliding-Tile Puzzles: Complexity\n  and Bounds","summary":"  The Generalized Sliding-Tile Puzzle (GSTP), allowing many square tiles on a\nboard to move in parallel while enforcing natural geometric collision\nconstraints on the movement of neighboring tiles, provide a high-fidelity\nmathematical model for many high-utility existing and future multi-robot\napplications, e.g., at mobile robot-based warehouses or autonomous garages.\nMotivated by practical relevance, this work examines a further generalization\nof GSTP called the Colored Generalized Sliding-Tile Puzzle (CGSP), where tiles\ncan now assume varying degrees of distinguishability, a common occurrence in\nthe aforementioned applications. Our study establishes the computational\ncomplexity of CGSP and its key sub-problems under a broad spectrum of possible\nconditions and characterizes solution makespan lower and upper bounds that\ndiffer by at most a logarithmic factor. These results are further extended to\nhigher-dimensional versions of the puzzle game.\n","authors":["Marcus Gozon","Jingjin Yu"],"pdf_url":"https://arxiv.org/pdf/2410.14947v1.pdf","comment":"WAFR 2024 Conference Version"},{"id":"http://arxiv.org/abs/2410.14934v1","updated":"2024-10-19T01:47:51Z","published":"2024-10-19T01:47:51Z","title":"Development of a Simple and Novel Digital Twin Framework for Industrial\n  Robots in Intelligent robotics manufacturing","summary":"  This paper has proposed an easily replicable and novel approach for\ndeveloping a Digital Twin (DT) system for industrial robots in intelligent\nmanufacturing applications. Our framework enables effective communication via\nRobot Web Service (RWS), while a real-time simulation is implemented in Unity\n3D and Web-based Platform without any other 3rd party tools. The framework can\ndo real-time visualization and control of the entire work process, as well as\nimplement real-time path planning based on algorithms executed in MATLAB.\nResults verify the high communication efficiency with a refresh rate of only\n$17 ms$. Furthermore, our developed web-based platform and Graphical User\nInterface (GUI) enable easy accessibility and user-friendliness in real-time\ncontrol.\n","authors":["Tianyi Xiang","Borui Li","Xin Pan","Quan Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.14934v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14928v1","updated":"2024-10-19T01:31:36Z","published":"2024-10-19T01:31:36Z","title":"A Novel Approach to Grasping Control of Soft Robotic Grippers based on\n  Digital Twin","summary":"  This paper has proposed a Digital Twin (DT) framework for real-time motion\nand pose control of soft robotic grippers. The developed DT is based on an\nindustrial robot workstation, integrated with our newly proposed approach for\nsoft gripper control, primarily based on computer vision, for setting the\ndriving pressure for desired gripper status in real-time. Knowing the gripper\nmotion, the gripper parameters (e.g. curvatures and bending angles, etc.) are\nsimulated by kinematics modelling in Unity 3D, which is based on four-piecewise\nconstant curvature kinematics. The mapping in between the driving pressure and\ngripper parameters is achieved by implementing OpenCV based image processing\nalgorithms and data fitting. Results show that our DT-based approach can\nachieve satisfactory performance in real-time control of soft gripper\nmanipulation, which can satisfy a wide range of industrial applications.\n","authors":["Tianyi Xiang","Borui Li","Quan Zhang","Mark Leach","Eng Gee Lim"],"pdf_url":"https://arxiv.org/pdf/2410.14928v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14916v1","updated":"2024-10-19T00:10:52Z","published":"2024-10-19T00:10:52Z","title":"Cooperation and Fairness in Multi-Agent Reinforcement Learning","summary":"  Multi-agent systems are trained to maximize shared cost objectives, which\ntypically reflect system-level efficiency. However, in the resource-constrained\nenvironments of mobility and transportation systems, efficiency may be achieved\nat the expense of fairness -- certain agents may incur significantly greater\ncosts or lower rewards compared to others. Tasks could be distributed\ninequitably, leading to some agents receiving an unfair advantage while others\nincur disproportionately high costs. It is important to consider the tradeoffs\nbetween efficiency and fairness. We consider the problem of fair multi-agent\nnavigation for a group of decentralized agents using multi-agent reinforcement\nlearning (MARL). We consider the reciprocal of the coefficient of variation of\nthe distances traveled by different agents as a measure of fairness and\ninvestigate whether agents can learn to be fair without significantly\nsacrificing efficiency (i.e., increasing the total distance traveled). We find\nthat by training agents using min-max fair distance goal assignments along with\na reward term that incentivizes fairness as they move towards their goals, the\nagents (1) learn a fair assignment of goals and (2) achieve almost perfect goal\ncoverage in navigation scenarios using only local observations. For goal\ncoverage scenarios, we find that, on average, our model yields a 14%\nimprovement in efficiency and a 5% improvement in fairness over a baseline\ntrained using random assignments. Furthermore, an average of 21% improvement in\nfairness can be achieved compared to a model trained on optimally efficient\nassignments; this increase in fairness comes at the expense of only a 7%\ndecrease in efficiency. Finally, we extend our method to environments in which\nagents must complete coverage tasks in prescribed formations and show that it\nis possible to do so without tailoring the models to specific formation shapes.\n","authors":["Jasmine Jerry Aloor","Siddharth Nayak","Sydney Dolan","Hamsa Balakrishnan"],"pdf_url":"https://arxiv.org/pdf/2410.14916v1.pdf","comment":"Manuscript accepted in ACM Journal on Autonomous Transportation\n  Systems"}]},"2024-10-22T00:00:00Z":{"Robotics":[{"id":"http://arxiv.org/abs/2410.17246v1","updated":"2024-10-22T17:59:49Z","published":"2024-10-22T17:59:49Z","title":"Learning Precise, Contact-Rich Manipulation through Uncalibrated Tactile\n  Skins","summary":"  While visuomotor policy learning has advanced robotic manipulation, precisely\nexecuting contact-rich tasks remains challenging due to the limitations of\nvision in reasoning about physical interactions. To address this, recent work\nhas sought to integrate tactile sensing into policy learning. However, many\nexisting approaches rely on optical tactile sensors that are either restricted\nto recognition tasks or require complex dimensionality reduction steps for\npolicy learning. In this work, we explore learning policies with magnetic skin\nsensors, which are inherently low-dimensional, highly sensitive, and\ninexpensive to integrate with robotic platforms. To leverage these sensors\neffectively, we present the Visuo-Skin (ViSk) framework, a simple approach that\nuses a transformer-based policy and treats skin sensor data as additional\ntokens alongside visual information. Evaluated on four complex real-world tasks\ninvolving credit card swiping, plug insertion, USB insertion, and bookshelf\nretrieval, ViSk significantly outperforms both vision-only and optical tactile\nsensing based policies. Further analysis reveals that combining tactile and\nvisual modalities enhances policy performance and spatial generalization,\nachieving an average improvement of 27.5% across tasks.\nhttps://visuoskin.github.io/\n","authors":["Venkatesh Pattabiraman","Yifeng Cao","Siddhant Haldar","Lerrel Pinto","Raunaq Bhirangi"],"pdf_url":"https://arxiv.org/pdf/2410.17246v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17188v1","updated":"2024-10-22T17:09:28Z","published":"2024-10-22T17:09:28Z","title":"Minimum-Violation Temporal Logic Planning for Heterogeneous Robots under\n  Robot Skill Failures","summary":"  In this paper, we consider teams of robots with heterogeneous skills (e.g.,\nsensing and manipulation) tasked with collaborative missions described by\nLinear Temporal Logic (LTL) formulas. These LTL-encoded tasks require robots to\napply their skills to specific regions and objects in a temporal and logical\norder. While existing temporal logic planning algorithms can synthesize\ncorrect-by-construction paths, they typically lack reactivity to unexpected\nfailures of robot skills, which can compromise mission performance. This paper\naddresses this challenge by proposing a reactive LTL planning algorithm that\nadapts to unexpected failures during deployment. Specifically, the proposed\nalgorithm reassigns sub-tasks to robots based on their functioning skills and\nlocally revises team plans to accommodate these new assignments and ensure\nmission completion. The main novelty of the proposed algorithm is its ability\nto handle cases where mission completion becomes impossible due to limited\nfunctioning robots. Instead of reporting mission failure, the algorithm\nstrategically prioritizes the most crucial sub-tasks and locally revises the\nteam's plans, as per user-specified priorities, to minimize mission violations.\nWe provide theoretical conditions under which the proposed framework computes\nthe minimum violation task reassignments and team plans. We provide numerical\nand hardware experiments to demonstrate the efficiency of the proposed method.\n","authors":["Samarth Kalluraya","Beichen Zhou","Yiannis Kantaros"],"pdf_url":"https://arxiv.org/pdf/2410.17188v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17186v1","updated":"2024-10-22T17:07:26Z","published":"2024-10-22T17:07:26Z","title":"DyPNIPP: Predicting Environment Dynamics for RL-based Robust Informative\n  Path Planning","summary":"  Informative path planning (IPP) is an important planning paradigm for various\nreal-world robotic applications such as environment monitoring. IPP involves\nplanning a path that can learn an accurate belief of the quantity of interest,\nwhile adhering to planning constraints. Traditional IPP methods typically\nrequire high computation time during execution, giving rise to reinforcement\nlearning (RL) based IPP methods. However, the existing RL-based methods do not\nconsider spatio-temporal environments which involve their own challenges due to\nvariations in environment characteristics. In this paper, we propose DyPNIPP, a\nrobust RL-based IPP framework, designed to operate effectively across\nspatio-temporal environments with varying dynamics. To achieve this, DyPNIPP\nincorporates domain randomization to train the agent across diverse\nenvironments and introduces a dynamics prediction model to capture and adapt\nthe agent actions to specific environment dynamics. Our extensive experiments\nin a wildfire environment demonstrate that DyPNIPP outperforms existing\nRL-based IPP algorithms by significantly improving robustness and performing\nacross diverse environment conditions.\n","authors":["Srujan Deolasee","Siva Kailas","Wenhao Luo","Katia Sycara","Woojun Kim"],"pdf_url":"https://arxiv.org/pdf/2410.17186v1.pdf","comment":"8 pages, 4 figures, submitted to IEEE RA-L"},{"id":"http://arxiv.org/abs/2410.17183v1","updated":"2024-10-22T17:02:33Z","published":"2024-10-22T17:02:33Z","title":"Risk-Averse Model Predictive Control for Racing in Adverse Conditions","summary":"  Model predictive control (MPC) algorithms can be sensitive to model mismatch\nwhen used in challenging nonlinear control tasks. In particular, the\nperformance of MPC for vehicle control at the limits of handling suffers when\nthe underlying model overestimates the vehicle's capabilities. In this work, we\npropose a risk-averse MPC framework that explicitly accounts for uncertainty\nover friction limits and tire parameters. Our approach leverages a sample-based\napproximation of an optimal control problem with a conditional value at risk\n(CVaR) constraint. This sample-based formulation enables planning with a set of\nexpressive vehicle dynamics models using different tire parameters. Moreover,\nthis formulation enables efficient numerical resolution via sequential\nquadratic programming and GPU parallelization. Experiments on a Lexus LC 500\nshow that risk-averse MPC unlocks reliable performance, while a deterministic\nbaseline that plans using a single dynamics model may lose control of the\nvehicle in adverse road conditions.\n","authors":["Thomas Lew","Marcus Greiff","Franck Djeumou","Makoto Suminaka","Michael Thompson","John Subosits"],"pdf_url":"https://arxiv.org/pdf/2410.17183v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.17379v2","updated":"2024-10-22T16:58:31Z","published":"2024-08-30T16:15:28Z","title":"EMPOWER: Embodied Multi-role Open-vocabulary Planning with Online\n  Grounding and Execution","summary":"  Task planning for robots in real-life settings presents significant\nchallenges. These challenges stem from three primary issues: the difficulty in\nidentifying grounded sequences of steps to achieve a goal; the lack of a\nstandardized mapping between high-level actions and low-level commands; and the\nchallenge of maintaining low computational overhead given the limited resources\nof robotic hardware. We introduce EMPOWER, a framework designed for\nopen-vocabulary online grounding and planning for embodied agents aimed at\naddressing these issues. By leveraging efficient pre-trained foundation models\nand a multi-role mechanism, EMPOWER demonstrates notable improvements in\ngrounded planning and execution. Quantitative results highlight the\neffectiveness of our approach, achieving an average success rate of 0.73 across\nsix different real-life scenarios using a TIAGo robot.\n","authors":["Francesco Argenziano","Michele Brienza","Vincenzo Suriani","Daniele Nardi","Domenico D. Bloisi"],"pdf_url":"https://arxiv.org/pdf/2408.17379v2.pdf","comment":"Accepted at IROS 2024"},{"id":"http://arxiv.org/abs/2410.17171v1","updated":"2024-10-22T16:50:09Z","published":"2024-10-22T16:50:09Z","title":"Impact of 3D LiDAR Resolution in Graph-based SLAM Approaches: A\n  Comparative Study","summary":"  Simultaneous Localization and Mapping (SLAM) is a key component of autonomous\nsystems operating in environments that require a consistent map for reliable\nlocalization. SLAM has been a widely studied topic for decades with most of the\nsolutions being camera or LiDAR based. Early LiDAR-based approaches primarily\nrelied on 2D data, whereas more recent frameworks use 3D data. In this work, we\nsurvey recent 3D LiDAR-based Graph-SLAM methods in urban environments, aiming\nto compare their strengths, weaknesses, and limitations. Additionally, we\nevaluate their robustness regarding the LiDAR resolution namely 64 $vs$ 128\nchannels. Regarding SLAM methods, we evaluate SC-LeGO-LOAM, SC-LIO-SAM,\nCartographer, and HDL-Graph on real-world urban environments using the KITTI\nodometry dataset (a LiDAR with 64-channels only) and a new dataset\n(AUTONOMOS-LABS). The latter dataset, collected using instrumented vehicles\ndriving in Berlin suburban area, comprises both 64 and 128 LiDARs. The\nexperimental results are reported in terms of quantitative `metrics' and\ncomplemented by qualitative maps.\n","authors":["J. Jorge","T. Barros","C. Premebida","M. Aleksandrov","D. Goehring","U. J. Nunes"],"pdf_url":"https://arxiv.org/pdf/2410.17171v1.pdf","comment":"This work has been accepted for publication in ROBOT24"},{"id":"http://arxiv.org/abs/2410.17166v1","updated":"2024-10-22T16:43:21Z","published":"2024-10-22T16:43:21Z","title":"Towards Map-Agnostic Policies for Adaptive Informative Path Planning","summary":"  Robots are frequently tasked to gather relevant sensor data in unknown\nterrains. A key challenge for classical path planning algorithms used for\nautonomous information gathering is adaptively replanning paths online as the\nterrain is explored given limited onboard compute resources. Recently,\nlearning-based approaches emerged that train planning policies offline and\nenable computationally efficient online replanning performing policy inference.\nThese approaches are designed and trained for terrain monitoring missions\nassuming a single specific map representation, which limits their applicability\nto different terrains. To address these issues, we propose a novel formulation\nof the adaptive informative path planning problem unified across different map\nrepresentations, enabling training and deploying planning policies in a larger\nvariety of monitoring missions. Experimental results validate that our novel\nformulation easily integrates with classical non-learning-based planning\napproaches while maintaining their performance. Our trained planning policy\nperforms similarly to state-of-the-art map-specifically trained policies. We\nvalidate our learned policy on unseen real-world terrain datasets.\n","authors":["Julius Rückin","David Morilla-Cabello","Cyrill Stachniss","Eduardo Montijano","Marija Popović"],"pdf_url":"https://arxiv.org/pdf/2410.17166v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.17160v1","updated":"2024-10-22T16:34:24Z","published":"2024-10-22T16:34:24Z","title":"Layered LA-MAPF: a decomposition of large agent MAPF instance to\n  accelerate solving without compromising solvability","summary":"  Multi-Agent Path Finding (MAPF) has been widely studied in recent years.\nHowever, most existing MAPF algorithms assume that an agent occupies only a\nsingle grid in a grid-based map. This assumption limits their applicability in\nmany real-world domains where agents have geometric shapes, rather than being\npoint-like. Such agents, which can occupy multiple cells simultaneously, are\nreferred to as ``large'' agents. When considering the shape and size of agents\nin MAPF, the computational complexity increases significantly as the number of\nagents grows, primarily due to the increased overhead in conflict detection\nbetween geometric agents. In this paper, we propose two types of subproblems\nfor the LA-MAPF (Large-Agent MAPF) problem: \\textbf{cluster} (which has no\nconstraints on the order of solution) and \\textbf{level} (which imposes\nconstraints on the solution order). We introduce \\textbf{Layered LA-MAPF}, a\nmethod that decomposes a MAPF instance involving geometric agents into\nclusters, and then further decomposes each cluster into levels. This approach\naims to reduce time complexity when solving LA-MAPF problems. Our results\ndemonstrate the performance of our method as the number of agents increases\nacross various maps, and how it accelerates LA-MAPF methods, such as LA-CBS and\nLA-LaCAM. Experiments show that our LA-MAPF method with instance decomposition\n\\textbf{halves the time cost (reducing from an average of 40s to 20s) and\ntriples the success rate (from an average of 0.27 to 0.80)} in finding a\nsolution within 60 seconds. To facilitate further research, we have made the\nsource code for Layered LA-MAPF publicly available at\n\\url{https://github.com/JoeYao-bit/LayeredMAPF/algorithm/LA-MAPF}.\n","authors":["Zhuo Yao"],"pdf_url":"https://arxiv.org/pdf/2410.17160v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.10078v4","updated":"2024-10-22T15:53:40Z","published":"2024-09-16T08:30:59Z","title":"3D-TAFS: A Training-free Framework for 3D Affordance Segmentation","summary":"  Translating high-level linguistic instructions into precise robotic actions\nin the physical world remains challenging, particularly when considering the\nfeasibility of interacting with 3D objects. In this paper, we introduce\n3D-TAFS, a novel training-free multimodal framework for 3D affordance\nsegmentation, alongside a benchmark for evaluating interactive language-guided\naffordance in everyday environments. In particular, our framework integrates a\nlarge multimodal model with a specialized 3D vision network, enabling seamless\nfusion of 2D and 3D visual understanding with language comprehension. To\nfacilitate evaluation, we present a dataset of ten typical indoor environments,\neach with 50 images annotated for object actions and 3D affordance\nsegmentation. Extensive experiments validate the proposed 3D-TAFS's capability\nin handling interactive 3D affordance segmentation tasks across diverse\nsettings, showcasing competitive performance across various metrics. Our\nresults highlight 3D-TAFS's potential for enhancing human-robot interaction\nbased on affordance understanding in complex indoor environments, advancing the\ndevelopment of more intuitive and efficient robotic frameworks for real-world\napplications.\n","authors":["Meng Chu","Xuan Zhang","Zhedong Zheng","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2409.10078v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.01596v3","updated":"2024-10-22T15:47:12Z","published":"2024-04-02T02:36:31Z","title":"PhysORD: A Neuro-Symbolic Approach for Physics-infused Motion Prediction\n  in Off-road Driving","summary":"  Motion prediction is critical for autonomous off-road driving, however, it\npresents significantly more challenges than on-road driving because of the\ncomplex interaction between the vehicle and the terrain. Traditional\nphysics-based approaches encounter difficulties in accurately modeling dynamic\nsystems and external disturbance. In contrast, data-driven neural networks\nrequire extensive datasets and struggle with explicitly capturing the\nfundamental physical laws, which can easily lead to poor generalization. By\nmerging the advantages of both methods, neuro-symbolic approaches present a\npromising direction. These methods embed physical laws into neural models,\npotentially significantly improving generalization capabilities. However, no\nprior works were evaluated in real-world settings for off-road driving. To\nbridge this gap, we present PhysORD, a neural-symbolic approach integrating the\nconservation law, i.e., the Euler-Lagrange equation, into data-driven neural\nmodels for motion prediction in off-road driving. Our experiments showed that\nPhysORD can accurately predict vehicle motion and tolerate external disturbance\nby modeling uncertainties. The learned dynamics model achieves 46.7% higher\naccuracy using only 3.1% of the parameters compared to data-driven methods,\ndemonstrating the data efficiency and superior generalization ability of our\nneural-symbolic method.\n","authors":["Zhipeng Zhao","Bowen Li","Yi Du","Taimeng Fu","Chen Wang"],"pdf_url":"https://arxiv.org/pdf/2404.01596v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17062v1","updated":"2024-10-22T14:41:30Z","published":"2024-10-22T14:41:30Z","title":"Miniature magneto-oscillatory wireless sensor for magnetic field and\n  gradient measurements","summary":"  Magneto-oscillatory devices have been recently developed as very potent\nwireless miniature position trackers and sensors with an exceptional accuracy\nand sensing distance for surgical and robotic applications. However, it is\nstill unclear to which extend a mechanically resonating sub-millimeter magnet\ninteracts with external magnetic fields or gradients, which induce frequency\nshifts of sub-mHz to several Hz and therefore affect the sensing accuracy.\nHere, we investigate this effect experimentally on a cantilever-based\nmagneto-oscillatory wireless sensor (MOWS) and build an analytical model\nconcerning magnetic and mechanical interactions. The millimeter-scale MOWS is\ncapable to detect magnetic fields with sub-uT resolution to at least +/- 5 mT,\nand simultaneously detects magnetic field gradients with a resolution of 65\nuT/m to at least +/- 50 mT/m. The magnetic field sensitivity allows direct\ncalculation of mechanical device properties, and by rotation, individual\ncontributions of the magnetic field and gradient can be analyzed. The derived\nmodel is general and can be applied to other magneto-oscillatory systems\ninteracting with magnetic environments.\n","authors":["Felix Fischer","Moonkwang Jeong","Tian Qiu"],"pdf_url":"https://arxiv.org/pdf/2410.17062v1.pdf","comment":"Main text: 7 pages with figures; Supplementary materials 6 pages with\n  figures"},{"id":"http://arxiv.org/abs/2402.03860v4","updated":"2024-10-22T14:27:04Z","published":"2024-02-06T10:18:30Z","title":"AED: Adaptable Error Detection for Few-shot Imitation Policy","summary":"  We introduce a new task called Adaptable Error Detection (AED), which aims to\nidentify behavior errors in few-shot imitation (FSI) policies based on visual\nobservations in novel environments. The potential to cause serious damage to\nsurrounding areas limits the application of FSI policies in real-world\nscenarios. Thus, a robust system is necessary to notify operators when FSI\npolicies are inconsistent with the intent of demonstrations. This task\nintroduces three challenges: (1) detecting behavior errors in novel\nenvironments, (2) identifying behavior errors that occur without revealing\nnotable changes, and (3) lacking complete temporal information of the rollout\ndue to the necessity of online detection. However, the existing benchmarks\ncannot support the development of AED because their tasks do not present all\nthese challenges. To this end, we develop a cross-domain AED benchmark,\nconsisting of 322 base and 153 novel environments. Additionally, we propose\nPattern Observer (PrObe) to address these challenges. PrObe is equipped with a\npowerful pattern extractor and guided by novel learning objectives to parse\ndiscernible patterns in the policy feature representations of normal or error\nstates. Through our comprehensive evaluation, PrObe demonstrates superior\ncapability to detect errors arising from a wide range of FSI policies,\nconsistently surpassing strong baselines. Moreover, we conduct detailed\nablations and a pilot study on error correction to validate the effectiveness\nof the proposed architecture design and the practicality of the AED task,\nrespectively. The AED project page can be found at\nhttps://aed-neurips.github.io/.\n","authors":["Jia-Fong Yeh","Kuo-Han Hung","Pang-Chi Lo","Chi-Ming Chung","Tsung-Han Wu","Hung-Ting Su","Yi-Ting Chen","Winston H. Hsu"],"pdf_url":"https://arxiv.org/pdf/2402.03860v4.pdf","comment":"Accepted to NeurIPS2024"},{"id":"http://arxiv.org/abs/2410.17015v1","updated":"2024-10-22T13:36:49Z","published":"2024-10-22T13:36:49Z","title":"Magneto-oscillatory localization for small-scale robots","summary":"  Magnetism is widely used for the wireless localization and actuation of\nrobots and devices for medical procedures. However, current static magnetic\nlocalization methods suffer from large required magnets and are limited to only\nfive degrees of freedom due to a fundamental constraint of the rotational\nsymmetry around the magnetic axis. We present the small-scale\nmagneto-oscillatory localization (SMOL) method, which is capable of wirelessly\nlocalizing a millimeter-scale tracker with full six degrees of freedom in deep\nbiological tissues. The SMOL device uses the temporal oscillation of a\nmechanically resonant cantilever with a magnetic dipole to break the rotational\nsymmetry, and exploits the frequency-response to achieve a high signal-to-noise\nratio with sub-millimeter accuracy over a large distance of up to 12\ncentimeters and quasi-continuous refresh rates up to 200 Hz. Integration into\nreal-time closed-loop controlled robots and minimally-invasive surgical tools\nare demonstrated to reveal the vast potential of the SMOL method.\n","authors":["Felix Fischer","Christian Gletter","Moonkwang Jeong","Tian Qiu"],"pdf_url":"https://arxiv.org/pdf/2410.17015v1.pdf","comment":"Pages 1-35 main text (incl. 4 figures), pages 36-57 supplementary\n  materials"},{"id":"http://arxiv.org/abs/2406.10060v2","updated":"2024-10-22T13:35:07Z","published":"2024-06-14T14:16:39Z","title":"PRIMER: Perception-Aware Robust Learning-based Multiagent Trajectory\n  Planner","summary":"  In decentralized multiagent trajectory planners, agents need to communicate\nand exchange their positions to generate collision-free trajectories. However,\ndue to localization errors/uncertainties, trajectory deconfliction can fail\neven if trajectories are perfectly shared between agents. To address this\nissue, we first present PARM and PARM*, perception-aware, decentralized,\nasynchronous multiagent trajectory planners that enable a team of agents to\nnavigate uncertain environments while deconflicting trajectories and avoiding\nobstacles using perception information. PARM* differs from PARM as it is less\nconservative, using more computation to find closer-to-optimal solutions. While\nthese methods achieve state-of-the-art performance, they suffer from high\ncomputational costs as they need to solve large optimization problems onboard,\nmaking it difficult for agents to replan at high rates. To overcome this\nchallenge, we present our second key contribution, PRIMER, a learning-based\nplanner trained with imitation learning (IL) using PARM* as the expert\ndemonstrator. PRIMER leverages the low computational requirements at deployment\nof neural networks and achieves a computation speed up to 5500 times faster\nthan optimization-based approaches.\n","authors":["Kota Kondo","Claudius T. Tewari","Andrea Tagliabue","Jesus Tordesillas","Parker C. Lusk","Jonathan P. How"],"pdf_url":"https://arxiv.org/pdf/2406.10060v2.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.16995v1","updated":"2024-10-22T13:17:20Z","published":"2024-10-22T13:17:20Z","title":"E-3DGS: Gaussian Splatting with Exposure and Motion Events","summary":"  Estimating Neural Radiance Fields (NeRFs) from images captured under optimal\nconditions has been extensively explored in the vision community. However,\nrobotic applications often face challenges such as motion blur, insufficient\nillumination, and high computational overhead, which adversely affect\ndownstream tasks like navigation, inspection, and scene visualization. To\naddress these challenges, we propose E-3DGS, a novel event-based approach that\npartitions events into motion (from camera or object movement) and exposure\n(from camera exposure), using the former to handle fast-motion scenes and using\nthe latter to reconstruct grayscale images for high-quality training and\noptimization of event-based 3D Gaussian Splatting (3DGS). We introduce a novel\nintegration of 3DGS with exposure events for high-quality reconstruction of\nexplicit scene representations. Our versatile framework can operate on motion\nevents alone for 3D reconstruction, enhance quality using exposure events, or\nadopt a hybrid mode that balances quality and effectiveness by optimizing with\ninitial exposure events followed by high-speed motion events. We also introduce\nEME-3D, a real-world 3D dataset with exposure events, motion events, camera\ncalibration parameters, and sparse point clouds. Our method is faster and\ndelivers better reconstruction quality than event-based NeRF while being more\ncost-effective than NeRF methods that combine event and RGB data by using a\nsingle event sensor. By combining motion and exposure events, E-3DGS sets a new\nbenchmark for event-based 3D reconstruction with robust performance in\nchallenging conditions and lower hardware demands. The source code and dataset\nwill be available at https://github.com/MasterHow/E-3DGS.\n","authors":["Xiaoting Yin","Hao Shi","Yuhan Bao","Zhenshan Bing","Yiyi Liao","Kailun Yang","Kaiwei Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16995v1.pdf","comment":"The source code and dataset will be available at\n  https://github.com/MasterHow/E-3DGS"},{"id":"http://arxiv.org/abs/2404.06050v2","updated":"2024-10-22T13:15:20Z","published":"2024-04-09T06:27:35Z","title":"Incremental Joint Learning of Depth, Pose and Implicit Scene\n  Representation on Monocular Camera in Large-scale Scenes","summary":"  Dense scene reconstruction for photo-realistic view synthesis has various\napplications, such as VR/AR, autonomous vehicles. However, most existing\nmethods have difficulties in large-scale scenes due to three core challenges:\n\\textit{(a) inaccurate depth input.} Accurate depth input is impossible to get\nin real-world large-scale scenes. \\textit{(b) inaccurate pose estimation.} Most\nexisting approaches rely on accurate pre-estimated camera poses. \\textit{(c)\ninsufficient scene representation capability.} A single global radiance field\nlacks the capacity to effectively scale to large-scale scenes. To this end, we\npropose an incremental joint learning framework, which can achieve accurate\ndepth, pose estimation, and large-scale scene reconstruction. A vision\ntransformer-based network is adopted as the backbone to enhance performance in\nscale information estimation. For pose estimation, a feature-metric bundle\nadjustment (FBA) method is designed for accurate and robust camera tracking in\nlarge-scale scenes. In terms of implicit scene representation, we propose an\nincremental scene representation method to construct the entire large-scale\nscene as multiple local radiance fields to enhance the scalability of 3D scene\nrepresentation. Extended experiments have been conducted to demonstrate the\neffectiveness and accuracy of our method in depth estimation, pose estimation,\nand large-scale scene reconstruction.\n","authors":["Tianchen Deng","Nailin Wang","Chongdi Wang","Shenghai Yuan","Jingchuan Wang","Danwei Wang","Weidong Chen"],"pdf_url":"https://arxiv.org/pdf/2404.06050v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16981v1","updated":"2024-10-22T13:01:21Z","published":"2024-10-22T13:01:21Z","title":"Proleptic Temporal Ensemble for Improving the Speed of Robot Tasks\n  Generated by Imitation Learning","summary":"  Imitation learning, which enables robots to learn behaviors from\ndemonstrations by non-experts, has emerged as a promising solution for\ngenerating robot motions in such environments. The imitation learning based\nrobot motion generation method, however, has the drawback of being limited by\nthe demonstrators task execution speed. This paper presents a novel temporal\nensemble approach applied to imitation learning algorithms, allowing for\nexecution of future actions. The proposed method leverages existing\ndemonstration data and pretrained policies, offering the advantages of\nrequiring no additional computation and being easy to implement. The algorithms\nperformance was validated through real world experiments involving robotic\nblock color sorting, demonstrating up to 3x increase in task execution speed\nwhile maintaining a high success rate compared to the action chunking with\ntransformer method. This study highlights the potential for significantly\nimproving the performance of imitation learning-based policies, which were\npreviously limited by the demonstrator's speed. It is expected to contribute\nsubstantially to future advancements in autonomous object manipulation\ntechnologies aimed at enhancing productivity.\n","authors":["Hyeonjun Park","Daegyu Lim","Seungyeon Kim","Sumin Park"],"pdf_url":"https://arxiv.org/pdf/2410.16981v1.pdf","comment":"This paper has been submitted to the Journal of Korea Robotics\n  Society and is currently under review"},{"id":"http://arxiv.org/abs/2410.16943v1","updated":"2024-10-22T12:18:38Z","published":"2024-10-22T12:18:38Z","title":"FlightAR: AR Flight Assistance Interface with Multiple Video Streams and\n  Object Detection Aimed at Immersive Drone Control","summary":"  The swift advancement of unmanned aerial vehicle (UAV) technologies\nnecessitates new standards for developing human-drone interaction (HDI)\ninterfaces. Most interfaces for HDI, especially first-person view (FPV)\ngoggles, limit the operator's ability to obtain information from the\nenvironment. This paper presents a novel interface, FlightAR, that integrates\naugmented reality (AR) overlays of UAV first-person view (FPV) and bottom\ncamera feeds with head-mounted display (HMD) to enhance the pilot's situational\nawareness. Using FlightAR, the system provides pilots not only with a video\nstream from several UAV cameras simultaneously, but also the ability to observe\ntheir surroundings in real time. User evaluation with NASA-TLX and UEQ surveys\nshowed low physical demand ($\\mu=1.8$, $SD = 0.8$) and good performance\n($\\mu=3.4$, $SD = 0.8$), proving better user assessments in comparison with\nbaseline FPV goggles. Participants also rated the system highly for stimulation\n($\\mu=2.35$, $SD = 0.9$), novelty ($\\mu=2.1$, $SD = 0.9$) and attractiveness\n($\\mu=1.97$, $SD = 1$), indicating positive user experiences. These results\ndemonstrate the potential of the system to improve UAV piloting experience\nthrough enhanced situational awareness and intuitive control. The code is\navailable here: https://github.com/Sautenich/FlightAR\n","authors":["Oleg Sautenkov","Selamawit Asfaw","Yasheerah Yaqoot","Muhammad Ahsan Mustafa","Aleksey Fedoseev","Daria Trinitatova","Dzmitry Tsetserukou"],"pdf_url":"https://arxiv.org/pdf/2410.16943v1.pdf","comment":"Manuscript accepted in IEEE International Conference on Robotics and\n  Biomimetics (IEEE ROBIO 2024)"},{"id":"http://arxiv.org/abs/2410.16922v1","updated":"2024-10-22T11:55:54Z","published":"2024-10-22T11:55:54Z","title":"Direction-Constrained Control for Efficient Physical Human-Robot\n  Interaction under Hierarchical Tasks","summary":"  This paper proposes a control method to address the physical Human-Robot\nInteraction (pHRI) challenge in the context of hierarchical tasks. A common\napproach to managing hierarchical tasks is Hierarchical Quadratic Programming\n(HQP), which, however, cannot be directly applied to human interaction due to\nits allowance of arbitrary velocity direction adjustments. To resolve this\nlimitation, we introduce the concept of directional constraints and develop a\ndirection-constrained optimization algorithm to handle the nonlinearities\ninduced by these constraints. The algorithm solves two sub-problems, minimizing\nthe error and minimizing the deviation angle, in parallel, and combines the\nresults of the two sub-problems to produce a final optimal outcome. The mutual\ninfluence between these two sub-problems is analyzed to determine the best\nparameter for combination. Additionally, the velocity objective in our control\nframework is computed using a variable admittance controller. Traditional\nadmittance control does not account for constraints. To address this issue, we\npropose a variable admittance control method to adjust control objectives\ndynamically. The method helps reduce the deviation between robot velocity and\nhuman intention at the constraint boundaries, thereby enhancing interaction\nefficiency. We evaluate the proposed method in scenarios where a human operator\nphysically interacts with a 7-degree-of-freedom robotic arm. The results\nhighlight the importance of incorporating directional constraints in pHRI for\nhierarchical tasks. Compared to existing methods, our approach generates\nsmoother robotic trajectories during interaction while avoiding interaction\ndelays at the constraint boundaries.\n","authors":["Mengxin Xu","Weiwei Wan","Hesheng Wang","Kensuke Harada"],"pdf_url":"https://arxiv.org/pdf/2410.16922v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16919v1","updated":"2024-10-22T11:52:22Z","published":"2024-10-22T11:52:22Z","title":"EnvBridge: Bridging Diverse Environments with Cross-Environment\n  Knowledge Transfer for Embodied AI","summary":"  In recent years, Large Language Models (LLMs) have demonstrated high\nreasoning capabilities, drawing attention for their applications as agents in\nvarious decision-making processes. One notably promising application of LLM\nagents is robotic manipulation. Recent research has shown that LLMs can\ngenerate text planning or control code for robots, providing substantial\nflexibility and interaction capabilities. However, these methods still face\nchallenges in terms of flexibility and applicability across different\nenvironments, limiting their ability to adapt autonomously. Current approaches\ntypically fall into two categories: those relying on environment-specific\npolicy training, which restricts their transferability, and those generating\ncode actions based on fixed prompts, which leads to diminished performance when\nconfronted with new environments. These limitations significantly constrain the\ngeneralizability of agents in robotic manipulation. To address these\nlimitations, we propose a novel method called EnvBridge. This approach involves\nthe retention and transfer of successful robot control codes from source\nenvironments to target environments. EnvBridge enhances the agent's\nadaptability and performance across diverse settings by leveraging insights\nfrom multiple environments. Notably, our approach alleviates environmental\nconstraints, offering a more flexible and generalizable solution for robotic\nmanipulation tasks. We validated the effectiveness of our method using robotic\nmanipulation benchmarks: RLBench, MetaWorld, and CALVIN. Our experiments\ndemonstrate that LLM agents can successfully leverage diverse knowledge sources\nto solve complex tasks. Consequently, our approach significantly enhances the\nadaptability and robustness of robotic manipulation agents in planning across\ndiverse environments.\n","authors":["Tomoyuki Kagaya","Yuxuan Lou","Thong Jing Yuan","Subramanian Lakshmi","Jayashree Karlekar","Sugiri Pranata","Natsuki Murakami","Akira Kinose","Koki Oguri","Felix Wick","Yang You"],"pdf_url":"https://arxiv.org/pdf/2410.16919v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16887v1","updated":"2024-10-22T10:45:05Z","published":"2024-10-22T10:45:05Z","title":"Distribution of Responsibility During the Usage of AI-Based Exoskeletons\n  for Upper Limb Rehabilitation","summary":"  The ethical issues concerning the AI-based exoskeletons used in healthcare\nhave already been studied literally rather than technically. How the ethical\nguidelines can be integrated into the development process has not been widely\nstudied. However, this is one of the most important topics which should be\nstudied more in real-life applications. Therefore, in this paper we highlight\none ethical concern in the context of an exoskeleton used to train a user to\nperform a gesture: during the interaction between the exoskeleton, patient and\ntherapist, how is the responsibility for decision making distributed? Based on\nthe outcome of this, we will discuss how to integrate ethical guidelines into\nthe development process of an AI-based exoskeleton. The discussion is based on\na case study: AiBle. The different technical factors affecting the\nrehabilitation results and the human-machine interaction for AI-based\nexoskeletons are identified and discussed in this paper in order to better\napply the ethical guidelines during the development of AI-based exoskeletons.\n","authors":[" Huaxi"," Zhang","Melanie Fontaine","Marianne Huchard","Baptiste Mereaux","Olivier Remy-Neris"],"pdf_url":"https://arxiv.org/pdf/2410.16887v1.pdf","comment":"Robot Trust for Symbiotic Societies (RTSS) at IROS 2022"},{"id":"http://arxiv.org/abs/2303.01205v2","updated":"2024-10-22T10:12:15Z","published":"2023-03-02T12:42:55Z","title":"Consistent Distributed Cooperative Localization: A Coordinate\n  Transformation Approach","summary":"  This paper addresses the consistency issue of multi-robot distributed\ncooperative localization. We introduce a consistent distributed cooperative\nlocalization algorithm conducting state estimation in a transformed coordinate.\nThe core idea involves a linear time-varying coordinated transformation to\nrender the propagation Jacobian independent of the state and make it suitable\nfor a distributed manner. This transformation is seamlessly integrated into a\nserver-based distributed cooperative localization framework, in which each\nrobot estimates its own state while the server maintains the\ncross-correlations. The transformation ensures the correct observability\nproperty of the entire framework. Moreover, the algorithm accommodates various\ntypes of robot-to-robot relative measurements, broadening its applicability.\nThrough simulations and real-world dataset experiments, the proposed algorithm\nhas demonstrated better performance in terms of both consistency and accuracy\ncompared to existing algorithms.\n","authors":["Chungeng Tian","Ning Hao","Fenghua He","Haodi Yao"],"pdf_url":"https://arxiv.org/pdf/2303.01205v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16864v1","updated":"2024-10-22T10:06:50Z","published":"2024-10-22T10:06:50Z","title":"Pedestrian motion prediction evaluation for urban autonomous driving","summary":"  Pedestrian motion prediction is a key part of the modular-based autonomous\ndriving pipeline, ensuring safe, accurate, and timely awareness of human\nagents' possible future trajectories. The autonomous vehicle can use this\ninformation to prevent any possible accidents and create a comfortable and\npleasant driving experience for the passengers and pedestrians. A wealth of\nresearch was done on the topic from the authors of robotics, computer vision,\nintelligent transportation systems, and other fields. However, a relatively\nunexplored angle is the integration of the state-of-art solutions into existing\nautonomous driving stacks and evaluating them in real-life conditions rather\nthan sanitized datasets. We analyze selected publications with provided\nopen-source solutions and provide a perspective obtained by integrating them\ninto existing Autonomous Driving framework - Autoware Mini and performing\nexperiments in natural urban conditions in Tartu, Estonia to determine\nvaluability of traditional motion prediction metrics. This perspective should\nbe valuable to any potential autonomous driving or robotics engineer looking\nfor the real-world performance of the existing state-of-art pedestrian motion\nprediction problem. The code with instructions on accessing the dataset is\navailable at https://github.com/dmytrozabolotnii/autoware_mini.\n","authors":["Dmytro Zabolotnii","Yar Muhammad","Naveed Muhammad"],"pdf_url":"https://arxiv.org/pdf/2410.16864v1.pdf","comment":"7 pages, 2 figures, 4 tables This work has been submitted to the IEEE\n  for possible publication"},{"id":"http://arxiv.org/abs/2410.11989v3","updated":"2024-10-22T09:46:12Z","published":"2024-10-15T18:52:22Z","title":"Dynamic Open-Vocabulary 3D Scene Graphs for Long-term Language-Guided\n  Mobile Manipulation","summary":"  Enabling mobile robots to perform long-term tasks in dynamic real-world\nenvironments is a formidable challenge, especially when the environment changes\nfrequently due to human-robot interactions or the robot's own actions.\nTraditional methods typically assume static scenes, which limits their\napplicability in the continuously changing real world. To overcome these\nlimitations, we present DovSG, a novel mobile manipulation framework that\nleverages dynamic open-vocabulary 3D scene graphs and a language-guided task\nplanning module for long-term task execution. DovSG takes RGB-D sequences as\ninput and utilizes vision-language models (VLMs) for object detection to obtain\nhigh-level object semantic features. Based on the segmented objects, a\nstructured 3D scene graph is generated for low-level spatial relationships.\nFurthermore, an efficient mechanism for locally updating the scene graph,\nallows the robot to adjust parts of the graph dynamically during interactions\nwithout the need for full scene reconstruction. This mechanism is particularly\nvaluable in dynamic environments, enabling the robot to continually adapt to\nscene changes and effectively support the execution of long-term tasks. We\nvalidated our system in real-world environments with varying degrees of manual\nmodifications, demonstrating its effectiveness and superior performance in\nlong-term tasks. Our project page is available at:\nhttps://bjhyzj.github.io/dovsg-web.\n","authors":["Zhijie Yan","Shufei Li","Zuoxu Wang","Lixiu Wu","Han Wang","Jun Zhu","Lijiang Chen","Jihong Liu"],"pdf_url":"https://arxiv.org/pdf/2410.11989v3.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2402.02500v3","updated":"2024-10-22T09:42:39Z","published":"2024-02-04T14:18:45Z","title":"Point Cloud Matters: Rethinking the Impact of Different Observation\n  Spaces on Robot Learning","summary":"  In robot learning, the observation space is crucial due to the distinct\ncharacteristics of different modalities, which can potentially become a\nbottleneck alongside policy design. In this study, we explore the influence of\nvarious observation spaces on robot learning, focusing on three predominant\nmodalities: RGB, RGB-D, and point cloud. We introduce OBSBench, a benchmark\ncomprising two simulators and 125 tasks, along with standardized pipelines for\nvarious encoders and policy baselines. Extensive experiments on diverse\ncontact-rich manipulation tasks reveal a notable trend: point cloud-based\nmethods, even those with the simplest designs, frequently outperform their RGB\nand RGB-D counterparts. This trend persists in both scenarios: training from\nscratch and utilizing pre-training. Furthermore, our findings demonstrate that\npoint cloud observations often yield better policy performance and\nsignificantly stronger generalization capabilities across various geometric and\nvisual conditions. These outcomes suggest that the 3D point cloud is a valuable\nobservation modality for intricate robotic tasks. We also suggest that\nincorporating both appearance and coordinate information can enhance the\nperformance of point cloud methods. We hope our work provides valuable insights\nand guidance for designing more generalizable and robust robotic models. Codes\nare available at https://github.com/HaoyiZhu/PointCloudMatters.\n","authors":["Haoyi Zhu","Yating Wang","Di Huang","Weicai Ye","Wanli Ouyang","Tong He"],"pdf_url":"https://arxiv.org/pdf/2402.02500v3.pdf","comment":"38th Conference on Neural Information Processing Systems (NeurIPS\n  2024) Track on Datasets and Benchmarks"},{"id":"http://arxiv.org/abs/2410.16821v1","updated":"2024-10-22T08:48:48Z","published":"2024-10-22T08:48:48Z","title":"Guiding Reinforcement Learning with Incomplete System Dynamics","summary":"  Model-free reinforcement learning (RL) is inherently a reactive method,\noperating under the assumption that it starts with no prior knowledge of the\nsystem and entirely depends on trial-and-error for learning. This approach\nfaces several challenges, such as poor sample efficiency, generalization, and\nthe need for well-designed reward functions to guide learning effectively. On\nthe other hand, controllers based on complete system dynamics do not require\ndata. This paper addresses the intermediate situation where there is not enough\nmodel information for complete controller design, but there is enough to\nsuggest that a model-free approach is not the best approach either. By\ncarefully decoupling known and unknown information about the system dynamics,\nwe obtain an embedded controller guided by our partial model and thus improve\nthe learning efficiency of an RL-enhanced approach. A modular design allows us\nto deploy mainstream RL algorithms to refine the policy. Simulation results\nshow that our method significantly improves sample efficiency compared with\nstandard RL methods on continuous control tasks, and also offers enhanced\nperformance over traditional control approaches. Experiments on a real ground\nvehicle also validate the performance of our method, including generalization\nand robustness.\n","authors":["Shuyuan Wang","Jingliang Duan","Nathan P. Lawrence","Philip D. Loewen","Michael G. Forbes","R. Bhushan Gopaluni","Lixian Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.16821v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16804v1","updated":"2024-10-22T08:32:01Z","published":"2024-10-22T08:32:01Z","title":"Combining Ontological Knowledge and Large Language Model for\n  User-Friendly Service Robots","summary":"  Lifestyle support through robotics is an increasingly promising field, with\nexpectations for robots to take over or assist with chores like floor cleaning,\ntable setting and clearing, and fetching items. The growth of AI, particularly\nfoundation models, such as large language models (LLMs) and visual language\nmodels (VLMs), is significantly shaping this sector. LLMs, by facilitating\nnatural interactions and providing vast general knowledge, are proving\ninvaluable for robotic tasks. This paper zeroes in on the benefits of LLMs for\n\"bring-me\" tasks, where robots fetch specific items for users, often based on\nvague instructions. Our previous efforts utilized an ontology extended to\nhandle environmental data to decipher such vagueness, but faced limitations\nwhen unresolvable ambiguities required user intervention for clarity. Here, we\nenhance our approach by integrating LLMs for providing additional commonsense\nknowledge, pairing it with ontological data to mitigate the issue of\nhallucinations and reduce the need for user queries, thus improving system\nusability. We present a system that merges these knowledge bases and assess its\nefficacy on \"bring-me\" tasks, aiming to provide a more seamless and efficient\nrobotic assistance experience.\n","authors":["Haru Nakajima","Jun Miura"],"pdf_url":"https://arxiv.org/pdf/2410.16804v1.pdf","comment":"Accepted to IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS2024)"},{"id":"http://arxiv.org/abs/2410.16790v1","updated":"2024-10-22T08:07:44Z","published":"2024-10-22T08:07:44Z","title":"Sample-Efficient Curriculum Reinforcement Learning for Complex Reward\n  Functions","summary":"  Reinforcement learning (RL) shows promise in control problems, but its\npractical application is often hindered by the complexity arising from\nintricate reward functions with constraints. While the reward hypothesis\nsuggests these competing demands can be encapsulated in a single scalar reward\nfunction, designing such functions remains challenging. Building on existing\nwork, we start by formulating preferences over trajectories to derive a\nrealistic reward function that balances goal achievement with constraint\nsatisfaction in the application of mobile robotics with dynamic obstacles. To\nmitigate reward exploitation in such complex settings, we propose a novel\ntwo-stage reward curriculum combined with a flexible replay buffer that\nadaptively samples experiences. Our approach first learns on a subset of\nrewards before transitioning to the full reward, allowing the agent to learn\ntrade-offs between objectives and constraints. After transitioning to a new\nstage, our method continues to make use of past experiences by updating their\nrewards for sample-efficient learning. We investigate the efficacy of our\napproach in robot navigation tasks and demonstrate superior performance\ncompared to baselines in terms of true reward achievement and task completion,\nunderlining its effectiveness.\n","authors":["Kilian Freitag","Kristian Ceder","Rita Laezza","Knut Åkesson","Morteza Haghir Chehreghani"],"pdf_url":"https://arxiv.org/pdf/2410.16790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12214v3","updated":"2024-10-22T07:58:01Z","published":"2024-06-18T02:28:02Z","title":"Is Your HD Map Constructor Reliable under Sensor Corruptions?","summary":"  Driving systems often rely on high-definition (HD) maps for precise\nenvironmental information, which is crucial for planning and navigation. While\ncurrent HD map constructors perform well under ideal conditions, their\nresilience to real-world challenges, \\eg, adverse weather and sensor failures,\nis not well understood, raising safety concerns. This work introduces MapBench,\nthe first comprehensive benchmark designed to evaluate the robustness of HD map\nconstruction methods against various sensor corruptions. Our benchmark\nencompasses a total of 29 types of corruptions that occur from cameras and\nLiDAR sensors. Extensive evaluations across 31 HD map constructors reveal\nsignificant performance degradation of existing methods under adverse weather\nconditions and sensor failures, underscoring critical safety concerns. We\nidentify effective strategies for enhancing robustness, including innovative\napproaches that leverage multi-modal fusion, advanced data augmentation, and\narchitectural techniques. These insights provide a pathway for developing more\nreliable HD map construction methods, which are essential for the advancement\nof autonomous driving technology. The benchmark toolkit and affiliated code and\nmodel checkpoints have been made publicly accessible.\n","authors":["Xiaoshuai Hao","Mengchuan Wei","Yifan Yang","Haimei Zhao","Hui Zhang","Yi Zhou","Qiang Wang","Weiming Li","Lingdong Kong","Jing Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.12214v3.pdf","comment":"NeurIPS 2024; 40 pages, 17 figures, 23 tables; Code at\n  https://mapbench.github.io/"},{"id":"http://arxiv.org/abs/2410.16762v1","updated":"2024-10-22T07:29:05Z","published":"2024-10-22T07:29:05Z","title":"Deep-Sea A*+: An Advanced Path Planning Method Integrating Enhanced A*\n  and Dynamic Window Approach for Autonomous Underwater Vehicles","summary":"  As terrestrial resources become increasingly depleted, the demand for\ndeep-sea resource exploration has intensified. However, the extreme conditions\nin the deep-sea environment pose significant challenges for underwater\noperations, necessitating the development of robust detection robots. In this\npaper, we propose an advanced path planning methodology that integrates an\nimproved A* algorithm with the Dynamic Window Approach (DWA). By optimizing the\nsearch direction of the traditional A* algorithm and introducing an enhanced\nevaluation function, our improved A* algorithm accelerates path searching and\nreduces computational load. Additionally, the path-smoothing process has been\nrefined to improve continuity and smoothness, minimizing sharp turns. This\nmethod also integrates global path planning with local dynamic obstacle\navoidance via DWA, improving the real-time response of underwater robots in\ndynamic environments. Simulation results demonstrate that our proposed method\nsurpasses the traditional A* algorithm in terms of path smoothness, obstacle\navoidance, and real-time performance. The robustness of this approach in\ncomplex environments with both static and dynamic obstacles highlights its\npotential in autonomous underwater vehicle (AUV) navigation and obstacle\navoidance.\n","authors":["Yinyi Lai","Jiaqi Shang","Zenghui Liu","Zheyu Jiang","Yuyang Li","Longchao Chen"],"pdf_url":"https://arxiv.org/pdf/2410.16762v1.pdf","comment":"Accepted by 2024 International Conference on Big Data, Artificial\n  Intelligence and Internet of Things Engineering (ICBAIE 2024)"},{"id":"http://arxiv.org/abs/2409.15717v2","updated":"2024-10-22T07:24:38Z","published":"2024-09-24T04:06:01Z","title":"Autonomous Wheel Loader Navigation Using Goal-Conditioned Actor-Critic\n  MPC","summary":"  This paper proposes a novel control method for an autonomous wheel loader,\nenabling time-efficient navigation to an arbitrary goal pose. Unlike prior\nworks that combine high-level trajectory planners with Model Predictive Control\n(MPC), we directly enhance the planning capabilities of MPC by integrating a\ncost function derived from Actor-Critic Reinforcement Learning (RL).\nSpecifically, we train an RL agent to solve the pose reaching task in\nsimulation, then incorporate the trained neural network critic as both the\nstage and terminal cost of an MPC. We show through comprehensive simulations\nthat the resulting MPC inherits the time-efficient behavior of the RL agent,\ngenerating trajectories that compare favorably against those found using\ntrajectory optimization. We also deploy our method on a real wheel loader,\nwhere we successfully navigate to various goal poses.\n","authors":["Aleksi Mäki-Penttilä","Naeim Ebrahimi Toulkani","Reza Ghabcheloo"],"pdf_url":"https://arxiv.org/pdf/2409.15717v2.pdf","comment":"Submitted to International Conference on Robotics and Automation\n  (ICRA) 2025"},{"id":"http://arxiv.org/abs/2410.16197v2","updated":"2024-10-22T07:14:11Z","published":"2024-10-21T17:00:03Z","title":"LASER: Script Execution by Autonomous Agents for On-demand Traffic\n  Simulation","summary":"  Autonomous Driving Systems (ADS) require diverse and safety-critical traffic\nscenarios for effective training and testing, but the existing data generation\nmethods struggle to provide flexibility and scalability. We propose LASER, a\nnovel frame-work that leverage large language models (LLMs) to conduct traffic\nsimulations based on natural language inputs. The framework operates in two\nstages: it first generates scripts from user-provided descriptions and then\nexecutes them using autonomous agents in real time. Validated in the CARLA\nsimulator, LASER successfully generates complex, on-demand driving scenarios,\nsignificantly improving ADS training and testing data generation.\n","authors":["Hao Gao","Jingyue Wang","Wenyang Fang","Jingwei Xu","Yunpeng Huang","Taolue Chen","Xiaoxing Ma"],"pdf_url":"https://arxiv.org/pdf/2410.16197v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16749v1","updated":"2024-10-22T07:08:50Z","published":"2024-10-22T07:08:50Z","title":"Fast State-of-Health Estimation Method for Lithium-ion Battery using\n  Sparse Identification of Nonlinear Dynamics","summary":"  Lithium-ion batteries (LIBs) are utilized as a major energy source in various\nfields because of their high energy density and long lifespan. During repeated\ncharging and discharging, the degradation of LIBs, which reduces their maximum\npower output and operating time, is a pivotal issue. This degradation can\naffect not only battery performance but also safety of the system. Therefore,\nit is essential to accurately estimate the state-of-health (SOH) of the battery\nin real time. To address this problem, we propose a fast SOH estimation method\nthat utilizes the sparse model identification algorithm (SINDy) for nonlinear\ndynamics. SINDy can discover the governing equations of target systems with low\ndata assuming that few functions have the dominant characteristic of the\nsystem. To decide the state of degradation model, correlation analysis is\nsuggested. Using SINDy and correlation analysis, we can obtain the data-driven\nSOH model to improve the interpretability of the system. To validate the\nfeasibility of the proposed method, the estimation performance of the SOH and\nthe computation time are evaluated by comparing it with various machine\nlearning algorithms.\n","authors":["Jayden Dongwoo Lee","Donghoon Seo","Jongho Shin","Hyochoong Bang"],"pdf_url":"https://arxiv.org/pdf/2410.16749v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16727v1","updated":"2024-10-22T06:25:34Z","published":"2024-10-22T06:25:34Z","title":"DiffusionSeeder: Seeding Motion Optimization with Diffusion for Rapid\n  Motion Planning","summary":"  Running optimization across many parallel seeds leveraging GPU compute have\nrelaxed the need for a good initialization, but this can fail if the problem is\nhighly non-convex as all seeds could get stuck in local minima. One such\nsetting is collision-free motion optimization for robot manipulation, where\noptimization converges quickly on easy problems but struggle in obstacle dense\nenvironments (e.g., a cluttered cabinet or table). In these situations,\ngraph-based planning algorithms are used to obtain seeds, resulting in\nsignificant slowdowns. We propose DiffusionSeeder, a diffusion based approach\nthat generates trajectories to seed motion optimization for rapid robot motion\nplanning. DiffusionSeeder takes the initial depth image observation of the\nscene and generates high quality, multi-modal trajectories that are then\nfine-tuned with a few iterations of motion optimization. We integrate\nDiffusionSeeder to generate the seed trajectories for cuRobo, a GPU-accelerated\nmotion optimization method, which results in 12x speed up on average, and 36x\nspeed up for more complicated problems, while achieving 10% higher success rate\nin partially observed simulation environments. Our results show the\neffectiveness of using diverse solutions from a learned diffusion model.\nPhysical experiments on a Franka robot demonstrate the sim2real transfer of\nDiffusionSeeder to the real robot, with an average success rate of 86% and\nplanning time of 26ms, improving on cuRobo by 51% higher success rate while\nalso being 2.5x faster.\n","authors":["Huang Huang","Balakumar Sundaralingam","Arsalan Mousavian","Adithyavairavan Murali","Ken Goldberg","Dieter Fox"],"pdf_url":"https://arxiv.org/pdf/2410.16727v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.05289v3","updated":"2024-10-22T06:23:49Z","published":"2024-09-09T02:54:24Z","title":"Developing Path Planning with Behavioral Cloning and Proximal Policy\n  Optimization for Path-Tracking and Static Obstacle Nudging","summary":"  In autonomous driving, end-to-end methods utilizing Imitation Learning (IL)\nand Reinforcement Learning (RL) are becoming more and more common. However,\nthey do not involve explicit reasoning like classic robotics workflow and\nplanning with horizons, resulting in strategies implicit and myopic. In this\npaper, we introduce a path planning method that uses Behavioral Cloning (BC)\nfor path-tracking and Proximal Policy Optimization (PPO) for static obstacle\nnudging. It outputs lateral offset values to adjust the given reference\nwaypoints and performs modified path for different controllers. Experimental\nresults show that the algorithm can do path following that mimics the expert\nperformance of path-tracking controllers, and avoid collision to fixed\nobstacles. The method makes a good attempt at planning with learning-based\nmethods in path planning problems of autonomous driving.\n","authors":["Mingyan Zhou","Biao Wang","Tian Tan","Xiatao Sun"],"pdf_url":"https://arxiv.org/pdf/2409.05289v3.pdf","comment":"6 pages, 8 figures"},{"id":"http://arxiv.org/abs/2410.16687v1","updated":"2024-10-22T04:36:06Z","published":"2024-10-22T04:36:06Z","title":"DARE: Diffusion Policy for Autonomous Robot Exploration","summary":"  Autonomous robot exploration requires a robot to efficiently explore and map\nunknown environments. Compared to conventional methods that can only optimize\npaths based on the current robot belief, learning-based methods show the\npotential to achieve improved performance by drawing on past experiences to\nreason about unknown areas. In this paper, we propose DARE, a novel generative\napproach that leverages diffusion models trained on expert demonstrations,\nwhich can explicitly generate an exploration path through one-time inference.\nWe build DARE upon an attention-based encoder and a diffusion policy model, and\nintroduce ground truth optimal demonstrations for training to learn better\npatterns for exploration. The trained planner can reason about the partial\nbelief to recognize the potential structure in unknown areas and consider these\nareas during path planning. Our experiments demonstrate that DARE achieves\non-par performance with both conventional and learning-based state-of-the-art\nexploration planners, as well as good generalizability in both simulations and\nreal-life scenarios.\n","authors":["Yuhong Cao","Jeric Lew","Jingsong Liang","Jin Cheng","Guillaume Sartoretti"],"pdf_url":"https://arxiv.org/pdf/2410.16687v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16686v1","updated":"2024-10-22T04:35:57Z","published":"2024-10-22T04:35:57Z","title":"SERN: Simulation-Enhanced Realistic Navigation for Multi-Agent Robotic\n  Systems in Contested Environments","summary":"  The increasing deployment of autonomous systems in complex environments\nnecessitates efficient communication and task completion among multiple agents.\nThis paper presents SERN (Simulation-Enhanced Realistic Navigation), a novel\nframework integrating virtual and physical environments for real-time\ncollaborative decision-making in multi-robot systems. SERN addresses key\nchallenges in asset deployment and coordination through a bi-directional\ncommunication framework using the AuroraXR ROS Bridge. Our approach advances\nthe SOTA through accurate real-world representation in virtual environments\nusing Unity high-fidelity simulator; synchronization of physical and virtual\nrobot movements; efficient ROS data distribution between remote locations; and\nintegration of SOTA semantic segmentation for enhanced environmental\nperception. Our evaluations show a 15% to 24% improvement in latency and up to\na 15% increase in processing efficiency compared to traditional ROS setups.\nReal-world and virtual simulation experiments with multiple robots demonstrate\nsynchronization accuracy, achieving less than 5 cm positional error and under\n2-degree rotational error. These results highlight SERN's potential to enhance\nsituational awareness and multi-agent coordination in diverse, contested\nenvironments.\n","authors":["Jumman Hossain","Emon Dey","Snehalraj Chugh","Masud Ahmed","MS Anwar","Abu-Zaher Faridee","Jason Hoppes","Theron Trout","Anjon Basak","Rafidh Chowdhury","Rishabh Mistry","Hyun Kim","Jade Freeman","Niranjan Suri","Adrienne Raglin","Carl Busart","Timothy Gregory","Anuradha Ravi","Nirmalya Roy"],"pdf_url":"https://arxiv.org/pdf/2410.16686v1.pdf","comment":"Under Review for ICRA 2025"},{"id":"http://arxiv.org/abs/2409.18390v2","updated":"2024-10-22T04:16:23Z","published":"2024-09-27T02:12:56Z","title":"Speech to Reality: On-Demand Production using Natural Language, 3D\n  Generative AI, and Discrete Robotic Assembly","summary":"  We present a system that transforms speech into physical objects by combining\n3D generative Artificial Intelligence with robotic assembly. The system\nleverages natural language input to make design and manufacturing more\naccessible, enabling individuals without expertise in 3D modeling or robotic\nprogramming to create physical objects. We propose utilizing discrete robotic\nassembly of lattice-based voxel components to address the challenges of using\ngenerative AI outputs in physical production, such as design variability,\nfabrication speed, structural integrity, and material waste. The system\ninterprets speech to generate 3D objects, discretizes them into voxel\ncomponents, computes an optimized assembly sequence, and generates a robotic\ntoolpath. The results are demonstrated through the assembly of various objects,\nranging from chairs to shelves, which are prompted via speech and realized\nwithin 5 minutes using a 6-axis robotic arm.\n","authors":["Alexander Htet Kyaw","Se Hwan Jeon","Miana Smith","Neil Gershenfeld"],"pdf_url":"https://arxiv.org/pdf/2409.18390v2.pdf","comment":"This work has been submitted to the IEEE for possible publication. An\n  updated version will replace this version"},{"id":"http://arxiv.org/abs/2410.16666v1","updated":"2024-10-22T03:39:21Z","published":"2024-10-22T03:39:21Z","title":"QuasiNav: Asymmetric Cost-Aware Navigation Planning with Constrained\n  Quasimetric Reinforcement Learning","summary":"  Autonomous navigation in unstructured outdoor environments is inherently\nchallenging due to the presence of asymmetric traversal costs, such as varying\nenergy expenditures for uphill versus downhill movement. Traditional\nreinforcement learning methods often assume symmetric costs, which can lead to\nsuboptimal navigation paths and increased safety risks in real-world scenarios.\nIn this paper, we introduce QuasiNav, a novel reinforcement learning framework\nthat integrates quasimetric embeddings to explicitly model asymmetric costs and\nguide efficient, safe navigation. QuasiNav formulates the navigation problem as\na constrained Markov decision process (CMDP) and employs quasimetric embeddings\nto capture directionally dependent costs, allowing for a more accurate\nrepresentation of the terrain. This approach is combined with adaptive\nconstraint tightening within a constrained policy optimization framework to\ndynamically enforce safety constraints during learning. We validate QuasiNav\nacross three challenging navigation scenarios-undulating terrains, asymmetric\nhill traversal, and directionally dependent terrain traversal-demonstrating its\neffectiveness in both simulated and real-world environments. Experimental\nresults show that QuasiNav significantly outperforms conventional methods,\nachieving higher success rates, improved energy efficiency, and better\nadherence to safety constraints.\n","authors":["Jumman Hossain","Abu-Zaher Faridee","Derrik Asher","Jade Freeman","Theron Trout","Timothy Gregory","Nirmalya Roy"],"pdf_url":"https://arxiv.org/pdf/2410.16666v1.pdf","comment":"Under Review for ICRA 2025"},{"id":"http://arxiv.org/abs/2402.04061v3","updated":"2024-10-22T02:31:13Z","published":"2024-02-06T15:05:25Z","title":"TopoNav: Topological Navigation for Efficient Exploration in Sparse\n  Reward Environments","summary":"  Autonomous robots exploring unknown environments face a significant\nchallenge: navigating effectively without prior maps and with limited external\nfeedback. This challenge intensifies in sparse reward environments, where\ntraditional exploration techniques often fail. In this paper, we present\nTopoNav, a novel topological navigation framework that integrates active\nmapping, hierarchical reinforcement learning, and intrinsic motivation to\nenable efficient goal-oriented exploration and navigation in sparse-reward\nsettings. TopoNav dynamically constructs a topological map of the environment,\ncapturing key locations and pathways. A two-level hierarchical policy\narchitecture, comprising a high-level graph traversal policy and low-level\nmotion control policies, enables effective navigation and obstacle avoidance\nwhile maintaining focus on the overall goal. Additionally, TopoNav incorporates\nintrinsic motivation to guide exploration toward relevant regions and frontier\nnodes in the topological map, addressing the challenges of sparse extrinsic\nrewards. We evaluate TopoNav both in the simulated and real-world off-road\nenvironments using a Clearpath Jackal robot, across three challenging\nnavigation scenarios: goal-reaching, feature-based navigation, and navigation\nin complex terrains. We observe an increase in exploration coverage by 7- 20%,\nin success rates by 9-19%, and reductions in navigation times by 15-36% across\nvarious scenarios, compared to state-of-the-art methods\n","authors":["Jumman Hossain","Abu-Zaher Faridee","Nirmalya Roy","Jade Freeman","Timothy Gregory","Theron T. Trout"],"pdf_url":"https://arxiv.org/pdf/2402.04061v3.pdf","comment":"Accepted at the 37th IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS) 2024"},{"id":"http://arxiv.org/abs/2410.16632v1","updated":"2024-10-22T02:21:30Z","published":"2024-10-22T02:21:30Z","title":"Benchmarking Smoothness and Reducing High-Frequency Oscillations in\n  Continuous Control Policies","summary":"  Reinforcement learning (RL) policies are prone to high-frequency\noscillations, especially undesirable when deploying to hardware in the\nreal-world. In this paper, we identify, categorize, and compare methods from\nthe literature that aim to mitigate high-frequency oscillations in deep RL. We\ndefine two broad classes: loss regularization and architectural methods. At\ntheir core, these methods incentivize learning a smooth mapping, such that\nnearby states in the input space produce nearby actions in the output space. We\npresent benchmarks in terms of policy performance and control smoothness on\ntraditional RL environments from the Gymnasium and a complex manipulation task,\nas well as three robotics locomotion tasks that include deployment and\nevaluation with real-world hardware. Finally, we also propose hybrid methods\nthat combine elements from both loss regularization and architectural methods.\nWe find that the best-performing hybrid outperforms other methods, and improves\ncontrol smoothness by 26.8% over the baseline, with a worst-case performance\ndegradation of just 2.8%.\n","authors":["Guilherme Christmann","Ying-Sheng Luo","Hanjaya Mandala","Wei-Chao Chen"],"pdf_url":"https://arxiv.org/pdf/2410.16632v1.pdf","comment":"Presented in IROS 2024"},{"id":"http://arxiv.org/abs/2410.16623v1","updated":"2024-10-22T02:14:29Z","published":"2024-10-22T02:14:29Z","title":"MotionGlot: A Multi-Embodied Motion Generation Model","summary":"  This paper introduces MotionGlot, a model that can generate motion across\nmultiple embodiments with different action dimensions, such as quadruped robots\nand human bodies. By leveraging the well-established training procedures\ncommonly used in large language models (LLMs), we introduce an\ninstruction-tuning template specifically designed for motion-related tasks. Our\napproach demonstrates that the principles underlying LLM training can be\nsuccessfully adapted to learn a wide range of motion generation tasks across\nmultiple embodiments with different action dimensions. We demonstrate the\nvarious abilities of MotionGlot on a set of 6 tasks and report an average\nimprovement of 35.3% across tasks. Additionally, we contribute two new\ndatasets: (1) a dataset of expert-controlled quadruped locomotion with\napproximately 48,000 trajectories paired with direction-based text annotations,\nand (2) a dataset of over 23,000 situational text prompts for human motion\ngeneration tasks. Finally, we conduct hardware experiments to validate the\ncapabilities of our system in real-world applications.\n","authors":["Sudarshan Harithas","Srinath Sridhar"],"pdf_url":"https://arxiv.org/pdf/2410.16623v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16194v2","updated":"2024-10-22T02:06:35Z","published":"2024-05-25T11:53:23Z","title":"Diffusion-Reward Adversarial Imitation Learning","summary":"  Imitation learning aims to learn a policy from observing expert\ndemonstrations without access to reward signals from environments. Generative\nadversarial imitation learning (GAIL) formulates imitation learning as\nadversarial learning, employing a generator policy learning to imitate expert\nbehaviors and discriminator learning to distinguish the expert demonstrations\nfrom agent trajectories. Despite its encouraging results, GAIL training is\noften brittle and unstable. Inspired by the recent dominance of diffusion\nmodels in generative modeling, we propose Diffusion-Reward Adversarial\nImitation Learning (DRAIL), which integrates a diffusion model into GAIL,\naiming to yield more robust and smoother rewards for policy learning.\nSpecifically, we propose a diffusion discriminative classifier to construct an\nenhanced discriminator, and design diffusion rewards based on the classifier's\noutput for policy learning. Extensive experiments are conducted in navigation,\nmanipulation, and locomotion, verifying DRAIL's effectiveness compared to prior\nimitation learning methods. Moreover, additional experimental results\ndemonstrate the generalizability and data efficiency of DRAIL. Visualized\nlearned reward functions of GAIL and DRAIL suggest that DRAIL can produce more\nrobust and smoother rewards. Project page:\nhttps://nturobotlearninglab.github.io/DRAIL/\n","authors":["Chun-Mao Lai","Hsiang-Chun Wang","Ping-Chun Hsieh","Yu-Chiang Frank Wang","Min-Hung Chen","Shao-Hua Sun"],"pdf_url":"https://arxiv.org/pdf/2405.16194v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16605v1","updated":"2024-10-22T01:25:15Z","published":"2024-10-22T01:25:15Z","title":"EnKode: Active Learning of Unknown Flows with Koopman Operators","summary":"  In this letter, we address the task of adaptive sampling to model vector\nfields. When modeling environmental phenomena with a robot, gathering high\nresolution information can be resource intensive. Actively gathering data and\nmodeling flows with the data is a more efficient alternative. However, in such\nscenarios, data is often sparse and thus requires flow modeling techniques that\nare effective at capturing the relevant dynamical features of the flow to\nensure high prediction accuracy of the resulting models. To accomplish this\neffectively, regions with high informative value must be identified. We propose\nEnKode, an active sampling approach based on Koopman Operator theory and\nensemble methods that can build high quality flow models and effectively\nestimate model uncertainty. For modeling complex flows, EnKode provides\ncomparable or better estimates of unsampled flow regions than Gaussian Process\nRegression models with hyperparameter optimization. Additionally, our active\nsensing scheme provides more accurate flow estimates than comparable strategies\nthat rely on uniform sampling. We evaluate EnKode using three common\nbenchmarking systems: the Bickley Jet, Lid-Driven Cavity flow with an obstacle,\nand real ocean currents from the National Oceanic and Atmospheric\nAdministration (NOAA).\n","authors":["Alice Kate Li","Thales C. Silva","M. Ani Hsieh"],"pdf_url":"https://arxiv.org/pdf/2410.16605v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2410.16591v1","updated":"2024-10-22T00:20:54Z","published":"2024-10-22T00:20:54Z","title":"Cycloidal Quasi-Direct Drive Actuator Designs with Learning-based Torque\n  Estimation for Legged Robotics","summary":"  This paper presents a novel approach through the design and implementation of\nCycloidal Quasi-Direct Drive actuators for legged robotics. The cycloidal gear\nmechanism, with its inherent high torque density and mechanical robustness,\noffers significant advantages over conventional designs. By integrating\ncycloidal gears into the Quasi-Direct Drive framework, we aim to enhance the\nperformance of legged robots, particularly in tasks demanding high torque and\ndynamic loads, while still keeping them lightweight. Additionally, we develop a\ntorque estimation framework for the actuator using an Actuator Network, which\neffectively reduces the sim-to-real gap introduced by the cycloidal drive's\ncomplex dynamics. This integration is crucial for capturing the complex\ndynamics of a cycloidal drive, which contributes to improved learning\nefficiency, agility, and adaptability for reinforcement learning.\n","authors":["Alvin Zhu","Yusuke Tanaka","Fadi Rafeedi","Dennis Hong"],"pdf_url":"https://arxiv.org/pdf/2410.16591v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17479v1","updated":"2024-10-22T23:57:37Z","published":"2024-10-22T23:57:37Z","title":"Composing Diffusion Policies for Few-shot Learning of Movement\n  Trajectories","summary":"  Humans can perform various combinations of physical skills without having to\nrelearn skills from scratch every single time. For example, we can swing a bat\nwhen walking without having to re-learn such a policy from scratch by composing\nthe individual skills of walking and bat swinging. Enabling robots to combine\nor compose skills is essential so they can learn novel skills and tasks faster\nwith fewer real world samples. To this end, we propose a novel compositional\napproach called DSE- Diffusion Score Equilibrium that enables few-shot learning\nfor novel skills by utilizing a combination of base policy priors. Our method\nis based on probabilistically composing diffusion policies to better model the\nfew-shot demonstration data-distribution than any individual policy. Our goal\nhere is to learn robot motions few-shot and not necessarily goal oriented\ntrajectories. Unfortunately we lack a general purpose metric to evaluate the\nerror between a skill or motion and the provided demonstrations. Hence, we\npropose a probabilistic measure - Maximum Mean Discrepancy on the Forward\nKinematics Kernel (MMD-FK), that is task and action space agnostic. By using\nour few-shot learning approach DSE, we show that we are able to achieve a\nreduction of over 30% in MMD-FK across skills and number of demonstrations.\nMoreover, we show the utility of our approach through real world experiments by\nteaching novel trajectories to a robot in 5 demonstrations.\n","authors":["Omkar Patil","Anant Sah","Nakul Gopalan"],"pdf_url":"https://arxiv.org/pdf/2410.17479v1.pdf","comment":"6(+1) pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.17453v1","updated":"2024-10-22T22:00:58Z","published":"2024-10-22T22:00:58Z","title":"Configuração e operação da plataforma Clearpath Husky A200 e\n  Manipulador Cobot UR5 2-Finger Gripper","summary":"  This article presents initial configuration work and use of the robotic\nplatform and manipulator in question. The development of the ideal\nconfiguration for using this robot serves as a guide for new users and also\nvalidates its functionality for use in projects. Husky is a large payload\ncapacity and power systems robotics development platform that accommodates a\nwide variety of payloads, customized to meet research needs. Together with the\nCobot UR5 Manipulator attached to its base, it expands the application area of\nits capacity in projects. Advances in robots and mobile manipulators have\nrevolutionized industries by automating tasks that previously required human\nintervention. These innovations alone increase productivity but also reduce\noperating costs, which makes the company more competitive in an evolving global\nmarket. Therefore, this article investigates the functionalities of this robot\nto validate its execution in robotics projects.\n","authors":["Hiago Sodre","Sebastian Barcelona","Vincent Sandin","Pablo Moraes","Christopher Peters","Braian Vidal","Angél da Silva","Gabriela Flores","Ahilen Mazondo","Santiago Fernández"],"pdf_url":"https://arxiv.org/pdf/2410.17453v1.pdf","comment":"in Portuguese language"},{"id":"http://arxiv.org/abs/2410.17450v1","updated":"2024-10-22T21:55:54Z","published":"2024-10-22T21:55:54Z","title":"Interação entre robôs humanoides: desenvolvendo a\n  colaboração e comunicação autônoma","summary":"  This study investigates the interaction between humanoid robots NAO and\nPepper, emphasizing their potential applications in educational settings. NAO,\nwidely used in education, and Pepper, designed for social interactions, of er\nnew opportunities for autonomous communication and collaboration. Through a\nseries of programmed interactions, the robots demonstrated their ability to\ncommunicate and coordinate actions autonomously, highlighting their potential\nas tools for enhancing learning environments. The research also explores the\nintegration of emerging technologies, such as artificial intelligence, into\nthese systems, allowing robots to learn from each other and adapt their\nbehavior. The findings suggest that NAO and Pepper can significantly contribute\nto both technical learning and the development of social and emotional skills\nin students, of ering innovative pedagogical approaches through the use of\nhumanoid robotics.\n","authors":["Moraes Pablo","Peters Christopher","Rodríguez Mónica","Sodre Hiago","Mazondo Ahilen","Sandin Vincent","Barcelona Sebastian","Moraes William","Fernández Santiago","Assunção Nathalie","de Vargas Bruna","Dörnbach Tobias","Kelbouscas André","Grando Ricardo"],"pdf_url":"https://arxiv.org/pdf/2410.17450v1.pdf","comment":"in Portuguese language"},{"id":"http://arxiv.org/abs/2410.17430v1","updated":"2024-10-22T21:00:18Z","published":"2024-10-22T21:00:18Z","title":"Real-time experiment-theory closed-loop interaction for autonomous\n  materials science","summary":"  Iterative cycles of theoretical prediction and experimental validation are\nthe cornerstone of the modern scientific method. However, the proverbial\n\"closing of the loop\" in experiment-theory cycles in practice are usually ad\nhoc, often inherently difficult, or impractical to repeat on a systematic\nbasis, beset by the scale or the time constraint of computation or the\nphenomena under study. Here, we demonstrate Autonomous MAterials Search Engine\n(AMASE), where we enlist robot science to perform self-driving continuous\ncyclical interaction of experiments and computational predictions for materials\nexploration. In particular, we have applied the AMASE formalism to the rapid\nmapping of a temperature-composition phase diagram, a fundamental task for the\nsearch and discovery of new materials. Thermal processing and experimental\ndetermination of compositional phase boundaries in thin films are autonomously\ninterspersed with real-time updating of the phase diagram prediction through\nthe minimization of Gibbs free energies. AMASE was able to accurately determine\nthe eutectic phase diagram of the Sn-Bi binary thin-film system on the fly from\na self-guided campaign covering just a small fraction of the entire composition\n- temperature phase space, translating to a 6-fold reduction in the number of\nnecessary experiments. This study demonstrates for the first time the\npossibility of real-time, autonomous, and iterative interactions of experiments\nand theory carried out without any human intervention.\n","authors":["Haotong Liang","Chuangye Wang","Heshan Yu","Dylan Kirsch","Rohit Pant","Austin McDannald","A. Gilad Kusne","Ji-Cheng Zhao","Ichiro Takeuchi"],"pdf_url":"https://arxiv.org/pdf/2410.17430v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17422v1","updated":"2024-10-22T20:51:45Z","published":"2024-10-22T20:51:45Z","title":"AG-SLAM: Active Gaussian Splatting SLAM","summary":"  We present AG-SLAM, the first active SLAM system utilizing 3D Gaussian\nSplatting (3DGS) for online scene reconstruction. In recent years, radiance\nfield scene representations, including 3DGS have been widely used in SLAM and\nexploration, but actively planning trajectories for robotic exploration is\nstill unvisited. In particular, many exploration methods assume precise\nlocalization and thus do not mitigate the significant risk of constructing a\ntrajectory, which is difficult for a SLAM system to operate on. This can cause\ncamera tracking failure and lead to failures in real-world robotic\napplications. Our method leverages Fisher Information to balance the dual\nobjectives of maximizing the information gain for the environment while\nminimizing the cost of localization errors. Experiments conducted on the Gibson\nand Habitat-Matterport 3D datasets demonstrate state-of-the-art results of the\nproposed method.\n","authors":["Wen Jiang","Boshu Lei","Katrina Ashton","Kostas Daniilidis"],"pdf_url":"https://arxiv.org/pdf/2410.17422v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12142v2","updated":"2024-10-22T20:51:12Z","published":"2024-10-16T01:04:10Z","title":"Design Space Exploration of Embedded SoC Architectures for Real-Time\n  Optimal Control","summary":"  Empowering resource-limited robots to execute computationally intensive tasks\nsuch as locomotion and manipulation is challenging. This project provides a\ncomprehensive design space exploration to determine optimal hardware\ncomputation architectures suitable for model-based control algorithms. We\nprofile and optimize representative architectural designs across\ngeneral-purpose scalar, vector processors, and specialized accelerators.\nSpecifically, we compare CPUs, vector machines, and domain-specialized\naccelerators with kernel-level benchmarks and end-to-end representative robotic\nworkloads. Our exploration provides a quantitative performance, area, and\nutilization comparison and analyzes the trade-offs between these representative\ndistinct architectural designs. We demonstrate that architectural\nmodifications, software, and system optimization can alleviate bottlenecks and\nenhance utilization. Finally, we propose a code generation flow to simplify the\nengineering work for mapping robotic workloads to specialized architectures.\n","authors":["Kris Shengjun Dong","Dima Nikiforov","Widyadewi Soedarmadji","Minh Nguyen","Christopher Fletcher","Yakun Sophia Shao"],"pdf_url":"https://arxiv.org/pdf/2410.12142v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17409v1","updated":"2024-10-22T20:33:10Z","published":"2024-10-22T20:33:10Z","title":"Geometric Graph Neural Network Modeling of Human Interactions in Crowded\n  Environments","summary":"  Modeling human trajectories in crowded environments is challenging due to the\ncomplex nature of pedestrian behavior and interactions. This paper proposes a\ngeometric graph neural network (GNN) architecture that integrates domain\nknowledge from psychological studies to model pedestrian interactions and\npredict future trajectories. Unlike prior studies using complete graphs, we\ndefine interaction neighborhoods using pedestrians' field of view, motion\ndirection, and distance-based kernel functions to construct graph\nrepresentations of crowds. Evaluations across multiple datasets demonstrate\nimproved prediction accuracy through reduced average and final displacement\nerror metrics. Our findings underscore the importance of integrating domain\nknowledge with data-driven approaches for effective modeling of human\ninteractions in crowds.\n","authors":["Sara Honarvar","Yancy Diaz-Mercado"],"pdf_url":"https://arxiv.org/pdf/2410.17409v1.pdf","comment":"\\c{opyright} 2024 the authors. This work has been accepted to IFAC\n  for publication under a Creative Commons Licence CC-BY-NC-ND"},{"id":"http://arxiv.org/abs/2307.15250v4","updated":"2024-10-22T19:09:54Z","published":"2023-07-28T01:20:12Z","title":"D2S: Representing sparse descriptors and 3D coordinates for camera\n  relocalization","summary":"  State-of-the-art visual localization methods mostly rely on complex\nprocedures to match local descriptors and 3D point clouds. However, these\nprocedures can incur significant costs in terms of inference, storage, and\nupdates over time. In this study, we propose a direct learning-based approach\nthat utilizes a simple network named D2S to represent complex local descriptors\nand their scene coordinates. Our method is characterized by its simplicity and\ncost-effectiveness. It solely leverages a single RGB image for localization\nduring the testing phase and only requires a lightweight model to encode a\ncomplex sparse scene. The proposed D2S employs a combination of a simple loss\nfunction and graph attention to selectively focus on robust descriptors while\ndisregarding areas such as clouds, trees, and several dynamic objects. This\nselective attention enables D2S to effectively perform a binary-semantic\nclassification for sparse descriptors. Additionally, we propose a simple\noutdoor dataset to evaluate the capabilities of visual localization methods in\nscene-specific generalization and self-updating from unlabeled observations.\nOur approach outperforms the previous regression-based methods in both indoor\nand outdoor environments. It demonstrates the ability to generalize beyond\ntraining data, including scenarios involving transitions from day to night and\nadapting to domain shifts. The source code, trained models, dataset, and demo\nvideos are available at the following link: https://thpjp.github.io/d2s.\n","authors":["Bach-Thuan Bui","Huy-Hoang Bui","Dinh-Tuan Tran","Joo-Ho Lee"],"pdf_url":"https://arxiv.org/pdf/2307.15250v4.pdf","comment":"Accepted to IEEE Robotics and Automation Letters"},{"id":"http://arxiv.org/abs/2311.13732v2","updated":"2024-10-22T19:08:04Z","published":"2023-11-22T23:16:40Z","title":"A Propagation Perspective on Recursive Forward Dynamics for Systems with\n  Kinematic Loops","summary":"  We revisit the concept of constraint embedding as a means for dealing with\nkinematic loop constraints during dynamics computations for rigid-body systems.\nSpecifically, we consider the local loop constraints emerging from common\nactuation sub-mechanisms in modern robotics systems (e.g., geared motors,\ndifferential drives, and four-bar mechanisms). However, rather than develop the\nconcept of constraint embedding from the perspective of graphical analysis, we\npresent a novel analysis of constraint embedding that generalizes the\ntraditional concepts of joint models and motion/force subspaces between\nindividual rigid bodies to generalized joint models and motion/force subspaces\nbetween groups of rigid bodies subject to loop constraints. The generalized\nconcepts are used in a self-contained, articulated-body-based derivation of the\nconstraint-embedding-based recursive algorithm for forward dynamics. The\nderivation represents the first assembly method to demonstrate the recursivity\nof articulated inertia computation in the presence of loop constraints. We\ndemonstrate the broad applicability of the generalized joint concepts by\nshowing how they also lead to the constraint-embedding-based recursive\nalgorithm for inverse dynamics. Lastly, we benchmark our open-source\nimplementation in C++ for the forward dynamics algorithm against a\nstate-of-the-art, non-recursive algorithm. Our benchmarking validates that\nconstraint embedding outperforms the non-recursive alternative in the case of\nlocal kinematic loops.\n","authors":["Matthew Chignoli","Nicholas Adrian","Sangbae Kim","Patrick M. Wensing"],"pdf_url":"https://arxiv.org/pdf/2311.13732v2.pdf","comment":"Submitted to IEEE Transactions on Robotics"},{"id":"http://arxiv.org/abs/2409.10953v2","updated":"2024-10-22T18:58:09Z","published":"2024-09-17T07:42:46Z","title":"Robust High-Speed State Estimation for Off-road Navigation using Radar\n  Velocity Factors","summary":"  Enabling robot autonomy in complex environments for mission critical\napplication requires robust state estimation. Particularly under conditions\nwhere the exteroceptive sensors, which the navigation depends on, can be\ndegraded by environmental challenges thus, leading to mission failure. It is\nprecisely in such challenges where the potential for FMCW radar sensors is\nhighlighted: as a complementary exteroceptive sensing modality with direct\nvelocity measuring capabilities. In this work we integrate radial speed\nmeasurements from a FMCW radar sensor, using a radial speed factor, to provide\nlinear velocity updates into a sliding-window state estimator for fusion with\nLiDAR pose and IMU measurements. We demonstrate that this augmentation\nincreases the robustness of the state estimator to challenging conditions\npresent in the environment and the negative effects they can pose to vulnerable\nexteroceptive modalities. The proposed method is extensively evaluated using\nrobotic field experiments conducted using an autonomous, full-scale, off-road\nvehicle operating at high-speeds (~12 m/s) in complex desert environments.\nFurthermore, the robustness of the approach is demonstrated for cases of both\nsimulated and real-world degradation of the LiDAR odometry performance along\nwith comparison against state-of-the-art methods for radar-inertial odometry on\npublic datasets.\n","authors":["Morten Nissov","Jeffrey A. Edlund","Patrick Spieler","Curtis Padgett","Kostas Alexis","Shehryar Khattak"],"pdf_url":"https://arxiv.org/pdf/2409.10953v2.pdf","comment":"8 pages, 9 figures. Accepted for publication in IEEE Robotics and\n  Automation Letters (RA-L), 2024"},{"id":"http://arxiv.org/abs/2305.17828v2","updated":"2024-10-22T18:51:50Z","published":"2023-05-28T23:42:35Z","title":"Counter-Hypothetical Particle Filters for Single Object Pose Tracking","summary":"  Particle filtering is a common technique for six degrees of freedom (6D) pose\nestimation due to its ability to tractably represent belief over object pose.\nHowever, the particle filter is prone to particle deprivation due to the\nhigh-dimensional nature of 6D pose. When particle deprivation occurs, it can\ncause mode collapse of the underlying belief distribution during importance\nsampling. If the region surrounding the true state suffers from mode collapse,\nrecovering its belief is challenging since the area is no longer represented in\nthe probability mass formed by the particles. Previous methods mitigate this\nproblem by randomizing and resetting particles in the belief distribution, but\ndetermining the frequency of reinvigoration has relied on hand-tuning abstract\nheuristics. In this paper, we estimate the necessary reinvigoration rate at\neach time step by introducing a Counter-Hypothetical likelihood function, which\nis used alongside the standard likelihood. Inspired by the notions of\nplausibility and implausibility from Evidential Reasoning, the addition of our\nCounter-Hypothetical likelihood function assigns a level of doubt to each\nparticle. The competing cumulative values of confidence and doubt across the\nparticle set are used to estimate the level of failure within the filter, in\norder to determine the portion of particles to be reinvigorated. We demonstrate\nthe effectiveness of our method on the rigid body object 6D pose tracking task.\n","authors":["Elizabeth A. Olson","Jana Pavlasek","Jasmine A. Berry","Odest Chadwicke Jenkins"],"pdf_url":"https://arxiv.org/pdf/2305.17828v2.pdf","comment":"International Conference on Robotics and Automation (ICRA) 2023"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2410.17251v1","updated":"2024-10-22T17:59:57Z","published":"2024-10-22T17:59:57Z","title":"Altogether: Image Captioning via Re-aligning Alt-text","summary":"  This paper focuses on creating synthetic data to improve the quality of image\ncaptions. Existing works typically have two shortcomings. First, they caption\nimages from scratch, ignoring existing alt-text metadata, and second, lack\ntransparency if the captioners' training data (e.g. GPT) is unknown. In this\npaper, we study a principled approach Altogether based on the key idea to edit\nand re-align existing alt-texts associated with the images. To generate\ntraining data, we perform human annotation where annotators start with the\nexisting alt-text and re-align it to the image content in multiple rounds,\nconsequently constructing captions with rich visual concepts. This differs from\nprior work that carries out human annotation as a one-time description task\nsolely based on images and annotator knowledge. We train a captioner on this\ndata that generalizes the process of re-aligning alt-texts at scale. Our\nresults show our Altogether approach leads to richer image captions that also\nimprove text-to-image generation and zero-shot image classification tasks.\n","authors":["Hu Xu","Po-Yao Huang","Xiaoqing Ellen Tan","Ching-Feng Yeh","Jacob Kahn","Christine Jou","Gargi Ghosh","Omer Levy","Luke Zettlemoyer","Wen-tau Yih","Shang-Wen Li","Saining Xie","Christoph Feichtenhofer"],"pdf_url":"https://arxiv.org/pdf/2410.17251v1.pdf","comment":"accepted by EMNLP 2024; MetaCLIPv2"},{"id":"http://arxiv.org/abs/2410.17249v1","updated":"2024-10-22T17:59:56Z","published":"2024-10-22T17:59:56Z","title":"SpectroMotion: Dynamic 3D Reconstruction of Specular Scenes","summary":"  We present SpectroMotion, a novel approach that combines 3D Gaussian\nSplatting (3DGS) with physically-based rendering (PBR) and deformation fields\nto reconstruct dynamic specular scenes. Previous methods extending 3DGS to\nmodel dynamic scenes have struggled to accurately represent specular surfaces.\nOur method addresses this limitation by introducing a residual correction\ntechnique for accurate surface normal computation during deformation,\ncomplemented by a deformable environment map that adapts to time-varying\nlighting conditions. We implement a coarse-to-fine training strategy that\nsignificantly enhances both scene geometry and specular color prediction. We\ndemonstrate that our model outperforms prior methods for view synthesis of\nscenes containing dynamic specular objects and that it is the only existing\n3DGS method capable of synthesizing photorealistic real-world dynamic specular\nscenes, outperforming state-of-the-art methods in rendering complex, dynamic,\nand specular scenes.\n","authors":["Cheng-De Fan","Chen-Wei Chang","Yi-Ruei Liu","Jie-Ying Lee","Jiun-Long Huang","Yu-Chee Tseng","Yu-Lun Liu"],"pdf_url":"https://arxiv.org/pdf/2410.17249v1.pdf","comment":"Project page: https://cdfan0627.github.io/spectromotion/"},{"id":"http://arxiv.org/abs/2410.17250v1","updated":"2024-10-22T17:59:56Z","published":"2024-10-22T17:59:56Z","title":"JMMMU: A Japanese Massive Multi-discipline Multimodal Understanding\n  Benchmark for Culture-aware Evaluation","summary":"  Accelerating research on Large Multimodal Models (LMMs) in non-English\nlanguages is crucial for enhancing user experiences across broader populations.\nIn this paper, we introduce JMMMU (Japanese MMMU), the first large-scale\nJapanese benchmark designed to evaluate LMMs on expert-level tasks based on the\nJapanese cultural context. To facilitate comprehensive culture-aware\nevaluation, JMMMU features two complementary subsets: (i) culture-agnostic (CA)\nsubset, where the culture-independent subjects (e.g., Math) are selected and\ntranslated into Japanese, enabling one-to-one comparison with its English\ncounterpart MMMU; and (ii) culture-specific (CS) subset, comprising newly\ncrafted subjects that reflect Japanese cultural context. Using the CA subset,\nwe observe performance drop in many LMMs when evaluated in Japanese, which is\npurely attributable to language variation. Using the CS subset, we reveal their\ninadequate Japanese cultural understanding. Further, by combining both subsets,\nwe identify that some LMMs perform well on the CA subset but not on the CS\nsubset, exposing a shallow understanding of the Japanese language that lacks\ndepth in cultural understanding. We hope this work will not only help advance\nLMM performance in Japanese but also serve as a guideline to create\nhigh-standard, culturally diverse benchmarks for multilingual LMM development.\nThe project page is https://mmmu-japanese-benchmark.github.io/JMMMU/.\n","authors":["Shota Onohara","Atsuyuki Miyai","Yuki Imajuku","Kazuki Egashira","Jeonghun Baek","Xiang Yue","Graham Neubig","Kiyoharu Aizawa"],"pdf_url":"https://arxiv.org/pdf/2410.17250v1.pdf","comment":"Project page: https://mmmu-japanese-benchmark.github.io/JMMMU/"},{"id":"http://arxiv.org/abs/2410.17247v1","updated":"2024-10-22T17:59:53Z","published":"2024-10-22T17:59:53Z","title":"PyramidDrop: Accelerating Your Large Vision-Language Models via Pyramid\n  Visual Redundancy Reduction","summary":"  In large vision-language models (LVLMs), images serve as inputs that carry a\nwealth of information. As the idiom \"A picture is worth a thousand words\"\nimplies, representing a single image in current LVLMs can require hundreds or\neven thousands of tokens. This results in significant computational costs,\nwhich grow quadratically as input image resolution increases, thereby severely\nimpacting the efficiency of both training and inference. Previous approaches\nhave attempted to reduce the number of image tokens either before or within the\nearly layers of LVLMs. However, these strategies inevitably result in the loss\nof crucial image information, ultimately diminishing model performance. To\naddress this challenge, we conduct an empirical study revealing that all visual\ntokens are necessary for LVLMs in the shallow layers, and token redundancy\nprogressively increases in the deeper layers of the model. To this end, we\npropose PyramidDrop, a visual redundancy reduction strategy for LVLMs to boost\ntheir efficiency in both training and inference with neglectable performance\nloss. Specifically, we partition the LVLM into several stages and drop part of\nthe image tokens at the end of each stage with a pre-defined ratio, creating\npyramid-like visual tokens across model layers. The dropping is based on a\nlightweight similarity calculation with a negligible time overhead. Extensive\nexperiments demonstrate that PyramidDrop can achieve a 40% training time and\n55% inference FLOPs acceleration of LLaVA-NeXT with comparable performance.\nBesides, the PyramidDrop could also serve as a plug-and-play strategy for\ninference acceleration without training, with better performance and lower\ninference cost than counterparts. We hope that the insights and approach\nintroduced by PyramidDrop will inspire future research to further investigate\nthe role of image tokens in LVLMs.\n","authors":["Long Xing","Qidong Huang","Xiaoyi Dong","Jiajie Lu","Pan Zhang","Yuhang Zang","Yuhang Cao","Conghui He","Jiaqi Wang","Feng Wu","Dahua Lin"],"pdf_url":"https://arxiv.org/pdf/2410.17247v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2410.17243v1","updated":"2024-10-22T17:59:30Z","published":"2024-10-22T17:59:30Z","title":"Breaking the Memory Barrier: Near Infinite Batch Size Scaling for\n  Contrastive Loss","summary":"  Contrastive loss is a powerful approach for representation learning, where\nlarger batch sizes enhance performance by providing more negative samples to\nbetter distinguish between similar and dissimilar data. However, scaling batch\nsizes is constrained by the quadratic growth in GPU memory consumption,\nprimarily due to the full instantiation of the similarity matrix. To address\nthis, we propose a tile-based computation strategy that partitions the\ncontrastive loss calculation into arbitrary small blocks, avoiding full\nmaterialization of the similarity matrix. Furthermore, we introduce a\nmulti-level tiling strategy to leverage the hierarchical structure of\ndistributed systems, employing ring-based communication at the GPU level to\noptimize synchronization and fused kernels at the CUDA core level to reduce I/O\noverhead. Experimental results show that the proposed method scales batch sizes\nto unprecedented levels. For instance, it enables contrastive training of a\nCLIP-ViT-L/14 model with a batch size of 4M or 12M using 8 or 32 A800 80GB\nwithout sacrificing any accuracy. Compared to SOTA memory-efficient solutions,\nit achieves a two-order-of-magnitude reduction in memory while maintaining\ncomparable speed. The code will be made publicly available.\n","authors":["Zesen Cheng","Hang Zhang","Kehan Li","Sicong Leng","Zhiqiang Hu","Fei Wu","Deli Zhao","Xin Li","Lidong Bing"],"pdf_url":"https://arxiv.org/pdf/2410.17243v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17242v1","updated":"2024-10-22T17:58:28Z","published":"2024-10-22T17:58:28Z","title":"LVSM: A Large View Synthesis Model with Minimal 3D Inductive Bias","summary":"  We propose the Large View Synthesis Model (LVSM), a novel transformer-based\napproach for scalable and generalizable novel view synthesis from sparse-view\ninputs. We introduce two architectures: (1) an encoder-decoder LVSM, which\nencodes input image tokens into a fixed number of 1D latent tokens, functioning\nas a fully learned scene representation, and decodes novel-view images from\nthem; and (2) a decoder-only LVSM, which directly maps input images to\nnovel-view outputs, completely eliminating intermediate scene representations.\nBoth models bypass the 3D inductive biases used in previous methods -- from 3D\nrepresentations (e.g., NeRF, 3DGS) to network designs (e.g., epipolar\nprojections, plane sweeps) -- addressing novel view synthesis with a fully\ndata-driven approach. While the encoder-decoder model offers faster inference\ndue to its independent latent representation, the decoder-only LVSM achieves\nsuperior quality, scalability, and zero-shot generalization, outperforming\nprevious state-of-the-art methods by 1.5 to 3.5 dB PSNR. Comprehensive\nevaluations across multiple datasets demonstrate that both LVSM variants\nachieve state-of-the-art novel view synthesis quality. Notably, our models\nsurpass all previous methods even with reduced computational resources (1-2\nGPUs). Please see our website for more details:\nhttps://haian-jin.github.io/projects/LVSM/ .\n","authors":["Haian Jin","Hanwen Jiang","Hao Tan","Kai Zhang","Sai Bi","Tianyuan Zhang","Fujun Luan","Noah Snavely","Zexiang Xu"],"pdf_url":"https://arxiv.org/pdf/2410.17242v1.pdf","comment":"project page: https://haian-jin.github.io/projects/LVSM/"},{"id":"http://arxiv.org/abs/2410.17241v1","updated":"2024-10-22T17:57:12Z","published":"2024-10-22T17:57:12Z","title":"Frontiers in Intelligent Colonoscopy","summary":"  Colonoscopy is currently one of the most sensitive screening methods for\ncolorectal cancer. This study investigates the frontiers of intelligent\ncolonoscopy techniques and their prospective implications for multimodal\nmedical applications. With this goal, we begin by assessing the current\ndata-centric and model-centric landscapes through four tasks for colonoscopic\nscene perception, including classification, detection, segmentation, and\nvision-language understanding. This assessment enables us to identify\ndomain-specific challenges and reveals that multimodal research in colonoscopy\nremains open for further exploration. To embrace the coming multimodal era, we\nestablish three foundational initiatives: a large-scale multimodal instruction\ntuning dataset ColonINST, a colonoscopy-designed multimodal language model\nColonGPT, and a multimodal benchmark. To facilitate ongoing monitoring of this\nrapidly evolving field, we provide a public website for the latest updates:\nhttps://github.com/ai4colonoscopy/IntelliScope.\n","authors":["Ge-Peng Ji","Jingyi Liu","Peng Xu","Nick Barnes","Fahad Shahbaz Khan","Salman Khan","Deng-Ping Fan"],"pdf_url":"https://arxiv.org/pdf/2410.17241v1.pdf","comment":"[work in progress] A comprehensive survey of intelligent colonoscopy\n  in the multimodal era"},{"id":"http://arxiv.org/abs/2410.17235v1","updated":"2024-10-22T17:54:07Z","published":"2024-10-22T17:54:07Z","title":"Automated Spinal MRI Labelling from Reports Using a Large Language Model","summary":"  We propose a general pipeline to automate the extraction of labels from\nradiology reports using large language models, which we validate on spinal MRI\nreports. The efficacy of our labelling method is measured on five distinct\nconditions: spinal cancer, stenosis, spondylolisthesis, cauda equina\ncompression and herniation. Using open-source models, our method equals or\nsurpasses GPT-4 on a held-out set of reports. Furthermore, we show that the\nextracted labels can be used to train imaging models to classify the identified\nconditions in the accompanying MR scans. All classifiers trained using\nautomated labels achieve comparable performance to models trained using scans\nmanually annotated by clinicians. Code can be found at\nhttps://github.com/robinyjpark/AutoLabelClassifier.\n","authors":["Robin Y. Park","Rhydian Windsor","Amir Jamaludin","Andrew Zisserman"],"pdf_url":"https://arxiv.org/pdf/2410.17235v1.pdf","comment":"Accepted to Medical Image Computing and Computer Assisted\n  Intervention (MICCAI 2024, Spotlight). 11 pages plus appendix"},{"id":"http://arxiv.org/abs/2405.20090v3","updated":"2024-10-22T17:36:30Z","published":"2024-05-30T14:27:20Z","title":"Typography Leads Semantic Diversifying: Amplifying Adversarial\n  Transferability across Multimodal Large Language Models","summary":"  Recently, Multimodal Large Language Models (MLLMs) achieve remarkable\nperformance in numerous zero-shot tasks due to their outstanding cross-modal\ninteraction and comprehension abilities. However, MLLMs are found to still be\nvulnerable to human-imperceptible adversarial examples. In the exploration of\nsecurity vulnerabilities in real-world scenarios, transferability, which can\nachieve cross-model impact, is considered the greatest threat posed by\nadversarial examples. However, there is currently no systematic research on the\nthreat of cross-MLLMs adversarial transferability. Therefore, this paper as the\nfirst step to provide a comprehensive evaluation of the transferability of\nadversarial examples generated by various MLLMs. Furthermore, leveraging two\nkey factors that influence transferability performance: 1) The strength of\ninformation diversity involved in the adversarial generation process; 2)\nEditing across vision-language modality information. We propose a boosting\nmethod called Typography Augment Transferability Method (TATM) to investigate\nthe adversarial transferability performance across MLLMs further. Through\nextensive experimental validation, our TATM demonstrates exceptional\nperformance in real-world applications of \"Harmful Word Insertion\" and\n\"Important Information Protection\".\n","authors":["Hao Cheng","Erjia Xiao","Jiayan Yang","Jiahang Cao","Qiang Zhang","Le Yang","Jize Zhang","Kaidi Xu","Jindong Gu","Renjing Xu"],"pdf_url":"https://arxiv.org/pdf/2405.20090v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17207v1","updated":"2024-10-22T17:27:16Z","published":"2024-10-22T17:27:16Z","title":"EPContrast: Effective Point-level Contrastive Learning for Large-scale\n  Point Cloud Understanding","summary":"  The acquisition of inductive bias through point-level contrastive learning\nholds paramount significance in point cloud pre-training. However, the square\ngrowth in computational requirements with the scale of the point cloud poses a\nsubstantial impediment to the practical deployment and execution. To address\nthis challenge, this paper proposes an Effective Point-level Contrastive\nLearning method for large-scale point cloud understanding dubbed\n\\textbf{EPContrast}, which consists of AGContrast and ChannelContrast. In\npractice, AGContrast constructs positive and negative pairs based on asymmetric\ngranularity embedding, while ChannelContrast imposes contrastive supervision\nbetween channel feature maps. EPContrast offers point-level contrastive loss\nwhile concurrently mitigating the computational resource burden. The efficacy\nof EPContrast is substantiated through comprehensive validation on S3DIS and\nScanNetV2, encompassing tasks such as semantic segmentation, instance\nsegmentation, and object detection. In addition, rich ablation experiments\ndemonstrate remarkable bias induction capabilities under label-efficient and\none-epoch training settings.\n","authors":["Zhiyi Pan","Guoqing Liu","Wei Gao","Thomas H. Li"],"pdf_url":"https://arxiv.org/pdf/2410.17207v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17193v1","updated":"2024-10-22T17:13:19Z","published":"2024-10-22T17:13:19Z","title":"Emphasizing Discriminative Features for Dataset Distillation in Complex\n  Scenarios","summary":"  Dataset distillation has demonstrated strong performance on simple datasets\nlike CIFAR, MNIST, and TinyImageNet but struggles to achieve similar results in\nmore complex scenarios. In this paper, we propose EDF (emphasizes the\ndiscriminative features), a dataset distillation method that enhances key\ndiscriminative regions in synthetic images using Grad-CAM activation maps. Our\napproach is inspired by a key observation: in simple datasets, high-activation\nareas typically occupy most of the image, whereas in complex scenarios, the\nsize of these areas is much smaller. Unlike previous methods that treat all\npixels equally when synthesizing images, EDF uses Grad-CAM activation maps to\nenhance high-activation areas. From a supervision perspective, we downplay\nsupervision signals that have lower losses, as they contain common patterns.\nAdditionally, to help the DD community better explore complex scenarios, we\nbuild the Complex Dataset Distillation (Comp-DD) benchmark by meticulously\nselecting sixteen subsets, eight easy and eight hard, from ImageNet-1K. In\nparticular, EDF consistently outperforms SOTA results in complex scenarios,\nsuch as ImageNet-1K subsets. Hopefully, more researchers will be inspired and\nencouraged to improve the practicality and efficacy of DD. Our code and\nbenchmark will be made public at https://github.com/NUS-HPC-AI-Lab/EDF.\n","authors":["Kai Wang","Zekai Li","Zhi-Qi Cheng","Samir Khaki","Ahmad Sajedi","Ramakrishna Vedantam","Konstantinos N Plataniotis","Alexander Hauptmann","Yang You"],"pdf_url":"https://arxiv.org/pdf/2410.17193v1.pdf","comment":"24 pages, 13 figures"},{"id":"http://arxiv.org/abs/2408.11982v3","updated":"2024-10-22T16:58:09Z","published":"2024-08-21T20:32:45Z","title":"AIM 2024 Challenge on Compressed Video Quality Assessment: Methods and\n  Results","summary":"  Video quality assessment (VQA) is a crucial task in the development of video\ncompression standards, as it directly impacts the viewer experience. This paper\npresents the results of the Compressed Video Quality Assessment challenge, held\nin conjunction with the Advances in Image Manipulation (AIM) workshop at ECCV\n2024. The challenge aimed to evaluate the performance of VQA methods on a\ndiverse dataset of 459 videos, encoded with 14 codecs of various compression\nstandards (AVC/H.264, HEVC/H.265, AV1, and VVC/H.266) and containing a\ncomprehensive collection of compression artifacts. To measure the methods\nperformance, we employed traditional correlation coefficients between their\npredictions and subjective scores, which were collected via large-scale\ncrowdsourced pairwise human comparisons. For training purposes, participants\nwere provided with the Compressed Video Quality Assessment Dataset (CVQAD), a\npreviously developed dataset of 1022 videos. Up to 30 participating teams\nregistered for the challenge, while we report the results of 6 teams, which\nsubmitted valid final solutions and code for reproducing the results. Moreover,\nwe calculated and present the performance of state-of-the-art VQA methods on\nthe developed dataset, providing a comprehensive benchmark for future research.\nThe dataset, results, and online leaderboard are publicly available at\nhttps://challenges.videoprocessing.ai/challenges/compressedvideo-quality-assessment.html.\n","authors":["Maksim Smirnov","Aleksandr Gushchin","Anastasia Antsiferova","Dmitry Vatolin","Radu Timofte","Ziheng Jia","Zicheng Zhang","Wei Sun","Jiaying Qian","Yuqin Cao","Yinan Sun","Yuxin Zhu","Xiongkuo Min","Guangtao Zhai","Kanjar De","Qing Luo","Ao-Xiang Zhang","Peng Zhang","Haibo Lei","Linyan Jiang","Yaqing Li","Wenhui Meng","Zhenzhong Chen","Zhengxue Cheng","Jiahao Xiao","Jun Xu","Chenlong He","Qi Zheng","Ruoxi Zhu","Min Li","Yibo Fan","Zhengzhong Tu"],"pdf_url":"https://arxiv.org/pdf/2408.11982v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17172v1","updated":"2024-10-22T16:50:34Z","published":"2024-10-22T16:50:34Z","title":"KANICE: Kolmogorov-Arnold Networks with Interactive Convolutional\n  Elements","summary":"  We introduce KANICE (Kolmogorov-Arnold Networks with Interactive\nConvolutional Elements), a novel neural architecture that combines\nConvolutional Neural Networks (CNNs) with Kolmogorov-Arnold Network (KAN)\nprinciples. KANICE integrates Interactive Convolutional Blocks (ICBs) and KAN\nlinear layers into a CNN framework. This leverages KANs' universal\napproximation capabilities and ICBs' adaptive feature learning. KANICE captures\ncomplex, non-linear data relationships while enabling dynamic,\ncontext-dependent feature extraction based on the Kolmogorov-Arnold\nrepresentation theorem. We evaluated KANICE on four datasets: MNIST,\nFashion-MNIST, EMNIST, and SVHN, comparing it against standard CNNs, CNN-KAN\nhybrids, and ICB variants. KANICE consistently outperformed baseline models,\nachieving 99.35% accuracy on MNIST and 90.05% on the SVHN dataset.\n  Furthermore, we introduce KANICE-mini, a compact variant designed for\nefficiency. A comprehensive ablation study demonstrates that KANICE-mini\nachieves comparable performance to KANICE with significantly fewer parameters.\nKANICE-mini reached 90.00% accuracy on SVHN with 2,337,828 parameters, compared\nto KANICE's 25,432,000. This study highlights the potential of KAN-based\narchitectures in balancing performance and computational efficiency in image\nclassification tasks. Our work contributes to research in adaptive neural\nnetworks, integrates mathematical theorems into deep learning architectures,\nand explores the trade-offs between model complexity and performance, advancing\ncomputer vision and pattern recognition. The source code for this paper is\npublicly accessible through our GitHub repository\n(https://github.com/m-ferdaus/kanice).\n","authors":["Md Meftahul Ferdaus","Mahdi Abdelguerfi","Elias Ioup","David Dobson","Kendall N. Niles","Ken Pathak","Steven Sloan"],"pdf_url":"https://arxiv.org/pdf/2410.17172v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17149v1","updated":"2024-10-22T16:28:21Z","published":"2024-10-22T16:28:21Z","title":"Are Visual-Language Models Effective in Action Recognition? A\n  Comparative Study","summary":"  Current vision-language foundation models, such as CLIP, have recently shown\nsignificant improvement in performance across various downstream tasks.\nHowever, whether such foundation models significantly improve more complex\nfine-grained action recognition tasks is still an open question. To answer this\nquestion and better find out the future research direction on human behavior\nanalysis in-the-wild, this paper provides a large-scale study and insight on\ncurrent state-of-the-art vision foundation models by comparing their transfer\nability onto zero-shot and frame-wise action recognition tasks. Extensive\nexperiments are conducted on recent fine-grained, human-centric action\nrecognition datasets (e.g., Toyota Smarthome, Penn Action, UAV-Human, TSU,\nCharades) including action classification and segmentation.\n","authors":["Mahmoud Ali","Di Yang","François Brémond"],"pdf_url":"https://arxiv.org/pdf/2410.17149v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17146v1","updated":"2024-10-22T16:26:05Z","published":"2024-10-22T16:26:05Z","title":"LiNeS: Post-training Layer Scaling Prevents Forgetting and Enhances\n  Model Merging","summary":"  Large pre-trained models exhibit impressive zero-shot performance across\ndiverse tasks, but fine-tuning often leads to catastrophic forgetting, where\nimprovements on a target domain degrade generalization on other tasks. To\naddress this challenge, we introduce LiNeS, Layer-increasing Network Scaling, a\npost-training editing technique designed to preserve pre-trained generalization\nwhile enhancing fine-tuned task performance. LiNeS scales parameter updates\nlinearly based on their layer depth within the network, maintaining shallow\nlayers close to their pre-trained values to preserve general features while\nallowing deeper layers to retain task-specific representations. We further\nextend this approach to multi-task model merging scenarios, where layer-wise\nscaling of merged parameters reduces negative task interference. LiNeS\ndemonstrates significant improvements in both single-task and multi-task\nsettings across various benchmarks in vision and natural language processing.\nIt mitigates forgetting, enhances out-of-distribution generalization,\nintegrates seamlessly with existing multi-task model merging baselines\nimproving their performance across benchmarks and model sizes, and can boost\ngeneralization when merging LLM policies aligned with different rewards via\nRLHF. Importantly, our method is simple to implement and complementary to many\nexisting techniques.\n","authors":["Ke Wang","Nikolaos Dimitriadis","Alessandro Favero","Guillermo Ortiz-Jimenez","Francois Fleuret","Pascal Frossard"],"pdf_url":"https://arxiv.org/pdf/2410.17146v1.pdf","comment":"The first two authors contributed equally to this work; Project\n  website: \\url{https://lines-merging.github.io/}"},{"id":"http://arxiv.org/abs/2410.17144v1","updated":"2024-10-22T16:19:55Z","published":"2024-10-22T16:19:55Z","title":"YOLO-TS: Real-Time Traffic Sign Detection with Enhanced Accuracy Using\n  Optimized Receptive Fields and Anchor-Free Fusion","summary":"  Ensuring safety in both autonomous driving and advanced driver-assistance\nsystems (ADAS) depends critically on the efficient deployment of traffic sign\nrecognition technology. While current methods show effectiveness, they often\ncompromise between speed and accuracy. To address this issue, we present a\nnovel real-time and efficient road sign detection network, YOLO-TS. This\nnetwork significantly improves performance by optimizing the receptive fields\nof multi-scale feature maps to align more closely with the size distribution of\ntraffic signs in various datasets. Moreover, our innovative feature-fusion\nstrategy, leveraging the flexibility of Anchor-Free methods, allows for\nmulti-scale object detection on a high-resolution feature map abundant in\ncontextual information, achieving remarkable enhancements in both accuracy and\nspeed. To mitigate the adverse effects of the grid pattern caused by dilated\nconvolutions on the detection of smaller objects, we have devised a unique\nmodule that not only mitigates this grid effect but also widens the receptive\nfield to encompass an extensive range of spatial contextual information, thus\nboosting the efficiency of information usage. Evaluation on challenging public\ndatasets, TT100K and CCTSDB2021, demonstrates that YOLO-TS surpasses existing\nstate-of-the-art methods in terms of both accuracy and speed. The code for our\nmethod will be available.\n","authors":["Junzhou Chen","Heqiang Huang","Ronghui Zhang","Nengchao Lyu","Yanyong Guo","Hong-Ning Dai","Hong Yan"],"pdf_url":"https://arxiv.org/pdf/2410.17144v1.pdf","comment":"13 pages, 9 figures and 7 tables"},{"id":"http://arxiv.org/abs/2409.12961v2","updated":"2024-10-22T16:17:13Z","published":"2024-09-19T17:59:51Z","title":"Oryx MLLM: On-Demand Spatial-Temporal Understanding at Arbitrary\n  Resolution","summary":"  Visual data comes in various forms, ranging from small icons of just a few\npixels to long videos spanning hours. Existing multi-modal LLMs usually\nstandardize these diverse visual inputs to a fixed resolution for visual\nencoders and yield similar numbers of tokens for LLMs. This approach is\nnon-optimal for multimodal understanding and inefficient for processing inputs\nwith long and short visual contents. To solve the problem, we propose Oryx, a\nunified multimodal architecture for the spatial-temporal understanding of\nimages, videos, and multi-view 3D scenes. Oryx offers an on-demand solution to\nseamlessly and efficiently process visual inputs with arbitrary spatial sizes\nand temporal lengths through two core innovations: 1) a pre-trained OryxViT\nmodel that can encode images at any resolution into LLM-friendly visual\nrepresentations; 2) a dynamic compressor module that supports 1x to 16x\ncompression on visual tokens by request. These design features enable Oryx to\naccommodate extremely long visual contexts, such as videos, with lower\nresolution and high compression while maintaining high recognition precision\nfor tasks like document understanding with native resolution and no\ncompression. Beyond the architectural improvements, enhanced data curation and\nspecialized training on long-context retrieval and spatial-aware data help Oryx\nachieve strong capabilities in image, video, and 3D multimodal understanding\nsimultaneously. Our work is open-sourced at https://github.com/Oryx-mllm/Oryx.\n","authors":["Zuyan Liu","Yuhao Dong","Ziwei Liu","Winston Hu","Jiwen Lu","Yongming Rao"],"pdf_url":"https://arxiv.org/pdf/2409.12961v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17136v1","updated":"2024-10-22T16:08:09Z","published":"2024-10-22T16:08:09Z","title":"AlphaChimp: Tracking and Behavior Recognition of Chimpanzees","summary":"  Understanding non-human primate behavior is crucial for improving animal\nwelfare, modeling social behavior, and gaining insights into both distinctly\nhuman and shared behaviors. Despite recent advances in computer vision,\nautomated analysis of primate behavior remains challenging due to the\ncomplexity of their social interactions and the lack of specialized algorithms.\nExisting methods often struggle with the nuanced behaviors and frequent\nocclusions characteristic of primate social dynamics. This study aims to\ndevelop an effective method for automated detection, tracking, and recognition\nof chimpanzee behaviors in video footage. Here we show that our proposed\nmethod, AlphaChimp, an end-to-end approach that simultaneously detects\nchimpanzee positions and estimates behavior categories from videos,\nsignificantly outperforms existing methods in behavior recognition. AlphaChimp\nachieves approximately 10% higher tracking accuracy and a 20% improvement in\nbehavior recognition compared to state-of-the-art methods, particularly\nexcelling in the recognition of social behaviors. This superior performance\nstems from AlphaChimp's innovative architecture, which integrates temporal\nfeature fusion with a Transformer-based self-attention mechanism, enabling more\neffective capture and interpretation of complex social interactions among\nchimpanzees. Our approach bridges the gap between computer vision and\nprimatology, enhancing technical capabilities and deepening our understanding\nof primate communication and sociality. We release our code and models and hope\nthis will facilitate future research in animal social dynamics. This work\ncontributes to ethology, cognitive science, and artificial intelligence,\noffering new perspectives on social intelligence.\n","authors":["Xiaoxuan Ma","Yutang Lin","Yuan Xu","Stephan P. Kaufhold","Jack Terwilliger","Andres Meza","Yixin Zhu","Federico Rossano","Yizhou Wang"],"pdf_url":"https://arxiv.org/pdf/2410.17136v1.pdf","comment":"An eXpressive extension of ChimpACT [arXiv:2310.16447], proposes\n  AlphaChimp for tracking and behavior recognition of chimpanzees. arXiv admin\n  note: substantial text overlap with arXiv:2310.16447"},{"id":"http://arxiv.org/abs/2410.14669v2","updated":"2024-10-22T16:07:22Z","published":"2024-10-18T17:58:21Z","title":"NaturalBench: Evaluating Vision-Language Models on Natural Adversarial\n  Samples","summary":"  Vision-language models (VLMs) have made significant progress in recent\nvisual-question-answering (VQA) benchmarks that evaluate complex\nvisio-linguistic reasoning. However, are these models truly effective? In this\nwork, we show that VLMs still struggle with natural images and questions that\nhumans can easily answer, which we term natural adversarial samples. We also\nfind it surprisingly easy to generate these VQA samples from natural image-text\ncorpora using off-the-shelf models like CLIP and ChatGPT. We propose a\nsemi-automated approach to collect a new benchmark, NaturalBench, for reliably\nevaluating VLMs with 10,000 human-verified VQA samples. Crucially, we adopt a\n$\\textbf{vision-centric}$ design by pairing each question with two images that\nyield different answers, preventing blind solutions from answering without\nusing the images. This makes NaturalBench more challenging than previous\nbenchmarks that can be solved with commonsense priors. We evaluate 53\nstate-of-the-art VLMs on NaturalBench, showing that models like\nLLaVA-OneVision, Cambrian-1, Llama3.2-Vision, Molmo, Qwen2-VL, and even GPT-4o\nlag 50%-70% behind human performance (over 90%). We analyze why NaturalBench is\nhard from two angles: (1) Compositionality: Solving NaturalBench requires\ndiverse visio-linguistic skills, including understanding attribute bindings,\nobject relationships, and advanced reasoning like logic and counting. To this\nend, unlike prior work that uses a single tag per sample, we tag each\nNaturalBench sample with 1 to 8 skill tags for fine-grained evaluation. (2)\nBiases: NaturalBench exposes severe biases in VLMs, as models often choose the\nsame answer regardless of the image. Lastly, we apply our benchmark curation\nmethod to diverse data sources, including long captions (over 100 words) and\nnon-English languages like Chinese and Hindi, highlighting its potential for\ndynamic evaluations of VLMs.\n","authors":["Baiqi Li","Zhiqiu Lin","Wenxuan Peng","Jean de Dieu Nyandwi","Daniel Jiang","Zixian Ma","Simran Khanuja","Ranjay Krishna","Graham Neubig","Deva Ramanan"],"pdf_url":"https://arxiv.org/pdf/2410.14669v2.pdf","comment":"Accepted to NeurIPS 24; We open-source our dataset at:\n  https://huggingface.co/datasets/BaiqiL/NaturalBench ; Project page at:\n  https://linzhiqiu.github.io/papers/naturalbench/"},{"id":"http://arxiv.org/abs/2410.17101v1","updated":"2024-10-22T15:28:18Z","published":"2024-10-22T15:28:18Z","title":"CLAP: Concave Linear APproximation for Quadratic Graph Matching","summary":"  Solving point-wise feature correspondence in visual data is a fundamental\nproblem in computer vision. A powerful model that addresses this challenge is\nto formulate it as graph matching, which entails solving a Quadratic Assignment\nProblem (QAP) with node-wise and edge-wise constraints. However, solving such a\nQAP can be both expensive and difficult due to numerous local extreme points.\nIn this work, we introduce a novel linear model and solver designed to\naccelerate the computation of graph matching. Specifically, we employ a\npositive semi-definite matrix approximation to establish the structural\nattribute constraint.We then transform the original QAP into a linear model\nthat is concave for maximization. This model can subsequently be solved using\nthe Sinkhorn optimal transport algorithm, known for its enhanced efficiency and\nnumerical stability compared to existing approaches. Experimental results on\nthe widely used benchmark PascalVOC showcase that our algorithm achieves\nstate-of-the-art performance with significantly improved efficiency. Source\ncode: https://github.com/xmlyqing00/clap\n","authors":["Yongqing Liang","Huijun Han","Xin Li"],"pdf_url":"https://arxiv.org/pdf/2410.17101v1.pdf","comment":"Accepted as an oral paper in International Symposium on Visual\n  Computing (ISCV2024)"},{"id":"http://arxiv.org/abs/2410.17098v1","updated":"2024-10-22T15:22:53Z","published":"2024-10-22T15:22:53Z","title":"Masked Differential Privacy","summary":"  Privacy-preserving computer vision is an important emerging problem in\nmachine learning and artificial intelligence. The prevalent methods tackling\nthis problem use differential privacy or anonymization and obfuscation\ntechniques to protect the privacy of individuals. In both cases, the utility of\nthe trained model is sacrificed heavily in this process. In this work, we\npropose an effective approach called masked differential privacy (MaskDP),\nwhich allows for controlling sensitive regions where differential privacy is\napplied, in contrast to applying DP on the entire input. Our method operates\nselectively on the data and allows for defining non-sensitive spatio-temporal\nregions without DP application or combining differential privacy with other\nprivacy techniques within data samples. Experiments on four challenging action\nrecognition datasets demonstrate that our proposed techniques result in better\nutility-privacy trade-offs compared to standard differentially private training\nin the especially demanding $\\epsilon<1$ regime.\n","authors":["David Schneider","Sina Sajadmanesh","Vikash Sehwag","Saquib Sarfraz","Rainer Stiefelhagen","Lingjuan Lyu","Vivek Sharma"],"pdf_url":"https://arxiv.org/pdf/2410.17098v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17082v1","updated":"2024-10-22T15:07:07Z","published":"2024-10-22T15:07:07Z","title":"A Survey on Deep Learning-based Gaze Direction Regression: Searching for\n  the State-of-the-art","summary":"  In this paper, we present a survey of deep learning-based methods for the\nregression of gaze direction vector from head and eye images. We describe in\ndetail numerous published methods with a focus on the input data, architecture\nof the model, and loss function used to supervise the model. Additionally, we\npresent a list of datasets that can be used to train and evaluate gaze\ndirection regression methods. Furthermore, we noticed that the results reported\nin the literature are often not comparable one to another due to differences in\nthe validation or even test subsets used. To address this problem, we\nre-evaluated several methods on the commonly used in-the-wild Gaze360 dataset\nusing the same validation setup. The experimental results show that the latest\nmethods, although claiming state-of-the-art results, significantly underperform\ncompared with some older methods. Finally, we show that the temporal models\noutperform the static models under static test conditions.\n","authors":["Franko Šikić","Donik Vršnak","Sven Lončarić"],"pdf_url":"https://arxiv.org/pdf/2410.17082v1.pdf","comment":"Accepted on SPRA 2024 (Istanbul, Turkey)"},{"id":"http://arxiv.org/abs/2407.05180v2","updated":"2024-10-22T14:54:42Z","published":"2024-04-22T10:33:06Z","title":"ReCAP: Recursive Cross Attention Network for Pseudo-Label Generation in\n  Robotic Surgical Skill Assessment","summary":"  In surgical skill assessment, Objective Structured Assessments of Technical\nSkills (OSATS scores) and the Global Rating Scale (GRS) are established tools\nfor evaluating the performance of surgeons during training. These metrics,\ncoupled with feedback on their performance, enable surgeons to improve and\nachieve standards of practice. Recent studies on the open-source dataset\nJIGSAW, which contains both GRS and OSATS labels, have focused on regressing\nGRS scores from kinematic signals, video data, or a combination of both. In\nthis paper, we argue that regressing the GRS score, a unitless value, by itself\nis too restrictive, and variations throughout the surgical trial do not hold\nsignificant clinical meaning. To address this gap, we developed a recurrent\ntransformer model that outputs the surgeon's performance throughout their\ntraining session by relating the model's hidden states to five OSATS scores\nderived from kinematic signals. These scores are averaged and aggregated to\nproduce a GRS prediction, enabling assessment of the model's performance\nagainst the state-of-the-art (SOTA). We report Spearman's Correlation\nCoefficient (SCC), demonstrating that our model outperforms SOTA models for all\ntasks, except for Suturing under the leave-one-subject-out (LOSO) scheme (SCC\n0.68-0.89), while achieving comparable performance for suturing and across\ntasks under the leave-one-user-out (LOUO) scheme (SCC 0.45-0.68) and beating\nSOTA for Needle Passing (0.69). We argue that relating final OSATS scores to\nshort instances throughout a surgeon's procedure is more clinically meaningful\nthan a single GRS score. This approach also allows us to translate quantitative\npredictions into qualitative feedback, which is crucial for any automated\nsurgical skill assessment pipeline. A senior surgeon validated our model's\nbehaviour and agreed with the semi-supervised predictions 77 \\% (p = 0.006) of\nthe time.\n","authors":["Julien Quarez","Matthew Elliot","Oscar Maccormac","Marc Modat","Sebastien Ourselin","Jonathan Shapey","Alejandro Granados"],"pdf_url":"https://arxiv.org/pdf/2407.05180v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17066v1","updated":"2024-10-22T14:46:20Z","published":"2024-10-22T14:46:20Z","title":"Neuronal Competition Groups with Supervised STDP for Spike-Based\n  Classification","summary":"  Spike Timing-Dependent Plasticity (STDP) is a promising substitute to\nbackpropagation for local training of Spiking Neural Networks (SNNs) on\nneuromorphic hardware. STDP allows SNNs to address classification tasks by\ncombining unsupervised STDP for feature extraction and supervised STDP for\nclassification. Unsupervised STDP is usually employed with Winner-Takes-All\n(WTA) competition to learn distinct patterns. However, WTA for supervised STDP\nclassification faces unbalanced competition challenges. In this paper, we\npropose a method to effectively implement WTA competition in a spiking\nclassification layer employing first-spike coding and supervised STDP training.\nWe introduce the Neuronal Competition Group (NCG), an architecture that\nimproves classification capabilities by promoting the learning of various\npatterns per class. An NCG is a group of neurons mapped to a specific class,\nimplementing intra-class WTA and a novel competition regulation mechanism based\non two-compartment thresholds. We incorporate our proposed architecture into\nspiking classification layers trained with state-of-the-art supervised STDP\nrules. On top of two different unsupervised feature extractors, we obtain\nsignificant accuracy improvements on image recognition datasets such as\nCIFAR-10 and CIFAR-100. We show that our competition regulation mechanism is\ncrucial for ensuring balanced competition and improved class separation.\n","authors":["Gaspard Goupy","Pierre Tirilly","Ioan Marius Bilasco"],"pdf_url":"https://arxiv.org/pdf/2410.17066v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17064v1","updated":"2024-10-22T14:44:47Z","published":"2024-10-22T14:44:47Z","title":"Multi Kernel Estimation based Object Segmentation","summary":"  This paper presents a novel approach for multi-kernel estimation by enhancing\nthe KernelGAN algorithm, which traditionally estimates a single kernel for the\nentire image. We introduce Multi-KernelGAN, which extends KernelGAN's\ncapabilities by estimating two distinct kernels based on object segmentation\nmasks. Our approach is validated through three distinct methods: texture-based\npatch Fast Fourier Transform (FFT) calculation, detail-based segmentation, and\ndeep learning-based object segmentation using YOLOv8 and the Segment Anything\nModel (SAM). Among these methods, the combination of YOLO and SAM yields the\nbest results for kernel estimation. Experimental results demonstrate that our\nmulti-kernel estimation technique outperforms conventional single-kernel\nmethods in super-resolution tasks.\n","authors":["Haim Goldfisher","Asaf Yekutiel"],"pdf_url":"https://arxiv.org/pdf/2410.17064v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.13675v4","updated":"2024-10-22T14:28:56Z","published":"2024-05-22T14:16:30Z","title":"Context and Geometry Aware Voxel Transformer for Semantic Scene\n  Completion","summary":"  Vision-based Semantic Scene Completion (SSC) has gained much attention due to\nits widespread applications in various 3D perception tasks. Existing\nsparse-to-dense approaches typically employ shared context-independent queries\nacross various input images, which fails to capture distinctions among them as\nthe focal regions of different inputs vary and may result in undirected feature\naggregation of cross-attention. Additionally, the absence of depth information\nmay lead to points projected onto the image plane sharing the same 2D position\nor similar sampling points in the feature map, resulting in depth ambiguity. In\nthis paper, we present a novel context and geometry aware voxel transformer. It\nutilizes a context aware query generator to initialize context-dependent\nqueries tailored to individual input images, effectively capturing their unique\ncharacteristics and aggregating information within the region of interest.\nFurthermore, it extend deformable cross-attention from 2D to 3D pixel space,\nenabling the differentiation of points with similar image coordinates based on\ntheir depth coordinates. Building upon this module, we introduce a neural\nnetwork named CGFormer to achieve semantic scene completion. Simultaneously,\nCGFormer leverages multiple 3D representations (i.e., voxel and TPV) to boost\nthe semantic and geometric representation abilities of the transformed 3D\nvolume from both local and global perspectives. Experimental results\ndemonstrate that CGFormer achieves state-of-the-art performance on the\nSemanticKITTI and SSCBench-KITTI-360 benchmarks, attaining a mIoU of 16.87 and\n20.05, as well as an IoU of 45.99 and 48.07, respectively. Remarkably, CGFormer\neven outperforms approaches employing temporal images as inputs or much larger\nimage backbone networks.\n","authors":["Zhu Yu","Runmin Zhang","Jiacheng Ying","Junchen Yu","Xiaohai Hu","Lun Luo","Si-Yuan Cao","Hui-Liang Shen"],"pdf_url":"https://arxiv.org/pdf/2405.13675v4.pdf","comment":"NIPS 2024 Spotlight"},{"id":"http://arxiv.org/abs/2410.14980v2","updated":"2024-10-22T14:27:32Z","published":"2024-10-19T05:10:07Z","title":"DCDepth: Progressive Monocular Depth Estimation in Discrete Cosine\n  Domain","summary":"  In this paper, we introduce DCDepth, a novel framework for the long-standing\nmonocular depth estimation task. Moving beyond conventional pixel-wise depth\nestimation in the spatial domain, our approach estimates the frequency\ncoefficients of depth patches after transforming them into the discrete cosine\ndomain. This unique formulation allows for the modeling of local depth\ncorrelations within each patch. Crucially, the frequency transformation\nsegregates the depth information into various frequency components, with\nlow-frequency components encapsulating the core scene structure and\nhigh-frequency components detailing the finer aspects. This decomposition forms\nthe basis of our progressive strategy, which begins with the prediction of\nlow-frequency components to establish a global scene context, followed by\nsuccessive refinement of local details through the prediction of\nhigher-frequency components. We conduct comprehensive experiments on\nNYU-Depth-V2, TOFDC, and KITTI datasets, and demonstrate the state-of-the-art\nperformance of DCDepth. Code is available at https://github.com/w2kun/DCDepth.\n","authors":["Kun Wang","Zhiqiang Yan","Junkai Fan","Wanlu Zhu","Xiang Li","Jun Li","Jian Yang"],"pdf_url":"https://arxiv.org/pdf/2410.14980v2.pdf","comment":"Accepted by NeurIPS-2024"},{"id":"http://arxiv.org/abs/2405.14677v2","updated":"2024-10-22T14:21:19Z","published":"2024-05-23T15:12:15Z","title":"RectifID: Personalizing Rectified Flow with Anchored Classifier Guidance","summary":"  Customizing diffusion models to generate identity-preserving images from\nuser-provided reference images is an intriguing new problem. The prevalent\napproaches typically require training on extensive domain-specific images to\nachieve identity preservation, which lacks flexibility across different use\ncases. To address this issue, we exploit classifier guidance, a training-free\ntechnique that steers diffusion models using an existing classifier, for\npersonalized image generation. Our study shows that based on a recent rectified\nflow framework, the major limitation of vanilla classifier guidance in\nrequiring a special classifier can be resolved with a simple fixed-point\nsolution, allowing flexible personalization with off-the-shelf image\ndiscriminators. Moreover, its solving procedure proves to be stable when\nanchored to a reference flow trajectory, with a convergence guarantee. The\nderived method is implemented on rectified flow with different off-the-shelf\nimage discriminators, delivering advantageous personalization results for human\nfaces, live subjects, and certain objects. Code is available at\nhttps://github.com/feifeiobama/RectifID.\n","authors":["Zhicheng Sun","Zhenhao Yang","Yang Jin","Haozhe Chi","Kun Xu","Kun Xu","Liwei Chen","Hao Jiang","Yang Song","Kun Gai","Yadong Mu"],"pdf_url":"https://arxiv.org/pdf/2405.14677v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2409.16320v2","updated":"2024-10-22T14:09:10Z","published":"2024-09-21T03:45:05Z","title":"Developing a Thailand solar irradiance map using Himawari-8 satellite\n  imageries and deep learning models","summary":"  This paper presents an online platform that shows Thailand's solar irradiance\nmap every 30 minutes. It is available at https://www.cusolarforecast.com. The\nmethodology for estimating global horizontal irradiance (GHI) across Thailand\nrelies on cloud index extracted from Himawari-8 satellite imagery, Ineichen\nclear-sky model with locally-tuned Linke turbidity, and machine learning\nmodels. The methods take clear-sky irradiance, cloud index, re-analyzed GHI and\ntemperature data from the MERRA-2 database, and date-time as inputs for GHI\nestimation models, including LightGBM, LSTM, Informer, and Transformer. These\nare benchmarked with the estimate from a commercial service X by evaluating\n15-minute ground GHI data from 53 ground stations over 1.5 years from\n2022-2023. The results show that the four models have competitive performances\nand outperform the service X. The best model is LightGBM, with an MAE of 78.58\nW/sqm and RMSE of 118.97 W/sqm. Obtaining re-analyzed MERRA-2 data for Thailand\nis not economically feasible for deployment. When removing these features, the\nInformer model has a winning performance of 78.67 W/sqm in MAE. The obtained\nperformance aligns with existing literature by taking the climate zone and time\ngranularity of data into consideration. As the map shows an estimate of GHI\nover 93,000 grids with a frequent update, the paper also describes a\ncomputational framework for displaying the entire map. It tests the runtime\nperformance of deep learning models in the GHI estimation process.\n","authors":["Suwichaya Suwanwimolkul","Natanon Tongamrak","Nuttamon Thungka","Naebboon Hoonchareon","Jitkomut Songsiri"],"pdf_url":"https://arxiv.org/pdf/2409.16320v2.pdf","comment":"23 pages, 14 figures"},{"id":"http://arxiv.org/abs/2403.07389v2","updated":"2024-10-22T14:07:54Z","published":"2024-03-12T07:57:33Z","title":"Auxiliary CycleGAN-guidance for Task-Aware Domain Translation from\n  Duplex to Monoplex IHC Images","summary":"  Generative models enable the translation from a source image domain where\nreadily trained models are available to a target domain unseen during training.\nWhile Cycle Generative Adversarial Networks (GANs) are well established, the\nassociated cycle consistency constrain relies on that an invertible mapping\nexists between the two domains. This is, however, not the case for the\ntranslation between images stained with chromogenic monoplex and duplex\nimmunohistochemistry (IHC) assays. Focusing on the translation from the latter\nto the first, we propose - through the introduction of a novel training design,\nan alternative constrain leveraging a set of immunofluorescence (IF) images as\nan auxiliary unpaired image domain. Quantitative and qualitative results on a\ndownstream segmentation task show the benefit of the proposed method in\ncomparison to baseline approaches.\n","authors":["Nicolas Brieu","Nicolas Triltsch","Philipp Wortmann","Dominik Winter","Shashank Saran","Marlon Rebelatto","Günter Schmidt"],"pdf_url":"https://arxiv.org/pdf/2403.07389v2.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2410.17020v1","updated":"2024-10-22T13:44:10Z","published":"2024-10-22T13:44:10Z","title":"LFME: A Simple Framework for Learning from Multiple Experts in Domain\n  Generalization","summary":"  Domain generalization (DG) methods aim to maintain good performance in an\nunseen target domain by using training data from multiple source domains. While\nsuccess on certain occasions are observed, enhancing the baseline across most\nscenarios remains challenging. This work introduces a simple yet effective\nframework, dubbed learning from multiple experts (LFME), that aims to make the\ntarget model an expert in all source domains to improve DG. Specifically,\nbesides learning the target model used in inference, LFME will also train\nmultiple experts specialized in different domains, whose output probabilities\nprovide professional guidance by simply regularizing the logit of the target\nmodel. Delving deep into the framework, we reveal that the introduced logit\nregularization term implicitly provides effects of enabling the target model to\nharness more information, and mining hard samples from the experts during\ntraining. Extensive experiments on benchmarks from different DG tasks\ndemonstrate that LFME is consistently beneficial to the baseline and can\nachieve comparable performance to existing arts. Code is available\nat~\\url{https://github.com/liangchen527/LFME}.\n","authors":["Liang Chen","Yong Zhang","Yibing Song","Zhiqiang Shen","Lingqiao Liu"],"pdf_url":"https://arxiv.org/pdf/2410.17020v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.17017v1","updated":"2024-10-22T13:37:55Z","published":"2024-10-22T13:37:55Z","title":"SPVSoAP3D: A Second-order Average Pooling Approach to enhance 3D Place\n  Recognition in Horticultural Environments","summary":"  3D LiDAR-based place recognition has been extensively researched in urban\nenvironments, yet it remains underexplored in agricultural settings. Unlike\nurban contexts, horticultural environments, characterized by their permeability\nto laser beams, result in sparse and overlapping LiDAR scans with suboptimal\ngeometries. This phenomenon leads to intra- and inter-row descriptor ambiguity.\nIn this work, we address this challenge by introducing SPVSoAP3D, a novel\nmodeling approach that combines a voxel-based feature extraction network with\nan aggregation technique based on a second-order average pooling operator,\ncomplemented by a descriptor enhancement stage. Furthermore, we augment the\nexisting HORTO-3DLM dataset by introducing two new sequences derived from\nhorticultural environments. We evaluate the performance of SPVSoAP3D against\nstate-of-the-art (SOTA) models, including OverlapTransformer, PointNetVLAD, and\nLOGG3D-Net, utilizing a cross-validation protocol on both the newly introduced\nsequences and the existing HORTO-3DLM dataset. The findings indicate that the\naverage operator is more suitable for horticultural environments compared to\nthe max operator and other first-order pooling techniques. Additionally, the\nresults highlight the improvements brought by the descriptor enhancement stage.\n","authors":["T. Barros","C. Premebida","S. Aravecchia","C. Pradalier","U. J. Nunes"],"pdf_url":"https://arxiv.org/pdf/2410.17017v1.pdf","comment":"This work has been accepted to IROS 2024"},{"id":"http://arxiv.org/abs/2205.07708v3","updated":"2024-10-22T13:34:45Z","published":"2022-05-16T14:21:30Z","title":"Exploring Diversity-based Active Learning for 3D Object Detection in\n  Autonomous Driving","summary":"  3D object detection has recently received much attention due to its great\npotential in autonomous vehicle (AV). The success of deep learning based object\ndetectors relies on the availability of large-scale annotated datasets, which\nis time-consuming and expensive to compile, especially for 3D bounding box\nannotation. In this work, we investigate diversity-based active learning (AL)\nas a potential solution to alleviate the annotation burden. Given limited\nannotation budget, only the most informative frames and objects are\nautomatically selected for human to annotate. Technically, we take the\nadvantage of the multimodal information provided in an AV dataset, and propose\na novel acquisition function that enforces spatial and temporal diversity in\nthe selected samples. We benchmark the proposed method against other AL\nstrategies under realistic annotation cost measurement, where the realistic\ncosts for annotating a frame and a 3D bounding box are both taken into\nconsideration. We demonstrate the effectiveness of the proposed method on the\nnuScenes dataset and show that it outperforms existing AL strategies\nsignificantly. Code is available at\nhttps://github.com/Linkon87/Exploring-Diversity-based-Active-Learning-for-3D-Object-Detection-in-Autonomous-Driving\n","authors":["Jinpeng Lin","Zhihao Liang","Shengheng Deng","Lile Cai","Tao Jiang","Tianrui Li","Kui Jia","Xun Xu"],"pdf_url":"https://arxiv.org/pdf/2205.07708v3.pdf","comment":"IEEE Transactions on Intelligent Transportation Systems. Code is\n  available at\n  https://github.com/Linkon87/Exploring-Diversity-based-Active-Learning-for-3D-Object-Detection-in-Autonomous-Driving"},{"id":"http://arxiv.org/abs/2406.12142v2","updated":"2024-10-22T13:32:34Z","published":"2024-06-17T23:08:46Z","title":"Slicing Through Bias: Explaining Performance Gaps in Medical Image\n  Analysis using Slice Discovery Methods","summary":"  Machine learning models have achieved high overall accuracy in medical image\nanalysis. However, performance disparities on specific patient groups pose\nchallenges to their clinical utility, safety, and fairness. This can affect\nknown patient groups - such as those based on sex, age, or disease subtype - as\nwell as previously unknown and unlabeled groups. Furthermore, the root cause of\nsuch observed performance disparities is often challenging to uncover,\nhindering mitigation efforts. In this paper, to address these issues, we\nleverage Slice Discovery Methods (SDMs) to identify interpretable\nunderperforming subsets of data and formulate hypotheses regarding the cause of\nobserved performance disparities. We introduce a novel SDM and apply it in a\ncase study on the classification of pneumothorax and atelectasis from chest\nx-rays. Our study demonstrates the effectiveness of SDMs in hypothesis\nformulation and yields an explanation of previously observed but unexplained\nperformance disparities between male and female patients in widely used chest\nX-ray datasets and models. Our findings indicate shortcut learning in both\nclassification tasks, through the presence of chest drains and ECG wires,\nrespectively. Sex-based differences in the prevalence of these shortcut\nfeatures appear to cause the observed classification performance gap,\nrepresenting a previously underappreciated interaction between shortcut\nlearning and model fairness analyses.\n","authors":["Vincent Olesen","Nina Weng","Aasa Feragen","Eike Petersen"],"pdf_url":"https://arxiv.org/pdf/2406.12142v2.pdf","comment":"MICCAI 2024 Workshop on Fairness of AI in Medical Imaging"},{"id":"http://arxiv.org/abs/2410.17001v1","updated":"2024-10-22T13:23:05Z","published":"2024-10-22T13:23:05Z","title":"Joint Point Cloud Upsampling and Cleaning with Octree-based CNNs","summary":"  Recovering dense and uniformly distributed point clouds from sparse or noisy\ndata remains a significant challenge. Recently, great progress has been made on\nthese tasks, but usually at the cost of increasingly intricate modules or\ncomplicated network architectures, leading to long inference time and huge\nresource consumption. Instead, we embrace simplicity and present a simple yet\nefficient method for jointly upsampling and cleaning point clouds. Our method\nleverages an off-the-shelf octree-based 3D U-Net (OUNet) with minor\nmodifications, enabling the upsampling and cleaning tasks within a single\nnetwork. Our network directly processes each input point cloud as a whole\ninstead of processing each point cloud patch as in previous works, which\nsignificantly eases the implementation and brings at least 47 times faster\ninference. Extensive experiments demonstrate that our method achieves\nstate-of-the-art performances under huge efficiency advantages on a series of\nbenchmarks. We expect our method to serve simple baselines and inspire\nresearchers to rethink the method design on point cloud upsampling and\ncleaning.\n","authors":["Jihe Li","Bo Pang","Peng-Shuai Wang"],"pdf_url":"https://arxiv.org/pdf/2410.17001v1.pdf","comment":"Accepted by Computational Visual Media"},{"id":"http://arxiv.org/abs/2410.16999v1","updated":"2024-10-22T13:21:36Z","published":"2024-10-22T13:21:36Z","title":"AGSENet: A Robust Road Ponding Detection Method for Proactive Traffic\n  Safety","summary":"  Road ponding, a prevalent traffic hazard, poses a serious threat to road\nsafety by causing vehicles to lose control and leading to accidents ranging\nfrom minor fender benders to severe collisions. Existing technologies struggle\nto accurately identify road ponding due to complex road textures and variable\nponding coloration influenced by reflection characteristics. To address this\nchallenge, we propose a novel approach called Self-Attention-based Global\nSaliency-Enhanced Network (AGSENet) for proactive road ponding detection and\ntraffic safety improvement. AGSENet incorporates saliency detection techniques\nthrough the Channel Saliency Information Focus (CSIF) and Spatial Saliency\nInformation Enhancement (SSIE) modules. The CSIF module, integrated into the\nencoder, employs self-attention to highlight similar features by fusing spatial\nand channel information. The SSIE module, embedded in the decoder, refines edge\nfeatures and reduces noise by leveraging correlations across different feature\nlevels. To ensure accurate and reliable evaluation, we corrected significant\nmislabeling and missing annotations in the Puddle-1000 dataset. Additionally,\nwe constructed the Foggy-Puddle and Night-Puddle datasets for road ponding\ndetection in low-light and foggy conditions, respectively. Experimental results\ndemonstrate that AGSENet outperforms existing methods, achieving IoU\nimprovements of 2.03\\%, 0.62\\%, and 1.06\\% on the Puddle-1000, Foggy-Puddle,\nand Night-Puddle datasets, respectively, setting a new state-of-the-art in this\nfield. Finally, we verified the algorithm's reliability on edge computing\ndevices. This work provides a valuable reference for proactive warning research\nin road traffic safety.\n","authors":["Ronghui Zhang","Shangyu Yang","Dakang Lyu","Zihan Wang","Junzhou Chen","Yilong Ren","Bolin Gao","Zhihan Lv"],"pdf_url":"https://arxiv.org/pdf/2410.16999v1.pdf","comment":"21 pages, 15 figures"},{"id":"http://arxiv.org/abs/2410.16995v1","updated":"2024-10-22T13:17:20Z","published":"2024-10-22T13:17:20Z","title":"E-3DGS: Gaussian Splatting with Exposure and Motion Events","summary":"  Estimating Neural Radiance Fields (NeRFs) from images captured under optimal\nconditions has been extensively explored in the vision community. However,\nrobotic applications often face challenges such as motion blur, insufficient\nillumination, and high computational overhead, which adversely affect\ndownstream tasks like navigation, inspection, and scene visualization. To\naddress these challenges, we propose E-3DGS, a novel event-based approach that\npartitions events into motion (from camera or object movement) and exposure\n(from camera exposure), using the former to handle fast-motion scenes and using\nthe latter to reconstruct grayscale images for high-quality training and\noptimization of event-based 3D Gaussian Splatting (3DGS). We introduce a novel\nintegration of 3DGS with exposure events for high-quality reconstruction of\nexplicit scene representations. Our versatile framework can operate on motion\nevents alone for 3D reconstruction, enhance quality using exposure events, or\nadopt a hybrid mode that balances quality and effectiveness by optimizing with\ninitial exposure events followed by high-speed motion events. We also introduce\nEME-3D, a real-world 3D dataset with exposure events, motion events, camera\ncalibration parameters, and sparse point clouds. Our method is faster and\ndelivers better reconstruction quality than event-based NeRF while being more\ncost-effective than NeRF methods that combine event and RGB data by using a\nsingle event sensor. By combining motion and exposure events, E-3DGS sets a new\nbenchmark for event-based 3D reconstruction with robust performance in\nchallenging conditions and lower hardware demands. The source code and dataset\nwill be available at https://github.com/MasterHow/E-3DGS.\n","authors":["Xiaoting Yin","Hao Shi","Yuhan Bao","Zhenshan Bing","Yiyi Liao","Kailun Yang","Kaiwei Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16995v1.pdf","comment":"The source code and dataset will be available at\n  https://github.com/MasterHow/E-3DGS"},{"id":"http://arxiv.org/abs/2404.06050v2","updated":"2024-10-22T13:15:20Z","published":"2024-04-09T06:27:35Z","title":"Incremental Joint Learning of Depth, Pose and Implicit Scene\n  Representation on Monocular Camera in Large-scale Scenes","summary":"  Dense scene reconstruction for photo-realistic view synthesis has various\napplications, such as VR/AR, autonomous vehicles. However, most existing\nmethods have difficulties in large-scale scenes due to three core challenges:\n\\textit{(a) inaccurate depth input.} Accurate depth input is impossible to get\nin real-world large-scale scenes. \\textit{(b) inaccurate pose estimation.} Most\nexisting approaches rely on accurate pre-estimated camera poses. \\textit{(c)\ninsufficient scene representation capability.} A single global radiance field\nlacks the capacity to effectively scale to large-scale scenes. To this end, we\npropose an incremental joint learning framework, which can achieve accurate\ndepth, pose estimation, and large-scale scene reconstruction. A vision\ntransformer-based network is adopted as the backbone to enhance performance in\nscale information estimation. For pose estimation, a feature-metric bundle\nadjustment (FBA) method is designed for accurate and robust camera tracking in\nlarge-scale scenes. In terms of implicit scene representation, we propose an\nincremental scene representation method to construct the entire large-scale\nscene as multiple local radiance fields to enhance the scalability of 3D scene\nrepresentation. Extended experiments have been conducted to demonstrate the\neffectiveness and accuracy of our method in depth estimation, pose estimation,\nand large-scale scene reconstruction.\n","authors":["Tianchen Deng","Nailin Wang","Chongdi Wang","Shenghai Yuan","Jingchuan Wang","Danwei Wang","Weidong Chen"],"pdf_url":"https://arxiv.org/pdf/2404.06050v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.09553v3","updated":"2024-10-22T13:04:29Z","published":"2024-06-28T08:21:49Z","title":"DPEC: Dual-Path Error Compensation Method for Enhanced Low-Light Image\n  Clarity","summary":"  For the task of low-light image enhancement, deep learning-based algorithms\nhave demonstrated superiority and effectiveness compared to traditional\nmethods. Existing deep learning algorithms are proposed mainly based on the\nRetinex theory but overlook the noise and color distortion present in the\ninput, which frequently results in significant noise amplification and local\ncolor distortion in the final results. To address this, we propose a Dual-Path\nError Compensation method (DPEC), which aims to improve image quality in\nlow-light conditions. DPEC performs precise pixel-level error estimation, which\naccurately captures subtle pixels differences, and independent denoising, which\neffectively removes unnecessary noise. This method restores image brightness\nwhile preserving local texture details and avoiding noise amplification.\nFurthermore, to compensate for the traditional CNN's limited ability to capture\nlong-range semantic information and considering both computational speed and\nresource efficiency, we integrated the VMamba architecture into the backbone of\nDPEC. In addition, we introduced the HIS-Retinex loss to constrain the training\nof DPEC, ensuring that the overall brightness distribution of the images more\nclosely aligns with real-world conditions. Comprehensive quantitative and\nqualitative experimental results demonstrate that our algorithm significantly\noutperforms state-of-the-art methods across six benchmark tests.\n","authors":["Shuang Wang","Qianwen Lu","Yihe Nie","Qingchuan Tao","Yanmei Yu"],"pdf_url":"https://arxiv.org/pdf/2407.09553v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16978v1","updated":"2024-10-22T12:56:58Z","published":"2024-10-22T12:56:58Z","title":"Multi-Layer Gaussian Splatting for Immersive Anatomy Visualization","summary":"  In medical image visualization, path tracing of volumetric medical data like\nCT scans produces lifelike three-dimensional visualizations. Immersive VR\ndisplays can further enhance the understanding of complex anatomies. Going\nbeyond the diagnostic quality of traditional 2D slices, they enable interactive\n3D evaluation of anatomies, supporting medical education and planning.\nRendering high-quality visualizations in real-time, however, is computationally\nintensive and impractical for compute-constrained devices like mobile headsets.\n  We propose a novel approach utilizing GS to create an efficient but static\nintermediate representation of CT scans. We introduce a layered GS\nrepresentation, incrementally including different anatomical structures while\nminimizing overlap and extending the GS training to remove inactive Gaussians.\nWe further compress the created model with clustering across layers.\n  Our approach achieves interactive frame rates while preserving anatomical\nstructures, with quality adjustable to the target hardware. Compared to\nstandard GS, our representation retains some of the explorative qualities\ninitially enabled by immersive path tracing. Selective activation and clipping\nof layers are possible at rendering time, adding a degree of interactivity to\notherwise static GS models. This could enable scenarios where high\ncomputational demands would otherwise prohibit using path-traced medical\nvolumes.\n","authors":["Constantin Kleinbeck","Hannah Schieber","Klaus Engel","Ralf Gutjahr","Daniel Roth"],"pdf_url":"https://arxiv.org/pdf/2410.16978v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16592v2","updated":"2024-10-22T12:46:00Z","published":"2024-06-24T12:33:21Z","title":"Toward Fairer Face Recognition Datasets","summary":"  Face recognition and verification are two computer vision tasks whose\nperformance has progressed with the introduction of deep representations.\nHowever, ethical, legal, and technical challenges due to the sensitive\ncharacter of face data and biases in real training datasets hinder their\ndevelopment. Generative AI addresses privacy by creating fictitious identities,\nbut fairness problems persist. We promote fairness by introducing a demographic\nattributes balancing mechanism in generated training datasets. We experiment\nwith an existing real dataset, three generated training datasets, and the\nbalanced versions of a diffusion-based dataset. We propose a comprehensive\nevaluation that considers accuracy and fairness equally and includes a rigorous\nregression-based statistical analysis of attributes. The analysis shows that\nbalancing reduces demographic unfairness. Also, a performance gap persists\ndespite generation becoming more accurate with time. The proposed balancing\nmethod and comprehensive verification evaluation promote fairer and transparent\nface recognition and verification.\n","authors":["Alexandre Fournier-Mongieux","Michael Soumm","Adrian Popescu","Bertrand Luvison","Hervé Le Borgne"],"pdf_url":"https://arxiv.org/pdf/2406.16592v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13717v5","updated":"2024-10-22T12:42:06Z","published":"2023-11-22T22:21:26Z","title":"Feature Extraction for Generative Medical Imaging Evaluation: New\n  Evidence Against an Evolving Trend","summary":"  Fr\\'echet Inception Distance (FID) is a widely used metric for assessing\nsynthetic image quality. It relies on an ImageNet-based feature extractor,\nmaking its applicability to medical imaging unclear. A recent trend is to adapt\nFID to medical imaging through feature extractors trained on medical images.\nOur study challenges this practice by demonstrating that ImageNet-based\nextractors are more consistent and aligned with human judgment than their\nRadImageNet counterparts. We evaluated sixteen StyleGAN2 networks across four\nmedical imaging modalities and four data augmentation techniques with Fr\\'echet\ndistances (FDs) computed using eleven ImageNet or RadImageNet-trained feature\nextractors. Comparison with human judgment via visual Turing tests revealed\nthat ImageNet-based extractors produced rankings consistent with human\njudgment, with the FD derived from the ImageNet-trained SwAV extractor\nsignificantly correlating with expert evaluations. In contrast,\nRadImageNet-based rankings were volatile and inconsistent with human judgment.\nOur findings challenge prevailing assumptions, providing novel evidence that\nmedical image-trained feature extractors do not inherently improve FDs and can\neven compromise their reliability. Our code is available at\nhttps://github.com/mckellwoodland/fid-med-eval.\n","authors":["McKell Woodland","Austin Castelo","Mais Al Taie","Jessica Albuquerque Marques Silva","Mohamed Eltaher","Frank Mohn","Alexander Shieh","Suprateek Kundu","Joshua P. Yung","Ankit B. Patel","Kristy K. Brock"],"pdf_url":"https://arxiv.org/pdf/2311.13717v5.pdf","comment":"This preprint has not undergone peer review or any post-submission\n  improvements or corrections. The Version of Record of this contribution is\n  published in LNCS vol. 15012, and is available online at\n  https://doi.org/10.1007/978-3-031-72390-2_9"},{"id":"http://arxiv.org/abs/2410.16958v1","updated":"2024-10-22T12:38:39Z","published":"2024-10-22T12:38:39Z","title":"Leaky ReLUs That Differ in Forward and Backward Pass Facilitate\n  Activation Maximization in Deep Neural Networks","summary":"  Activation maximization (AM) strives to generate optimal input stimuli,\nrevealing features that trigger high responses in trained deep neural networks.\nAM is an important method of explainable AI. We demonstrate that AM fails to\nproduce optimal input stimuli for simple functions containing ReLUs or Leaky\nReLUs, casting doubt on the practical usefulness of AM and the visual\ninterpretation of the generated images. This paper proposes a solution based on\nusing Leaky ReLUs with a high negative slope in the backward pass while keeping\nthe original, usually zero, slope in the forward pass. The approach\nsignificantly increases the maxima found by AM. The resulting ProxyGrad\nalgorithm implements a novel optimization technique for neural networks that\nemploys a secondary network as a proxy for gradient computation. This proxy\nnetwork is designed to have a simpler loss landscape with fewer local maxima\nthan the original network. Our chosen proxy network is an identical copy of the\noriginal network, including its weights, with distinct negative slopes in the\nLeaky ReLUs. Moreover, we show that ProxyGrad can be used to train the weights\nof Convolutional Neural Networks for classification such that, on some of the\ntested benchmarks, they outperform traditional networks.\n","authors":["Christoph Linse","Erhardt Barth","Thomas Martinetz"],"pdf_url":"https://arxiv.org/pdf/2410.16958v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16955v1","updated":"2024-10-22T12:36:03Z","published":"2024-10-22T12:36:03Z","title":"PGCS: Physical Law embedded Generative Cloud Synthesis in Remote Sensing\n  Images","summary":"  Data quantity and quality are both critical for information extraction and\nanalyzation in remote sensing. However, the current remote sensing datasets\noften fail to meet these two requirements, for which cloud is a primary factor\ndegrading the data quantity and quality. This limitation affects the precision\nof results in remote sensing application, particularly those derived from\ndata-driven techniques. In this paper, a physical law embedded generative cloud\nsynthesis method (PGCS) is proposed to generate diverse realistic cloud images\nto enhance real data and promote the development of algorithms for subsequent\ntasks, such as cloud correction, cloud detection, and data augmentation for\nclassification, recognition, and segmentation. The PGCS method involves two key\nphases: spatial synthesis and spectral synthesis. In the spatial synthesis\nphase, a style-based generative adversarial network is utilized to simulate the\nspatial characteristics, generating an infinite number of single-channel\nclouds. In the spectral synthesis phase, the atmospheric scattering law is\nembedded through a local statistics and global fitting method, converting the\nsingle-channel clouds into multi-spectral clouds. The experimental results\ndemonstrate that PGCS achieves a high accuracy in both phases and performs\nbetter than three other existing cloud synthesis methods. Two cloud correction\nmethods are developed from PGCS and exhibits a superior performance compared to\nstate-of-the-art methods in the cloud correction task. Furthermore, the\napplication of PGCS with data from various sensors was investigated and\nsuccessfully extended. Code will be provided at\nhttps://github.com/Liying-Xu/PGCS.\n","authors":["Liying Xu","Huifang Li","Huanfeng Shen","Mingyang Lei","Tao Jiang"],"pdf_url":"https://arxiv.org/pdf/2410.16955v1.pdf","comment":"20 pages, 16 figures"},{"id":"http://arxiv.org/abs/2410.16953v1","updated":"2024-10-22T12:33:38Z","published":"2024-10-22T12:33:38Z","title":"Towards Real Zero-Shot Camouflaged Object Segmentation without\n  Camouflaged Annotations","summary":"  Camouflaged Object Segmentation (COS) faces significant challenges due to the\nscarcity of annotated data, where meticulous pixel-level annotation is both\nlabor-intensive and costly, primarily due to the intricate object-background\nboundaries. Addressing the core question, \"Can COS be effectively achieved in a\nzero-shot manner without manual annotations for any camouflaged object?\" we\naffirmatively respond and introduce a robust zero-shot COS framework. This\nframework leverages the inherent local pattern bias of COS and employs a broad\nsemantic feature space derived from salient object segmentation (SOS) for\nefficient zero-shot transfer. We incorporate an Masked Image Modeling (MIM)\nbased image encoder optimized for Parameter-Efficient Fine-Tuning (PEFT), a\nMultimodal Large Language Model (M-LLM), and a Multi-scale Fine-grained\nAlignment (MFA) mechanism. The MIM pre-trained image encoder focuses on\ncapturing essential low-level features, while the M-LLM generates caption\nembeddings processed alongside these visual cues. These embeddings are\nprecisely aligned using MFA, enabling our framework to accurately interpret and\nnavigate complex semantic contexts. To optimize operational efficiency, we\nintroduce a learnable codebook that represents the M-LLM during inference,\nsignificantly reducing computational overhead. Our framework demonstrates its\nversatility and efficacy through rigorous experimentation, achieving\nstate-of-the-art performance in zero-shot COS with $F_{\\beta}^w$ scores of\n72.9\\% on CAMO and 71.7\\% on COD10K. By removing the M-LLM during inference, we\nachieve an inference speed comparable to that of traditional end-to-end models,\nreaching 18.1 FPS. Code: https://github.com/R-LEI360725/ZSCOS-CaMF\n","authors":["Cheng Lei","Jie Fan","Xinran Li","Tianzhu Xiang","Ao Li","Ce Zhu","Le Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.16953v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.10353v2","updated":"2024-10-22T12:31:51Z","published":"2024-09-16T15:04:14Z","title":"Taming Diffusion Models for Image Restoration: A Review","summary":"  Diffusion models have achieved remarkable progress in generative modelling,\nparticularly in enhancing image quality to conform to human preferences.\nRecently, these models have also been applied to low-level computer vision for\nphoto-realistic image restoration (IR) in tasks such as image denoising,\ndeblurring, dehazing, etc. In this review paper, we introduce key constructions\nin diffusion models and survey contemporary techniques that make use of\ndiffusion models in solving general IR tasks. Furthermore, we point out the\nmain challenges and limitations of existing diffusion-based IR frameworks and\nprovide potential directions for future work.\n","authors":["Ziwei Luo","Fredrik K. Gustafsson","Zheng Zhao","Jens Sjölund","Thomas B. Schön"],"pdf_url":"https://arxiv.org/pdf/2409.10353v2.pdf","comment":"Review paper; any comments and suggestions are most welcome!"},{"id":"http://arxiv.org/abs/2407.21497v3","updated":"2024-10-22T12:23:20Z","published":"2024-07-31T10:11:57Z","title":"Mitral Regurgitation Recognition based on Unsupervised\n  Out-of-Distribution Detection with Residual Diffusion Amplification","summary":"  Mitral regurgitation (MR) is a serious heart valve disease. Early and\naccurate diagnosis of MR via ultrasound video is critical for timely clinical\ndecision-making and surgical intervention. However, manual MR diagnosis heavily\nrelies on the operator's experience, which may cause misdiagnosis and\ninter-observer variability. Since MR data is limited and has large intra-class\nvariability, we propose an unsupervised out-of-distribution (OOD) detection\nmethod to identify MR rather than building a deep classifier. To our knowledge,\nwe are the first to explore OOD in MR ultrasound videos. Our method consists of\na feature extractor, a feature reconstruction model, and a residual\naccumulation amplification algorithm. The feature extractor obtains features\nfrom the video clips and feeds them into the feature reconstruction model to\nrestore the original features. The residual accumulation amplification\nalgorithm then iteratively performs noise feature reconstruction, amplifying\nthe reconstructed error of OOD features. This algorithm is straightforward yet\nefficient and can seamlessly integrate as a plug-and-play component in\nreconstruction-based OOD detection methods. We validated the proposed method on\na large ultrasound dataset containing 893 non-MR and 267 MR videos.\nExperimental results show that our OOD detection method can effectively\nidentify MR samples.\n","authors":["Zhe Liu","Xiliang Zhu","Tong Han","Yuhao Huang","Jian Wang","Lian Liu","Fang Wang","Dong Ni","Zhongshan Gou","Xin Yang"],"pdf_url":"https://arxiv.org/pdf/2407.21497v3.pdf","comment":"Accepted by MICCAI MLMI 2024, 11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.16947v1","updated":"2024-10-22T12:21:39Z","published":"2024-10-22T12:21:39Z","title":"ISImed: A Framework for Self-Supervised Learning using Intrinsic Spatial\n  Information in Medical Images","summary":"  This paper demonstrates that spatial information can be used to learn\ninterpretable representations in medical images using Self-Supervised Learning\n(SSL). Our proposed method, ISImed, is based on the observation that medical\nimages exhibit a much lower variability among different images compared to\nclassic data vision benchmarks. By leveraging this resemblance of human body\nstructures across multiple images, we establish a self-supervised objective\nthat creates a latent representation capable of capturing its location in the\nphysical realm. More specifically, our method involves sampling image crops and\ncreating a distance matrix that compares the learned representation vectors of\nall possible combinations of these crops to the true distance between them. The\nintuition is, that the learned latent space is a positional encoding for a\ngiven image crop. We hypothesize, that by learning these positional encodings,\ncomprehensive image representations have to be generated. To test this\nhypothesis and evaluate our method, we compare our learned representation with\ntwo state-of-the-art SSL benchmarking methods on two publicly available medical\nimaging datasets. We show that our method can efficiently learn representations\nthat capture the underlying structure of the data and can be used to transfer\nto a downstream classification task.\n","authors":["Nabil Jabareen","Dongsheng Yuan","Sören Lukassen"],"pdf_url":"https://arxiv.org/pdf/2410.16947v1.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.16945v1","updated":"2024-10-22T12:20:15Z","published":"2024-10-22T12:20:15Z","title":"IdenBAT: Disentangled Representation Learning for Identity-Preserved\n  Brain Age Transformation","summary":"  Brain age transformation aims to convert reference brain images into\nsynthesized images that accurately reflect the age-specific features of a\ntarget age group. The primary objective of this task is to modify only the\nage-related attributes of the reference image while preserving all other\nage-irrelevant attributes. However, achieving this goal poses substantial\nchallenges due to the inherent entanglement of various image attributes within\nfeatures extracted from a backbone encoder, resulting in simultaneous\nalterations during the image generation. To address this challenge, we propose\na novel architecture that employs disentangled representation learning for\nidentity-preserved brain age transformation called IdenBAT. This approach\nfacilitates the decomposition of image features, ensuring the preservation of\nindividual traits while selectively transforming age-related characteristics to\nmatch those of the target age group. Through comprehensive experiments\nconducted on both 2D and full-size 3D brain datasets, our method adeptly\nconverts input images to target age while retaining individual characteristics\naccurately. Furthermore, our approach demonstrates superiority over existing\nstate-of-the-art regarding performance fidelity.\n","authors":["Junyeong Maeng","Kwanseok Oh","Wonsik Jung","Heung-Il Suk"],"pdf_url":"https://arxiv.org/pdf/2410.16945v1.pdf","comment":"16 pages, 8 figures, 2 tables"},{"id":"http://arxiv.org/abs/2410.16942v1","updated":"2024-10-22T12:18:24Z","published":"2024-10-22T12:18:24Z","title":"DiP-GO: A Diffusion Pruner via Few-step Gradient Optimization","summary":"  Diffusion models have achieved remarkable progress in the field of image\ngeneration due to their outstanding capabilities. However, these models require\nsubstantial computing resources because of the multi-step denoising process\nduring inference. While traditional pruning methods have been employed to\noptimize these models, the retraining process necessitates large-scale training\ndatasets and extensive computational costs to maintain generalization ability,\nmaking it neither convenient nor efficient. Recent studies attempt to utilize\nthe similarity of features across adjacent denoising stages to reduce\ncomputational costs through simple and static strategies. However, these\nstrategies cannot fully harness the potential of the similar feature patterns\nacross adjacent timesteps. In this work, we propose a novel pruning method that\nderives an efficient diffusion model via a more intelligent and differentiable\npruner. At the core of our approach is casting the model pruning process into a\nSubNet search process. Specifically, we first introduce a SuperNet based on\nstandard diffusion via adding some backup connections built upon the similar\nfeatures. We then construct a plugin pruner network and design optimization\nlosses to identify redundant computation. Finally, our method can identify an\noptimal SubNet through few-step gradient optimization and a simple\npost-processing procedure. We conduct extensive experiments on various\ndiffusion models including Stable Diffusion series and DiTs. Our DiP-GO\napproach achieves 4.4 x speedup for SD-1.5 without any loss of accuracy,\nsignificantly outperforming the previous state-of-the-art methods.\n","authors":["Haowei Zhu","Dehua Tang","Ji Liu","Mingjie Lu","Jintu Zheng","Jinzhang Peng","Dong Li","Yu Wang","Fan Jiang","Lu Tian","Spandan Tiwari","Ashish Sirasao","Jun-Hai Yong","Bin Wang","Emad Barsoum"],"pdf_url":"https://arxiv.org/pdf/2410.16942v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16939v1","updated":"2024-10-22T12:13:47Z","published":"2024-10-22T12:13:47Z","title":"LIMIS: Towards Language-based Interactive Medical Image Segmentation","summary":"  Within this work, we introduce LIMIS: The first purely language-based\ninteractive medical image segmentation model. We achieve this by adapting\nGrounded SAM to the medical domain and designing a language-based model\ninteraction strategy that allows radiologists to incorporate their knowledge\ninto the segmentation process. LIMIS produces high-quality initial segmentation\nmasks by leveraging medical foundation models and allows users to adapt\nsegmentation masks using only language, opening up interactive segmentation to\nscenarios where physicians require using their hands for other tasks. We\nevaluate LIMIS on three publicly available medical datasets in terms of\nperformance and usability with experts from the medical domain confirming its\nhigh-quality segmentation masks and its interactive usability.\n","authors":["Lena Heinemann","Alexander Jaus","Zdravko Marinov","Moon Kim","Maria Francesca Spadea","Jens Kleesiek","Rainer Stiefelhagen"],"pdf_url":"https://arxiv.org/pdf/2410.16939v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15629v2","updated":"2024-10-22T12:02:29Z","published":"2024-10-21T04:25:43Z","title":"Fully Explicit Dynamic Gaussian Splatting","summary":"  3D Gaussian Splatting has shown fast and high-quality rendering results in\nstatic scenes by leveraging dense 3D prior and explicit representations.\nUnfortunately, the benefits of the prior and representation do not involve\nnovel view synthesis for dynamic motions. Ironically, this is because the main\nbarrier is the reliance on them, which requires increasing training and\nrendering times to account for dynamic motions. In this paper, we design a\nExplicit 4D Gaussian Splatting(Ex4DGS). Our key idea is to firstly separate\nstatic and dynamic Gaussians during training, and to explicitly sample\npositions and rotations of the dynamic Gaussians at sparse timestamps. The\nsampled positions and rotations are then interpolated to represent both\nspatially and temporally continuous motions of objects in dynamic scenes as\nwell as reducing computational cost. Additionally, we introduce a progressive\ntraining scheme and a point-backtracking technique that improves Ex4DGS's\nconvergence. We initially train Ex4DGS using short timestamps and progressively\nextend timestamps, which makes it work well with a few point clouds. The\npoint-backtracking is used to quantify the cumulative error of each Gaussian\nover time, enabling the detection and removal of erroneous Gaussians in dynamic\nscenes. Comprehensive experiments on various scenes demonstrate the\nstate-of-the-art rendering quality from our method, achieving fast rendering of\n62 fps on a single 2080Ti GPU.\n","authors":["Junoh Lee","Chang-Yeon Won","Hyunjun Jung","Inhwan Bae","Hae-Gon Jeon"],"pdf_url":"https://arxiv.org/pdf/2410.15629v2.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2405.15330v2","updated":"2024-10-22T12:01:45Z","published":"2024-05-24T08:12:41Z","title":"Towards Understanding the Working Mechanism of Text-to-Image Diffusion\n  Model","summary":"  Recently, the strong latent Diffusion Probabilistic Model (DPM) has been\napplied to high-quality Text-to-Image (T2I) generation (e.g., Stable\nDiffusion), by injecting the encoded target text prompt into the gradually\ndenoised diffusion image generator. Despite the success of DPM in practice, the\nmechanism behind it remains to be explored. To fill this blank, we begin by\nexamining the intermediate statuses during the gradual denoising generation\nprocess in DPM. The empirical observations indicate, the shape of image is\nreconstructed after the first few denoising steps, and then the image is filled\nwith details (e.g., texture). The phenomenon is because the low-frequency\nsignal (shape relevant) of the noisy image is not corrupted until the final\nstage in the forward process (initial stage of generation) of adding noise in\nDPM. Inspired by the observations, we proceed to explore the influence of each\ntoken in the text prompt during the two stages. After a series of experiments\nof T2I generations conditioned on a set of text prompts. We conclude that in\nthe earlier generation stage, the image is mostly decided by the special token\n[\\texttt{EOS}] in the text prompt, and the information in the text prompt is\nalready conveyed in this stage. After that, the diffusion model completes the\ndetails of generated images by information from themselves. Finally, we propose\nto apply this observation to accelerate the process of T2I generation by\nproperly removing text guidance, which finally accelerates the sampling up to\n25\\%+.\n","authors":["Mingyang Yi","Aoxue Li","Yi Xin","Zhenguo Li"],"pdf_url":"https://arxiv.org/pdf/2405.15330v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16910v1","updated":"2024-10-22T11:35:36Z","published":"2024-10-22T11:35:36Z","title":"Hierarchical Clustering for Conditional Diffusion in Image Generation","summary":"  Finding clusters of data points with similar characteristics and generating\nnew cluster-specific samples can significantly enhance our understanding of\ncomplex data distributions. While clustering has been widely explored using\nVariational Autoencoders, these models often lack generation quality in\nreal-world datasets. This paper addresses this gap by introducing\nTreeDiffusion, a deep generative model that conditions Diffusion Models on\nhierarchical clusters to obtain high-quality, cluster-specific generations. The\nproposed pipeline consists of two steps: a VAE-based clustering model that\nlearns the hierarchical structure of the data, and a conditional diffusion\nmodel that generates realistic images for each cluster. We propose this\ntwo-stage process to ensure that the generated samples remain representative of\ntheir respective clusters and enhance image fidelity to the level of diffusion\nmodels. A key strength of our method is its ability to create images for each\ncluster, providing better visualization of the learned representations by the\nclustering model, as demonstrated through qualitative results. This method\neffectively addresses the generative limitations of VAE-based approaches while\npreserving their clustering performance. Empirically, we demonstrate that\nconditioning diffusion models on hierarchical clusters significantly enhances\ngenerative performance, thereby advancing the state of generative clustering\nmodels.\n","authors":["Jorge da Silva Goncalves","Laura Manduchi","Moritz Vandenhirtz","Julia E. Vogt"],"pdf_url":"https://arxiv.org/pdf/2410.16910v1.pdf","comment":"25 pages, submitted to ICLR 2025"},{"id":"http://arxiv.org/abs/2410.16908v1","updated":"2024-10-22T11:28:39Z","published":"2024-10-22T11:28:39Z","title":"Mitigating Vanishing Activations in Deep CapsNets Using Channel Pruning","summary":"  Capsule Networks outperform Convolutional Neural Networks in learning the\npart-whole relationships with viewpoint invariance, and the credit goes to\ntheir multidimensional capsules. It was assumed that increasing the number of\ncapsule layers in the capsule networks would enhance the model performance.\nHowever, recent studies found that Capsule Networks lack scalability due to\nvanishing activations in the capsules of deeper layers. This paper thoroughly\ninvestigates the vanishing activation problem in deep Capsule Networks. To\nanalyze this issue and understand how increasing capsule dimensions can\nfacilitate deeper networks, various Capsule Network models are constructed and\nevaluated with different numbers of capsules, capsule dimensions, and\nintermediate layers for this paper. Unlike traditional model pruning, which\nreduces the number of model parameters and expedites model training, this study\nuses pruning to mitigate the vanishing activations in the deeper capsule\nlayers. In addition, the backbone network and capsule layers are pruned with\ndifferent pruning ratios to reduce the number of inactive capsules and achieve\nbetter model accuracy than the unpruned models.\n","authors":["Siddharth Sahu","Abdulrahman Altahhan"],"pdf_url":"https://arxiv.org/pdf/2410.16908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16898v1","updated":"2024-10-22T11:03:06Z","published":"2024-10-22T11:03:06Z","title":"MBD: Multi b-value Denoising of Diffusion Magnetic Resonance Images","summary":"  We propose a novel approach to denoising diffusion magnetic resonance images\n(dMRI) using convolutional neural networks, that exploits the benefits of data\nacquired at multiple b-values to offset the need for many redundant\nobservations. Denoising is especially relevant in dMRI since noise can have a\ndeleterious impact on both quantification accuracy and image preprocessing. The\nmost successful methods proposed to date, like Marchenko-Pastur Principal\nComponent Analysis (MPPCA) denoising, are tailored to diffusion-weighting\nrepeated for many encoding directions. They exploit high redundancy of the\ndataset that oversamples the diffusion-encoding direction space, since many\ndirections have collinear components.\n  However, there are many dMRI techniques that do not entail a large number of\nencoding directions or repetitions, and are therefore less suited to this\napproach. For example, clinical dMRI exams may include as few as three encoding\ndirections, with low or negligible data redundancy across directions. Moreover,\npromising new dMRI approaches, like spherical b-tensor encoding (STE), benefit\nfrom high b-values while sensitizing the signal to diffusion along all\ndirections in just a single shot.\n  We introduce a convolutional neural network approach that we call\nmulti-b-value-based denoising (MBD). MBD exploits the similarity in\ndiffusion-weighted images (DWI) across different b-values but along the same\ndiffusion encoding direction. It allows denoising of diffusion images with high\nnoise variance while avoiding blurring, and using just a small number input\nimages.\n","authors":["Jakub Jurek","Andrzej Materka","Kamil Ludwisiak","Agata Majos","Filip Szczepankiewicz"],"pdf_url":"https://arxiv.org/pdf/2410.16898v1.pdf","comment":"this is a biomedical engineering work using machine learning to\n  enhance medical images"},{"id":"http://arxiv.org/abs/2410.16897v1","updated":"2024-10-22T11:02:32Z","published":"2024-10-22T11:02:32Z","title":"Enhancing Generalization in Convolutional Neural Networks through\n  Regularization with Edge and Line Features","summary":"  This paper proposes a novel regularization approach to bias Convolutional\nNeural Networks (CNNs) toward utilizing edge and line features in their hidden\nlayers. Rather than learning arbitrary kernels, we constrain the convolution\nlayers to edge and line detection kernels. This intentional bias regularizes\nthe models, improving generalization performance, especially on small datasets.\nAs a result, test accuracies improve by margins of 5-11 percentage points\nacross four challenging fine-grained classification datasets with limited\ntraining data and an identical number of trainable parameters. Instead of\ntraditional convolutional layers, we use Pre-defined Filter Modules, which\nconvolve input data using a fixed set of 3x3 pre-defined edge and line filters.\nA subsequent ReLU erases information that did not trigger any positive\nresponse. Next, a 1x1 convolutional layer generates linear combinations.\nNotably, the pre-defined filters are a fixed component of the architecture,\nremaining unchanged during the training phase. Our findings reveal that the\nnumber of dimensions spanned by the set of pre-defined filters has a low impact\non recognition performance. However, the size of the set of filters matters,\nwith nine or more filters providing optimal results.\n","authors":["Christoph Linse","Beatrice Brückner","Thomas Martinetz"],"pdf_url":"https://arxiv.org/pdf/2410.16897v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16892v1","updated":"2024-10-22T10:55:59Z","published":"2024-10-22T10:55:59Z","title":"VistaDream: Sampling multiview consistent images for single-view scene\n  reconstruction","summary":"  In this paper, we propose VistaDream a novel framework to reconstruct a 3D\nscene from a single-view image. Recent diffusion models enable generating\nhigh-quality novel-view images from a single-view input image. Most existing\nmethods only concentrate on building the consistency between the input image\nand the generated images while losing the consistency between the generated\nimages. VistaDream addresses this problem by a two-stage pipeline. In the first\nstage, VistaDream begins with building a global coarse 3D scaffold by zooming\nout a little step with inpainted boundaries and an estimated depth map. Then,\non this global scaffold, we use iterative diffusion-based RGB-D inpainting to\ngenerate novel-view images to inpaint the holes of the scaffold. In the second\nstage, we further enhance the consistency between the generated novel-view\nimages by a novel training-free Multiview Consistency Sampling (MCS) that\nintroduces multi-view consistency constraints in the reverse sampling process\nof diffusion models. Experimental results demonstrate that without training or\nfine-tuning existing diffusion models, VistaDream achieves consistent and\nhigh-quality novel view synthesis using just single-view images and outperforms\nbaseline methods by a large margin. The code, videos, and interactive demos are\navailable at https://vistadream-project-page.github.io/.\n","authors":["Haiping Wang","Yuan Liu","Ziwei Liu","Wenping Wang","Zhen Dong","Bisheng Yang"],"pdf_url":"https://arxiv.org/pdf/2410.16892v1.pdf","comment":"Project Page: https://vistadream-project-page.github.io/"},{"id":"http://arxiv.org/abs/2410.16884v1","updated":"2024-10-22T10:42:08Z","published":"2024-10-22T10:42:08Z","title":"Network Inversion for Training-Like Data Reconstruction","summary":"  Machine Learning models are often trained on proprietary and private data\nthat cannot be shared, though the trained models themselves are distributed\nopenly assuming that sharing model weights is privacy preserving, as training\ndata is not expected to be inferred from the model weights. In this paper, we\npresent Training-Like Data Reconstruction (TLDR), a network inversion-based\napproach to reconstruct training-like data from trained models. To begin with,\nwe introduce a comprehensive network inversion technique that learns the input\nspace corresponding to different classes in the classifier using a single\nconditioned generator. While inversion may typically return random and\narbitrary input images for a given output label, we modify the inversion\nprocess to incentivize the generator to reconstruct training-like data by\nexploiting key properties of the classifier with respect to the training data\nalong with some prior knowledge about the images. To validate our approach, we\nconduct empirical evaluations on multiple standard vision classification\ndatasets, thereby highlighting the potential privacy risks involved in sharing\nmachine learning models.\n","authors":["Pirzada Suhail","Amit Sethi"],"pdf_url":"https://arxiv.org/pdf/2410.16884v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16868v1","updated":"2024-10-22T10:12:57Z","published":"2024-10-22T10:12:57Z","title":"Rethinking generalization of classifiers in separable classes scenarios\n  and over-parameterized regimes","summary":"  We investigate the learning dynamics of classifiers in scenarios where\nclasses are separable or classifiers are over-parameterized. In both cases,\nEmpirical Risk Minimization (ERM) results in zero training error. However,\nthere are many global minima with a training error of zero, some of which\ngeneralize well and some of which do not. We show that in separable classes\nscenarios the proportion of \"bad\" global minima diminishes exponentially with\nthe number of training data n. Our analysis provides bounds and learning curves\ndependent solely on the density distribution of the true error for the given\nclassifier function set, irrespective of the set's size or complexity (e.g.,\nnumber of parameters). This observation may shed light on the unexpectedly good\ngeneralization of over-parameterized Neural Networks. For the\nover-parameterized scenario, we propose a model for the density distribution of\nthe true error, yielding learning curves that align with experiments on MNIST\nand CIFAR-10.\n","authors":["Julius Martinetz","Christoph Linse","Thomas Martinetz"],"pdf_url":"https://arxiv.org/pdf/2410.16868v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.05375v6","updated":"2024-10-22T09:52:42Z","published":"2023-10-09T03:11:08Z","title":"IPDreamer: Appearance-Controllable 3D Object Generation with Complex\n  Image Prompts","summary":"  Recent advances in 3D generation have been remarkable, with methods such as\nDreamFusion leveraging large-scale text-to-image diffusion-based models to\nguide 3D object generation. These methods enable the synthesis of detailed and\nphotorealistic textured objects. However, the appearance of 3D objects produced\nby such text-to-3D models is often unpredictable, and it is hard for\nsingle-image-to-3D methods to deal with images lacking a clear subject,\ncomplicating the generation of appearance-controllable 3D objects from complex\nimages. To address these challenges, we present IPDreamer, a novel method that\ncaptures intricate appearance features from complex $\\textbf{I}$mage\n$\\textbf{P}$rompts and aligns the synthesized 3D object with these extracted\nfeatures, enabling high-fidelity, appearance-controllable 3D object generation.\nOur experiments demonstrate that IPDreamer consistently generates high-quality\n3D objects that align with both the textual and complex image prompts,\nhighlighting its promising capability in appearance-controlled, complex 3D\nobject generation. Our code is available at\nhttps://github.com/zengbohan0217/IPDreamer.\n","authors":["Bohan Zeng","Shanglin Li","Yutang Feng","Ling Yang","Hong Li","Sicheng Gao","Jiaming Liu","Conghui He","Wentao Zhang","Jianzhuang Liu","Baochang Zhang","Shuicheng Yan"],"pdf_url":"https://arxiv.org/pdf/2310.05375v6.pdf","comment":"20 pages, 12 figures"},{"id":"http://arxiv.org/abs/2410.16857v1","updated":"2024-10-22T09:46:09Z","published":"2024-10-22T09:46:09Z","title":"Nash Meets Wertheimer: Using Good Continuation in Jigsaw Puzzles","summary":"  Jigsaw puzzle solving is a challenging task for computer vision since it\nrequires high-level spatial and semantic reasoning. To solve the problem,\nexisting approaches invariably use color and/or shape information but in many\nreal-world scenarios, such as in archaeological fresco reconstruction, this\nkind of clues is often unreliable due to severe physical and pictorial\ndeterioration of the individual fragments. This makes state-of-the-art\napproaches entirely unusable in practice. On the other hand, in such cases,\nsimple geometrical patterns such as lines or curves offer a powerful yet\nunexplored clue. In an attempt to fill in this gap, in this paper we introduce\na new challenging version of the puzzle solving problem in which one\ndeliberately ignores conventional color and shape features and relies solely on\nthe presence of linear geometrical patterns. The reconstruction process is then\nonly driven by one of the most fundamental principles of Gestalt perceptual\norganization, namely Wertheimer's {\\em law of good continuation}. In order to\ntackle this problem, we formulate the puzzle solving problem as the problem of\nfinding a Nash equilibrium of a (noncooperative) multiplayer game and use\nclassical multi-population replicator dynamics to solve it. The proposed\napproach is general and allows us to deal with pieces of arbitrary shape, size\nand orientation. We evaluate our approach on both synthetic and real-world data\nand compare it with state-of-the-art algorithms. The results show the intrinsic\ncomplexity of our purely line-based puzzle problem as well as the relative\neffectiveness of our game-theoretic formulation.\n","authors":["Marina Khoroshiltseva","Luca Palmieri","Sinem Aslan","Sebastiano Vascon","Marcello Pelillo"],"pdf_url":"https://arxiv.org/pdf/2410.16857v1.pdf","comment":"to be published in ACCV2024"},{"id":"http://arxiv.org/abs/2402.02500v3","updated":"2024-10-22T09:42:39Z","published":"2024-02-04T14:18:45Z","title":"Point Cloud Matters: Rethinking the Impact of Different Observation\n  Spaces on Robot Learning","summary":"  In robot learning, the observation space is crucial due to the distinct\ncharacteristics of different modalities, which can potentially become a\nbottleneck alongside policy design. In this study, we explore the influence of\nvarious observation spaces on robot learning, focusing on three predominant\nmodalities: RGB, RGB-D, and point cloud. We introduce OBSBench, a benchmark\ncomprising two simulators and 125 tasks, along with standardized pipelines for\nvarious encoders and policy baselines. Extensive experiments on diverse\ncontact-rich manipulation tasks reveal a notable trend: point cloud-based\nmethods, even those with the simplest designs, frequently outperform their RGB\nand RGB-D counterparts. This trend persists in both scenarios: training from\nscratch and utilizing pre-training. Furthermore, our findings demonstrate that\npoint cloud observations often yield better policy performance and\nsignificantly stronger generalization capabilities across various geometric and\nvisual conditions. These outcomes suggest that the 3D point cloud is a valuable\nobservation modality for intricate robotic tasks. We also suggest that\nincorporating both appearance and coordinate information can enhance the\nperformance of point cloud methods. We hope our work provides valuable insights\nand guidance for designing more generalizable and robust robotic models. Codes\nare available at https://github.com/HaoyiZhu/PointCloudMatters.\n","authors":["Haoyi Zhu","Yating Wang","Di Huang","Weicai Ye","Wanli Ouyang","Tong He"],"pdf_url":"https://arxiv.org/pdf/2402.02500v3.pdf","comment":"38th Conference on Neural Information Processing Systems (NeurIPS\n  2024) Track on Datasets and Benchmarks"},{"id":"http://arxiv.org/abs/2410.16853v1","updated":"2024-10-22T09:37:29Z","published":"2024-10-22T09:37:29Z","title":"Bridging the Modality Gap: Dimension Information Alignment and Sparse\n  Spatial Constraint for Image-Text Matching","summary":"  Many contrastive learning based models have achieved advanced performance in\nimage-text matching tasks. The key of these models lies in analyzing the\ncorrelation between image-text pairs, which involves cross-modal interaction of\nembeddings in corresponding dimensions. However, the embeddings of different\nmodalities are from different models or modules, and there is a significant\nmodality gap. Directly interacting such embeddings lacks rationality and may\ncapture inaccurate correlation. Therefore, we propose a novel method called\nDIAS to bridge the modality gap from two aspects: (1) We align the information\nrepresentation of embeddings from different modalities in corresponding\ndimension to ensure the correlation calculation is based on interactions of\nsimilar information. (2) The spatial constraints of inter- and intra-modalities\nunmatched pairs are introduced to ensure the effectiveness of semantic\nalignment of the model. Besides, a sparse correlation algorithm is proposed to\nselect strong correlated spatial relationships, enabling the model to learn\nmore significant features and avoid being misled by weak correlation. Extensive\nexperiments demonstrate the superiority of DIAS, achieving 4.3\\%-10.2\\% rSum\nimprovements on Flickr30k and MSCOCO benchmarks.\n","authors":["Xiang Ma","Xuemei Li","Lexin Fang","Caiming Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.16853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.09534v2","updated":"2024-10-22T09:27:26Z","published":"2023-09-18T07:26:58Z","title":"Selective Volume Mixup for Video Action Recognition","summary":"  The recent advances in Convolutional Neural Networks (CNNs) and Vision\nTransformers have convincingly demonstrated high learning capability for video\naction recognition on large datasets. Nevertheless, deep models often suffer\nfrom the overfitting effect on small-scale datasets with a limited number of\ntraining videos. A common solution is to exploit the existing image\naugmentation strategies for each frame individually including Mixup, Cutmix,\nand RandAugment, which are not particularly optimized for video data. In this\npaper, we propose a novel video augmentation strategy named Selective Volume\nMixup (SV-Mix) to improve the generalization ability of deep models with\nlimited training videos. SV-Mix devises a learnable selective module to choose\nthe most informative volumes from two videos and mixes the volumes up to\nachieve a new training video. Technically, we propose two new modules, i.e., a\nspatial selective module to select the local patches for each spatial position,\nand a temporal selective module to mix the entire frames for each timestamp and\nmaintain the spatial pattern. At each time, we randomly choose one of the two\nmodules to expand the diversity of training samples. The selective modules are\njointly optimized with the video action recognition framework to find the\noptimal augmentation strategy. We empirically demonstrate the merits of the\nSV-Mix augmentation on a wide range of video action recognition benchmarks and\nconsistently boot the performances of both CNN-based and transformer-based\nmodels.\n","authors":["Yi Tan","Zhaofan Qiu","Yanbin Hao","Ting Yao","Tao Mei"],"pdf_url":"https://arxiv.org/pdf/2309.09534v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16840v1","updated":"2024-10-22T09:20:03Z","published":"2024-10-22T09:20:03Z","title":"MPDS: A Movie Posters Dataset for Image Generation with Diffusion Model","summary":"  Movie posters are vital for captivating audiences, conveying themes, and\ndriving market competition in the film industry. While traditional designs are\nlaborious, intelligent generation technology offers efficiency gains and design\nenhancements. Despite exciting progress in image generation, current models\noften fall short in producing satisfactory poster results. The primary issue\nlies in the absence of specialized poster datasets for targeted model training.\nIn this work, we propose a Movie Posters DataSet (MPDS), tailored for\ntext-to-image generation models to revolutionize poster production. As\ndedicated to posters, MPDS stands out as the first image-text pair dataset to\nour knowledge, composing of 373k+ image-text pairs and 8k+ actor images\n(covering 4k+ actors). Detailed poster descriptions, such as movie titles,\ngenres, casts, and synopses, are meticulously organized and standardized based\non public movie synopsis, also named movie-synopsis prompt. To bolster poster\ndescriptions as well as reduce differences from movie synopsis, further, we\nleverage a large-scale vision-language model to automatically produce\nvision-perceptive prompts for each poster, then perform manual rectification\nand integration with movie-synopsis prompt. In addition, we introduce a prompt\nof poster captions to exhibit text elements in posters like actor names and\nmovie titles. For movie poster generation, we develop a multi-condition\ndiffusion framework that takes poster prompt, poster caption, and actor image\n(for personalization) as inputs, yielding excellent results through the\nlearning of a diffusion model. Experiments demonstrate the valuable role of our\nproposed MPDS dataset in advancing personalized movie poster generation. MPDS\nis available at https://anonymous.4open.science/r/MPDS-373k-BD3B.\n","authors":["Meng Xu","Tong Zhang","Fuyun Wang","Yi Lei","Xin Liu","Zhen Cui"],"pdf_url":"https://arxiv.org/pdf/2410.16840v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15574v3","updated":"2024-10-22T09:05:30Z","published":"2024-05-24T14:04:03Z","title":"Meteor: Mamba-based Traversal of Rationale for Large Language and Vision\n  Models","summary":"  The rapid development of large language and vision models (LLVMs) has been\ndriven by advances in visual instruction tuning. Recently, open-source LLVMs\nhave curated high-quality visual instruction tuning datasets and utilized\nadditional vision encoders or multiple computer vision models in order to\nnarrow the performance gap with powerful closed-source LLVMs. These\nadvancements are attributed to multifaceted information required for diverse\ncapabilities, including fundamental image understanding, real-world knowledge\nabout common-sense and non-object concepts (e.g., charts, diagrams, symbols,\nsigns, and math problems), and step-by-step procedures for solving complex\nquestions. Drawing from the multifaceted information, we present a new\nefficient LLVM, Mamba-based traversal of rationales (Meteor), which leverages\nmultifaceted rationale to enhance understanding and answering capabilities. To\nembed lengthy rationales containing abundant information, we employ the Mamba\narchitecture, capable of processing sequential data with linear time\ncomplexity. We introduce a new concept of traversal of rationale that\nfacilitates efficient embedding of rationale. Subsequently, the backbone\nmultimodal language model (MLM) is trained to generate answers with the aid of\nrationale. Through these steps, Meteor achieves significant improvements in\nvision language performances across multiple evaluation benchmarks requiring\ndiverse capabilities, without scaling up the model size or employing additional\nvision encoders and computer vision models.\n","authors":["Byung-Kwan Lee","Chae Won Kim","Beomchan Park","Yong Man Ro"],"pdf_url":"https://arxiv.org/pdf/2405.15574v3.pdf","comment":"Code is available in https://github.com/ByungKwanLee/Meteor"},{"id":"http://arxiv.org/abs/2410.16824v1","updated":"2024-10-22T08:57:17Z","published":"2024-10-22T08:57:17Z","title":"PerspectiveNet: Multi-View Perception for Dynamic Scene Understanding","summary":"  Generating detailed descriptions from multiple cameras and viewpoints is\nchallenging due to the complex and inconsistent nature of visual data. In this\npaper, we introduce PerspectiveNet, a lightweight yet efficient model for\ngenerating long descriptions across multiple camera views. Our approach\nutilizes a vision encoder, a compact connector module to convert visual\nfeatures into a fixed-size tensor, and large language models (LLMs) to harness\nthe strong natural language generation capabilities of LLMs. The connector\nmodule is designed with three main goals: mapping visual features onto LLM\nembeddings, emphasizing key information needed for description generation, and\nproducing a fixed-size feature matrix. Additionally, we augment our solution\nwith a secondary task, the correct frame sequence detection, enabling the model\nto search for the correct sequence of frames to generate descriptions. Finally,\nwe integrate the connector module, the secondary task, the LLM, and a visual\nfeature extraction model into a single architecture, which is trained for the\nTraffic Safety Description and Analysis task. This task requires generating\ndetailed, fine-grained descriptions of events from multiple cameras and\nviewpoints. The resulting model is lightweight, ensuring efficient training and\ninference, while remaining highly effective.\n","authors":["Vinh Nguyen"],"pdf_url":"https://arxiv.org/pdf/2410.16824v1.pdf","comment":"6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2405.20674v2","updated":"2024-10-22T08:50:16Z","published":"2024-05-31T08:18:39Z","title":"4Diffusion: Multi-view Video Diffusion Model for 4D Generation","summary":"  Current 4D generation methods have achieved noteworthy efficacy with the aid\nof advanced diffusion generative models. However, these methods lack multi-view\nspatial-temporal modeling and encounter challenges in integrating diverse prior\nknowledge from multiple diffusion models, resulting in inconsistent temporal\nappearance and flickers. In this paper, we propose a novel 4D generation\npipeline, namely 4Diffusion, aimed at generating spatial-temporally consistent\n4D content from a monocular video. We first design a unified diffusion model\ntailored for multi-view video generation by incorporating a learnable motion\nmodule into a frozen 3D-aware diffusion model to capture multi-view\nspatial-temporal correlations. After training on a curated dataset, our\ndiffusion model acquires reasonable temporal consistency and inherently\npreserves the generalizability and spatial consistency of the 3D-aware\ndiffusion model. Subsequently, we propose 4D-aware Score Distillation Sampling\nloss, which is based on our multi-view video diffusion model, to optimize 4D\nrepresentation parameterized by dynamic NeRF. This aims to eliminate\ndiscrepancies arising from multiple diffusion models, allowing for generating\nspatial-temporally consistent 4D content. Moreover, we devise an anchor loss to\nenhance the appearance details and facilitate the learning of dynamic NeRF.\nExtensive qualitative and quantitative experiments demonstrate that our method\nachieves superior performance compared to previous methods.\n","authors":["Haiyu Zhang","Xinyuan Chen","Yaohui Wang","Xihui Liu","Yunhong Wang","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2405.20674v2.pdf","comment":"NeurIPS 2024. Project Page: https://aejion.github.io/4diffusion/"},{"id":"http://arxiv.org/abs/2410.16820v1","updated":"2024-10-22T08:48:41Z","published":"2024-10-22T08:48:41Z","title":"AttriPrompter: Auto-Prompting with Attribute Semantics for Zero-shot\n  Nuclei Detection via Visual-Language Pre-trained Models","summary":"  Large-scale visual-language pre-trained models (VLPMs) have demonstrated\nexceptional performance in downstream object detection through text prompts for\nnatural scenes. However, their application to zero-shot nuclei detection on\nhistopathology images remains relatively unexplored, mainly due to the\nsignificant gap between the characteristics of medical images and the\nweb-originated text-image pairs used for pre-training. This paper aims to\ninvestigate the potential of the object-level VLPM, Grounded Language-Image\nPre-training (GLIP), for zero-shot nuclei detection. Specifically, we propose\nan innovative auto-prompting pipeline, named AttriPrompter, comprising\nattribute generation, attribute augmentation, and relevance sorting, to avoid\nsubjective manual prompt design. AttriPrompter utilizes VLPMs' text-to-image\nalignment to create semantically rich text prompts, which are then fed into\nGLIP for initial zero-shot nuclei detection. Additionally, we propose a\nself-trained knowledge distillation framework, where GLIP serves as the teacher\nwith its initial predictions used as pseudo labels, to address the challenges\nposed by high nuclei density, including missed detections, false positives, and\noverlapping instances. Our method exhibits remarkable performance in label-free\nnuclei detection, outperforming all existing unsupervised methods and\ndemonstrating excellent generality. Notably, this work highlights the\nastonishing potential of VLPMs pre-trained on natural image-text pairs for\ndownstream tasks in the medical field as well. Code will be released at\nhttps://github.com/wuyongjianCODE/AttriPrompter.\n","authors":["Yongjian Wu","Yang Zhou","Jiya Saiyin","Bingzheng Wei","Maode Lai","Jianzhong Shou","Yan Xu"],"pdf_url":"https://arxiv.org/pdf/2410.16820v1.pdf","comment":"This article has been accepted for publication in a future issue of\n  IEEE Transactions on Medical Imaging (TMI), but has not been fully edited.\n  Content may change prior to final publication. Citation information: DOI:\n  https://doi.org/10.1109/TMI.2024.3473745 . Code:\n  https://github.com/wuyongjianCODE/AttriPrompter"},{"id":"http://arxiv.org/abs/2407.11965v2","updated":"2024-10-22T08:31:44Z","published":"2024-07-16T17:59:29Z","title":"UrbanWorld: An Urban World Model for 3D City Generation","summary":"  Cities, as the essential environment of human life, encompass diverse\nphysical elements such as buildings, roads and vegetation, which continuously\ninteract with dynamic entities like people and vehicles. Crafting realistic,\ninteractive 3D urban environments is essential for nurturing AGI systems and\nconstructing AI agents capable of perceiving, decision-making, and acting like\nhumans in real-world environments. However, creating high-fidelity 3D urban\nenvironments usually entails extensive manual labor from designers, involving\nintricate detailing and representation of complex urban elements. Therefore,\naccomplishing this automatically remains a longstanding challenge. Toward this\nproblem, we propose UrbanWorld, the first generative urban world model that can\nautomatically create a customized, realistic and interactive 3D urban world\nwith flexible control conditions. UrbanWorld incorporates four key stages in\nthe generation pipeline: flexible 3D layout generation from OSM data or urban\nlayout with semantic and height maps, urban scene design with Urban MLLM,\ncontrollable urban asset rendering via progressive 3D diffusion, and\nMLLM-assisted scene refinement. We conduct extensive quantitative analysis on\nfive visual metrics, demonstrating that UrbanWorld achieves SOTA generation\nrealism. Next, we provide qualitative results about the controllable generation\ncapabilities of UrbanWorld using both textual and image-based prompts. Lastly,\nwe verify the interactive nature of these environments by showcasing the agent\nperception and navigation within the created environments. We contribute\nUrbanWorld as an open-source tool available at\nhttps://github.com/Urban-World/UrbanWorld.\n","authors":["Yu Shang","Yuming Lin","Yu Zheng","Hangyu Fan","Jingtao Ding","Jie Feng","Jiansheng Chen","Li Tian","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2407.11965v2.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2406.05723v2","updated":"2024-10-22T08:28:13Z","published":"2024-06-09T10:30:25Z","title":"Binarized Diffusion Model for Image Super-Resolution","summary":"  Advanced diffusion models (DMs) perform impressively in image\nsuper-resolution (SR), but the high memory and computational costs hinder their\ndeployment. Binarization, an ultra-compression algorithm, offers the potential\nfor effectively accelerating DMs. Nonetheless, due to the model structure and\nthe multi-step iterative attribute of DMs, existing binarization methods result\nin significant performance degradation. In this paper, we introduce a novel\nbinarized diffusion model, BI-DiffSR, for image SR. First, for the model\nstructure, we design a UNet architecture optimized for binarization. We propose\nthe consistent-pixel-downsample (CP-Down) and consistent-pixel-upsample (CP-Up)\nto maintain dimension consistent and facilitate the full-precision information\ntransfer. Meanwhile, we design the channel-shuffle-fusion (CS-Fusion) to\nenhance feature fusion in skip connection. Second, for the activation\ndifference across timestep, we design the timestep-aware redistribution (TaR)\nand activation function (TaA). The TaR and TaA dynamically adjust the\ndistribution of activations based on different timesteps, improving the\nflexibility and representation alability of the binarized module. Comprehensive\nexperiments demonstrate that our BI-DiffSR outperforms existing binarization\nmethods. Code is released at: https://github.com/zhengchen1999/BI-DiffSR.\n","authors":["Zheng Chen","Haotong Qin","Yong Guo","Xiongfei Su","Xin Yuan","Linghe Kong","Yulun Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.05723v2.pdf","comment":"Accepted to NeurIPS 2024. Code is available at\n  https://github.com/zhengchen1999/BI-DiffSR"},{"id":"http://arxiv.org/abs/2410.16802v1","updated":"2024-10-22T08:27:43Z","published":"2024-10-22T08:27:43Z","title":"Evaluating the Effectiveness of Attack-Agnostic Features for Morphing\n  Attack Detection","summary":"  Morphing attacks have diversified significantly over the past years, with new\nmethods based on generative adversarial networks (GANs) and diffusion models\nposing substantial threats to face recognition systems. Recent research has\ndemonstrated the effectiveness of features extracted from large vision models\npretrained on bonafide data only (attack-agnostic features) for detecting deep\ngenerative images. Building on this, we investigate the potential of these\nimage representations for morphing attack detection (MAD). We develop\nsupervised detectors by training a simple binary linear SVM on the extracted\nfeatures and one-class detectors by modeling the distribution of bonafide\nfeatures with a Gaussian Mixture Model (GMM). Our method is evaluated across a\ncomprehensive set of attacks and various scenarios, including generalization to\nunseen attacks, different source datasets, and print-scan data. Our results\nindicate that attack-agnostic features can effectively detect morphing attacks,\noutperforming traditional supervised and one-class detectors from the\nliterature in most scenarios. Additionally, we provide insights into the\nstrengths and limitations of each considered representation and discuss\npotential future research directions to further enhance the robustness and\ngeneralizability of our approach.\n","authors":["Laurent Colbois","Sébastien Marcel"],"pdf_url":"https://arxiv.org/pdf/2410.16802v1.pdf","comment":"Published in the 2024 IEEE International Joint Conference on\n  Biometrics (IJCB)"},{"id":"http://arxiv.org/abs/2410.16794v1","updated":"2024-10-22T08:17:20Z","published":"2024-10-22T08:17:20Z","title":"One-Step Diffusion Distillation through Score Implicit Matching","summary":"  Despite their strong performances on many generative tasks, diffusion models\nrequire a large number of sampling steps in order to generate realistic\nsamples. This has motivated the community to develop effective methods to\ndistill pre-trained diffusion models into more efficient models, but these\nmethods still typically require few-step inference or perform substantially\nworse than the underlying model. In this paper, we present Score Implicit\nMatching (SIM) a new approach to distilling pre-trained diffusion models into\nsingle-step generator models, while maintaining almost the same sample\ngeneration ability as the original model as well as being data-free with no\nneed of training samples for distillation. The method rests upon the fact that,\nalthough the traditional score-based loss is intractable to minimize for\ngenerator models, under certain conditions we can efficiently compute the\ngradients for a wide class of score-based divergences between a diffusion model\nand a generator. SIM shows strong empirical performances for one-step\ngenerators: on the CIFAR10 dataset, it achieves an FID of 2.06 for\nunconditional generation and 1.96 for class-conditional generation. Moreover,\nby applying SIM to a leading transformer-based diffusion model, we distill a\nsingle-step generator for text-to-image (T2I) generation that attains an\naesthetic score of 6.42 with no performance decline over the original\nmulti-step counterpart, clearly outperforming the other one-step generators\nincluding SDXL-TURBO of 5.33, SDXL-LIGHTNING of 5.34 and HYPER-SDXL of 5.85. We\nwill release this industry-ready one-step transformer-based T2I generator along\nwith this paper.\n","authors":["Weijian Luo","Zemin Huang","Zhengyang Geng","J. Zico Kolter","Guo-jun Qi"],"pdf_url":"https://arxiv.org/pdf/2410.16794v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.16261v2","updated":"2024-10-22T08:09:52Z","published":"2024-10-21T17:58:20Z","title":"Mini-InternVL: A Flexible-Transfer Pocket Multimodal Model with 5%\n  Parameters and 90% Performance","summary":"  Multimodal large language models (MLLMs) have demonstrated impressive\nperformance in vision-language tasks across a broad spectrum of domains.\nHowever, the large model scale and associated high computational costs pose\nsignificant challenges for training and deploying MLLMs on consumer-grade GPUs\nor edge devices, thereby hindering their widespread application. In this work,\nwe introduce Mini-InternVL, a series of MLLMs with parameters ranging from 1B\nto 4B, which achieves 90% of the performance with only 5% of the parameters.\nThis significant improvement in efficiency and effectiveness makes our models\nmore accessible and applicable in various real-world scenarios. To further\npromote the adoption of our models, we develop a unified adaptation framework\nfor Mini-InternVL, which enables our models to transfer and outperform\nspecialized models in downstream tasks, including autonomous driving, medical\nimages, and remote sensing. We believe that our study can provide valuable\ninsights and resources to advance the development of efficient and effective\nMLLMs. Code is available at https://github.com/OpenGVLab/InternVL.\n","authors":["Zhangwei Gao","Zhe Chen","Erfei Cui","Yiming Ren","Weiyun Wang","Jinguo Zhu","Hao Tian","Shenglong Ye","Junjun He","Xizhou Zhu","Lewei Lu","Tong Lu","Yu Qiao","Jifeng Dai","Wenhai Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16261v2.pdf","comment":"Technical report"},{"id":"http://arxiv.org/abs/2406.00432v2","updated":"2024-10-22T07:59:51Z","published":"2024-06-01T13:10:43Z","title":"Localize, Understand, Collaborate: Semantic-Aware Dragging via Intention\n  Reasoner","summary":"  Flexible and accurate drag-based editing is a challenging task that has\nrecently garnered significant attention. Current methods typically model this\nproblem as automatically learning \"how to drag\" through point dragging and\noften produce one deterministic estimation, which presents two key limitations:\n1) Overlooking the inherently ill-posed nature of drag-based editing, where\nmultiple results may correspond to a given input, as illustrated in Fig.1; 2)\nIgnoring the constraint of image quality, which may lead to unexpected\ndistortion. To alleviate this, we propose LucidDrag, which shifts the focus\nfrom \"how to drag\" to \"what-then-how\" paradigm. LucidDrag comprises an\nintention reasoner and a collaborative guidance sampling mechanism. The former\ninfers several optimal editing strategies, identifying what content and what\nsemantic direction to be edited. Based on the former, the latter addresses \"how\nto drag\" by collaboratively integrating existing editing guidance with the\nnewly proposed semantic guidance and quality guidance. Specifically, semantic\nguidance is derived by establishing a semantic editing direction based on\nreasoned intentions, while quality guidance is achieved through classifier\nguidance using an image fidelity discriminator. Both qualitative and\nquantitative comparisons demonstrate the superiority of LucidDrag over previous\nmethods.\n","authors":["Xing Cui","Peipei Li","Zekun Li","Xuannan Liu","Yueying Zou","Zhaofeng He"],"pdf_url":"https://arxiv.org/pdf/2406.00432v2.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2406.12214v3","updated":"2024-10-22T07:58:01Z","published":"2024-06-18T02:28:02Z","title":"Is Your HD Map Constructor Reliable under Sensor Corruptions?","summary":"  Driving systems often rely on high-definition (HD) maps for precise\nenvironmental information, which is crucial for planning and navigation. While\ncurrent HD map constructors perform well under ideal conditions, their\nresilience to real-world challenges, \\eg, adverse weather and sensor failures,\nis not well understood, raising safety concerns. This work introduces MapBench,\nthe first comprehensive benchmark designed to evaluate the robustness of HD map\nconstruction methods against various sensor corruptions. Our benchmark\nencompasses a total of 29 types of corruptions that occur from cameras and\nLiDAR sensors. Extensive evaluations across 31 HD map constructors reveal\nsignificant performance degradation of existing methods under adverse weather\nconditions and sensor failures, underscoring critical safety concerns. We\nidentify effective strategies for enhancing robustness, including innovative\napproaches that leverage multi-modal fusion, advanced data augmentation, and\narchitectural techniques. These insights provide a pathway for developing more\nreliable HD map construction methods, which are essential for the advancement\nof autonomous driving technology. The benchmark toolkit and affiliated code and\nmodel checkpoints have been made publicly accessible.\n","authors":["Xiaoshuai Hao","Mengchuan Wei","Yifan Yang","Haimei Zhao","Hui Zhang","Yi Zhou","Qiang Wang","Weiming Li","Lingdong Kong","Jing Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.12214v3.pdf","comment":"NeurIPS 2024; 40 pages, 17 figures, 23 tables; Code at\n  https://mapbench.github.io/"},{"id":"http://arxiv.org/abs/2211.12702v2","updated":"2024-10-22T07:57:55Z","published":"2022-11-23T04:48:49Z","title":"Evaluating Feature Attribution Methods for Electrocardiogram","summary":"  The performance of cardiac arrhythmia detection with electrocardiograms(ECGs)\nhas been considerably improved since the introduction of deep learning models.\nIn practice, the high performance alone is not sufficient and a proper\nexplanation is also required. Recently, researchers have started adopting\nfeature attribution methods to address this requirement, but it has been\nunclear which of the methods are appropriate for ECG. In this work, we identify\nand customize three evaluation metrics for feature attribution methods based on\nthe characteristics of ECG: localization score, pointing game, and degradation\nscore. Using the three evaluation metrics, we evaluate and analyze eleven\nwidely-used feature attribution methods. We find that some of the feature\nattribution methods are much more adequate for explaining ECG, where Grad-CAM\noutperforms the second-best method by a large margin.\n","authors":["Jangwon Suh","Jimyeong Kim","Euna Jung","Wonjong Rhee"],"pdf_url":"https://arxiv.org/pdf/2211.12702v2.pdf","comment":"This is preliminary research related to\n  https://www.sciencedirect.com/science/article/pii/S0010482524011739 . Code is\n  available at https://github.com/SNU-DRL/Attribution-ECG"},{"id":"http://arxiv.org/abs/2408.10787v3","updated":"2024-10-22T07:51:43Z","published":"2024-08-20T12:27:53Z","title":"A Lightweight Modular Framework for Low-Cost Open-Vocabulary Object\n  Detection Training","summary":"  Object detection is a fundamental challenge in computer vision, centered on\nrecognizing objects within images, with diverse applications in areas like\nimage analysis, robotics, and autonomous vehicles. Although existing methods\nhave achieved great success, they are often constrained by a fixed vocabulary\nof objects. To overcome this limitation, approaches like MDETR have redefined\nobject detection by incorporating region-level vision-language pre-training,\nenabling open-vocabulary object detectors. However, these methods are\ncomputationally heavy due to the simultaneous training of large models for both\nvision and language representations. To address this, we introduce a\nlightweight framework that significantly reduces the number of parameters while\npreserving, or even improving, performance. Our solution is applied to MDETR,\nresulting in the development of Lightweight MDETR (LightMDETR), an optimized\nversion of MDETR designed to enhance computational efficiency without\nsacrificing accuracy. The core of our approach involves freezing the MDETR\nbackbone and training only the Universal Projection module (UP), which bridges\nvision and language representations. A learnable modality token parameter\nallows the UP to seamlessly switch between modalities. Evaluations on tasks\nlike phrase grounding, referring expression comprehension, and segmentation\nshow that LightMDETR not only reduces computational costs but also outperforms\nseveral state-of-the-art methods in terms of accuracy.\n","authors":["Bilal Faye","Binta Sow","Hanane Azzag","Mustapha Lebbah"],"pdf_url":"https://arxiv.org/pdf/2408.10787v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16770v1","updated":"2024-10-22T07:40:20Z","published":"2024-10-22T07:40:20Z","title":"The Scene Language: Representing Scenes with Programs, Words, and\n  Embeddings","summary":"  We introduce the Scene Language, a visual scene representation that concisely\nand precisely describes the structure, semantics, and identity of visual\nscenes. It represents a scene with three key components: a program that\nspecifies the hierarchical and relational structure of entities in the scene,\nwords in natural language that summarize the semantic class of each entity, and\nembeddings that capture the visual identity of each entity. This representation\ncan be inferred from pre-trained language models via a training-free inference\ntechnique, given text or image inputs. The resulting scene can be rendered into\nimages using traditional, neural, or hybrid graphics renderers. Together, this\nforms a robust, automated system for high-quality 3D and 4D scene generation.\nCompared with existing representations like scene graphs, our proposed Scene\nLanguage generates complex scenes with higher fidelity, while explicitly\nmodeling the scene structures to enable precise control and editing.\n","authors":["Yunzhi Zhang","Zizhang Li","Matt Zhou","Shangzhe Wu","Jiajun Wu"],"pdf_url":"https://arxiv.org/pdf/2410.16770v1.pdf","comment":"Project page:\n  https://ai.stanford.edu/~yzzhang/projects/scene-language/"},{"id":"http://arxiv.org/abs/2004.04454v2","updated":"2024-10-22T07:40:17Z","published":"2020-04-09T09:52:49Z","title":"TensorProjection Layer: A Tensor-Based Dimension Reduction Method in\n  Deep Neural Networks","summary":"  In this paper, we propose a dimension reduction method specifically designed\nfor tensor-structured feature data in deep neural networks. The method is\nimplemented as a hidden layer, called the TensorProjection layer, which\ntransforms input tensors into output tensors with reduced dimensions through\nmode-wise projections. The projection directions are treated as model\nparameters of the layer and are optimized during model training. Our method can\nserve as an alternative to pooling layers for summarizing image data, or to\nconvolutional layers as a technique for reducing the number of channels. We\nconduct experiments on tasks such as medical image classification and\nsegmentation, integrating the TensorProjection layer into commonly used\nbaseline architectures to evaluate its effectiveness. Numerical experiments\nindicate that the proposed method can outperform traditional downsampling\nmethods, such as pooling layers, in our tasks, suggesting it as a promising\nalternative for feature summarization.\n","authors":["Toshinari Morimoto","Su-Yun Huang"],"pdf_url":"https://arxiv.org/pdf/2004.04454v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16769v1","updated":"2024-10-22T07:37:47Z","published":"2024-10-22T07:37:47Z","title":"DSORT-MCU: Detecting Small Objects in Real-Time on Microcontroller Units","summary":"  Advances in lightweight neural networks have revolutionized computer vision\nin a broad range of IoT applications, encompassing remote monitoring and\nprocess automation. However, the detection of small objects, which is crucial\nfor many of these applications, remains an underexplored area in current\ncomputer vision research, particularly for low-power embedded devices that host\nresource-constrained processors. To address said gap, this paper proposes an\nadaptive tiling method for lightweight and energy-efficient object detection\nnetworks, including YOLO-based models and the popular FOMO network. The\nproposed tiling enables object detection on low-power MCUs with no compromise\non accuracy compared to large-scale detection models. The benefit of the\nproposed method is demonstrated by applying it to FOMO and TinyissimoYOLO\nnetworks on a novel RISC-V-based MCU with built-in ML accelerators. Extensive\nexperimental results show that the proposed tiling method boosts the F1-score\nby up to 225% for both FOMO and TinyissimoYOLO networks while reducing the\naverage object count error by up to 76% with FOMO and up to 89% for\nTinyissimoYOLO. Furthermore, the findings of this work indicate that using a\nsoft F1 loss over the popular binary cross-entropy loss can serve as an\nimplicit non-maximum suppression for the FOMO network. To evaluate the\nreal-world performance, the networks are deployed on the RISC-V based GAP9\nmicrocontroller from GreenWaves Technologies, showcasing the proposed method's\nability to strike a balance between detection performance ($58% - 95%$ F1\nscore), low latency (0.6 ms/Inference - 16.2 ms/Inference}), and energy\nefficiency (31 uJ/Inference} - 1.27 mJ/Inference) while performing multiple\npredictions using high-resolution images on a MCU.\n","authors":["Liam Boyle","Julian Moosmann","Nicolas Baumann","Seonyeong Heo","Michele Magno"],"pdf_url":"https://arxiv.org/pdf/2410.16769v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2311.07163"},{"id":"http://arxiv.org/abs/2306.16759v3","updated":"2024-10-22T07:29:07Z","published":"2023-06-29T07:55:43Z","title":"Boosting the Generalization Ability for Hyperspectral Image\n  Classification using Spectral-spatial Axial Aggregation Transformer","summary":"  In the hyperspectral image classification (HSIC) task, the most commonly used\nmodel validation paradigm is partitioning the training-test dataset through\npixel-wise random sampling. By training on a small amount of data, the deep\nlearning model can achieve almost perfect accuracy. However, in our\nexperiments, we found that the high accuracy was reached because the training\nand test datasets share a lot of information. On non-overlapping dataset\npartitions, well-performing models suffer significant performance degradation.\nTo this end, we propose a spectral-spatial axial aggregation transformer model,\nnamely SaaFormer, that preserves generalization across dataset partitions.\nSaaFormer applies a multi-level spectral extraction structure to segment the\nspectrum into multiple spectrum clips, such that the wavelength continuity of\nthe spectrum across the channel are preserved. For each spectrum clip, the\naxial aggregation attention mechanism, which integrates spatial features along\nmultiple spectral axes is applied to mine the spectral characteristic. The\nmulti-level spectral extraction and the axial aggregation attention emphasize\nspectral characteristic to improve the model generalization. The experimental\nresults on five publicly available datasets demonstrate that our model exhibits\ncomparable performance on the random partition, while significantly\noutperforming other methods on non-overlapping partitions. Moreover, SaaFormer\nshows excellent performance on background classification.\n","authors":["Enzhe Zhao","Zhichang Guo","Shengzhu Shi","Yao Li","Jia Li","Dazhi Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.16759v3.pdf","comment":"arXiv admin note: text overlap with arXiv:2107.02988 by other authors"},{"id":"http://arxiv.org/abs/2410.04183v2","updated":"2024-10-22T07:24:05Z","published":"2024-10-05T14:57:52Z","title":"Unsupervised Assessment of Landscape Shifts Based on Persistent Entropy\n  and Topological Preservation","summary":"  In Continual Learning (CL) contexts, concept drift typically refers to the\nanalysis of changes in data distribution. A drift in the input data can have\nnegative consequences on a learning predictor and the system's stability. The\nmajority of concept drift methods emphasize the analysis of statistical changes\nin non-stationary data over time. In this context, we consider another\nperspective, where the concept drift also integrates substantial changes in the\ntopological characteristics of the data stream. In this article, we introduce a\nnovel framework for monitoring changes in multi-dimensional data streams. We\nexplore variations in the topological structures of the data, presenting\nanother angle on the standard concept drift. Our developed approach is based on\npersistent entropy and topology-preserving projections in a continual learning\nscenario. The framework operates in both unsupervised and supervised\nenvironments. To show the utility of the proposed framework, we analyze the\nmodel across three scenarios using data streams generated with MNIST samples.\nThe obtained results reveal the potential of applying topological data analysis\nfor shift detection and encourage further research in this area.\n","authors":["Sebastian Basterrech"],"pdf_url":"https://arxiv.org/pdf/2410.04183v2.pdf","comment":"KDD'2024. Workshop on Drift Detection and Landscape Shifts"},{"id":"http://arxiv.org/abs/2401.06960v2","updated":"2024-10-22T07:17:47Z","published":"2024-01-13T03:17:57Z","title":"Transformer for Object Re-Identification: A Survey","summary":"  Object Re-identification (Re-ID) aims to identify specific objects across\ndifferent times and scenes, which is a widely researched task in computer\nvision. For a prolonged period, this field has been predominantly driven by\ndeep learning technology based on convolutional neural networks. In recent\nyears, the emergence of Vision Transformers has spurred a growing number of\nstudies delving deeper into Transformer-based Re-ID, continuously breaking\nperformance records and witnessing significant progress in the Re-ID field.\nOffering a powerful, flexible, and unified solution, Transformers cater to a\nwide array of Re-ID tasks with unparalleled efficacy. This paper provides a\ncomprehensive review and in-depth analysis of the Transformer-based Re-ID. In\ncategorizing existing works into Image/Video-Based Re-ID, Re-ID with limited\ndata/annotations, Cross-Modal Re-ID, and Special Re-ID Scenarios, we thoroughly\nelucidate the advantages demonstrated by the Transformer in addressing a\nmultitude of challenges across these domains. Considering the trending\nunsupervised Re-ID, we propose a new Transformer baseline, UntransReID,\nachieving state-of-the-art performance on both single/cross modal tasks. For\nthe under-explored animal Re-ID, we devise a standardized experimental\nbenchmark and conduct extensive experiments to explore the applicability of\nTransformer for this task and facilitate future research. Finally, we discuss\nsome important yet under-investigated open issues in the large foundation model\nera, we believe it will serve as a new handbook for researchers in this field.\nA periodically updated website will be available at\nhttps://github.com/mangye16/ReID-Survey.\n","authors":["Mang Ye","Shuoyi Chen","Chenyue Li","Wei-Shi Zheng","David Crandall","Bo Du"],"pdf_url":"https://arxiv.org/pdf/2401.06960v2.pdf","comment":"Accepted by International Journal of Computer Vision (IJCV) in\n  October 2024"},{"id":"http://arxiv.org/abs/2410.15636v2","updated":"2024-10-22T07:10:45Z","published":"2024-10-21T04:47:01Z","title":"LucidFusion: Generating 3D Gaussians with Arbitrary Unposed Images","summary":"  Recent large reconstruction models have made notable progress in generating\nhigh-quality 3D objects from single images. However, these methods often\nstruggle with controllability, as they lack information from multiple views,\nleading to incomplete or inconsistent 3D reconstructions. To address this\nlimitation, we introduce LucidFusion, a flexible end-to-end feed-forward\nframework that leverages the Relative Coordinate Map (RCM). Unlike traditional\nmethods linking images to 3D world thorough pose, LucidFusion utilizes RCM to\nalign geometric features coherently across different views, making it highly\nadaptable for 3D generation from arbitrary, unposed images. Furthermore,\nLucidFusion seamlessly integrates with the original single-image-to-3D\npipeline, producing detailed 3D Gaussians at a resolution of $512 \\times 512$,\nmaking it well-suited for a wide range of applications.\n","authors":["Hao He","Yixun Liang","Luozhou Wang","Yuanhao Cai","Xinli Xu","Hao-Xiang Guo","Xiang Wen","Yingcong Chen"],"pdf_url":"https://arxiv.org/pdf/2410.15636v2.pdf","comment":"17 pages, 12 figures, [project\n  page](https://heye0507.github.io/LucidFusion_page/)"},{"id":"http://arxiv.org/abs/2410.16746v1","updated":"2024-10-22T07:00:43Z","published":"2024-10-22T07:00:43Z","title":"SpikMamba: When SNN meets Mamba in Event-based Human Action Recognition","summary":"  Human action recognition (HAR) plays a key role in various applications such\nas video analysis, surveillance, autonomous driving, robotics, and healthcare.\nMost HAR algorithms are developed from RGB images, which capture detailed\nvisual information. However, these algorithms raise concerns in\nprivacy-sensitive environments due to the recording of identifiable features.\nEvent cameras offer a promising solution by capturing scene brightness changes\nsparsely at the pixel level, without capturing full images. Moreover, event\ncameras have high dynamic ranges that can effectively handle scenarios with\ncomplex lighting conditions, such as low light or high contrast environments.\nHowever, using event cameras introduces challenges in modeling the spatially\nsparse and high temporal resolution event data for HAR. To address these\nissues, we propose the SpikMamba framework, which combines the energy\nefficiency of spiking neural networks and the long sequence modeling capability\nof Mamba to efficiently capture global features from spatially sparse and high\na temporal resolution event data. Additionally, to improve the locality of\nmodeling, a spiking window-based linear attention mechanism is used. Extensive\nexperiments show that SpikMamba achieves remarkable recognition performance,\nsurpassing the previous state-of-the-art by 1.45%, 7.22%, 0.15%, and 3.92% on\nthe PAF, HARDVS, DVS128, and E-FAction datasets, respectively. The code is\navailable at https://github.com/Typistchen/SpikMamba.\n","authors":["Jiaqi Chen","Yan Yang","Shizhuo Deng","Da Teng","Liyuan Pan"],"pdf_url":"https://arxiv.org/pdf/2410.16746v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.16744v1","updated":"2024-10-22T06:58:37Z","published":"2024-10-22T06:58:37Z","title":"Time-Resolved MNIST Dataset for Single-Photon Recognition","summary":"  Time-resolved single photon imaging is a promising imaging modality\ncharacterized by the unique capability of timestamping the arrivals of single\nphotons. Single-Photon Avalanche Diodes (SPADs) are the leading technology for\nimplementing modern time-resolved pixels, suitable for passive imaging with\nasynchronous readout. However, they are currently limited to small sized\narrays, thus there is a lack of datasets for passive time-resolved SPAD\nimaging, which in turn hinders research on this peculiar imaging data. In this\npaper we describe a realistic simulation process for SPAD imaging, which takes\ninto account both the stochastic nature of photon arrivals and all the noise\nsources involved in the acquisition process of time-resolved SPAD arrays. We\nhave implemented this simulator in a software prototype able to generate\narbitrary-sized time-resolved SPAD arrays operating in passive mode. Starting\nfrom a reference image, our simulator generates a realistic stream of\ntimestamped photon detections. We use our simulator to generate a time-resolved\nversion of MNIST, which we make publicly available. Our dataset has the purpose\nof encouraging novel research directions in time-resolved SPAD imaging, as well\nas investigating the performance of CNN classifiers in extremely low-light\nconditions.\n","authors":["Aleksi Suonsivu","Lauri Salmela","Edoardo Peretti","Leevi Uosukainen","Radu Ciprian Bilcu","Giacomo Boracchi"],"pdf_url":"https://arxiv.org/pdf/2410.16744v1.pdf","comment":"12 pages, 4 figures. Accepted for Workshop on Synthetic Data for\n  Computer Vision at ECCV 2024"},{"id":"http://arxiv.org/abs/2212.04681v3","updated":"2024-10-22T06:56:00Z","published":"2022-12-09T06:06:47Z","title":"Dynamic Test-Time Augmentation via Differentiable Functions","summary":"  Distribution shifts, which often occur in the real world, degrade the\naccuracy of deep learning systems, and thus improving robustness to\ndistribution shifts is essential for practical applications. To improve\nrobustness, we study an image enhancement method that generates\nrecognition-friendly images without retraining the recognition model. We\npropose a novel image enhancement method, DynTTA, which is based on\ndifferentiable data augmentation techniques and generates a blended image from\nmany augmented images to improve the recognition accuracy under distribution\nshifts. In addition to standard data augmentations, DynTTA also incorporates\ndeep neural network-based image transformation, further improving the\nrobustness. Because DynTTA is composed of differentiable functions, it can be\ndirectly trained with the classification loss of the recognition model. In\nexperiments with widely used image recognition datasets using various\nclassification models, DynTTA improves the robustness with almost no reduction\nin classification accuracy for clean images, thus outperforming the existing\nmethods. Furthermore, the results show that robustness is significantly\nimproved by estimating the training-time augmentations for distribution-shifted\ndatasets using DynTTA and retraining the recognition model with the estimated\naugmentations. DynTTA is a promising approach for applications that require\nboth clean accuracy and robustness. Our code is available at\n\\url{https://github.com/s-enmt/DynTTA}.\n","authors":["Shohei Enomoto","Monikka Roslianna Busto","Takeharu Eda"],"pdf_url":"https://arxiv.org/pdf/2212.04681v3.pdf","comment":"IEEE Access"},{"id":"http://arxiv.org/abs/2407.11664v2","updated":"2024-10-22T06:41:38Z","published":"2024-07-16T12:36:26Z","title":"Mask-guided cross-image attention for zero-shot in-silico\n  histopathologic image generation with a diffusion model","summary":"  Creating in-silico data with generative AI promises a cost-effective\nalternative to staining, imaging, and annotating whole slide images in\ncomputational pathology. Diffusion models are the state-of-the-art solution for\ngenerating in-silico images, offering unparalleled fidelity and realism. Using\nappearance transfer diffusion models allows for zero-shot image generation,\nfacilitating fast application and making model training unnecessary. However\ncurrent appearance transfer diffusion models are designed for natural images,\nwhere the main task is to transfer the foreground object from an origin to a\ntarget domain, while the background is of insignificant importance. In\ncomputational pathology, specifically in oncology, it is however not\nstraightforward to define which objects in an image should be classified as\nforeground and background, as all objects in an image may be of critical\nimportance for the detailed understanding the tumor micro-environment. We\ncontribute to the applicability of appearance transfer diffusion models to\nimmunohistochemistry-stained images by modifying the appearance transfer\nguidance to alternate between class-specific AdaIN feature statistics matchings\nusing existing segmentation masks. The performance of the proposed method is\ndemonstrated on the downstream task of supervised epithelium segmentation,\nshowing that the number of manual annotations required for model training can\nbe reduced by 75%, outperforming the baseline approach. Additionally, we\nconsulted with a certified pathologist to investigate future improvements. We\nanticipate this work to inspire the application of zero-shot diffusion models\nin computational pathology, providing an efficient method to generate in-silico\nimages with unmatched fidelity and realism, which prove meaningful for\ndownstream tasks, such as training existing deep learning models or finetuning\nfoundation models.\n","authors":["Dominik Winter","Nicolas Triltsch","Marco Rosati","Anatoliy Shumilov","Ziya Kokaragac","Yuri Popov","Thomas Padel","Laura Sebastian Monasor","Ross Hill","Markus Schick","Nicolas Brieu"],"pdf_url":"https://arxiv.org/pdf/2407.11664v2.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2410.15980v2","updated":"2024-10-22T06:35:13Z","published":"2024-10-21T13:06:21Z","title":"Granularity Matters in Long-Tail Learning","summary":"  Balancing training on long-tail data distributions remains a long-standing\nchallenge in deep learning. While methods such as re-weighting and re-sampling\nhelp alleviate the imbalance issue, limited sample diversity continues to\nhinder models from learning robust and generalizable feature representations,\nparticularly for tail classes. In contrast to existing methods, we offer a\nnovel perspective on long-tail learning, inspired by an observation: datasets\nwith finer granularity tend to be less affected by data imbalance. In this\npaper, we investigate this phenomenon through both quantitative and qualitative\nstudies, showing that increased granularity enhances the generalization of\nlearned features in tail categories. Motivated by these findings, we propose a\nmethod to increase dataset granularity through category extrapolation.\nSpecifically, we introduce open-set auxiliary classes that are visually similar\nto existing ones, aiming to enhance representation learning for both head and\ntail classes. This forms the core contribution and insight of our approach. To\nautomate the curation of auxiliary data, we leverage large language models\n(LLMs) as knowledge bases to search for auxiliary categories and retrieve\nrelevant images through web crawling. To prevent the overwhelming presence of\nauxiliary classes from disrupting training, we introduce a neighbor-silencing\nloss that encourages the model to focus on class discrimination within the\ntarget dataset. During inference, the classifier weights for auxiliary\ncategories are masked out, leaving only the target class weights for use.\nExtensive experiments and ablation studies on three standard long-tail\nbenchmarks demonstrate the effectiveness of our approach, notably outperforming\nstrong baseline methods that use the same amount of data. The code will be made\npublicly available.\n","authors":["Shizhen Zhao","Xin Wen","Jiahui Liu","Chuofan Ma","Chunfeng Yuan","Xiaojuan Qi"],"pdf_url":"https://arxiv.org/pdf/2410.15980v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16732v1","updated":"2024-10-22T06:30:37Z","published":"2024-10-22T06:30:37Z","title":"Polyp-E: Benchmarking the Robustness of Deep Segmentation Models via\n  Polyp Editing","summary":"  Automatic polyp segmentation is helpful to assist clinical diagnosis and\ntreatment. In daily clinical practice, clinicians exhibit robustness in\nidentifying polyps with both location and size variations. It is uncertain if\ndeep segmentation models can achieve comparable robustness in automated\ncolonoscopic analysis. To benchmark the model robustness, we focus on\nevaluating the robustness of segmentation models on the polyps with various\nattributes (e.g. location and size) and healthy samples. Based on the Latent\nDiffusion Model, we perform attribute editing on real polyps and build a new\ndataset named Polyp-E. Our synthetic dataset boasts exceptional realism, to the\nextent that clinical experts find it challenging to discern them from real\ndata. We evaluate several existing polyp segmentation models on the proposed\nbenchmark. The results reveal most of the models are highly sensitive to\nattribute variations. As a novel data augmentation technique, the proposed\nediting pipeline can improve both in-distribution and out-of-distribution\ngeneralization ability. The code and datasets will be released.\n","authors":["Runpu Wei","Zijin Yin","Kongming Liang","Min Min","Chengwei Pan","Gang Yu","Haonan Huang","Yan Liu","Zhanyu Ma"],"pdf_url":"https://arxiv.org/pdf/2410.16732v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15957v2","updated":"2024-10-22T06:26:45Z","published":"2024-10-21T12:36:27Z","title":"CamI2V: Camera-Controlled Image-to-Video Diffusion Model","summary":"  Recently, camera pose, as a user-friendly and physics-related condition, has\nbeen introduced into text-to-video diffusion model for camera control. However,\nexisting methods simply inject camera conditions through a side input. These\napproaches neglect the inherent physical knowledge of camera pose, resulting in\nimprecise camera control, inconsistencies, and also poor interpretability. In\nthis paper, we emphasize the necessity of integrating explicit physical\nconstraints into model design. Epipolar attention is proposed for modeling all\ncross-frame relationships from a novel perspective of noised condition. This\nensures that features are aggregated from corresponding epipolar lines in all\nnoised frames, overcoming the limitations of current attention mechanisms in\ntracking displaced features across frames, especially when features move\nsignificantly with the camera and become obscured by noise. Additionally, we\nintroduce register tokens to handle cases without intersections between frames,\ncommonly caused by rapid camera movements, dynamic objects, or occlusions. To\nsupport image-to-video, we propose the multiple guidance scale to allow for\nprecise control for image, text, and camera, respectively. Furthermore, we\nestablish a more robust and reproducible evaluation pipeline to solve the\ninaccuracy and instability of existing camera control measurement. We achieve a\n25.5% improvement in camera controllability on RealEstate10K while maintaining\nstrong generalization to out-of-domain images. Only 24GB and 12GB are required\nfor training and inference, respectively. We plan to release checkpoints, along\nwith training and evaluation codes. Dynamic videos are best viewed at\nhttps://zgctroy.github.io/CamI2V.\n","authors":["Guangcong Zheng","Teng Li","Rui Jiang","Yehao Lu","Tao Wu","Xi Li"],"pdf_url":"https://arxiv.org/pdf/2410.15957v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16719v1","updated":"2024-10-22T05:59:29Z","published":"2024-10-22T05:59:29Z","title":"Progressive Compositionality In Text-to-Image Generative Models","summary":"  Despite the impressive text-to-image (T2I) synthesis capabilities of\ndiffusion models, they often struggle to understand compositional relationships\nbetween objects and attributes, especially in complex settings. Existing\nsolutions have tackled these challenges by optimizing the cross-attention\nmechanism or learning from the caption pairs with minimal semantic changes.\nHowever, can we generate high-quality complex contrastive images that diffusion\nmodels can directly discriminate based on visual representations? In this work,\nwe leverage large-language models (LLMs) to compose realistic, complex\nscenarios and harness Visual-Question Answering (VQA) systems alongside\ndiffusion models to automatically curate a contrastive dataset, ConPair,\nconsisting of 15k pairs of high-quality contrastive images. These pairs feature\nminimal visual discrepancies and cover a wide range of attribute categories,\nespecially complex and natural scenarios. To learn effectively from these error\ncases, i.e., hard negative images, we propose EvoGen, a new multi-stage\ncurriculum for contrastive learning of diffusion models. Through extensive\nexperiments across a wide range of compositional scenarios, we showcase the\neffectiveness of our proposed framework on compositional T2I benchmarks.\n","authors":["Xu Han","Linghao Jin","Xiaofeng Liu","Paul Pu Liang"],"pdf_url":"https://arxiv.org/pdf/2410.16719v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16711v1","updated":"2024-10-22T05:37:51Z","published":"2024-10-22T05:37:51Z","title":"Development of CNN Architectures using Transfer Learning Methods for\n  Medical Image Classification","summary":"  The application of deep learning-based architecture has seen a tremendous\nrise in recent years. For example, medical image classification using deep\nlearning achieved breakthrough results. Convolutional Neural Networks (CNNs)\nare implemented predominantly in medical image classification and segmentation.\nOn the other hand, transfer learning has emerged as a prominent supporting tool\nfor enhancing the efficiency and accuracy of deep learning models. This paper\ninvestigates the development of CNN architectures using transfer learning\ntechniques in the field of medical image classification using a timeline\nmapping model for key image classification challenges. Our findings help make\nan informed decision while selecting the optimum and state-of-the-art CNN\narchitectures.\n","authors":["Ganga Prasad Basyal","David Zeng","Bhaskar Pm Rimal"],"pdf_url":"https://arxiv.org/pdf/2410.16711v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16707v1","updated":"2024-10-22T05:22:49Z","published":"2024-10-22T05:22:49Z","title":"DI-MaskDINO: A Joint Object Detection and Instance Segmentation Model","summary":"  This paper is motivated by an interesting phenomenon: the performance of\nobject detection lags behind that of instance segmentation (i.e., performance\nimbalance) when investigating the intermediate results from the beginning\ntransformer decoder layer of MaskDINO (i.e., the SOTA model for joint detection\nand segmentation). This phenomenon inspires us to think about a question: will\nthe performance imbalance at the beginning layer of transformer decoder\nconstrain the upper bound of the final performance? With this question in mind,\nwe further conduct qualitative and quantitative pre-experiments, which validate\nthe negative impact of detection-segmentation imbalance issue on the model\nperformance. To address this issue, this paper proposes DI-MaskDINO model, the\ncore idea of which is to improve the final performance by alleviating the\ndetection-segmentation imbalance. DI-MaskDINO is implemented by configuring our\nproposed De-Imbalance (DI) module and Balance-Aware Tokens Optimization (BATO)\nmodule to MaskDINO. DI is responsible for generating balance-aware query, and\nBATO uses the balance-aware query to guide the optimization of the initial\nfeature tokens. The balance-aware query and optimized feature tokens are\nrespectively taken as the Query and Key&Value of transformer decoder to perform\njoint object detection and instance segmentation. DI-MaskDINO outperforms\nexisting joint object detection and instance segmentation models on COCO and\nBDD100K benchmarks, achieving +1.2 $AP^{box}$ and +0.9 $AP^{mask}$ improvements\ncompared to SOTA joint detection and segmentation model MaskDINO. In addition,\nDI-MaskDINO also obtains +1.0 $AP^{box}$ improvement compared to SOTA object\ndetection model DINO and +3.0 $AP^{mask}$ improvement compared to SOTA\nsegmentation model Mask2Former.\n","authors":["Zhixiong Nan","Xianghong Li","Tao Xiang","Jifeng Dai"],"pdf_url":"https://arxiv.org/pdf/2410.16707v1.pdf","comment":"16 pages, 3 figures, Conference on Neural Information Processing\n  Systems"},{"id":"http://arxiv.org/abs/2410.15778v2","updated":"2024-10-22T05:01:28Z","published":"2024-10-21T08:42:30Z","title":"Reducing Hallucinations in Vision-Language Models via Latent Space\n  Steering","summary":"  Hallucination poses a challenge to the deployment of large vision-language\nmodels (LVLMs) in applications. Unlike in large language models (LLMs),\nhallucination in LVLMs often arises from misalignments between visual inputs\nand textual outputs. This paper investigates the underlying mechanisms of\nhallucination, focusing on the unique structure of LVLMs that distinguishes\nthem from large language models (LLMs). We identify that hallucinations often\narise from the sensitivity of text decoders to vision inputs, a natural\nphenomenon when image encoders and text decoders are pre-trained separately.\nInspired by this, we introduce Visual and Textual Intervention (VTI), a novel\ntechnique designed to reduce hallucinations by steering latent space\nrepresentations during inference to enhance the stability of vision features.\nAs a task-agnostic test-time intervention, VTI can be easily applied to any\nproblem without additional cost. Extensive experiments demonstrate that it can\neffectively reduce hallucinations and outperform baseline methods across\nmultiple metrics, highlighting the critical role of vision feature stability in\nLVLMs.\n","authors":["Sheng Liu","Haotian Ye","Lei Xing","James Zou"],"pdf_url":"https://arxiv.org/pdf/2410.15778v2.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2410.16695v1","updated":"2024-10-22T04:57:28Z","published":"2024-10-22T04:57:28Z","title":"MPT: A Large-scale Multi-Phytoplankton Tracking Benchmark","summary":"  Phytoplankton are a crucial component of aquatic ecosystems, and effective\nmonitoring of them can provide valuable insights into ocean environments and\necosystem changes. Traditional phytoplankton monitoring methods are often\ncomplex and lack timely analysis. Therefore, deep learning algorithms offer a\npromising approach for automated phytoplankton monitoring. However, the lack of\nlarge-scale, high-quality training samples has become a major bottleneck in\nadvancing phytoplankton tracking. In this paper, we propose a challenging\nbenchmark dataset, Multiple Phytoplankton Tracking (MPT), which covers diverse\nbackground information and variations in motion during observation. The dataset\nincludes 27 species of phytoplankton and zooplankton, 14 different backgrounds\nto simulate diverse and complex underwater environments, and a total of 140\nvideos. To enable accurate real-time observation of phytoplankton, we introduce\na multi-object tracking method, Deviation-Corrected Multi-Scale Feature Fusion\nTracker(DSFT), which addresses issues such as focus shifts during tracking and\nthe loss of small target information when computing frame-to-frame similarity.\nSpecifically, we introduce an additional feature extractor to predict the\nresiduals of the standard feature extractor's output, and compute multi-scale\nframe-to-frame similarity based on features from different layers of the\nextractor. Extensive experiments on the MPT have demonstrated the validity of\nthe dataset and the superiority of DSFT in tracking phytoplankton, providing an\neffective solution for phytoplankton monitoring.\n","authors":["Yang Yu","Yuezun Li","Xin Sun","Junyu Dong"],"pdf_url":"https://arxiv.org/pdf/2410.16695v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.05338v6","updated":"2024-10-22T04:22:16Z","published":"2024-06-08T03:44:25Z","title":"MotionClone: Training-Free Motion Cloning for Controllable Video\n  Generation","summary":"  Motion-based controllable video generation offers the potential for creating\ncaptivating visual content. Existing methods typically necessitate model\ntraining to encode particular motion cues or incorporate fine-tuning to inject\ncertain motion patterns, resulting in limited flexibility and generalization.\nIn this work, we propose MotionClone, a training-free framework that enables\nmotion cloning from reference videos to versatile motion-controlled video\ngeneration, including text-to-video and image-to-video. Based on the\nobservation that the dominant components in temporal-attention maps drive\nmotion synthesis, while the rest mainly capture noisy or very subtle motions,\nMotionClone utilizes sparse temporal attention weights as motion\nrepresentations for motion guidance, facilitating diverse motion transfer\nacross varying scenarios. Meanwhile, MotionClone allows for the direct\nextraction of motion representation through a single denoising step, bypassing\nthe cumbersome inversion processes and thus promoting both efficiency and\nflexibility. Extensive experiments demonstrate that MotionClone exhibits\nproficiency in both global camera motion and local object motion, with notable\nsuperiority in terms of motion fidelity, textual alignment, and temporal\nconsistency.\n","authors":["Pengyang Ling","Jiazi Bu","Pan Zhang","Xiaoyi Dong","Yuhang Zang","Tong Wu","Huaian Chen","Jiaqi Wang","Yi Jin"],"pdf_url":"https://arxiv.org/pdf/2406.05338v6.pdf","comment":"18 pages, 14 figures,\n  https://bujiazi.github.io/motionclone.github.io/"},{"id":"http://arxiv.org/abs/2410.16671v1","updated":"2024-10-22T04:03:36Z","published":"2024-10-22T04:03:36Z","title":"NucleiMix: Realistic Data Augmentation for Nuclei Instance Segmentation","summary":"  Nuclei instance segmentation is an essential task in pathology image\nanalysis, serving as the foundation for many downstream applications. The\nrelease of several public datasets has significantly advanced research in this\narea, yet many existing methods struggle with data imbalance issues. To address\nthis challenge, this study introduces a data augmentation method, called\nNucleiMix, which is designed to balance the distribution of nuclei types by\nincreasing the number of rare-type nuclei within datasets. NucleiMix operates\nin two phases. In the first phase, it identifies candidate locations similar to\nthe surroundings of rare-type nuclei and inserts rare-type nuclei into the\ncandidate locations. In the second phase, it employs a progressive inpainting\nstrategy using a pre-trained diffusion model to seamlessly integrate rare-type\nnuclei into their new environments in replacement of major-type nuclei or\nbackground locations. We systematically evaluate the effectiveness of NucleiMix\non three public datasets using two popular nuclei instance segmentation models.\nThe results demonstrate the superior ability of NucleiMix to synthesize\nrealistic rare-type nuclei and to enhance the quality of nuclei segmentation\nand classification in an accurate and robust manner.\n","authors":["Jiamu Wang","Jin Tae Kwak"],"pdf_url":"https://arxiv.org/pdf/2410.16671v1.pdf","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2410.17250v1","updated":"2024-10-22T17:59:56Z","published":"2024-10-22T17:59:56Z","title":"JMMMU: A Japanese Massive Multi-discipline Multimodal Understanding\n  Benchmark for Culture-aware Evaluation","summary":"  Accelerating research on Large Multimodal Models (LMMs) in non-English\nlanguages is crucial for enhancing user experiences across broader populations.\nIn this paper, we introduce JMMMU (Japanese MMMU), the first large-scale\nJapanese benchmark designed to evaluate LMMs on expert-level tasks based on the\nJapanese cultural context. To facilitate comprehensive culture-aware\nevaluation, JMMMU features two complementary subsets: (i) culture-agnostic (CA)\nsubset, where the culture-independent subjects (e.g., Math) are selected and\ntranslated into Japanese, enabling one-to-one comparison with its English\ncounterpart MMMU; and (ii) culture-specific (CS) subset, comprising newly\ncrafted subjects that reflect Japanese cultural context. Using the CA subset,\nwe observe performance drop in many LMMs when evaluated in Japanese, which is\npurely attributable to language variation. Using the CS subset, we reveal their\ninadequate Japanese cultural understanding. Further, by combining both subsets,\nwe identify that some LMMs perform well on the CA subset but not on the CS\nsubset, exposing a shallow understanding of the Japanese language that lacks\ndepth in cultural understanding. We hope this work will not only help advance\nLMM performance in Japanese but also serve as a guideline to create\nhigh-standard, culturally diverse benchmarks for multilingual LMM development.\nThe project page is https://mmmu-japanese-benchmark.github.io/JMMMU/.\n","authors":["Shota Onohara","Atsuyuki Miyai","Yuki Imajuku","Kazuki Egashira","Jeonghun Baek","Xiang Yue","Graham Neubig","Kiyoharu Aizawa"],"pdf_url":"https://arxiv.org/pdf/2410.17250v1.pdf","comment":"Project page: https://mmmu-japanese-benchmark.github.io/JMMMU/"},{"id":"http://arxiv.org/abs/2410.17248v1","updated":"2024-10-22T17:59:55Z","published":"2024-10-22T17:59:55Z","title":"HyperspectralViTs: Fast and Accurate methane detection on-board\n  satellites","summary":"  On-board processing of hyperspectral data with machine learning models would\nenable unprecedented amount of autonomy for a wide range of tasks, for example\nmethane detection or mineral identification. Methane is the second most\nimportant greenhouse gas contributor to climate change, and it's automated\ndetection on-board of satellites using machine learning models would allow for\nearly warning system and could enable new capabilities such as automated\nscheduling inside constellations of satellites. Classical methods for methane\ndetection suffer from high false positive rates and previous deep learning\nmodels exhibit prohibitive computational requirements. We propose fast and\naccurate machine learning architectures which support end-to-end training with\ndata of high spectral dimension. We evaluate our models on two tasks related to\nhyperspectral data processing - methane leak detection and mineral\nidentification. With our proposed general architectures, we improve the F1\nscore of the previous methane detection state-of-the-art models by more than\n27% on a newly created synthetic dataset and by almost 13% on the previously\nreleased large benchmark dataset. We also demonstrate that training models on\nthe synthetic dataset improves performance of models finetuned on the dataset\nof real events by 6.9% in F1 score in contrast with training from scratch. On a\nnewly created dataset for mineral identification, our models provide 3.5%\nimprovement in the F1 score in contrast to the default versions of the models.\nWith our proposed models we improve the inference speed by 85.19% in contrast\nto previous classical and deep learning approaches by removing the dependency\non classically computed features. Namely, one capture from the EMIT sensor can\nbe processed in only 30 seconds on a realistic proxy hardware used on the\nION-SCV 004 satellite.\n","authors":["Vít Růžička","Andrew Markham"],"pdf_url":"https://arxiv.org/pdf/2410.17248v1.pdf","comment":"13 pages, This work has been submitted for possible publication"},{"id":"http://arxiv.org/abs/2410.17246v1","updated":"2024-10-22T17:59:49Z","published":"2024-10-22T17:59:49Z","title":"Learning Precise, Contact-Rich Manipulation through Uncalibrated Tactile\n  Skins","summary":"  While visuomotor policy learning has advanced robotic manipulation, precisely\nexecuting contact-rich tasks remains challenging due to the limitations of\nvision in reasoning about physical interactions. To address this, recent work\nhas sought to integrate tactile sensing into policy learning. However, many\nexisting approaches rely on optical tactile sensors that are either restricted\nto recognition tasks or require complex dimensionality reduction steps for\npolicy learning. In this work, we explore learning policies with magnetic skin\nsensors, which are inherently low-dimensional, highly sensitive, and\ninexpensive to integrate with robotic platforms. To leverage these sensors\neffectively, we present the Visuo-Skin (ViSk) framework, a simple approach that\nuses a transformer-based policy and treats skin sensor data as additional\ntokens alongside visual information. Evaluated on four complex real-world tasks\ninvolving credit card swiping, plug insertion, USB insertion, and bookshelf\nretrieval, ViSk significantly outperforms both vision-only and optical tactile\nsensing based policies. Further analysis reveals that combining tactile and\nvisual modalities enhances policy performance and spatial generalization,\nachieving an average improvement of 27.5% across tasks.\nhttps://visuoskin.github.io/\n","authors":["Venkatesh Pattabiraman","Yifeng Cao","Siddhant Haldar","Lerrel Pinto","Raunaq Bhirangi"],"pdf_url":"https://arxiv.org/pdf/2410.17246v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17245v1","updated":"2024-10-22T17:59:39Z","published":"2024-10-22T17:59:39Z","title":"Towards Reliable Evaluation of Behavior Steering Interventions in LLMs","summary":"  Representation engineering methods have recently shown promise for enabling\nefficient steering of model behavior. However, evaluation pipelines for these\nmethods have primarily relied on subjective demonstrations, instead of\nquantitative, objective metrics. We aim to take a step towards addressing this\nissue by advocating for four properties missing from current evaluations: (i)\ncontexts sufficiently similar to downstream tasks should be used for assessing\nintervention quality; (ii) model likelihoods should be accounted for; (iii)\nevaluations should allow for standardized comparisons across different target\nbehaviors; and (iv) baseline comparisons should be offered. We introduce an\nevaluation pipeline grounded in these criteria, offering both a quantitative\nand visual analysis of how effectively a given method works. We use this\npipeline to evaluate two representation engineering methods on how effectively\nthey can steer behaviors such as truthfulness and corrigibility, finding that\nsome interventions are less effective than previously reported.\n","authors":["Itamar Pres","Laura Ruis","Ekdeep Singh Lubana","David Krueger"],"pdf_url":"https://arxiv.org/pdf/2410.17245v1.pdf","comment":"Accepted to the NeurIPS 2024 - Workshop on Foundation Model\n  Interventions"},{"id":"http://arxiv.org/abs/2410.17238v1","updated":"2024-10-22T17:56:08Z","published":"2024-10-22T17:56:08Z","title":"SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning","summary":"  Automated Machine Learning (AutoML) approaches encompass traditional methods\nthat optimize fixed pipelines for model selection and ensembling, as well as\nnewer LLM-based frameworks that autonomously build pipelines. While LLM-based\nagents have shown promise in automating machine learning tasks, they often\ngenerate low-diversity and suboptimal code, even after multiple iterations. To\novercome these limitations, we introduce Tree-Search Enhanced LLM Agents\n(SELA), an innovative agent-based system that leverages Monte Carlo Tree Search\n(MCTS) to optimize the AutoML process. By representing pipeline configurations\nas trees, our framework enables agents to conduct experiments intelligently and\niteratively refine their strategies, facilitating a more effective exploration\nof the machine learning solution space. This novel approach allows SELA to\ndiscover optimal pathways based on experimental feedback, improving the overall\nquality of the solutions. In an extensive evaluation across 20 machine learning\ndatasets, we compare the performance of traditional and agent-based AutoML\nmethods, demonstrating that SELA achieves a win rate of 65% to 80% against each\nbaseline across all datasets. These results underscore the significant\npotential of agent-based strategies in AutoML, offering a fresh perspective on\ntackling complex machine learning challenges.\n","authors":["Yizhou Chi","Yizhang Lin","Sirui Hong","Duyi Pan","Yaying Fei","Guanghao Mei","Bangbang Liu","Tianqi Pang","Jacky Kwok","Ceyao Zhang","Bang Liu","Chenglin Wu"],"pdf_url":"https://arxiv.org/pdf/2410.17238v1.pdf","comment":"The code is available at https://github.com/geekan/MetaGPT"},{"id":"http://arxiv.org/abs/2410.17236v1","updated":"2024-10-22T17:54:45Z","published":"2024-10-22T17:54:45Z","title":"Large Language Models Empowered Personalized Web Agents","summary":"  Web agents have emerged as a promising direction to automate Web task\ncompletion based on user instructions, significantly enhancing user experience.\nRecently, Web agents have evolved from traditional agents to Large Language\nModels (LLMs)-based Web agents. Despite their success, existing LLM-based Web\nagents overlook the importance of personalized data (e.g., user profiles and\nhistorical Web behaviors) in assisting the understanding of users' personalized\ninstructions and executing customized actions. To overcome the limitation, we\nfirst formulate the task of LLM-empowered personalized Web agents, which\nintegrate personalized data and user instructions to personalize instruction\ncomprehension and action execution. To address the absence of a comprehensive\nevaluation benchmark, we construct a Personalized Web Agent Benchmark\n(PersonalWAB), featuring user instructions, personalized user data, Web\nfunctions, and two evaluation paradigms across three personalized Web tasks.\nMoreover, we propose a Personalized User Memory-enhanced Alignment (PUMA)\nframework to adapt LLMs to the personalized Web agent task. PUMA utilizes a\nmemory bank with a task-specific retrieval strategy to filter relevant\nhistorical Web behaviors. Based on the behaviors, PUMA then aligns LLMs for\npersonalized action execution through fine-tuning and direct preference\noptimization. Extensive experiments validate the superiority of PUMA over\nexisting Web agents on PersonalWAB.\n","authors":["Hongru Cai","Yongqi Li","Wenjie Wang","Fengbin Zhu","Xiaoyu Shen","Wenjie Li","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2410.17236v1.pdf","comment":"The code and data are available on the project website\n  https://hongrucai.github.io/PersonalWAB/"},{"id":"http://arxiv.org/abs/2410.17233v1","updated":"2024-10-22T17:53:34Z","published":"2024-10-22T17:53:34Z","title":"Few-shot In-Context Preference Learning Using Large Language Models","summary":"  Designing reward functions is a core component of reinforcement learning but\ncan be challenging for truly complex behavior. Reinforcement Learning from\nHuman Feedback (RLHF) has been used to alleviate this challenge by replacing a\nhand-coded reward function with a reward function learned from preferences.\nHowever, it can be exceedingly inefficient to learn these rewards as they are\noften learned tabula rasa. We investigate whether Large Language Models (LLMs)\ncan reduce this query inefficiency by converting an iterative series of human\npreferences into code representing the rewards. We propose In-Context\nPreference Learning (ICPL), a method that uses the grounding of an LLM to\naccelerate learning reward functions from preferences. ICPL takes the\nenvironment context and task description, synthesizes a set of reward\nfunctions, and then repeatedly updates the reward functions using human\nrankings of videos of the resultant policies. Using synthetic preferences, we\ndemonstrate that ICPL is orders of magnitude more efficient than RLHF and is\neven competitive with methods that use ground-truth reward functions instead of\npreferences. Finally, we perform a series of human preference-learning trials\nand observe that ICPL extends beyond synthetic settings and can work\neffectively with humans-in-the-loop. Additional information and videos are\nprovided at https://sites.google.com/view/few-shot-icpl/home.\n","authors":["Chao Yu","Hong Lu","Jiaxuan Gao","Qixin Tan","Xinting Yang","Yu Wang","Yi Wu","Eugene Vinitsky"],"pdf_url":"https://arxiv.org/pdf/2410.17233v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17229v1","updated":"2024-10-22T17:51:13Z","published":"2024-10-22T17:51:13Z","title":"Responsibility in a Multi-Value Strategic Setting","summary":"  Responsibility is a key notion in multi-agent systems and in creating safe,\nreliable and ethical AI. However, most previous work on responsibility has only\nconsidered responsibility for single outcomes. In this paper we present a model\nfor responsibility attribution in a multi-agent, multi-value setting. We also\nexpand our model to cover responsibility anticipation, demonstrating how\nconsiderations of responsibility can help an agent to select strategies that\nare in line with its values. In particular we show that non-dominated\nregret-minimising strategies reliably minimise an agent's expected degree of\nresponsibility.\n","authors":["Timothy Parker","Umberto Grandi","Emiliano Lorini"],"pdf_url":"https://arxiv.org/pdf/2410.17229v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12883v2","updated":"2024-10-22T17:49:31Z","published":"2024-07-16T17:58:27Z","title":"BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive\n  Retrieval","summary":"  Existing retrieval benchmarks primarily consist of information-seeking\nqueries (e.g., aggregated questions from search engines) where keyword or\nsemantic-based retrieval is usually sufficient. However, many complex\nreal-world queries require in-depth reasoning to identify relevant documents\nthat go beyond surface form matching. For example, finding documentation for a\ncoding question requires understanding the logic and syntax of the functions\ninvolved. To better benchmark retrieval on such challenging queries, we\nintroduce BRIGHT, the first text retrieval benchmark that requires intensive\nreasoning to retrieve relevant documents. Our dataset consists of 1,384\nreal-world queries spanning diverse domains, such as economics, psychology,\nmathematics, and coding. These queries are drawn from naturally occurring and\ncarefully curated human data. Extensive evaluation reveals that even\nstate-of-the-art retrieval models perform poorly on BRIGHT. The leading model\non the MTEB leaderboard (Muennighoff et al., 2023), which achieves a score of\n59.0 nDCG@10, produces a score of nDCG@10 of 18.3 on BRIGHT. We show that\nincorporating explicit reasoning about the query improves retrieval performance\nby up to 12.2 points. Moreover, incorporating retrieved documents from the\ntop-performing retriever boosts question-answering performance by over 6.6\npoints. We believe that BRIGHT paves the way for future research on retrieval\nsystems in more realistic and challenging settings.\n","authors":["Hongjin Su","Howard Yen","Mengzhou Xia","Weijia Shi","Niklas Muennighoff","Han-yu Wang","Haisu Liu","Quan Shi","Zachary S. Siegel","Michael Tang","Ruoxi Sun","Jinsung Yoon","Sercan O. Arik","Danqi Chen","Tao Yu"],"pdf_url":"https://arxiv.org/pdf/2407.12883v2.pdf","comment":"48 pages"},{"id":"http://arxiv.org/abs/2410.12101v2","updated":"2024-10-22T17:48:56Z","published":"2024-10-15T22:52:45Z","title":"The Persian Rug: solving toy models of superposition using large-scale\n  symmetries","summary":"  We present a complete mechanistic description of the algorithm learned by a\nminimal non-linear sparse data autoencoder in the limit of large input\ndimension. The model, originally presented in arXiv:2209.10652, compresses\nsparse data vectors through a linear layer and decompresses using another\nlinear layer followed by a ReLU activation. We notice that when the data is\npermutation symmetric (no input feature is privileged) large models reliably\nlearn an algorithm that is sensitive to individual weights only through their\nlarge-scale statistics. For these models, the loss function becomes\nanalytically tractable. Using this understanding, we give the explicit scalings\nof the loss at high sparsity, and show that the model is near-optimal among\nrecently proposed architectures. In particular, changing or adding to the\nactivation function any elementwise or filtering operation can at best improve\nthe model's performance by a constant factor. Finally, we forward-engineer a\nmodel with the requisite symmetries and show that its loss precisely matches\nthat of the trained models. Unlike the trained model weights, the low\nrandomness in the artificial weights results in miraculous fractal structures\nresembling a Persian rug, to which the algorithm is oblivious. Our work\ncontributes to neural network interpretability by introducing techniques for\nunderstanding the structure of autoencoders. Code to reproduce our results can\nbe found at https://github.com/KfirD/PersianRug .\n","authors":["Aditya Cowsik","Kfir Dolev","Alex Infanger"],"pdf_url":"https://arxiv.org/pdf/2410.12101v2.pdf","comment":"Improved arguments, presentation. No changes to results"},{"id":"http://arxiv.org/abs/2410.17218v1","updated":"2024-10-22T17:43:39Z","published":"2024-10-22T17:43:39Z","title":"Creativity in AI: Progresses and Challenges","summary":"  Creativity is the ability to produce novel, useful, and surprising ideas, and\nhas been widely studied as a crucial aspect of human cognition. Machine\ncreativity on the other hand has been a long-standing challenge. With the rise\nof advanced generative AI, there has been renewed interest and debate regarding\nAI's creative capabilities. Therefore, it is imperative to revisit the state of\ncreativity in AI and identify key progresses and remaining challenges. In this\nwork, we survey leading works studying the creative capabilities of AI systems,\nfocusing on creative problem-solving, linguistic, artistic, and scientific\ncreativity. Our review suggests that while the latest AI models are largely\ncapable of producing linguistically and artistically creative outputs such as\npoems, images, and musical pieces, they struggle with tasks that require\ncreative problem-solving, abstract thinking and compositionality and their\ngenerations suffer from a lack of diversity, originality, long-range\nincoherence and hallucinations. We also discuss key questions concerning\ncopyright and authorship issues with generative models. Furthermore, we\nhighlight the need for a comprehensive evaluation of creativity that is\nprocess-driven and considers several dimensions of creativity. Finally, we\npropose future research directions to improve the creativity of AI outputs,\ndrawing inspiration from cognitive science and psychology.\n","authors":["Mete Ismayilzada","Debjit Paul","Antoine Bosselut","Lonneke van der Plas"],"pdf_url":"https://arxiv.org/pdf/2410.17218v1.pdf","comment":"44 pages"},{"id":"http://arxiv.org/abs/2410.17212v1","updated":"2024-10-22T17:37:18Z","published":"2024-10-22T17:37:18Z","title":"Neuroevolution Neural Architecture Search for Evolving RNNs in Stock\n  Return Prediction and Portfolio Trading","summary":"  Stock return forecasting is a major component of numerous finance\napplications. Predicted stock returns can be incorporated into portfolio\ntrading algorithms to make informed buy or sell decisions which can optimize\nreturns. In such portfolio trading applications, the predictive performance of\na time series forecasting model is crucial. In this work, we propose the use of\nthe Evolutionary eXploration of Augmenting Memory Models (EXAMM) algorithm to\nprogressively evolve recurrent neural networks (RNNs) for stock return\npredictions. RNNs are evolved independently for each stocks and portfolio\ntrading decisions are made based on the predicted stock returns. The portfolio\nused for testing consists of the 30 companies in the Dow-Jones Index (DJI) with\neach stock have the same weight. Results show that using these evolved RNNs and\na simple daily long-short strategy can generate higher returns than both the\nDJI index and the S&P 500 Index for both 2022 (bear market) and 2023 (bull\nmarket).\n","authors":["Zimeng Lyu","Amulya Saxena","Rohaan Nadeem","Hao Zhang","Travis Desell"],"pdf_url":"https://arxiv.org/pdf/2410.17212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17210v1","updated":"2024-10-22T17:34:59Z","published":"2024-10-22T17:34:59Z","title":"Exploring Possibilities of AI-Powered Legal Assistance in Bangladesh\n  through Large Language Modeling","summary":"  Purpose: Bangladesh's legal system struggles with major challenges like\ndelays, complexity, high costs, and millions of unresolved cases, which deter\nmany from pursuing legal action due to lack of knowledge or financial\nconstraints. This research seeks to develop a specialized Large Language Model\n(LLM) to assist in the Bangladeshi legal system. Methods: We created\nUKIL-DB-EN, an English corpus of Bangladeshi legal documents, by collecting and\nscraping data on various legal acts. We fine-tuned the GPT-2 model on this\ndataset to develop GPT2-UKIL-EN, an LLM focused on providing legal assistance\nin English. Results: The model was rigorously evaluated using semantic\nassessments, including case studies supported by expert opinions. The\nevaluation provided promising results, demonstrating the potential for the\nmodel to assist in legal matters within Bangladesh. Conclusion: Our work\nrepresents the first structured effort toward building an AI-based legal\nassistant for Bangladesh. While the results are encouraging, further\nrefinements are necessary to improve the model's accuracy, credibility, and\nsafety. This is a significant step toward creating a legal AI capable of\nserving the needs of a population of 180 million.\n","authors":["Azmine Toushik Wasi","Wahid Faisal","Mst Rafia Islam","Mahathir Mohammad Bappy"],"pdf_url":"https://arxiv.org/pdf/2410.17210v1.pdf","comment":"In Review"},{"id":"http://arxiv.org/abs/2308.02594v4","updated":"2024-10-22T17:29:53Z","published":"2023-08-03T21:08:51Z","title":"SMARLA: A Safety Monitoring Approach for Deep Reinforcement Learning\n  Agents","summary":"  Deep Reinforcement Learning (DRL) has made significant advancements in\nvarious fields, such as autonomous driving, healthcare, and robotics, by\nenabling agents to learn optimal policies through interactions with their\nenvironments. However, the application of DRL in safety-critical domains\npresents challenges, particularly concerning the safety of the learned\npolicies. DRL agents, which are focused on maximizing rewards, may select\nunsafe actions, leading to safety violations. Runtime safety monitoring is thus\nessential to ensure the safe operation of these agents, especially in\nunpredictable and dynamic environments. This paper introduces SMARLA, a\nblack-box safety monitoring approach specifically designed for DRL agents.\nSMARLA utilizes machine learning to predict safety violations by observing the\nagent's behavior during execution. The approach is based on Q-values, which\nreflect the expected reward for taking actions in specific states. SMARLA\nemploys state abstraction to reduce the complexity of the state space,\nenhancing the predictive capabilities of the monitoring model. Such abstraction\nenables the early detection of unsafe states, allowing for the implementation\nof corrective and preventive measures before incidents occur. We quantitatively\nand qualitatively validated SMARLA on three well-known case studies widely used\nin DRL research. Empirical results reveal that SMARLA is accurate at predicting\nsafety violations, with a low false positive rate, and can predict violations\nat an early stage, approximately halfway through the execution of the agent,\nbefore violations occur. We also discuss different decision criteria, based on\nconfidence intervals of the predicted violation probabilities, to trigger\nsafety mechanisms aiming at a trade-off between early detection and low false\npositive rates.\n","authors":["Amirhossein Zolfagharian","Manel Abdellatif","Lionel C. Briand","Ramesh S"],"pdf_url":"https://arxiv.org/pdf/2308.02594v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05669v2","updated":"2024-10-22T17:16:17Z","published":"2024-10-08T03:48:57Z","title":"ACPBench: Reasoning about Action, Change, and Planning","summary":"  There is an increasing body of work using Large Language Models (LLMs) as\nagents for orchestrating workflows and making decisions in domains that require\nplanning and multi-step reasoning. As a result, it is imperative to evaluate\nLLMs on core skills required for planning. In this work, we present ACPBench, a\nbenchmark for evaluating the reasoning tasks in the field of planning. The\nbenchmark consists of 7 reasoning tasks over 13 planning domains. The\ncollection is constructed from planning domains described in a formal language.\nThis allows us to synthesize problems with provably correct solutions across\nmany tasks and domains. Further, it allows us the luxury of scale without\nadditional human effort, i.e., many additional problems can be created\nautomatically. Our extensive evaluation of 22 LLMs and OpenAI o1 reasoning\nmodels highlights the significant gap in the reasoning capability of the LLMs.\nOur findings with OpenAI o1, a multi-turn reasoning model, reveal significant\ngains in performance on multiple-choice questions, yet surprisingly, no notable\nprogress is made on boolean questions.\n  The ACPBench collection is available at https://ibm.github.io/ACPBench.\n","authors":["Harsha Kokel","Michael Katz","Kavitha Srinivas","Shirin Sohrabi"],"pdf_url":"https://arxiv.org/pdf/2410.05669v2.pdf","comment":"Added OpenAI o1 results"},{"id":"http://arxiv.org/abs/2410.17196v1","updated":"2024-10-22T17:15:20Z","published":"2024-10-22T17:15:20Z","title":"VoiceBench: Benchmarking LLM-Based Voice Assistants","summary":"  Building on the success of large language models (LLMs), recent advancements\nsuch as GPT-4o have enabled real-time speech interactions through LLM-based\nvoice assistants, offering a significantly improved user experience compared to\ntraditional text-based interactions. However, the absence of benchmarks\ndesigned to evaluate these speech interaction capabilities has hindered\nprogress of LLM-based voice assistants development. Current evaluations focus\nprimarily on automatic speech recognition (ASR) or general knowledge evaluation\nwith clean speeches, neglecting the more intricate, real-world scenarios that\ninvolve diverse speaker characteristics, environmental and content factors. To\naddress this, we introduce VoiceBench, the first benchmark designed to provide\na multi-faceted evaluation of LLM-based voice assistants. VoiceBench also\nincludes both real and synthetic spoken instructions that incorporate the above\nthree key real-world variations. Extensive experiments reveal the limitations\nof current LLM-based voice assistant models and offer valuable insights for\nfuture research and development in this field.\n","authors":["Yiming Chen","Xianghu Yue","Chen Zhang","Xiaoxue Gao","Robby T. Tan","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2410.17196v1.pdf","comment":"Work in progress. Data is available at\n  https://github.com/MatthewCYM/VoiceBench"},{"id":"http://arxiv.org/abs/2410.17195v1","updated":"2024-10-22T17:13:38Z","published":"2024-10-22T17:13:38Z","title":"Language Model Non-myopic Generation for Reasoning and Planning","summary":"  Large Language Models have demonstrated remarkable abilities in reasoning and\nplanning by breaking down complex problems into sequential steps. Despite their\nsuccess in various domains like mathematical problem-solving and coding, LLMs\nface challenges in ensuring reliable and optimal planning due to their inherent\nmyopic nature of autoregressive decoding. This paper revisits LLM reasoning\nfrom an optimal-control perspective, proposing a novel method,\nPredictive-Decoding, that leverages Model Predictive Control to enhance\nplanning accuracy. By re-weighting LLM distributions based on foresight\ntrajectories, Predictive-Decoding aims to mitigate early errors and promote\nnon-myopic planning. Our experiments show significant improvements in a wide\nrange of tasks for math, coding, and agents. Furthermore, Predictive-Decoding\ndemonstrates computational efficiency, outperforming search baselines with\nreduced computational resources. This study provides insights into optimizing\nLLM planning capabilities.\n","authors":["Chang Ma","Haiteng Zhao","Junlei Zhang","Junxian He","Lingpeng Kong"],"pdf_url":"https://arxiv.org/pdf/2410.17195v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17193v1","updated":"2024-10-22T17:13:19Z","published":"2024-10-22T17:13:19Z","title":"Emphasizing Discriminative Features for Dataset Distillation in Complex\n  Scenarios","summary":"  Dataset distillation has demonstrated strong performance on simple datasets\nlike CIFAR, MNIST, and TinyImageNet but struggles to achieve similar results in\nmore complex scenarios. In this paper, we propose EDF (emphasizes the\ndiscriminative features), a dataset distillation method that enhances key\ndiscriminative regions in synthetic images using Grad-CAM activation maps. Our\napproach is inspired by a key observation: in simple datasets, high-activation\nareas typically occupy most of the image, whereas in complex scenarios, the\nsize of these areas is much smaller. Unlike previous methods that treat all\npixels equally when synthesizing images, EDF uses Grad-CAM activation maps to\nenhance high-activation areas. From a supervision perspective, we downplay\nsupervision signals that have lower losses, as they contain common patterns.\nAdditionally, to help the DD community better explore complex scenarios, we\nbuild the Complex Dataset Distillation (Comp-DD) benchmark by meticulously\nselecting sixteen subsets, eight easy and eight hard, from ImageNet-1K. In\nparticular, EDF consistently outperforms SOTA results in complex scenarios,\nsuch as ImageNet-1K subsets. Hopefully, more researchers will be inspired and\nencouraged to improve the practicality and efficacy of DD. Our code and\nbenchmark will be made public at https://github.com/NUS-HPC-AI-Lab/EDF.\n","authors":["Kai Wang","Zekai Li","Zhi-Qi Cheng","Samir Khaki","Ahmad Sajedi","Ramakrishna Vedantam","Konstantinos N Plataniotis","Alexander Hauptmann","Yang You"],"pdf_url":"https://arxiv.org/pdf/2410.17193v1.pdf","comment":"24 pages, 13 figures"},{"id":"http://arxiv.org/abs/2410.17186v1","updated":"2024-10-22T17:07:26Z","published":"2024-10-22T17:07:26Z","title":"DyPNIPP: Predicting Environment Dynamics for RL-based Robust Informative\n  Path Planning","summary":"  Informative path planning (IPP) is an important planning paradigm for various\nreal-world robotic applications such as environment monitoring. IPP involves\nplanning a path that can learn an accurate belief of the quantity of interest,\nwhile adhering to planning constraints. Traditional IPP methods typically\nrequire high computation time during execution, giving rise to reinforcement\nlearning (RL) based IPP methods. However, the existing RL-based methods do not\nconsider spatio-temporal environments which involve their own challenges due to\nvariations in environment characteristics. In this paper, we propose DyPNIPP, a\nrobust RL-based IPP framework, designed to operate effectively across\nspatio-temporal environments with varying dynamics. To achieve this, DyPNIPP\nincorporates domain randomization to train the agent across diverse\nenvironments and introduces a dynamics prediction model to capture and adapt\nthe agent actions to specific environment dynamics. Our extensive experiments\nin a wildfire environment demonstrate that DyPNIPP outperforms existing\nRL-based IPP algorithms by significantly improving robustness and performing\nacross diverse environment conditions.\n","authors":["Srujan Deolasee","Siva Kailas","Wenhao Luo","Katia Sycara","Woojun Kim"],"pdf_url":"https://arxiv.org/pdf/2410.17186v1.pdf","comment":"8 pages, 4 figures, submitted to IEEE RA-L"},{"id":"http://arxiv.org/abs/2409.13686v2","updated":"2024-10-22T17:06:17Z","published":"2024-09-20T17:54:16Z","title":"The Impact of Large Language Models in Academia: from Writing to\n  Speaking","summary":"  Large language models (LLMs) are increasingly impacting human society,\nparticularly in textual information. Based on more than 30,000 papers and 1,000\npresentations from machine learning conferences, we examined and compared the\nwords used in writing and speaking, representing the first large-scale study of\nhow LLMs influence the two main modes of verbal communication and expression\nwithin the same group of people. Our empirical results show that LLM-style\nwords such as \"significant\" have been used more frequently in abstracts and\noral presentations. The impact on speaking is beginning to emerge and is likely\nto grow in the future, calling attention to the implicit influence and ripple\neffect of LLMs on human society.\n","authors":["Mingmeng Geng","Caixi Chen","Yanru Wu","Dongping Chen","Yao Wan","Pan Zhou"],"pdf_url":"https://arxiv.org/pdf/2409.13686v2.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2407.14344v2","updated":"2024-10-22T16:59:12Z","published":"2024-07-19T14:28:07Z","title":"LLMs left, right, and center: Assessing GPT's capabilities to label\n  political bias from web domains","summary":"  This research investigates whether OpenAI's GPT-4, a state-of-the-art large\nlanguage model, can accurately classify the political bias of news sources\nbased solely on their URLs. Given the subjective nature of political labels,\nthird-party bias ratings like those from Ad Fontes Media, AllSides, and Media\nBias/Fact Check (MBFC) are often used in research to analyze news source\ndiversity. This study aims to determine if GPT-4 can replicate these human\nratings on a seven-degree scale (\"far-left\" to \"far-right\"). The analysis\ncompares GPT-4's classifications against MBFC's, and controls for website\npopularity using Open PageRank scores. Findings reveal a high correlation\n($\\text{Spearman's } \\rho = .89$, $n = 5,877$, $p < 0.001$) between GPT-4's and\nMBFC's ratings, indicating the model's potential reliability. However, GPT-4\nabstained from classifying approximately $\\frac{2}{3}$ of the dataset. It is\nmore likely to abstain from rating unpopular websites, which also suffer from\nless accurate assessments. The LLM tends to avoid classifying sources that MBFC\nconsiders to be centrist, resulting in more polarized outputs. Finally, this\nanalysis shows a slight leftward skew in GPT's classifications compared to\nMBFC's. Therefore, while this paper suggests that while GPT-4 can be a\nscalable, cost-effective tool for political bias classification of news\nwebsites, its use should be as a complement to human judgment to mitigate\nbiases.\n","authors":["Raphael Hernandes","Giulio Corsi"],"pdf_url":"https://arxiv.org/pdf/2407.14344v2.pdf","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/2408.17379v2","updated":"2024-10-22T16:58:31Z","published":"2024-08-30T16:15:28Z","title":"EMPOWER: Embodied Multi-role Open-vocabulary Planning with Online\n  Grounding and Execution","summary":"  Task planning for robots in real-life settings presents significant\nchallenges. These challenges stem from three primary issues: the difficulty in\nidentifying grounded sequences of steps to achieve a goal; the lack of a\nstandardized mapping between high-level actions and low-level commands; and the\nchallenge of maintaining low computational overhead given the limited resources\nof robotic hardware. We introduce EMPOWER, a framework designed for\nopen-vocabulary online grounding and planning for embodied agents aimed at\naddressing these issues. By leveraging efficient pre-trained foundation models\nand a multi-role mechanism, EMPOWER demonstrates notable improvements in\ngrounded planning and execution. Quantitative results highlight the\neffectiveness of our approach, achieving an average success rate of 0.73 across\nsix different real-life scenarios using a TIAGo robot.\n","authors":["Francesco Argenziano","Michele Brienza","Vincenzo Suriani","Daniele Nardi","Domenico D. Bloisi"],"pdf_url":"https://arxiv.org/pdf/2408.17379v2.pdf","comment":"Accepted at IROS 2024"},{"id":"http://arxiv.org/abs/2410.17172v1","updated":"2024-10-22T16:50:34Z","published":"2024-10-22T16:50:34Z","title":"KANICE: Kolmogorov-Arnold Networks with Interactive Convolutional\n  Elements","summary":"  We introduce KANICE (Kolmogorov-Arnold Networks with Interactive\nConvolutional Elements), a novel neural architecture that combines\nConvolutional Neural Networks (CNNs) with Kolmogorov-Arnold Network (KAN)\nprinciples. KANICE integrates Interactive Convolutional Blocks (ICBs) and KAN\nlinear layers into a CNN framework. This leverages KANs' universal\napproximation capabilities and ICBs' adaptive feature learning. KANICE captures\ncomplex, non-linear data relationships while enabling dynamic,\ncontext-dependent feature extraction based on the Kolmogorov-Arnold\nrepresentation theorem. We evaluated KANICE on four datasets: MNIST,\nFashion-MNIST, EMNIST, and SVHN, comparing it against standard CNNs, CNN-KAN\nhybrids, and ICB variants. KANICE consistently outperformed baseline models,\nachieving 99.35% accuracy on MNIST and 90.05% on the SVHN dataset.\n  Furthermore, we introduce KANICE-mini, a compact variant designed for\nefficiency. A comprehensive ablation study demonstrates that KANICE-mini\nachieves comparable performance to KANICE with significantly fewer parameters.\nKANICE-mini reached 90.00% accuracy on SVHN with 2,337,828 parameters, compared\nto KANICE's 25,432,000. This study highlights the potential of KAN-based\narchitectures in balancing performance and computational efficiency in image\nclassification tasks. Our work contributes to research in adaptive neural\nnetworks, integrates mathematical theorems into deep learning architectures,\nand explores the trade-offs between model complexity and performance, advancing\ncomputer vision and pattern recognition. The source code for this paper is\npublicly accessible through our GitHub repository\n(https://github.com/m-ferdaus/kanice).\n","authors":["Md Meftahul Ferdaus","Mahdi Abdelguerfi","Elias Ioup","David Dobson","Kendall N. Niles","Ken Pathak","Steven Sloan"],"pdf_url":"https://arxiv.org/pdf/2410.17172v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17173v1","updated":"2024-10-22T16:50:34Z","published":"2024-10-22T16:50:34Z","title":"Reinforcement learning on structure-conditioned categorical diffusion\n  for protein inverse folding","summary":"  Protein inverse folding-that is, predicting an amino acid sequence that will\nfold into the desired 3D structure-is an important problem for structure-based\nprotein design. Machine learning based methods for inverse folding typically\nuse recovery of the original sequence as the optimization objective. However,\ninverse folding is a one-to-many problem where several sequences can fold to\nthe same structure. Moreover, for many practical applications, it is often\ndesirable to have multiple, diverse sequences that fold into the target\nstructure since it allows for more candidate sequences for downstream\noptimizations. Here, we demonstrate that although recent inverse folding\nmethods show increased sequence recovery, their \"foldable diversity\"-i.e. their\nability to generate multiple non-similar sequences that fold into the\nstructures consistent with the target-does not increase. To address this, we\npresent RL-DIF, a categorical diffusion model for inverse folding that is\npre-trained on sequence recovery and tuned via reinforcement learning on\nstructural consistency. We find that RL-DIF achieves comparable sequence\nrecovery and structural consistency to benchmark models but shows greater\nfoldable diversity: experiments show RL-DIF can achieve an foldable diversity\nof 29% on CATH 4.2, compared to 23% from models trained on the same dataset.\nThe PyTorch model weights and sampling code are available on GitHub.\n","authors":["Yasha Ektefaie","Olivia Viessmann","Siddharth Narayanan","Drew Dresser","J. Mark Kim","Armen Mkrtchyan"],"pdf_url":"https://arxiv.org/pdf/2410.17173v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17160v1","updated":"2024-10-22T16:34:24Z","published":"2024-10-22T16:34:24Z","title":"Layered LA-MAPF: a decomposition of large agent MAPF instance to\n  accelerate solving without compromising solvability","summary":"  Multi-Agent Path Finding (MAPF) has been widely studied in recent years.\nHowever, most existing MAPF algorithms assume that an agent occupies only a\nsingle grid in a grid-based map. This assumption limits their applicability in\nmany real-world domains where agents have geometric shapes, rather than being\npoint-like. Such agents, which can occupy multiple cells simultaneously, are\nreferred to as ``large'' agents. When considering the shape and size of agents\nin MAPF, the computational complexity increases significantly as the number of\nagents grows, primarily due to the increased overhead in conflict detection\nbetween geometric agents. In this paper, we propose two types of subproblems\nfor the LA-MAPF (Large-Agent MAPF) problem: \\textbf{cluster} (which has no\nconstraints on the order of solution) and \\textbf{level} (which imposes\nconstraints on the solution order). We introduce \\textbf{Layered LA-MAPF}, a\nmethod that decomposes a MAPF instance involving geometric agents into\nclusters, and then further decomposes each cluster into levels. This approach\naims to reduce time complexity when solving LA-MAPF problems. Our results\ndemonstrate the performance of our method as the number of agents increases\nacross various maps, and how it accelerates LA-MAPF methods, such as LA-CBS and\nLA-LaCAM. Experiments show that our LA-MAPF method with instance decomposition\n\\textbf{halves the time cost (reducing from an average of 40s to 20s) and\ntriples the success rate (from an average of 0.27 to 0.80)} in finding a\nsolution within 60 seconds. To facilitate further research, we have made the\nsource code for Layered LA-MAPF publicly available at\n\\url{https://github.com/JoeYao-bit/LayeredMAPF/algorithm/LA-MAPF}.\n","authors":["Zhuo Yao"],"pdf_url":"https://arxiv.org/pdf/2410.17160v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02581v3","updated":"2024-10-22T16:26:40Z","published":"2024-10-03T15:25:37Z","title":"Boosting Sample Efficiency and Generalization in Multi-agent\n  Reinforcement Learning via Equivariance","summary":"  Multi-Agent Reinforcement Learning (MARL) struggles with sample inefficiency\nand poor generalization [1]. These challenges are partially due to a lack of\nstructure or inductive bias in the neural networks typically used in learning\nthe policy. One such form of structure that is commonly observed in multi-agent\nscenarios is symmetry. The field of Geometric Deep Learning has developed\nEquivariant Graph Neural Networks (EGNN) that are equivariant (or symmetric) to\nrotations, translations, and reflections of nodes. Incorporating equivariance\nhas been shown to improve learning efficiency and decrease error [ 2 ]. In this\npaper, we demonstrate that EGNNs improve the sample efficiency and\ngeneralization in MARL. However, we also show that a naive application of EGNNs\nto MARL results in poor early exploration due to a bias in the EGNN structure.\nTo mitigate this bias, we present Exploration-enhanced Equivariant Graph Neural\nNetworks or E2GN2. We compare E2GN2 to other common function approximators\nusing common MARL benchmarks MPE and SMACv2. E2GN2 demonstrates a significant\nimprovement in sample efficiency, greater final reward convergence, and a 2x-5x\ngain in over standard GNNs in our generalization tests. These results pave the\nway for more reliable and effective solutions in complex multi-agent systems.\n","authors":["Joshua McClellan","Naveed Haghani","John Winder","Furong Huang","Pratap Tokekar"],"pdf_url":"https://arxiv.org/pdf/2410.02581v3.pdf","comment":"accepted as a poster at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.17145v1","updated":"2024-10-22T16:26:03Z","published":"2024-10-22T16:26:03Z","title":"Can General-Purpose Large Language Models Generalize to English-Thai\n  Machine Translation ?","summary":"  Large language models (LLMs) perform well on common tasks but struggle with\ngeneralization in low-resource and low-computation settings. We examine this\nlimitation by testing various LLMs and specialized translation models on\nEnglish-Thai machine translation and code-switching datasets. Our findings\nreveal that under more strict computational constraints, such as 4-bit\nquantization, LLMs fail to translate effectively. In contrast, specialized\nmodels, with comparable or lower computational requirements, consistently\noutperform LLMs. This underscores the importance of specialized models for\nmaintaining performance under resource constraints.\n","authors":["Jirat Chiaranaipanich","Naiyarat Hanmatheekuna","Jitkapat Sawatphol","Krittamate Tiankanon","Jiramet Kinchagawat","Amrest Chinkamol","Parinthapat Pengpun","Piyalitt Ittichaiwong","Peerat Limkonchotiwat"],"pdf_url":"https://arxiv.org/pdf/2410.17145v1.pdf","comment":"Accepted in GenBench EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.17141v1","updated":"2024-10-22T16:18:41Z","published":"2024-10-22T16:18:41Z","title":"Towards Automated Penetration Testing: Introducing LLM Benchmark,\n  Analysis, and Improvements","summary":"  Hacking poses a significant threat to cybersecurity, inflicting billions of\ndollars in damages annually. To mitigate these risks, ethical hacking, or\npenetration testing, is employed to identify vulnerabilities in systems and\nnetworks. Recent advancements in large language models (LLMs) have shown\npotential across various domains, including cybersecurity. However, there is\ncurrently no comprehensive, open, end-to-end automated penetration testing\nbenchmark to drive progress and evaluate the capabilities of these models in\nsecurity contexts. This paper introduces a novel open benchmark for LLM-based\nautomated penetration testing, addressing this critical gap. We first evaluate\nthe performance of LLMs, including GPT-4o and Llama 3.1-405B, using the\nstate-of-the-art PentestGPT tool. Our findings reveal that while Llama 3.1\ndemonstrates an edge over GPT-4o, both models currently fall short of\nperforming fully automated, end-to-end penetration testing. Next, we advance\nthe state-of-the-art and present ablation studies that provide insights into\nimproving the PentestGPT tool. Our research illuminates the challenges LLMs\nface in each aspect of Pentesting, e.g. enumeration, exploitation, and\nprivilege escalation. This work contributes to the growing body of knowledge on\nAI-assisted cybersecurity and lays the foundation for future research in\nautomated penetration testing using large language models.\n","authors":["Isamu Isozaki","Manil Shrestha","Rick Console","Edward Kim"],"pdf_url":"https://arxiv.org/pdf/2410.17141v1.pdf","comment":"Main Paper 1-9 pages, Supplementary Materials: 10-17, 13 figures"},{"id":"http://arxiv.org/abs/2410.17139v1","updated":"2024-10-22T16:10:10Z","published":"2024-10-22T16:10:10Z","title":"Trustworthy XAI and Application","summary":"  One of today's most significant and transformative technologies is the\nrapidly developing field of artificial intelligence (AI). Deined as a computer\nsystem that simulates human cognitive processes, AI is present in many aspects\nof our daily lives, from the self-driving cars on the road to the intelligence\n(AI) because some AI systems are so complex and opaque. With millions of\nparameters and layers, these system-deep neural networks in particular-make it\ndifficult for humans to comprehend accountability, prejudice, and justice are\nraised by the opaqueness of its decision-making process. AI has a lot of\npotential, but it also comes with a lot of difficulties and moral dilemmas. In\nthe context of explainable artificial intelligence (XAI), trust is crucial as\nit ensures that AI systems behave consistently, fairly, and ethically. In the\npresent article, we explore XAI, reliable XAI, and several practical uses for\nreliable XAI. Once more, we go over the three main components-transparency,\nexplainability, and trustworthiness of XAI-that we determined are pertinent in\nthis situation. We present an overview of recent scientific studies that employ\ntrustworthy XAI in various application fields. In the end, trustworthiness is\ncrucial for establishing and maintaining trust between humans and AI systems,\nfacilitating the integration of AI systems into various applications and\ndomains for the benefit of society.\n","authors":["MD Abdullah Al Nasim","Parag Biswas","Abdur Rashid","Angona Biswas","Kishor Datta Gupta"],"pdf_url":"https://arxiv.org/pdf/2410.17139v1.pdf","comment":"28 pages, 14 figures"},{"id":"http://arxiv.org/abs/2410.17126v1","updated":"2024-10-22T15:59:58Z","published":"2024-10-22T15:59:58Z","title":"Exploring RL-based LLM Training for Formal Language Tasks with\n  Programmed Rewards","summary":"  Proximal Policy Optimization (PPO) is commonly used in Reinforcement Learning\nfrom Human Feedback to align large language models (LLMs) with downstream\ntasks. This paper investigates the feasibility of using PPO for direct\nreinforcement learning (RL) from explicitly programmed reward signals, as\nopposed to indirect learning from human feedback via an intermediary reward\nmodel. We focus on tasks expressed through formal languages, such as\nmathematics and programming, where explicit reward functions can be programmed\nto automatically assess the quality of generated outputs. We apply this\napproach to a sentiment alignment task, a simple arithmetic task, and a more\ncomplex game synthesis task. The sentiment alignment task replicates prior\nresearch and serves to validate our experimental setup. Our results show that\npure RL-based training for the two formal language tasks is challenging, with\nsuccess being limited even for the simple arithmetic task. We propose a novel\nbatch-entropy regularization term to aid exploration, although training is not\nyet entirely stable. Our findings suggest that direct RL training of LLMs may\nbe more suitable for relatively minor changes, such as alignment, than for\nlearning new tasks altogether, even if an informative reward signal can be\nexpressed programmatically.\n","authors":["Alexander G. Padula","Dennis J. N. J. Soemers"],"pdf_url":"https://arxiv.org/pdf/2410.17126v1.pdf","comment":"Accepted at BNAIC 2024"},{"id":"http://arxiv.org/abs/2410.17124v1","updated":"2024-10-22T15:59:07Z","published":"2024-10-22T15:59:07Z","title":"Automated neuroradiological support systems for multiple cerebrovascular\n  disease markers -- A systematic review and meta-analysis","summary":"  Cerebrovascular diseases (CVD) can lead to stroke and dementia. Stroke is the\nsecond leading cause of death world wide and dementia incidence is increasing\nby the year. There are several markers of CVD that are visible on brain\nimaging, including: white matter hyperintensities (WMH), acute and chronic\nischaemic stroke lesions (ISL), lacunes, enlarged perivascular spaces (PVS),\nacute and chronic haemorrhagic lesions, and cerebral microbleeds (CMB). Brain\natrophy also occurs in CVD. These markers are important for patient management\nand intervention, since they indicate elevated risk of future stroke and\ndementia. We systematically reviewed automated systems designed to support\nradiologists reporting on these CVD imaging findings. We considered\ncommercially available software and research publications which identify at\nleast two CVD markers. In total, we included 29 commercial products and 13\nresearch publications. Two distinct types of commercial support system were\navailable: those which identify acute stroke lesions (haemorrhagic and\nischaemic) from computed tomography (CT) scans, mainly for the purpose of\npatient triage; and those which measure WMH and atrophy regionally and\nlongitudinally. In research, WMH and ISL were the markers most frequently\nanalysed together, from magnetic resonance imaging (MRI) scans; lacunes and PVS\nwere each targeted only twice and CMB only once. For stroke, commercially\navailable systems largely support the emergency setting, whilst research\nsystems consider also follow-up and routine scans. The systems to quantify WMH\nand atrophy are focused on neurodegenerative disease support, where these CVD\nmarkers are also of significance. There are currently no openly validated\nsystems, commercially, or in research, performing a comprehensive joint\nanalysis of all CVD markers (WMH, ISL, lacunes, PVS, haemorrhagic lesions, CMB,\nand atrophy).\n","authors":["Jesse Phitidis","Alison Q. O'Neil","William N. Whiteley","Beatrice Alex","Joanna M. Wardlaw","Miguel O. Bernabeu","Maria Valdés Hernández"],"pdf_url":"https://arxiv.org/pdf/2410.17124v1.pdf","comment":"62 pages, 10 figures"},{"id":"http://arxiv.org/abs/2312.10219v2","updated":"2024-10-22T15:52:15Z","published":"2023-12-15T21:31:30Z","title":"The Complexity of Optimizing Atomic Congestion","summary":"  Atomic congestion games are a classic topic in network design, routing, and\nalgorithmic game theory, and are capable of modeling congestion and flow\noptimization tasks in various application areas. While both the price of\nanarchy for such games as well as the computational complexity of computing\ntheir Nash equilibria are by now well-understood, the computational complexity\nof computing a system-optimal set of strategies -- that is, a centrally planned\nrouting that minimizes the average cost of agents -- is severely understudied\nin the literature. We close this gap by identifying the exact boundaries of\ntractability for the problem through the lens of the parameterized complexity\nparadigm. After showing that the problem remains highly intractable even on\nextremely simple networks, we obtain a set of results which demonstrate that\nthe structural parameters which control the computational (in)tractability of\nthe problem are not vertex-separator based in nature (such as, e.g.,\ntreewidth), but rather based on edge separators. We conclude by extending our\nanalysis towards the (even more challenging) min-max variant of the problem.\n","authors":["Cornelius Brand","Robert Ganian","Subrahmanyam Kalyanasundaram","Fionn Mc Inerney"],"pdf_url":"https://arxiv.org/pdf/2312.10219v2.pdf","comment":"Short version appeared at AAAI 2024. Long version accepted in the\n  Journal of Artificial Intelligence"},{"id":"http://arxiv.org/abs/2404.01596v3","updated":"2024-10-22T15:47:12Z","published":"2024-04-02T02:36:31Z","title":"PhysORD: A Neuro-Symbolic Approach for Physics-infused Motion Prediction\n  in Off-road Driving","summary":"  Motion prediction is critical for autonomous off-road driving, however, it\npresents significantly more challenges than on-road driving because of the\ncomplex interaction between the vehicle and the terrain. Traditional\nphysics-based approaches encounter difficulties in accurately modeling dynamic\nsystems and external disturbance. In contrast, data-driven neural networks\nrequire extensive datasets and struggle with explicitly capturing the\nfundamental physical laws, which can easily lead to poor generalization. By\nmerging the advantages of both methods, neuro-symbolic approaches present a\npromising direction. These methods embed physical laws into neural models,\npotentially significantly improving generalization capabilities. However, no\nprior works were evaluated in real-world settings for off-road driving. To\nbridge this gap, we present PhysORD, a neural-symbolic approach integrating the\nconservation law, i.e., the Euler-Lagrange equation, into data-driven neural\nmodels for motion prediction in off-road driving. Our experiments showed that\nPhysORD can accurately predict vehicle motion and tolerate external disturbance\nby modeling uncertainties. The learned dynamics model achieves 46.7% higher\naccuracy using only 3.1% of the parameters compared to data-driven methods,\ndemonstrating the data efficiency and superior generalization ability of our\nneural-symbolic method.\n","authors":["Zhipeng Zhao","Bowen Li","Yi Du","Taimeng Fu","Chen Wang"],"pdf_url":"https://arxiv.org/pdf/2404.01596v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17111v1","updated":"2024-10-22T15:36:04Z","published":"2024-10-22T15:36:04Z","title":"Permutation Picture of Graph Combinatorial Optimization Problems","summary":"  This paper proposes a framework that formulates a wide range of graph\ncombinatorial optimization problems using permutation-based representations.\nThese problems include the travelling salesman problem, maximum independent\nset, maximum cut, and various other related problems. This work potentially\nopens up new avenues for algorithm design in neural combinatorial optimization,\nbridging the gap between discrete and continuous optimization techniques.\n","authors":["Yimeng Min"],"pdf_url":"https://arxiv.org/pdf/2410.17111v1.pdf","comment":"15 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.14516v2","updated":"2024-10-22T15:20:00Z","published":"2024-10-18T14:55:14Z","title":"Do LLMs \"know\" internally when they follow instructions?","summary":"  Instruction-following is crucial for building AI agents with large language\nmodels (LLMs), as these models must adhere strictly to user-provided\nconstraints and guidelines. However, LLMs often fail to follow even simple and\nclear instructions. To improve instruction-following behavior and prevent\nundesirable outputs, a deeper understanding of how LLMs' internal states relate\nto these outcomes is required. Our analysis of LLM internal states reveal a\ndimension in the input embedding space linked to successful\ninstruction-following. We demonstrate that modifying representations along this\ndimension improves instruction-following success rates compared to random\nchanges, without compromising response quality. Further investigation reveals\nthat this dimension is more closely related to the phrasing of prompts rather\nthan the inherent difficulty of the task or instructions. This discovery also\nsuggests explanations for why LLMs sometimes fail to follow clear instructions\nand why prompt engineering is often effective, even when the content remains\nlargely unchanged. This work provides insight into the internal workings of\nLLMs' instruction-following, paving the way for reliable LLM agents.\n","authors":["Juyeon Heo","Christina Heinze-Deml","Oussama Elachqar","Shirley Ren","Udhay Nallasamy","Andy Miller","Kwan Ho Ryan Chan","Jaya Narain"],"pdf_url":"https://arxiv.org/pdf/2410.14516v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14582v2","updated":"2024-10-22T15:16:14Z","published":"2024-10-18T16:32:10Z","title":"Do LLMs estimate uncertainty well in instruction-following?","summary":"  Large language models (LLMs) could be valuable personal AI agents across\nvarious domains, provided they can precisely follow user instructions. However,\nrecent studies have shown significant limitations in LLMs'\ninstruction-following capabilities, raising concerns about their reliability in\nhigh-stakes applications. Accurately estimating LLMs' uncertainty in adhering\nto instructions is critical to mitigating deployment risks. We present, to our\nknowledge, the first systematic evaluation of the uncertainty estimation\nabilities of LLMs in the context of instruction-following. Our study identifies\nkey challenges with existing instruction-following benchmarks, where multiple\nfactors are entangled with uncertainty stems from instruction-following,\ncomplicating the isolation and comparison across methods and models. To address\nthese issues, we introduce a controlled evaluation setup with two benchmark\nversions of data, enabling a comprehensive comparison of uncertainty estimation\nmethods under various conditions. Our findings show that existing uncertainty\nmethods struggle, particularly when models make subtle errors in instruction\nfollowing. While internal model states provide some improvement, they remain\ninadequate in more complex scenarios. The insights from our controlled\nevaluation setups provide a crucial understanding of LLMs' limitations and\npotential for uncertainty estimation in instruction-following tasks, paving the\nway for more trustworthy AI agents.\n","authors":["Juyeon Heo","Miao Xiong","Christina Heinze-Deml","Jaya Narain"],"pdf_url":"https://arxiv.org/pdf/2410.14582v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17088v1","updated":"2024-10-22T15:14:54Z","published":"2024-10-22T15:14:54Z","title":"Science Out of Its Ivory Tower: Improving Accessibility with\n  Reinforcement Learning","summary":"  A vast amount of scholarly work is published daily, yet much of it remains\ninaccessible to the general public due to dense jargon and complex language. To\naddress this challenge in science communication, we introduce a reinforcement\nlearning framework that fine-tunes a language model to rewrite scholarly\nabstracts into more comprehensible versions. Guided by a carefully balanced\ncombination of word- and sentence-level accessibility rewards, our language\nmodel effectively substitutes technical terms with more accessible\nalternatives, a task which models supervised fine-tuned or guided by\nconventional readability measures struggle to accomplish. Our best model\nadjusts the readability level of scholarly abstracts by approximately six U.S.\ngrade levels -- in other words, from a postgraduate to a high school level.\nThis translates to roughly a 90% relative boost over the supervised fine-tuning\nbaseline, all while maintaining factual accuracy and high-quality language. An\nin-depth analysis of our approach shows that balanced rewards lead to\nsystematic modifications in the base model, likely contributing to smoother\noptimization and superior performance. We envision this work as a step toward\nbridging the gap between scholarly research and the general public,\nparticularly younger readers and those without a college degree.\n","authors":["Haining Wang","Jason Clark","Hannah McKelvey","Leila Sterman","Zheng Gao","Zuoyu Tian","Sandra Kübler","Xiaozhong Liu"],"pdf_url":"https://arxiv.org/pdf/2410.17088v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16264v3","updated":"2024-10-22T15:09:58Z","published":"2024-06-24T02:03:57Z","title":"One Thousand and One Pairs: A \"novel\" challenge for long-context\n  language models","summary":"  Synthetic long-context LLM benchmarks (e.g., \"needle-in-the-haystack\") test\nonly surface-level retrieval capabilities, but how well can long-context LLMs\nretrieve, synthesize, and reason over information across book-length inputs? We\naddress this question by creating NoCha, a dataset of 1,001 minimally different\npairs of true and false claims about 67 recently-published English fictional\nbooks, written by human readers of those books. In contrast to existing\nlong-context benchmarks, our annotators confirm that the largest share of pairs\nin NoCha require global reasoning over the entire book to verify. Our\nexperiments show that while human readers easily perform this task, it is\nenormously challenging for all ten long-context LLMs that we evaluate: no\nopen-weight model performs above random chance (despite their strong\nperformance on synthetic benchmarks), while GPT-4o achieves the highest\naccuracy at 55.8%. Further analysis reveals that (1) on average, models perform\nmuch better on pairs that require only sentence-level retrieval vs. global\nreasoning; (2) model-generated explanations for their decisions are often\ninaccurate even for correctly-labeled claims; and (3) models perform\nsubstantially worse on speculative fiction books that contain extensive\nworld-building. The methodology proposed in NoCha allows for the evolution of\nthe benchmark dataset and the easy analysis of future models.\n","authors":["Marzena Karpinska","Katherine Thai","Kyle Lo","Tanya Goyal","Mohit Iyyer"],"pdf_url":"https://arxiv.org/pdf/2406.16264v3.pdf","comment":"EMNLP 2024, camera ready"},{"id":"http://arxiv.org/abs/2410.15028v2","updated":"2024-10-22T14:55:54Z","published":"2024-10-19T07:59:10Z","title":"A Novel Reinforcement Learning Model for Post-Incident Malware\n  Investigations","summary":"  This Research proposes a Novel Reinforcement Learning (RL) model to optimise\nmalware forensics investigation during cyber incident response. It aims to\nimprove forensic investigation efficiency by reducing false negatives and\nadapting current practices to evolving malware signatures. The proposed RL\nframework leverages techniques such as Q-learning and the Markov Decision\nProcess (MDP) to train the system to identify malware patterns in live memory\ndumps, thereby automating forensic tasks. The RL model is based on a detailed\nmalware workflow diagram that guides the analysis of malware artefacts using\nstatic and behavioural techniques as well as machine learning algorithms.\nFurthermore, it seeks to address challenges in the UK justice system by\nensuring the accuracy of forensic evidence. We conduct testing and evaluation\nin controlled environments, using datasets created with Windows operating\nsystems to simulate malware infections. The experimental results demonstrate\nthat RL improves malware detection rates compared to conventional methods, with\nthe RL model's performance varying depending on the complexity and learning\nrate of the environment. The study concludes that while RL offers promising\npotential for automating malware forensics, its efficacy across diverse malware\ntypes requires ongoing refinement of reward systems and feature extraction\nmethods.\n","authors":["Dipo Dunsin","Mohamed Chahine Ghanem","Karim Ouazzane","Vassil Vassilev"],"pdf_url":"https://arxiv.org/pdf/2410.15028v2.pdf","comment":"8 pages. arXiv admin note: substantial text overlap with\n  arXiv:2408.01999"},{"id":"http://arxiv.org/abs/2407.05180v2","updated":"2024-10-22T14:54:42Z","published":"2024-04-22T10:33:06Z","title":"ReCAP: Recursive Cross Attention Network for Pseudo-Label Generation in\n  Robotic Surgical Skill Assessment","summary":"  In surgical skill assessment, Objective Structured Assessments of Technical\nSkills (OSATS scores) and the Global Rating Scale (GRS) are established tools\nfor evaluating the performance of surgeons during training. These metrics,\ncoupled with feedback on their performance, enable surgeons to improve and\nachieve standards of practice. Recent studies on the open-source dataset\nJIGSAW, which contains both GRS and OSATS labels, have focused on regressing\nGRS scores from kinematic signals, video data, or a combination of both. In\nthis paper, we argue that regressing the GRS score, a unitless value, by itself\nis too restrictive, and variations throughout the surgical trial do not hold\nsignificant clinical meaning. To address this gap, we developed a recurrent\ntransformer model that outputs the surgeon's performance throughout their\ntraining session by relating the model's hidden states to five OSATS scores\nderived from kinematic signals. These scores are averaged and aggregated to\nproduce a GRS prediction, enabling assessment of the model's performance\nagainst the state-of-the-art (SOTA). We report Spearman's Correlation\nCoefficient (SCC), demonstrating that our model outperforms SOTA models for all\ntasks, except for Suturing under the leave-one-subject-out (LOSO) scheme (SCC\n0.68-0.89), while achieving comparable performance for suturing and across\ntasks under the leave-one-user-out (LOUO) scheme (SCC 0.45-0.68) and beating\nSOTA for Needle Passing (0.69). We argue that relating final OSATS scores to\nshort instances throughout a surgeon's procedure is more clinically meaningful\nthan a single GRS score. This approach also allows us to translate quantitative\npredictions into qualitative feedback, which is crucial for any automated\nsurgical skill assessment pipeline. A senior surgeon validated our model's\nbehaviour and agreed with the semi-supervised predictions 77 \\% (p = 0.006) of\nthe time.\n","authors":["Julien Quarez","Matthew Elliot","Oscar Maccormac","Marc Modat","Sebastien Ourselin","Jonathan Shapey","Alejandro Granados"],"pdf_url":"https://arxiv.org/pdf/2407.05180v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17050v1","updated":"2024-10-22T14:30:03Z","published":"2024-10-22T14:30:03Z","title":"UnStar: Unlearning with Self-Taught Anti-Sample Reasoning for LLMs","summary":"  The key components of machine learning are data samples for training, model\nfor learning patterns, and loss function for optimizing accuracy. Analogously,\nunlearning can potentially be achieved through anti-data samples (or\nanti-samples), unlearning method, and reversed loss function. While prior\nresearch has explored unlearning methods and reversed loss functions, the\npotential of anti-samples remains largely untapped. In this paper, we introduce\nUnSTAR: Unlearning with Self-Taught Anti-Sample Reasoning for large language\nmodels (LLMs). Our contributions are threefold; first, we propose a novel\nconcept of anti-sample-induced unlearning; second, we generate anti-samples by\nleveraging misleading rationales, which help reverse learned associations and\naccelerate the unlearning process; and third, we enable fine-grained targeted\nunlearning, allowing for the selective removal of specific associations without\nimpacting related knowledge - something not achievable by previous works.\nResults demonstrate that anti-samples offer an efficient, targeted unlearning\nstrategy for LLMs, opening new avenues for privacy-preserving machine learning\nand model modification.\n","authors":["Yash Sinha","Murari Mandal","Mohan Kankanhalli"],"pdf_url":"https://arxiv.org/pdf/2410.17050v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17049v1","updated":"2024-10-22T14:27:43Z","published":"2024-10-22T14:27:43Z","title":"A Comparison of Baseline Models and a Transformer Network for SOC\n  Prediction in Lithium-Ion Batteries","summary":"  Accurately predicting the state of charge of Lithium-ion batteries is\nessential to the performance of battery management systems of electric\nvehicles. One of the main reasons for the slow global adoption of electric cars\nis driving range anxiety. The ability of a battery management system to\naccurately estimate the state of charge can help alleviate this problem. In\nthis paper, a comparison between data-driven state-of-charge estimation methods\nis conducted. The paper compares different neural network-based models and\ncommon regression models for SOC estimation. These models include several\nablated transformer networks, a neural network, a lasso regression model, a\nlinear regression model and a decision tree. Results of various experiments\nconducted on data obtained from natural driving cycles of the BMW i3 battery\nshow that the decision tree outperformed all other models including the more\ncomplex transformer network with self-attention and positional encoding.\n","authors":["Hadeel Aboueidah","Abdulrahman Altahhan"],"pdf_url":"https://arxiv.org/pdf/2410.17049v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17042v1","updated":"2024-10-22T14:16:49Z","published":"2024-10-22T14:16:49Z","title":"Deep Memory Search: A Metaheuristic Approach for Optimizing Heuristic\n  Search","summary":"  Metaheuristic search methods have proven to be essential tools for tackling\ncomplex optimization challenges, but their full potential is often constrained\nby conventional algorithmic frameworks. In this paper, we introduce a novel\napproach called Deep Heuristic Search (DHS), which models metaheuristic search\nas a memory-driven process. DHS employs multiple search layers and memory-based\nexploration-exploitation mechanisms to navigate large, dynamic search spaces.\nBy utilizing model-free memory representations, DHS enhances the ability to\ntraverse temporal trajectories without relying on probabilistic transition\nmodels. The proposed method demonstrates significant improvements in search\nefficiency and performance across a range of heuristic optimization problems.\n","authors":["Abdel-Rahman Hedar","Alaa E. Abdel-Hakim","Wael Deabes","Youseef Alotaibi","Kheir Eddine Bouazza"],"pdf_url":"https://arxiv.org/pdf/2410.17042v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2409.16320v2","updated":"2024-10-22T14:09:10Z","published":"2024-09-21T03:45:05Z","title":"Developing a Thailand solar irradiance map using Himawari-8 satellite\n  imageries and deep learning models","summary":"  This paper presents an online platform that shows Thailand's solar irradiance\nmap every 30 minutes. It is available at https://www.cusolarforecast.com. The\nmethodology for estimating global horizontal irradiance (GHI) across Thailand\nrelies on cloud index extracted from Himawari-8 satellite imagery, Ineichen\nclear-sky model with locally-tuned Linke turbidity, and machine learning\nmodels. The methods take clear-sky irradiance, cloud index, re-analyzed GHI and\ntemperature data from the MERRA-2 database, and date-time as inputs for GHI\nestimation models, including LightGBM, LSTM, Informer, and Transformer. These\nare benchmarked with the estimate from a commercial service X by evaluating\n15-minute ground GHI data from 53 ground stations over 1.5 years from\n2022-2023. The results show that the four models have competitive performances\nand outperform the service X. The best model is LightGBM, with an MAE of 78.58\nW/sqm and RMSE of 118.97 W/sqm. Obtaining re-analyzed MERRA-2 data for Thailand\nis not economically feasible for deployment. When removing these features, the\nInformer model has a winning performance of 78.67 W/sqm in MAE. The obtained\nperformance aligns with existing literature by taking the climate zone and time\ngranularity of data into consideration. As the map shows an estimate of GHI\nover 93,000 grids with a frequent update, the paper also describes a\ncomputational framework for displaying the entire map. It tests the runtime\nperformance of deep learning models in the GHI estimation process.\n","authors":["Suwichaya Suwanwimolkul","Natanon Tongamrak","Nuttamon Thungka","Naebboon Hoonchareon","Jitkomut Songsiri"],"pdf_url":"https://arxiv.org/pdf/2409.16320v2.pdf","comment":"23 pages, 14 figures"},{"id":"http://arxiv.org/abs/2403.07389v2","updated":"2024-10-22T14:07:54Z","published":"2024-03-12T07:57:33Z","title":"Auxiliary CycleGAN-guidance for Task-Aware Domain Translation from\n  Duplex to Monoplex IHC Images","summary":"  Generative models enable the translation from a source image domain where\nreadily trained models are available to a target domain unseen during training.\nWhile Cycle Generative Adversarial Networks (GANs) are well established, the\nassociated cycle consistency constrain relies on that an invertible mapping\nexists between the two domains. This is, however, not the case for the\ntranslation between images stained with chromogenic monoplex and duplex\nimmunohistochemistry (IHC) assays. Focusing on the translation from the latter\nto the first, we propose - through the introduction of a novel training design,\nan alternative constrain leveraging a set of immunofluorescence (IF) images as\nan auxiliary unpaired image domain. Quantitative and qualitative results on a\ndownstream segmentation task show the benefit of the proposed method in\ncomparison to baseline approaches.\n","authors":["Nicolas Brieu","Nicolas Triltsch","Philipp Wortmann","Dominik Winter","Shashank Saran","Marlon Rebelatto","Günter Schmidt"],"pdf_url":"https://arxiv.org/pdf/2403.07389v2.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2410.17032v1","updated":"2024-10-22T13:59:21Z","published":"2024-10-22T13:59:21Z","title":"Insights on Disagreement Patterns in Multimodal Safety Perception across\n  Diverse Rater Groups","summary":"  AI systems crucially rely on human ratings, but these ratings are often\naggregated, obscuring the inherent diversity of perspectives in real-world\nphenomenon. This is particularly concerning when evaluating the safety of\ngenerative AI, where perceptions and associated harms can vary significantly\nacross socio-cultural contexts. While recent research has studied the impact of\ndemographic differences on annotating text, there is limited understanding of\nhow these subjective variations affect multimodal safety in generative AI. To\naddress this, we conduct a large-scale study employing highly-parallel safety\nratings of about 1000 text-to-image (T2I) generations from a demographically\ndiverse rater pool of 630 raters balanced across 30 intersectional groups\nacross age, gender, and ethnicity. Our study shows that (1) there are\nsignificant differences across demographic groups (including intersectional\ngroups) on how severe they assess the harm to be, and that these differences\nvary across different types of safety violations, (2) the diverse rater pool\ncaptures annotation patterns that are substantially different from expert\nraters trained on specific set of safety policies, and (3) the differences we\nobserve in T2I safety are distinct from previously documented group level\ndifferences in text-based safety tasks. To further understand these varying\nperspectives, we conduct a qualitative analysis of the open-ended explanations\nprovided by raters. This analysis reveals core differences into the reasons why\ndifferent groups perceive harms in T2I generations. Our findings underscore the\ncritical need for incorporating diverse perspectives into safety evaluation of\ngenerative AI ensuring these systems are truly inclusive and reflect the values\nof all users.\n","authors":["Charvi Rastogi","Tian Huey Teh","Pushkar Mishra","Roma Patel","Zoe Ashwood","Aida Mostafazadeh Davani","Mark Diaz","Michela Paganini","Alicia Parrish","Ding Wang","Vinodkumar Prabhakaran","Lora Aroyo","Verena Rieser"],"pdf_url":"https://arxiv.org/pdf/2410.17032v1.pdf","comment":"20 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.17031v1","updated":"2024-10-22T13:57:55Z","published":"2024-10-22T13:57:55Z","title":"GeoCode-GPT: A Large Language Model for Geospatial Code Generation Tasks","summary":"  The increasing demand for spatiotemporal data and modeling tasks in\ngeosciences has made geospatial code generation technology a critical factor in\nenhancing productivity. Although large language models (LLMs) have demonstrated\npotential in code generation tasks, they often encounter issues such as refusal\nto code or hallucination in geospatial code generation due to a lack of\ndomain-specific knowledge and code corpora. To address these challenges, this\npaper presents and open-sources the GeoCode-PT and GeoCode-SFT corpora, along\nwith the GeoCode-Eval evaluation dataset. Additionally, by leveraging QLoRA and\nLoRA for pretraining and fine-tuning, we introduce GeoCode-GPT-7B, the first\nLLM focused on geospatial code generation, fine-tuned from Code Llama-7B.\nFurthermore, we establish a comprehensive geospatial code evaluation framework,\nincorporating option matching, expert validation, and prompt engineering\nscoring for LLMs, and systematically evaluate GeoCode-GPT-7B using the\nGeoCode-Eval dataset. Experimental results show that GeoCode-GPT outperforms\nother models in multiple-choice accuracy by 9.1% to 32.1%, in code\nsummarization ability by 1.7% to 25.4%, and in code generation capability by\n1.2% to 25.1%. This paper provides a solution and empirical validation for\nenhancing LLMs' performance in geospatial code generation, extends the\nboundaries of domain-specific model applications, and offers valuable insights\ninto unlocking their potential in geospatial code generation.\n","authors":["Shuyang Hou","Zhangxiao Shen","Anqi Zhao","Jianyuan Liang","Zhipeng Gui","Xuefeng Guan","Rui Li","Huayi Wu"],"pdf_url":"https://arxiv.org/pdf/2410.17031v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17028v1","updated":"2024-10-22T13:52:51Z","published":"2024-10-22T13:52:51Z","title":"Can a Machine Distinguish High and Low Amount of Social Creak in Speech?","summary":"  Objectives: ncreased prevalence of social creak particularly among female\nspeakers has been reported in several studies. The study of social creak has\nbeen previously conducted by combining perceptual evaluation of speech with\nconventional acoustical parameters such as the harmonic-to-noise ratio and\ncepstral peak prominence. In the current study, machine learning (ML) was used\nto automatically distinguish speech of low amount of social creak from speech\nof high amount of social creak.\n  Methods: The amount of creak in continuous speech samples produced in Finnish\nby 90 female speakers was first perceptually assessed by two voice specialists.\nBased on their assessments, the speech samples were divided into two categories\n(low $vs$. high amount of creak). Using the speech signals and their creak\nlabels, seven different ML models were trained. Three spectral representations\nwere used as feature for each model.\n  Results: The results show that the best performance (accuracy of 71.1\\%) was\nobtained by the following two systems: an Adaboost classifier using the\nmel-spectrogram feature and a decision tree classifier using the mel-frequency\ncepstral coefficient feature.\n  Conclusions: The study of social creak is becoming increasingly popular in\nsociolinguistic and vocological research. The conventional human perceptual\nassessment of the amount of creak is laborious and therefore ML technology\ncould be used to assist researchers studying social creak. The classification\nsystems reported in this study could be considered as baselines in future\nML-based studies on social creak.\n","authors":["Anne-Maria Laukkanen","Sudarsana Reddy Kadiri","Shrikanth Narayanan","Paavo Alku"],"pdf_url":"https://arxiv.org/pdf/2410.17028v1.pdf","comment":"Accepted in Journal of Voice"},{"id":"http://arxiv.org/abs/2406.02362v3","updated":"2024-10-22T13:43:01Z","published":"2024-06-04T14:39:51Z","title":"Temporal Graph Rewiring with Expander Graphs","summary":"  Evolving relations in real-world networks are often modelled by temporal\ngraphs. Temporal Graph Neural Networks (TGNNs) emerged to model evolutionary\nbehaviour of such graphs by leveraging the message passing primitive at the\ncore of Graph Neural Networks (GNNs). It is well-known that GNNs are vulnerable\nto several issues directly related to the input graph topology, such as\nunder-reaching and over-squashing - we argue that these issues can often get\nexacerbated in temporal graphs, particularly as the result of stale nodes and\nedges. While graph rewiring techniques have seen frequent usage in GNNs to make\nthe graph topology more favourable for message passing, they have not seen any\nmainstream usage on TGNNs. In this work, we propose Temporal Graph Rewiring\n(TGR), the first approach for graph rewiring on temporal graphs, to the best of\nour knowledge. TGR constructs message passing highways between temporally\ndistant nodes in a continuous-time dynamic graph by utilizing expander graph\npropagation, a prominent framework used for graph rewiring on static graphs\nwhich makes minimal assumptions on the underlying graph structure. On the\nchallenging TGB benchmark, TGR achieves state-of-the-art results on\ntgbl-review, tgbl-coin, tgbl-comment and tgbl-flight datasets at the time of\nwriting. For tgbl-review, TGR has 50.5% improvement in MRR over the base TGN\nmodel and 22.2% improvement over the base TNCN model. The significant\nimprovement over base models demonstrates clear benefits of temporal graph\nrewiring.\n","authors":["Katarina Petrović","Shenyang Huang","Farimah Poursafaei","Petar Veličković"],"pdf_url":"https://arxiv.org/pdf/2406.02362v3.pdf","comment":"14 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.16070v2","updated":"2024-10-22T13:40:18Z","published":"2024-10-21T14:48:35Z","title":"On-Device LLMs for SMEs: Challenges and Opportunities","summary":"  This paper presents a systematic review of the infrastructure requirements\nfor deploying Large Language Models (LLMs) on-device within the context of\nsmall and medium-sized enterprises (SMEs), focusing on both hardware and\nsoftware perspectives. From the hardware viewpoint, we discuss the utilization\nof processing units like GPUs and TPUs, efficient memory and storage solutions,\nand strategies for effective deployment, addressing the challenges of limited\ncomputational resources typical in SME settings. From the software perspective,\nwe explore framework compatibility, operating system optimization, and the use\nof specialized libraries tailored for resource-constrained environments. The\nreview is structured to first identify the unique challenges faced by SMEs in\ndeploying LLMs on-device, followed by an exploration of the opportunities that\nboth hardware innovations and software adaptations offer to overcome these\nobstacles. Such a structured review provides practical insights, contributing\nsignificantly to the community by enhancing the technological resilience of\nSMEs in integrating LLMs.\n","authors":["Jeremy Stephen Gabriel Yee","Pai Chet Ng","Zhengkui Wang","Ian McLoughlin","Aik Beng Ng","Simon See"],"pdf_url":"https://arxiv.org/pdf/2410.16070v2.pdf","comment":"9 pages, 1 figure. The work is supported by the SIT-NVIDIA Joint AI\n  Centre"},{"id":"http://arxiv.org/abs/2311.18460v3","updated":"2024-10-22T13:37:04Z","published":"2023-11-30T11:11:26Z","title":"Causal Fairness under Unobserved Confounding: A Neural Sensitivity\n  Framework","summary":"  Fairness for machine learning predictions is widely required in practice for\nlegal, ethical, and societal reasons. Existing work typically focuses on\nsettings without unobserved confounding, even though unobserved confounding can\nlead to severe violations of causal fairness and, thus, unfair predictions. In\nthis work, we analyze the sensitivity of causal fairness to unobserved\nconfounding. Our contributions are three-fold. First, we derive bounds for\ncausal fairness metrics under different sources of unobserved confounding. This\nenables practitioners to examine the sensitivity of their machine learning\nmodels to unobserved confounding in fairness-critical applications. Second, we\npropose a novel neural framework for learning fair predictions, which allows us\nto offer worst-case guarantees of the extent to which causal fairness can be\nviolated due to unobserved confounding. Third, we demonstrate the effectiveness\nof our framework in a series of experiments, including a real-world case study\nabout predicting prison sentences. To the best of our knowledge, ours is the\nfirst work to study causal fairness under unobserved confounding. To this end,\nour work is of direct practical value as a refutation strategy to ensure the\nfairness of predictions in high-stakes applications.\n","authors":["Maresa Schröder","Dennis Frauen","Stefan Feuerriegel"],"pdf_url":"https://arxiv.org/pdf/2311.18460v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12142v2","updated":"2024-10-22T13:32:34Z","published":"2024-06-17T23:08:46Z","title":"Slicing Through Bias: Explaining Performance Gaps in Medical Image\n  Analysis using Slice Discovery Methods","summary":"  Machine learning models have achieved high overall accuracy in medical image\nanalysis. However, performance disparities on specific patient groups pose\nchallenges to their clinical utility, safety, and fairness. This can affect\nknown patient groups - such as those based on sex, age, or disease subtype - as\nwell as previously unknown and unlabeled groups. Furthermore, the root cause of\nsuch observed performance disparities is often challenging to uncover,\nhindering mitigation efforts. In this paper, to address these issues, we\nleverage Slice Discovery Methods (SDMs) to identify interpretable\nunderperforming subsets of data and formulate hypotheses regarding the cause of\nobserved performance disparities. We introduce a novel SDM and apply it in a\ncase study on the classification of pneumothorax and atelectasis from chest\nx-rays. Our study demonstrates the effectiveness of SDMs in hypothesis\nformulation and yields an explanation of previously observed but unexplained\nperformance disparities between male and female patients in widely used chest\nX-ray datasets and models. Our findings indicate shortcut learning in both\nclassification tasks, through the presence of chest drains and ECG wires,\nrespectively. Sex-based differences in the prevalence of these shortcut\nfeatures appear to cause the observed classification performance gap,\nrepresenting a previously underappreciated interaction between shortcut\nlearning and model fairness analyses.\n","authors":["Vincent Olesen","Nina Weng","Aasa Feragen","Eike Petersen"],"pdf_url":"https://arxiv.org/pdf/2406.12142v2.pdf","comment":"MICCAI 2024 Workshop on Fairness of AI in Medical Imaging"},{"id":"http://arxiv.org/abs/2410.17005v1","updated":"2024-10-22T13:25:28Z","published":"2024-10-22T13:25:28Z","title":"Hybrid Generative AI for De Novo Design of Co-Crystals with Enhanced\n  Tabletability","summary":"  Co-crystallization is an accessible way to control physicochemical\ncharacteristics of organic crystals, which finds many biomedical applications.\nIn this work, we present Generative Method for Co-crystal Design (GEMCODE), a\nnovel pipeline for automated co-crystal screening based on the hybridization of\ndeep generative models and evolutionary optimization for broader exploration of\nthe target chemical space. GEMCODE enables fast de novo co-crystal design with\ntarget tabletability profiles, which is crucial for the development of\npharmaceuticals. With a series of experimental studies highlighting validation\nand discovery cases, we show that GEMCODE is effective even under realistic\ncomputational constraints. Furthermore, we explore the potential of language\nmodels in generating co-crystals. Finally, we present numerous previously\nunknown co-crystals predicted by GEMCODE and discuss its potential in\naccelerating drug development.\n","authors":["Nina Gubina","Andrei Dmitrenko","Gleb Solovev","Lyubov Yamshchikova","Oleg Petrov","Ivan Lebedev","Nikita Serov","Grigorii Kirgizov","Nikolay Nikitin","Vladimir Vinogradov"],"pdf_url":"https://arxiv.org/pdf/2410.17005v1.pdf","comment":"Accepted at 38th Conference on Neural Information Processing Systems\n  (NeurIPS)"},{"id":"http://arxiv.org/abs/2410.16991v1","updated":"2024-10-22T13:12:47Z","published":"2024-10-22T13:12:47Z","title":"An Eye for an AI: Evaluating GPT-4o's Visual Perception Skills and\n  Geometric Reasoning Skills Using Computer Graphics Questions","summary":"  CG (Computer Graphics) is a popular field of CS (Computer Science), but many\nstudents find this topic difficult due to it requiring a large number of\nskills, such as mathematics, programming, geometric reasoning, and creativity.\nOver the past few years, researchers have investigated ways to harness the\npower of GenAI (Generative Artificial Intelligence) to improve teaching. In CS,\nmuch of the research has focused on introductory computing. A recent study\nevaluating the performance of an LLM (Large Language Model), GPT-4 (text-only),\non CG questions, indicated poor performance and reliance on detailed\ndescriptions of image content, which often required considerable insight from\nthe user to return reasonable results. So far, no studies have investigated the\nabilities of LMMs (Large Multimodal Models), or multimodal LLMs, to solve CG\nquestions and how these abilities can be used to improve teaching.\n  In this study, we construct two datasets of CG questions requiring varying\ndegrees of visual perception skills and geometric reasoning skills, and\nevaluate the current state-of-the-art LMM, GPT-4o, on the two datasets. We find\nthat although GPT-4o exhibits great potential in solving questions with visual\ninformation independently, major limitations still exist to the accuracy and\nquality of the generated results. We propose several novel approaches for CG\neducators to incorporate GenAI into CG teaching despite these limitations. We\nhope that our guidelines further encourage learning and engagement in CG\nclassrooms.\n","authors":["Tony Haoran Feng","Paul Denny","Burkhard C. Wünsche","Andrew Luxton-Reilly","Jacqueline Whalley"],"pdf_url":"https://arxiv.org/pdf/2410.16991v1.pdf","comment":"8 pages, 8 figures, 1 table, to be published in SIGGRAPH Asia 2024\n  Educator's Forum"},{"id":"http://arxiv.org/abs/2410.10851v2","updated":"2024-10-22T13:08:02Z","published":"2024-10-06T12:53:07Z","title":"LLM Gesticulator: Leveraging Large Language Models for Scalable and\n  Controllable Co-Speech Gesture Synthesis","summary":"  In this work, we present LLM Gesticulator, an LLM-based audio-driven\nco-speech gesture generation framework that synthesizes full-body animations\nthat are rhythmically aligned with the input audio while exhibiting natural\nmovements and editability. Compared to previous work, our model demonstrates\nsubstantial scalability. As the size of the backbone LLM model increases, our\nframework shows proportional improvements in evaluation metrics (a.k.a. scaling\nlaw). Our method also exhibits strong controllability where the content, style\nof the generated gestures can be controlled by text prompt. To the best of our\nknowledge, LLM gesticulator is the first work that use LLM on the co-speech\ngeneration task. Evaluation with existing objective metrics and user studies\nindicate that our framework outperforms prior works.\n","authors":["Haozhou Pang","Tianwei Ding","Lanshan He","Ming Tao","Lu Zhang","Qi Gan"],"pdf_url":"https://arxiv.org/pdf/2410.10851v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16983v1","updated":"2024-10-22T13:05:11Z","published":"2024-10-22T13:05:11Z","title":"Order Matters: Exploring Order Sensitivity in Multimodal Large Language\n  Models","summary":"  Multimodal Large Language Models (MLLMs) utilize multimodal contexts\nconsisting of text, images, or videos to solve various multimodal tasks.\nHowever, we find that changing the order of multimodal input can cause the\nmodel's performance to fluctuate between advanced performance and random\nguessing. This phenomenon exists in both single-modality (text-only or\nimage-only) and mixed-modality (image-text-pair) contexts. Furthermore, we\ndemonstrate that popular MLLMs pay special attention to certain multimodal\ncontext positions, particularly the beginning and end. Leveraging this special\nattention, we place key video frames and important image/text content in\nspecial positions within the context and submit them to the MLLM for inference.\nThis method results in average performance gains of 14.7% for video-caption\nmatching and 17.8% for visual question answering tasks. Additionally, we\npropose a new metric, Position-Invariant Accuracy (PIA), to address order bias\nin MLLM evaluation. Our research findings contribute to a better understanding\nof Multi-Modal In-Context Learning (MMICL) and provide practical strategies for\nenhancing MLLM performance without increasing computational costs.\n","authors":["Zhijie Tan","Xu Chu","Weiping Li","Tong Mo"],"pdf_url":"https://arxiv.org/pdf/2410.16983v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.09553v3","updated":"2024-10-22T13:04:29Z","published":"2024-06-28T08:21:49Z","title":"DPEC: Dual-Path Error Compensation Method for Enhanced Low-Light Image\n  Clarity","summary":"  For the task of low-light image enhancement, deep learning-based algorithms\nhave demonstrated superiority and effectiveness compared to traditional\nmethods. Existing deep learning algorithms are proposed mainly based on the\nRetinex theory but overlook the noise and color distortion present in the\ninput, which frequently results in significant noise amplification and local\ncolor distortion in the final results. To address this, we propose a Dual-Path\nError Compensation method (DPEC), which aims to improve image quality in\nlow-light conditions. DPEC performs precise pixel-level error estimation, which\naccurately captures subtle pixels differences, and independent denoising, which\neffectively removes unnecessary noise. This method restores image brightness\nwhile preserving local texture details and avoiding noise amplification.\nFurthermore, to compensate for the traditional CNN's limited ability to capture\nlong-range semantic information and considering both computational speed and\nresource efficiency, we integrated the VMamba architecture into the backbone of\nDPEC. In addition, we introduced the HIS-Retinex loss to constrain the training\nof DPEC, ensuring that the overall brightness distribution of the images more\nclosely aligns with real-world conditions. Comprehensive quantitative and\nqualitative experimental results demonstrate that our algorithm significantly\noutperforms state-of-the-art methods across six benchmark tests.\n","authors":["Shuang Wang","Qianwen Lu","Yihe Nie","Qingchuan Tao","Yanmei Yu"],"pdf_url":"https://arxiv.org/pdf/2407.09553v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16973v1","updated":"2024-10-22T12:51:51Z","published":"2024-10-22T12:51:51Z","title":"Learning Mathematical Rules with Large Language Models","summary":"  In this paper, we study the ability of large language models to learn\nspecific mathematical rules such as distributivity or simplifying equations. We\npresent an empirical analysis of their ability to generalize these rules, as\nwell as to reuse them in the context of word problems. For this purpose, we\nprovide a rigorous methodology to build synthetic data incorporating such\nrules, and perform fine-tuning of large language models on such data. Our\nexperiments show that our model can learn and generalize these rules to some\nextent, as well as suitably reuse them in the context of word problems.\n","authors":["Antoine Gorceix","Bastien Le Chenadec","Ahmad Rammal","Nelson Vadori","Manuela Veloso"],"pdf_url":"https://arxiv.org/pdf/2410.16973v1.pdf","comment":"4th MATH-AI Workshop at NeurIPS'24"},{"id":"http://arxiv.org/abs/2410.13226v2","updated":"2024-10-22T12:28:28Z","published":"2024-10-17T05:17:01Z","title":"Research on Travel Route Planing Problems Based on Greedy Algorithm","summary":"  The route planning problem based on the greedy algorithm represents a method\nof identifying the optimal or near-optimal route between a given start point\nand end point. In this paper, the PCA method is employed initially to downscale\nthe city evaluation indexes, extract the key principal components, and then\ndownscale the data using the KMO and TOPSIS algorithms, all of which are based\non the MindSpore framework. Secondly, for the dataset that does not pass the\nKMO test, the entropy weight method and TOPSIS method will be employed for\ncomprehensive evaluation. Finally, a route planning algorithm is proposed and\noptimised based on the greedy algorithm, which provides personalised route\ncustomisation according to the different needs of tourists. In addition, the\nlocal travelling efficiency, the time required to visit tourist attractions and\nthe necessary daily breaks are considered in order to reduce the cost and avoid\nfalling into the locally optimal solution.\n","authors":["Yiquan Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13226v2.pdf","comment":"5 pages, 3 figures"},{"id":"http://arxiv.org/abs/2304.07063v4","updated":"2024-10-22T12:28:13Z","published":"2023-04-14T11:35:35Z","title":"Rethinking Complex Queries on Knowledge Graphs with Neural Link\n  Predictors","summary":"  Reasoning on knowledge graphs is a challenging task because it utilizes\nobserved information to predict the missing one. Particularly, answering\ncomplex queries based on first-order logic is one of the crucial tasks to\nverify learning to reason abilities for generalization and composition.\nRecently, the prevailing method is query embedding which learns the embedding\nof a set of entities and treats logic operations as set operations and has\nshown great empirical success. Though there has been much research following\nthe same formulation, many of its claims lack a formal and systematic\ninspection. In this paper, we rethink this formulation and justify many of the\nprevious claims by characterizing the scope of queries investigated previously\nand precisely identifying the gap between its formulation and its goal, as well\nas providing complexity analysis for the currently investigated queries.\nMoreover, we develop a new dataset containing ten new types of queries with\nfeatures that have never been considered and therefore can provide a thorough\ninvestigation of complex queries. Finally, we propose a new neural-symbolic\nmethod, Fuzzy Inference with Truth value (FIT), where we equip the neural link\npredictors with fuzzy logic theory to support end-to-end learning using complex\nqueries with provable reasoning capability. Empirical results show that our\nmethod outperforms previous methods significantly in the new dataset and also\nsurpasses previous methods in the existing dataset at the same time.\n","authors":["Hang Yin","Zihao Wang","Yangqiu Song"],"pdf_url":"https://arxiv.org/pdf/2304.07063v4.pdf","comment":"Received in ICLR 2024"},{"id":"http://arxiv.org/abs/2410.16950v1","updated":"2024-10-22T12:24:41Z","published":"2024-10-22T12:24:41Z","title":"Breaking ReAct Agents: Foot-in-the-Door Attack Will Get You In","summary":"  Following the advancement of large language models (LLMs), the development of\nLLM-based autonomous agents has become increasingly prevalent. As a result, the\nneed to understand the security vulnerabilities of these agents has become a\ncritical task. We examine how ReAct agents can be exploited using a\nstraightforward yet effective method we refer to as the foot-in-the-door\nattack. Our experiments show that indirect prompt injection attacks, prompted\nby harmless and unrelated requests (such as basic calculations) can\nsignificantly increase the likelihood of the agent performing subsequent\nmalicious actions. Our results show that once a ReAct agents thought includes a\nspecific tool or action, the likelihood of executing this tool in the\nsubsequent steps increases significantly, as the agent seldom re-evaluates its\nactions. Consequently, even random, harmless requests can establish a\nfoot-in-the-door, allowing an attacker to embed malicious instructions into the\nagents thought process, making it more susceptible to harmful directives. To\nmitigate this vulnerability, we propose implementing a simple reflection\nmechanism that prompts the agent to reassess the safety of its actions during\nexecution, which can help reduce the success of such attacks.\n","authors":["Itay Nakash","George Kour","Guy Uziel","Ateret Anaby-Tavor"],"pdf_url":"https://arxiv.org/pdf/2410.16950v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16945v1","updated":"2024-10-22T12:20:15Z","published":"2024-10-22T12:20:15Z","title":"IdenBAT: Disentangled Representation Learning for Identity-Preserved\n  Brain Age Transformation","summary":"  Brain age transformation aims to convert reference brain images into\nsynthesized images that accurately reflect the age-specific features of a\ntarget age group. The primary objective of this task is to modify only the\nage-related attributes of the reference image while preserving all other\nage-irrelevant attributes. However, achieving this goal poses substantial\nchallenges due to the inherent entanglement of various image attributes within\nfeatures extracted from a backbone encoder, resulting in simultaneous\nalterations during the image generation. To address this challenge, we propose\na novel architecture that employs disentangled representation learning for\nidentity-preserved brain age transformation called IdenBAT. This approach\nfacilitates the decomposition of image features, ensuring the preservation of\nindividual traits while selectively transforming age-related characteristics to\nmatch those of the target age group. Through comprehensive experiments\nconducted on both 2D and full-size 3D brain datasets, our method adeptly\nconverts input images to target age while retaining individual characteristics\naccurately. Furthermore, our approach demonstrates superiority over existing\nstate-of-the-art regarding performance fidelity.\n","authors":["Junyeong Maeng","Kwanseok Oh","Wonsik Jung","Heung-Il Suk"],"pdf_url":"https://arxiv.org/pdf/2410.16945v1.pdf","comment":"16 pages, 8 figures, 2 tables"},{"id":"http://arxiv.org/abs/2406.08809v2","updated":"2024-10-22T12:18:27Z","published":"2024-06-13T05:00:27Z","title":"Are We There Yet? A Brief Survey of Music Emotion Prediction Datasets,\n  Models and Outstanding Challenges","summary":"  Deep learning models for music have advanced drastically in recent years, but\nhow good are machine learning models at capturing emotion, and what challenges\nare researchers facing? In this paper, we provide a comprehensive overview of\nthe available music-emotion datasets and discuss evaluation standards as well\nas competitions in the field. We also offer a brief overview of various types\nof music emotion prediction models that have been built over the years,\nproviding insights into the diverse approaches within the field. Through this\nexamination, we highlight the challenges that persist in accurately capturing\nemotion in music, including issues related to dataset quality, annotation\nconsistency, and model generalization. Additionally, we explore the impact of\ndifferent modalities, such as audio, MIDI, and physiological signals, on the\neffectiveness of emotion prediction models. Recognizing the dynamic nature of\nthis field, we have complemented our findings with an accompanying GitHub\nrepository. This repository contains a comprehensive list of music emotion\ndatasets and recent predictive models.\n","authors":["Jaeyong Kang","Dorien Herremans"],"pdf_url":"https://arxiv.org/pdf/2406.08809v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16930v1","updated":"2024-10-22T12:00:58Z","published":"2024-10-22T12:00:58Z","title":"Math Neurosurgery: Isolating Language Models' Math Reasoning Abilities\n  Using Only Forward Passes","summary":"  Math reasoning is a highly active area of Large Language Model (LLM) research\nbecause it is a hallmark of artificial intelligence. However, few works have\nexplored how math reasoning is encoded within LLM parameters and if it is a\nskill that can be isolated within a model. Doing so could allow targeted\nintervention to improve math performance without altering non-math behavior and\nfoster understanding of how models encode math reasoning. We introduce Math\nNeurosurgery (MathNeuro), a method for isolating math-specific parameters in\nLLMs using only forward passes. MathNeuro builds on existing work by using\nweights and activations to calculate parameter importance, but isolates\nmath-specific parameters by removing those important for general language\ntasks. Pruning parameters MathNeuro identifies deletes a LLM's math reasoning\nability without destroying its general language ability. Scaling these\nparameters by a small constant improves a pretrained or instruction-tuned LLM's\nperformance by 4-17% on GSM8K while leaving non-math behavior unaltered.\nMathNeuro is also data efficient: most of its effectiveness holds when\nidentifying math-specific parameters using a single sample. MathNeuro\nhighlights the potential for future work to intervene on math-specific\nparameters.\n","authors":["Bryan R. Christ","Zack Gottesman","Jonathan Kropko","Thomas Hartvigsen"],"pdf_url":"https://arxiv.org/pdf/2410.16930v1.pdf","comment":"21 pages, 29 figures"},{"id":"http://arxiv.org/abs/2410.16927v1","updated":"2024-10-22T11:58:54Z","published":"2024-10-22T11:58:54Z","title":"Revealing Hidden Bias in AI: Lessons from Large Language Models","summary":"  As large language models (LLMs) become integral to recruitment processes,\nconcerns about AI-induced bias have intensified. This study examines biases in\ncandidate interview reports generated by Claude 3.5 Sonnet, GPT-4o, Gemini 1.5,\nand Llama 3.1 405B, focusing on characteristics such as gender, race, and age.\nWe evaluate the effectiveness of LLM-based anonymization in reducing these\nbiases. Findings indicate that while anonymization reduces certain biases,\nparticularly gender bias, the degree of effectiveness varies across models and\nbias types. Notably, Llama 3.1 405B exhibited the lowest overall bias.\nMoreover, our methodology of comparing anonymized and non-anonymized data\nreveals a novel approach to assessing inherent biases in LLMs beyond\nrecruitment applications. This study underscores the importance of careful LLM\nselection and suggests best practices for minimizing bias in AI applications,\npromoting fairness and inclusivity.\n","authors":["Django Beatty","Kritsada Masanthia","Teepakorn Kaphol","Niphan Sethi"],"pdf_url":"https://arxiv.org/pdf/2410.16927v1.pdf","comment":"13 pages, 18 figures. This paper presents a technical analysis of\n  bias in large language models, focusing on bias detection and mitigation"},{"id":"http://arxiv.org/abs/2410.16924v1","updated":"2024-10-22T11:56:34Z","published":"2024-10-22T11:56:34Z","title":"SleepCoT: A Lightweight Personalized Sleep Health Model via\n  Chain-of-Thought Distillation","summary":"  We present a novel approach to personalized sleep health management using\nfew-shot Chain-of-Thought (CoT) distillation, enabling small-scale language\nmodels (> 2B parameters) to rival the performance of large language models\n(LLMs) in specialized health domains. Our method simultaneously distills\nproblem-solving strategies, long-tail expert knowledge, and personalized\nrecommendation capabilities from larger models into more efficient, compact\nmodels. Unlike existing systems, our approach offers three key functionalities:\ngenerating personalized sleep health recommendations, supporting user-specific\nfollow-up inquiries, and providing responses to domain-specific knowledge\nquestions. We focus on sleep health due to its measurability via wearable\ndevices and its impact on overall well-being. Our experimental setup, involving\nGPT-4o for data synthesis, Qwen-max for instruction set creation, and Qwen2.5\n1.5B for model distillation, demonstrates significant improvements over\nbaseline small-scale models in penalization, reasoning, and knowledge\napplication. Experiments using 100 simulated sleep reports and 1,000\ndomain-specific questions shows our model achieves comparable performance to\nlarger models while maintaining efficiency for real-world deployment. This\nresearch not only advances AI-driven health management but also provides a\nnovel approach to leveraging LLM capabilities in resource-constrained\nenvironments, potentially enhancing the accessibility of personalized\nhealthcare solutions.\n","authors":["Huimin Zheng","Xiaofeng Xing","Xiangmin Xu"],"pdf_url":"https://arxiv.org/pdf/2410.16924v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07114v3","updated":"2024-10-22T11:55:46Z","published":"2024-09-19T19:48:31Z","title":"System 2 thinking in OpenAI's o1-preview model: Near-perfect performance\n  on a mathematics exam","summary":"  The processes underlying human cognition are often divided into System 1,\nwhich involves fast, intuitive thinking, and System 2, which involves slow,\ndeliberate reasoning. Previously, large language models were criticized for\nlacking the deeper, more analytical capabilities of System 2. In September\n2024, OpenAI introduced the o1 model series, designed to handle System 2-like\nreasoning. While OpenAI's benchmarks are promising, independent validation is\nstill needed. In this study, we tested the o1-preview model twice on the Dutch\n'Mathematics B' final exam. It scored a near-perfect 76 and 74 out of 76\npoints. For context, only 24 out of 16,414 students in the Netherlands achieved\na perfect score. By comparison, the GPT-4o model scored 66 and 62 out of 76,\nwell above the Dutch average of 40.63 points. Neither model had access to the\nexam figures. Since there was a risk of model contamination (i.e., the\nknowledge cutoff of o1-preview and GPT-4o was after the exam was published\nonline), we repeated the procedure with a new Mathematics B exam that was\npublished after the cutoff date. The results again indicated that o1-preview\nperformed strongly (97.8th percentile), which suggests that contamination was\nnot a factor. We also show that there is some variability in the output of\no1-preview, which means that sometimes there is 'luck' (the answer is correct)\nor 'bad luck' (the output has diverged into something that is incorrect). We\ndemonstrate that a self-consistency approach, where repeated prompts are given\nand the most common answer is selected, is a useful strategy for identifying\nthe correct answer. It is concluded that while OpenAI's new model series holds\ngreat potential, certain risks must be considered.\n","authors":["Joost de Winter","Dimitra Dodou","Yke Bauke Eisma"],"pdf_url":"https://arxiv.org/pdf/2410.07114v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16919v1","updated":"2024-10-22T11:52:22Z","published":"2024-10-22T11:52:22Z","title":"EnvBridge: Bridging Diverse Environments with Cross-Environment\n  Knowledge Transfer for Embodied AI","summary":"  In recent years, Large Language Models (LLMs) have demonstrated high\nreasoning capabilities, drawing attention for their applications as agents in\nvarious decision-making processes. One notably promising application of LLM\nagents is robotic manipulation. Recent research has shown that LLMs can\ngenerate text planning or control code for robots, providing substantial\nflexibility and interaction capabilities. However, these methods still face\nchallenges in terms of flexibility and applicability across different\nenvironments, limiting their ability to adapt autonomously. Current approaches\ntypically fall into two categories: those relying on environment-specific\npolicy training, which restricts their transferability, and those generating\ncode actions based on fixed prompts, which leads to diminished performance when\nconfronted with new environments. These limitations significantly constrain the\ngeneralizability of agents in robotic manipulation. To address these\nlimitations, we propose a novel method called EnvBridge. This approach involves\nthe retention and transfer of successful robot control codes from source\nenvironments to target environments. EnvBridge enhances the agent's\nadaptability and performance across diverse settings by leveraging insights\nfrom multiple environments. Notably, our approach alleviates environmental\nconstraints, offering a more flexible and generalizable solution for robotic\nmanipulation tasks. We validated the effectiveness of our method using robotic\nmanipulation benchmarks: RLBench, MetaWorld, and CALVIN. Our experiments\ndemonstrate that LLM agents can successfully leverage diverse knowledge sources\nto solve complex tasks. Consequently, our approach significantly enhances the\nadaptability and robustness of robotic manipulation agents in planning across\ndiverse environments.\n","authors":["Tomoyuki Kagaya","Yuxuan Lou","Thong Jing Yuan","Subramanian Lakshmi","Jayashree Karlekar","Sugiri Pranata","Natsuki Murakami","Akira Kinose","Koki Oguri","Felix Wick","Yang You"],"pdf_url":"https://arxiv.org/pdf/2410.16919v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17066v2","updated":"2024-10-22T11:47:04Z","published":"2024-09-25T16:25:45Z","title":"VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large\n  Language Models","summary":"  Scaling model size significantly challenges the deployment and inference of\nLarge Language Models (LLMs). Due to the redundancy in LLM weights, recent\nresearch has focused on pushing weight-only quantization to extremely low-bit\n(even down to 2 bits). It reduces memory requirements, optimizes storage costs,\nand decreases memory bandwidth needs during inference. However, due to\nnumerical representation limitations, traditional scalar-based weight\nquantization struggles to achieve such extreme low-bit. Recent research on\nVector Quantization (VQ) for LLMs has demonstrated the potential for extremely\nlow-bit model quantization by compressing vectors into indices using lookup\ntables.\n  In this paper, we introduce Vector Post-Training Quantization (VPTQ) for\nextremely low-bit quantization of LLMs. We use Second-Order Optimization to\nformulate the LLM VQ problem and guide our quantization algorithm design by\nsolving the optimization. We further refine the weights using\nChannel-Independent Second-Order Optimization for a granular VQ. In addition,\nby decomposing the optimization problem, we propose a brief and effective\ncodebook initialization algorithm. We also extend VPTQ to support residual and\noutlier quantization, which enhances model accuracy and further compresses the\nmodel. Our experimental results show that VPTQ reduces model quantization\nperplexity by $0.01$-$0.34$ on LLaMA-2, $0.38$-$0.68$ on Mistral-7B,\n$4.41$-$7.34$ on LLaMA-3 over SOTA at 2-bit, with an average accuracy\nimprovement of $0.79$-$1.5\\%$ on LLaMA-2, $1\\%$ on Mistral-7B, $11$-$22\\%$ on\nLLaMA-3 on QA tasks on average. We only utilize $10.4$-$18.6\\%$ of the\nquantization algorithm execution time, resulting in a $1.6$-$1.8\\times$\nincrease in inference throughput compared to SOTA.\n","authors":["Yifei Liu","Jicheng Wen","Yang Wang","Shengyu Ye","Li Lyna Zhang","Ting Cao","Cheng Li","Mao Yang"],"pdf_url":"https://arxiv.org/pdf/2409.17066v2.pdf","comment":"EMNLP 2024, Main, Poster"},{"id":"http://arxiv.org/abs/2410.16908v1","updated":"2024-10-22T11:28:39Z","published":"2024-10-22T11:28:39Z","title":"Mitigating Vanishing Activations in Deep CapsNets Using Channel Pruning","summary":"  Capsule Networks outperform Convolutional Neural Networks in learning the\npart-whole relationships with viewpoint invariance, and the credit goes to\ntheir multidimensional capsules. It was assumed that increasing the number of\ncapsule layers in the capsule networks would enhance the model performance.\nHowever, recent studies found that Capsule Networks lack scalability due to\nvanishing activations in the capsules of deeper layers. This paper thoroughly\ninvestigates the vanishing activation problem in deep Capsule Networks. To\nanalyze this issue and understand how increasing capsule dimensions can\nfacilitate deeper networks, various Capsule Network models are constructed and\nevaluated with different numbers of capsules, capsule dimensions, and\nintermediate layers for this paper. Unlike traditional model pruning, which\nreduces the number of model parameters and expedites model training, this study\nuses pruning to mitigate the vanishing activations in the deeper capsule\nlayers. In addition, the backbone network and capsule layers are pruned with\ndifferent pruning ratios to reduce the number of inactive capsules and achieve\nbetter model accuracy than the unpruned models.\n","authors":["Siddharth Sahu","Abdulrahman Altahhan"],"pdf_url":"https://arxiv.org/pdf/2410.16908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15978v2","updated":"2024-10-22T10:56:35Z","published":"2024-10-21T13:05:33Z","title":"PROMPTHEUS: A Human-Centered Pipeline to Streamline SLRs with LLMs","summary":"  The growing volume of academic publications poses significant challenges for\nresearchers conducting timely and accurate Systematic Literature Reviews,\nparticularly in fast-evolving fields like artificial intelligence. This growth\nof academic literature also makes it increasingly difficult for lay people to\naccess scientific knowledge effectively, meaning academic literature is often\nmisrepresented in the popular press and, more broadly, in society. Traditional\nSLR methods are labor-intensive and error-prone, and they struggle to keep up\nwith the rapid pace of new research. To address these issues, we developed\n\\textit{PROMPTHEUS}: an AI-driven pipeline solution that automates the SLR\nprocess using Large Language Models. We aimed to enhance efficiency by reducing\nthe manual workload while maintaining the precision and coherence required for\ncomprehensive literature synthesis. PROMPTHEUS automates key stages of the SLR\nprocess, including systematic search, data extraction, topic modeling using\nBERTopic, and summarization with transformer models. Evaluations conducted\nacross five research domains demonstrate that PROMPTHEUS reduces review time,\nachieves high precision, and provides coherent topic organization, offering a\nscalable and effective solution for conducting literature reviews in an\nincreasingly crowded research landscape. In addition, such tools may reduce the\nincreasing mistrust in science by making summarization more accessible to\nlaypeople.\n  The code for this project can be found on the GitHub repository at\nhttps://github.com/joaopftorres/PROMPTHEUS.git\n","authors":["João Pedro Fernandes Torres","Catherine Mulligan","Joaquim Jorge","Catarina Moreira"],"pdf_url":"https://arxiv.org/pdf/2410.15978v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00467v2","updated":"2024-10-22T10:47:13Z","published":"2024-10-01T07:49:24Z","title":"Dynamic Planning for LLM-based Graphical User Interface Automation","summary":"  The advent of large language models (LLMs) has spurred considerable interest\nin advancing autonomous LLMs-based agents, particularly in intriguing\napplications within smartphone graphical user interfaces (GUIs). When presented\nwith a task goal, these agents typically emulate human actions within a GUI\nenvironment until the task is completed. However, a key challenge lies in\ndevising effective plans to guide action prediction in GUI tasks, though\nplanning have been widely recognized as effective for decomposing complex tasks\ninto a series of steps. Specifically, given the dynamic nature of environmental\nGUIs following action execution, it is crucial to dynamically adapt plans based\non environmental feedback and action history.We show that the widely-used ReAct\napproach fails due to the excessively long historical dialogues. To address\nthis challenge, we propose a novel approach called Dynamic Planning of Thoughts\n(D-PoT) for LLM-based GUI agents.D-PoT involves the dynamic adjustment of\nplanning based on the environmental feedback and execution history.\nExperimental results reveal that the proposed D-PoT significantly surpassed the\nstrong GPT-4V baseline by +12.7% (34.66% $\\rightarrow$ 47.36%) in accuracy. The\nanalysis highlights the generality of dynamic planning in different backbone\nLLMs, as well as the benefits in mitigating hallucinations and adapting to\nunseen tasks. Code is available at https://github.com/sqzhang-lazy/D-PoT.\n","authors":["Shaoqing Zhang","Zhuosheng Zhang","Kehai Chen","Xinbei Ma","Muyun Yang","Tiejun Zhao","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.00467v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15955v4","updated":"2024-10-22T10:41:58Z","published":"2024-09-24T10:36:40Z","title":"A Historical Trajectory Assisted Optimization Method for Zeroth-Order\n  Federated Learning","summary":"  Federated learning heavily relies on distributed gradient descent techniques.\nIn the situation where gradient information is not available, the gradients\nneed to be estimated from zeroth-order information, which typically involves\ncomputing finite-differences along isotropic random directions. This method\nsuffers from high estimation errors, as the geometric features of the objective\nlandscape may be overlooked during the isotropic sampling. In this work, we\npropose a non-isotropic sampling method to improve the gradient estimation\nprocedure. Gradients in our method are estimated in a subspace spanned by\nhistorical trajectories of solutions, aiming to encourage the exploration of\npromising regions and hence improve the convergence. The proposed method uses a\ncovariance matrix for sampling which is a convex combination of two parts. The\nfirst part is a thin projection matrix containing the basis of the subspace\nwhich is designed to improve the exploitation ability. The second part is the\nhistorical trajectories. We implement this method in zeroth-order federated\nsettings, and show that the convergence rate aligns with existing ones while\nintroducing no significant overheads in communication or local computation. The\neffectiveness of our proposal is verified on several numerical experiments in\ncomparison to several commonly-used zeroth-order federated optimization\nalgorithms.\n","authors":["Chenlin Wu","Xiaoyu He","Zike Li","Jing Gong","Zibin Zheng"],"pdf_url":"https://arxiv.org/pdf/2409.15955v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16882v1","updated":"2024-10-22T10:36:15Z","published":"2024-10-22T10:36:15Z","title":"Large Language Model-based Augmentation for Imbalanced Node\n  Classification on Text-Attributed Graphs","summary":"  Node classification on graphs frequently encounters the challenge of class\nimbalance, leading to biased performance and posing significant risks in\nreal-world applications. Although several data-centric solutions have been\nproposed, none of them focus on Text-Attributed Graphs (TAGs), and therefore\noverlook the potential of leveraging the rich semantics encoded in textual\nfeatures for boosting the classification of minority nodes. Given this crucial\ngap, we investigate the possibility of augmenting graph data in the text space,\nleveraging the textual generation power of Large Language Models (LLMs) to\nhandle imbalanced node classification on TAGs. Specifically, we propose a novel\napproach called LA-TAG (LLM-based Augmentation on Text-Attributed Graphs),\nwhich prompts LLMs to generate synthetic texts based on existing node texts in\nthe graph. Furthermore, to integrate these synthetic text-attributed nodes into\nthe graph, we introduce a text-based link predictor to connect the synthesized\nnodes with the existing nodes. Our experiments across multiple datasets and\nevaluation metrics show that our framework significantly outperforms\ntraditional non-textual-based data augmentation strategies and specific node\nimbalance solutions. This highlights the promise of using LLMs to resolve\nimbalance issues on TAGs.\n","authors":["Leyao Wang","Yu Wang","Bo Ni","Yuying Zhao","Tyler Derr"],"pdf_url":"https://arxiv.org/pdf/2410.16882v1.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2405.15319v2","updated":"2024-10-22T10:31:59Z","published":"2024-05-24T08:00:00Z","title":"Stacking Your Transformers: A Closer Look at Model Growth for Efficient\n  LLM Pre-Training","summary":"  LLMs are computationally expensive to pre-train due to their large scale.\nModel growth emerges as a promising approach by leveraging smaller models to\naccelerate the training of larger ones. However, the viability of these model\ngrowth methods in efficient LLM pre-training remains underexplored. This work\nidentifies three critical $\\underline{\\textit{O}}$bstacles: ($\\textit{O}$1)\nlack of comprehensive evaluation, ($\\textit{O}$2) untested viability for\nscaling, and ($\\textit{O}$3) lack of empirical guidelines. To tackle\n$\\textit{O}$1, we summarize existing approaches into four atomic growth\noperators and systematically evaluate them in a standardized LLM pre-training\nsetting. Our findings reveal that a depthwise stacking operator, called\n$G_{\\text{stack}}$, exhibits remarkable acceleration in training, leading to\ndecreased loss and improved overall performance on eight standard NLP\nbenchmarks compared to strong baselines. Motivated by these promising results,\nwe conduct extensive experiments to delve deeper into $G_{\\text{stack}}$ to\naddress $\\textit{O}$2 and $\\textit{O}$3. For $\\textit{O}$2 (untested\nscalability), our study shows that $G_{\\text{stack}}$ is scalable and\nconsistently performs well, with experiments up to 7B LLMs after growth and\npre-training LLMs with 750B tokens. For example, compared to a conventionally\ntrained 7B model using 300B tokens, our $G_{\\text{stack}}$ model converges to\nthe same loss with 194B tokens, resulting in a 54.6\\% speedup. We further\naddress $\\textit{O}$3 (lack of empirical guidelines) by formalizing guidelines\nto determine growth timing and growth factor for $G_{\\text{stack}}$, making it\npractical in general LLM pre-training. We also provide in-depth discussions and\ncomprehensive ablation studies of $G_{\\text{stack}}$. Our code and pre-trained\nmodel are available at https://llm-stacking.github.io.\n","authors":["Wenyu Du","Tongxu Luo","Zihan Qiu","Zeyu Huang","Yikang Shen","Reynold Cheng","Yike Guo","Jie Fu"],"pdf_url":"https://arxiv.org/pdf/2405.15319v2.pdf","comment":"NeurIPS 2024 Spotlight"},{"id":"http://arxiv.org/abs/2410.16879v1","updated":"2024-10-22T10:31:23Z","published":"2024-10-22T10:31:23Z","title":"Contrasting Attitudes Towards Current and Future AI Applications for\n  Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study","summary":"  Objectives: To investigate clinicians' attitudes towards current automated\ninterpretation of ECG and novel AI technologies and their perception of\ncomputer-assisted interpretation. Materials and Methods: We conducted a series\nof interviews with clinicians in the UK. Our study: (i) explores the potential\nfor AI, specifically future 'human-like' computing approaches, to facilitate\nECG interpretation and support clinical decision making, and (ii) elicits their\nopinions about the importance of explainability and trustworthiness of AI\nalgorithms. Results: We performed inductive thematic analysis on interview\ntranscriptions from 23 clinicians and identified the following themes: (i) a\nlack of trust in current systems, (ii) positive attitudes towards future AI\napplications and requirements for these, (iii) the relationship between the\naccuracy and explainability of algorithms, and (iv) opinions on education,\npossible deskilling, and the impact of AI on clinical competencies. Discussion:\nClinicians do not trust current computerised methods, but welcome future 'AI'\ntechnologies. Where clinicians trust future AI interpretation to be accurate,\nthey are less concerned that it is explainable. They also preferred ECG\ninterpretation that demonstrated the results of the algorithm visually. Whilst\nclinicians do not fear job losses, they are concerned about deskilling and the\nneed to educate the workforce to use AI responsibly. Conclusion: Clinicians are\npositive about the future application of AI in clinical decision-making.\nAccuracy is a key factor of uptake and visualisations are preferred over\ncurrent computerised methods. This is viewed as a potential means of training\nand upskilling, in contrast to the deskilling that automation might be\nperceived to bring.\n","authors":["Lukas Hughes-Noehrer","Leda Channer","Gabriel Strain","Gregory Yates","Richard Body","Caroline Jay"],"pdf_url":"https://arxiv.org/pdf/2410.16879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.17442v4","updated":"2024-10-22T10:30:19Z","published":"2024-02-27T11:57:28Z","title":"Insights from the Usage of the Ansible Lightspeed Code Completion\n  Service","summary":"  The availability of Large Language Models (LLMs) which can generate code, has\nmade it possible to create tools that improve developer productivity.\nIntegrated development environments or IDEs which developers use to write\nsoftware are often used as an interface to interact with LLMs. Although many\nsuch tools have been released, almost all of them focus on general-purpose\nprogramming languages. Domain-specific languages, such as those crucial for\nInformation Technology (IT) automation, have not received much attention.\nAnsible is one such YAML-based IT automation-specific language. Ansible\nLightspeed is an LLM-based service designed explicitly to generate Ansible\nYAML, given natural language prompt.\n  In this paper, we present the design and implementation of the Ansible\nLightspeed service. We then evaluate its utility to developers using diverse\nindicators, including extended utilization, analysis of user edited\nsuggestions, as well as user sentiments analysis. The evaluation is based on\ndata collected for 10,696 real users including 3,910 returning users. The code\nfor Ansible Lightspeed service and the analysis framework is made available for\nothers to use.\n  To our knowledge, our study is the first to involve thousands of users of\ncode assistants for domain-specific languages. We are also the first code\ncompletion tool to present N-Day user retention figures, which is 13.66% on Day\n30. We propose an improved version of user acceptance rate, called Strong\nAcceptance rate, where a suggestion is considered accepted only if less than\n50% of it is edited and these edits do not change critical parts of the\nsuggestion. By focusing on Ansible, Lightspeed is able to achieve a strong\nacceptance rate of 49.08% for multi-line Ansible task suggestions. With our\nfindings we provide insights into the effectiveness of small, dedicated models\nin a domain-specific context.\n","authors":["Priyam Sahoo","Saurabh Pujar","Ganesh Nalawade","Richard Gebhardt","Louis Mandel","Luca Buratti"],"pdf_url":"https://arxiv.org/pdf/2402.17442v4.pdf","comment":"This paper has been published at the 39th IEEE/ACM International\n  Conference on Automated Software Engineering (ASE 2024), Industry Showcase\n  under the title \"Ansible Lightspeed: A Code Generation Service for IT\n  Automation\""},{"id":"http://arxiv.org/abs/2410.16864v1","updated":"2024-10-22T10:06:50Z","published":"2024-10-22T10:06:50Z","title":"Pedestrian motion prediction evaluation for urban autonomous driving","summary":"  Pedestrian motion prediction is a key part of the modular-based autonomous\ndriving pipeline, ensuring safe, accurate, and timely awareness of human\nagents' possible future trajectories. The autonomous vehicle can use this\ninformation to prevent any possible accidents and create a comfortable and\npleasant driving experience for the passengers and pedestrians. A wealth of\nresearch was done on the topic from the authors of robotics, computer vision,\nintelligent transportation systems, and other fields. However, a relatively\nunexplored angle is the integration of the state-of-art solutions into existing\nautonomous driving stacks and evaluating them in real-life conditions rather\nthan sanitized datasets. We analyze selected publications with provided\nopen-source solutions and provide a perspective obtained by integrating them\ninto existing Autonomous Driving framework - Autoware Mini and performing\nexperiments in natural urban conditions in Tartu, Estonia to determine\nvaluability of traditional motion prediction metrics. This perspective should\nbe valuable to any potential autonomous driving or robotics engineer looking\nfor the real-world performance of the existing state-of-art pedestrian motion\nprediction problem. The code with instructions on accessing the dataset is\navailable at https://github.com/dmytrozabolotnii/autoware_mini.\n","authors":["Dmytro Zabolotnii","Yar Muhammad","Naveed Muhammad"],"pdf_url":"https://arxiv.org/pdf/2410.16864v1.pdf","comment":"7 pages, 2 figures, 4 tables This work has been submitted to the IEEE\n  for possible publication"},{"id":"http://arxiv.org/abs/2402.02500v3","updated":"2024-10-22T09:42:39Z","published":"2024-02-04T14:18:45Z","title":"Point Cloud Matters: Rethinking the Impact of Different Observation\n  Spaces on Robot Learning","summary":"  In robot learning, the observation space is crucial due to the distinct\ncharacteristics of different modalities, which can potentially become a\nbottleneck alongside policy design. In this study, we explore the influence of\nvarious observation spaces on robot learning, focusing on three predominant\nmodalities: RGB, RGB-D, and point cloud. We introduce OBSBench, a benchmark\ncomprising two simulators and 125 tasks, along with standardized pipelines for\nvarious encoders and policy baselines. Extensive experiments on diverse\ncontact-rich manipulation tasks reveal a notable trend: point cloud-based\nmethods, even those with the simplest designs, frequently outperform their RGB\nand RGB-D counterparts. This trend persists in both scenarios: training from\nscratch and utilizing pre-training. Furthermore, our findings demonstrate that\npoint cloud observations often yield better policy performance and\nsignificantly stronger generalization capabilities across various geometric and\nvisual conditions. These outcomes suggest that the 3D point cloud is a valuable\nobservation modality for intricate robotic tasks. We also suggest that\nincorporating both appearance and coordinate information can enhance the\nperformance of point cloud methods. We hope our work provides valuable insights\nand guidance for designing more generalizable and robust robotic models. Codes\nare available at https://github.com/HaoyiZhu/PointCloudMatters.\n","authors":["Haoyi Zhu","Yating Wang","Di Huang","Weicai Ye","Wanli Ouyang","Tong He"],"pdf_url":"https://arxiv.org/pdf/2402.02500v3.pdf","comment":"38th Conference on Neural Information Processing Systems (NeurIPS\n  2024) Track on Datasets and Benchmarks"},{"id":"http://arxiv.org/abs/2410.16845v1","updated":"2024-10-22T09:33:29Z","published":"2024-10-22T09:33:29Z","title":"Fast Graph Sharpness-Aware Minimization for Enhancing and Accelerating\n  Few-Shot Node Classification","summary":"  Graph Neural Networks (GNNs) have shown superior performance in node\nclassification. However, GNNs perform poorly in the Few-Shot Node\nClassification (FSNC) task that requires robust generalization to make accurate\npredictions for unseen classes with limited labels. To tackle the challenge, we\npropose the integration of Sharpness-Aware Minimization (SAM)--a technique\ndesigned to enhance model generalization by finding a flat minimum of the loss\nlandscape--into GNN training. The standard SAM approach, however, consists of\ntwo forward-backward steps in each training iteration, doubling the\ncomputational cost compared to the base optimizer (e.g., Adam). To mitigate\nthis drawback, we introduce a novel algorithm, Fast Graph Sharpness-Aware\nMinimization (FGSAM), that integrates the rapid training of Multi-Layer\nPerceptrons (MLPs) with the superior performance of GNNs. Specifically, we\nutilize GNNs for parameter perturbation while employing MLPs to minimize the\nperturbed loss so that we can find a flat minimum with good generalization more\nefficiently. Moreover, our method reutilizes the gradient from the perturbation\nphase to incorporate graph topology into the minimization process at almost\nzero additional cost. To further enhance training efficiency, we develop FGSAM+\nthat executes exact perturbations periodically. Extensive experiments\ndemonstrate that our proposed algorithm outperforms the standard SAM with lower\ncomputational costs in FSNC tasks. In particular, our FGSAM+ as a SAM variant\noffers a faster optimization than the base optimizer in most cases. In addition\nto FSNC, our proposed methods also demonstrate competitive performance in the\nstandard node classification task for heterophilic graphs, highlighting the\nbroad applicability. The code is available at\nhttps://github.com/draym28/FGSAM_NeurIPS24.\n","authors":["Yihong Luo","Yuhan Chen","Siya Qiu","Yiwei Wang","Chen Zhang","Yan Zhou","Xiaochun Cao","Jing Tang"],"pdf_url":"https://arxiv.org/pdf/2410.16845v1.pdf","comment":"NeurIPS24; The first two authors contributed equally to this work"},{"id":"http://arxiv.org/abs/2404.03348v2","updated":"2024-10-22T09:31:49Z","published":"2024-04-04T10:28:55Z","title":"Knowledge Distillation-Based Model Extraction Attack using GAN-based\n  Private Counterfactual Explanations","summary":"  In recent years, there has been a notable increase in the deployment of\nmachine learning (ML) models as services (MLaaS) across diverse production\nsoftware applications. In parallel, explainable AI (XAI) continues to evolve,\naddressing the necessity for transparency and trustworthiness in ML models. XAI\ntechniques aim to enhance the transparency of ML models by providing insights,\nin terms of model's explanations, into their decision-making process.\nSimultaneously, some MLaaS platforms now offer explanations alongside the ML\nprediction outputs. This setup has elevated concerns regarding vulnerabilities\nin MLaaS, particularly in relation to privacy leakage attacks such as model\nextraction attacks (MEA). This is due to the fact that explanations can unveil\ninsights about the inner workings of the model which could be exploited by\nmalicious users. In this work, we focus on investigating how model\nexplanations, particularly counterfactual explanations (CFs), can be exploited\nfor performing MEA within the MLaaS platform. We also delve into assessing the\neffectiveness of incorporating differential privacy (DP) as a mitigation\nstrategy. To this end, we first propose a novel approach for MEA based on\nKnowledge Distillation (KD) to enhance the efficiency of extracting a\nsubstitute model of a target model exploiting CFs, without any knowledge about\nthe training data distribution by the attacker. Then, we advise an approach for\ntraining CF generators incorporating DP to generate private CFs. We conduct\nthorough experimental evaluations on real-world datasets and demonstrate that\nour proposed KD-based MEA can yield a high-fidelity substitute model with a\nreduced number of queries with respect to baseline approaches. Furthermore, our\nfindings reveal that including a privacy layer can allow mitigating the MEA.\nHowever, on the account of the quality of CFs, impacts the performance of the\nexplanations.\n","authors":["Fatima Ezzeddine","Omran Ayoub","Silvia Giordano"],"pdf_url":"https://arxiv.org/pdf/2404.03348v2.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2404.16656v2","updated":"2024-10-22T09:30:36Z","published":"2024-04-25T14:48:29Z","title":"A Self-Organizing Clustering System for Unsupervised Distribution Shift\n  Detection","summary":"  Modeling non-stationary data is a challenging problem in the field of\ncontinual learning, and data distribution shifts may result in negative\nconsequences on the performance of a machine learning model. Classic learning\ntools are often vulnerable to perturbations of the input covariates, and are\nsensitive to outliers and noise, and some tools are based on rigid algebraic\nassumptions. Distribution shifts are frequently occurring due to changes in raw\nmaterials for production, seasonality, a different user base, or even\nadversarial attacks. Therefore, there is a need for more effective distribution\nshift detection techniques. In this work, we propose a continual learning\nframework for monitoring and detecting distribution changes. We explore the\nproblem in a latent space generated by a bio-inspired self-organizing\nclustering and statistical aspects of the latent space. In particular, we\ninvestigate the projections made by two topology-preserving maps: the\nSelf-Organizing Map and the Scale Invariant Map. Our method can be applied in\nboth a supervised and an unsupervised context. We construct the assessment of\nchanges in the data distribution as a comparison of Gaussian signals, making\nthe proposed method fast and robust. We compare it to other unsupervised\ntechniques, specifically Principal Component Analysis (PCA) and Kernel-PCA. Our\ncomparison involves conducting experiments using sequences of images (based on\nMNIST and injected shifts with adversarial samples), chemical sensor\nmeasurements, and the environmental variable related to ozone levels. The\nempirical study reveals the potential of the proposed approach.\n","authors":["Sebastián Basterrech","Line Clemmensen","Gerardo Rubino"],"pdf_url":"https://arxiv.org/pdf/2404.16656v2.pdf","comment":"Revised version of the accepted manuscript to IJCNN'2024. Main\n  corrections were in Section 2.2 and Section 3.3. In Section 2.2 was corrected\n  expression (3), and in Section 3.3 in the definition of the elements of the\n  matrix $D$ it was a typo where $\\phi(x)$ was written instead of $x$"},{"id":"http://arxiv.org/abs/2410.16842v1","updated":"2024-10-22T09:25:04Z","published":"2024-10-22T09:25:04Z","title":"Assessment of Transformer-Based Encoder-Decoder Model for Human-Like\n  Summarization","summary":"  In recent times, extracting valuable information from large text is making\nsignificant progress. Especially in the current era of social media, people\nexpect quick bites of information. Automatic text summarization seeks to tackle\nthis by slimming large texts down into more manageable summaries. This\nimportant research area can aid in decision-making by digging out salient\ncontent from large text. With the progress in deep learning models, significant\nwork in language models has emerged. The encoder-decoder framework in deep\nlearning has become the central approach for automatic text summarization. This\nwork leverages transformer-based BART model for human-like summarization which\nis an open-ended problem with many challenges. On training and fine-tuning the\nencoder-decoder model, it is tested with diverse sample articles and the\nquality of summaries of diverse samples is assessed based on human evaluation\nparameters. Further, the finetuned model performance is compared with the\nbaseline pretrained model based on evaluation metrics like ROUGE score and\nBERTScore. Additionally, domain adaptation of the model is required for\nimproved performance of abstractive summarization of dialogues between\ninterlocutors. On investigating, the above popular evaluation metrics are found\nto be insensitive to factual errors. Further investigation of the summaries\ngenerated by finetuned model is done using the contemporary evaluation metrics\nof factual consistency like WeCheck and SummaC. Empirical results on BBC News\narticles highlight that the gold standard summaries written by humans are more\nfactually consistent by 17% than the abstractive summaries generated by\nfinetuned model.\n","authors":["Sindhu Nair","Y. S. Rao","Radha Shankarmani"],"pdf_url":"https://arxiv.org/pdf/2410.16842v1.pdf","comment":"Pre-print"},{"id":"http://arxiv.org/abs/2409.15503v2","updated":"2024-10-22T09:23:03Z","published":"2024-09-23T19:46:19Z","title":"From Text to Treatment Effects: A Meta-Learning Approach to Handling\n  Text-Based Confounding","summary":"  One of the central goals of causal machine learning is the accurate\nestimation of heterogeneous treatment effects from observational data. In\nrecent years, meta-learning has emerged as a flexible, model-agnostic paradigm\nfor estimating conditional average treatment effects (CATE) using any\nsupervised model. This paper examines the performance of meta-learners when the\nconfounding variables are expressed in text. Through synthetic data\nexperiments, we show that learners using pre-trained text representations of\nconfounders, in addition to tabular background variables, achieve improved CATE\nestimates compared to those relying solely on the tabular variables,\nparticularly when sufficient data is available. However, due to the entangled\nnature of the text embeddings, these models do not fully match the performance\nof meta-learners with perfect confounder knowledge. These findings highlight\nboth the potential and the limitations of pre-trained text representations for\ncausal inference and open up interesting avenues for future research.\n","authors":["Henri Arno","Paloma Rabaey","Thomas Demeester"],"pdf_url":"https://arxiv.org/pdf/2409.15503v2.pdf","comment":"Presented at the Causal Representation Learning workshop at NeurIPS\n  2024"},{"id":"http://arxiv.org/abs/2312.01344v2","updated":"2024-10-22T09:22:33Z","published":"2023-12-03T10:40:07Z","title":"Enhancing Algorithm Performance Understanding through tsMorph:\n  Generating Semi-Synthetic Time Series for Robust Forecasting Evaluation","summary":"  Time series forecasting is a subject of significant scientific and industrial\nimportance. Despite the widespread utilization of forecasting methods, there is\na dearth of research aimed at comprehending the conditions under which these\nmethods yield favorable or unfavorable performances. Empirical studies,\nalthough common, are challenged by the limited availability of time series\ndatasets, restricting the extraction of reliable insights. To address this\nlimitation, we present tsMorph, a tool for generating semi-synthetic time\nseries through dataset morphing. tsMorph works by creating a sequence of\ndatasets from two original datasets. The characteristics of the generated\ndatasets progressively depart from those of one of the datasets and converge\ntoward the attributes of the other dataset. This method provides a valuable\nalternative for obtaining substantial datasets. In this paper, we show the\nbenefits of tsMorph by assessing the predictive performance of the Long\nShort-Term Memory Network and DeepAR forecasting algorithms. The time series\nused for the experiments comes from the NN5 Competition. The experimental\nresults provide important insights. Notably, the performances of the two\nalgorithms improve proportionally with the frequency of the time series. These\nexperiments confirm that tsMorph can be an effective tool for better\nunderstanding the behavior of forecasting algorithms, delivering a pathway to\novercoming the limitations posed by empirical studies and enabling more\nextensive and reliable experiments.\n","authors":["Moisés Santos","André de Carvalho","Carlos Soares"],"pdf_url":"https://arxiv.org/pdf/2312.01344v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07563v2","updated":"2024-10-22T09:06:38Z","published":"2024-10-10T02:59:36Z","title":"PLaMo-100B: A Ground-Up Language Model Designed for Japanese Proficiency","summary":"  We introduce PLaMo-100B, a large-scale language model designed for Japanese\nproficiency. The model was trained from scratch using 2 trillion tokens, with\narchitecture such as QK Normalization and Z-Loss to ensure training stability\nduring the training process. Post-training techniques, including Supervised\nFine-Tuning and Direct Preference Optimization, were applied to refine the\nmodel's performance. Benchmark evaluations suggest that PLaMo-100B performs\nwell, particularly in Japanese-specific tasks, achieving results that are\ncompetitive with frontier models like GPT-4. The base model is available at\nhttps://huggingface.co/pfnet/plamo-100b.\n","authors":["Preferred Elements"," :","Kenshin Abe","Kaizaburo Chubachi","Yasuhiro Fujita","Yuta Hirokawa","Kentaro Imajo","Toshiki Kataoka","Hiroyoshi Komatsu","Hiroaki Mikami","Tsuguo Mogami","Shogo Murai","Kosuke Nakago","Daisuke Nishino","Toru Ogawa","Daisuke Okanohara","Yoshihiko Ozaki","Shotaro Sano","Shuji Suzuki","Tianqi Xu","Toshihiko Yanase"],"pdf_url":"https://arxiv.org/pdf/2410.07563v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.14710v2","updated":"2024-10-22T09:00:19Z","published":"2024-09-23T05:12:13Z","title":"ERABAL: Enhancing Role-Playing Agents through Boundary-Aware Learning","summary":"  Role-playing is an emerging application in the field of Human-Computer\nInteraction (HCI), primarily implemented through the alignment training of a\nlarge language model (LLM) with assigned characters. Despite significant\nprogress, role-playing agents (RPLAs) still struggle with maintaining\nrole-consistency across conversations, particularly when confronted with\nboundary queries subtly related to character attributes. In this paper, we\npresent ERABAL, a framework aimed at enhancing RPLAs' role-playing capabilities\nthrough boundary-aware learning. ERABAL encompasses a generation pipeline for\nrole-specific dialogues and a concomitant methodology for alignment training.\nThrough comprehensive evaluations, we demonstrate that ERABAL is both efficient\nand effective. By training with significantly fewer dialogues than those used\nin leading approaches, ERABAL achieves notable improvements across\nWikiRoleEval, CharacterEval, and the role-playing subset of MT-Bench compared\nto the generalist baseline models. Our code and datasets will be made publicly\navailable to support further research.\n","authors":["Yihong Tang","Jiao Ou","Che Liu","Fuzheng Zhang","Di Zhang","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2409.14710v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2402.10618"},{"id":"http://arxiv.org/abs/2410.16824v1","updated":"2024-10-22T08:57:17Z","published":"2024-10-22T08:57:17Z","title":"PerspectiveNet: Multi-View Perception for Dynamic Scene Understanding","summary":"  Generating detailed descriptions from multiple cameras and viewpoints is\nchallenging due to the complex and inconsistent nature of visual data. In this\npaper, we introduce PerspectiveNet, a lightweight yet efficient model for\ngenerating long descriptions across multiple camera views. Our approach\nutilizes a vision encoder, a compact connector module to convert visual\nfeatures into a fixed-size tensor, and large language models (LLMs) to harness\nthe strong natural language generation capabilities of LLMs. The connector\nmodule is designed with three main goals: mapping visual features onto LLM\nembeddings, emphasizing key information needed for description generation, and\nproducing a fixed-size feature matrix. Additionally, we augment our solution\nwith a secondary task, the correct frame sequence detection, enabling the model\nto search for the correct sequence of frames to generate descriptions. Finally,\nwe integrate the connector module, the secondary task, the LLM, and a visual\nfeature extraction model into a single architecture, which is trained for the\nTraffic Safety Description and Analysis task. This task requires generating\ndetailed, fine-grained descriptions of events from multiple cameras and\nviewpoints. The resulting model is lightweight, ensuring efficient training and\ninference, while remaining highly effective.\n","authors":["Vinh Nguyen"],"pdf_url":"https://arxiv.org/pdf/2410.16824v1.pdf","comment":"6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.16822v1","updated":"2024-10-22T08:48:52Z","published":"2024-10-22T08:48:52Z","title":"Can Large Language Models Act as Ensembler for Multi-GNNs?","summary":"  Graph Neural Networks (GNNs) have emerged as powerful models for learning\nfrom graph-structured data. However, GNNs lack the inherent semantic\nunderstanding capability of rich textual nodesattributes, limiting their\neffectiveness in applications. On the other hand, we empirically observe that\nfor existing GNN models, no one can consistently outperforms others across\ndiverse datasets. In this paper, we study whether LLMs can act as an ensembler\nfor multi-GNNs and propose the LensGNN model. The model first aligns multiple\nGNNs, mapping the representations of different GNNs into the same space. Then,\nthrough LoRA fine-tuning, it aligns the space between the GNN and the LLM,\ninjecting graph tokens and textual information into LLMs. This allows LensGNN\nto integrate multiple GNNs and leverage LLM's strengths, resulting in better\nperformance. Experimental results show that LensGNN outperforms existing\nmodels. This research advances text-attributed graph ensemble learning by\nproviding a robust, superior solution for integrating semantic and structural\ninformation. We provide our code and data here:\nhttps://anonymous.4open.science/r/EnsemGNN-E267/.\n","authors":["Hanqi Duan","Yao Cheng","Jianxiang Yu","Xiang Li"],"pdf_url":"https://arxiv.org/pdf/2410.16822v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16803v1","updated":"2024-10-22T08:28:05Z","published":"2024-10-22T08:28:05Z","title":"Context-aware Inductive Knowledge Graph Completion with Latent Type\n  Constraints and Subgraph Reasoning","summary":"  Inductive knowledge graph completion (KGC) aims to predict missing triples\nwith unseen entities. Recent works focus on modeling reasoning paths between\nthe head and tail entity as direct supporting evidence. However, these methods\ndepend heavily on the existence and quality of reasoning paths, which limits\ntheir general applicability in different scenarios. In addition, we observe\nthat latent type constraints and neighboring facts inherent in KGs are also\nvital in inferring missing triples. To effectively utilize all useful\ninformation in KGs, we introduce CATS, a novel context-aware inductive KGC\nsolution. With sufficient guidance from proper prompts and supervised\nfine-tuning, CATS activates the strong semantic understanding and reasoning\ncapabilities of large language models to assess the existence of query triples,\nwhich consist of two modules. First, the type-aware reasoning module evaluates\nwhether the candidate entity matches the latent entity type as required by the\nquery relation. Then, the subgraph reasoning module selects relevant reasoning\npaths and neighboring facts, and evaluates their correlation to the query\ntriple. Experiment results on three widely used datasets demonstrate that CATS\nsignificantly outperforms state-of-the-art methods in 16 out of 18\ntransductive, inductive, and few-shot settings with an average absolute MRR\nimprovement of 7.2%.\n","authors":["Muzhi Li","Cehao Yang","Chengjin Xu","Zixing Song","Xuhui Jiang","Jian Guo","Ho-fung Leung","Irwin King"],"pdf_url":"https://arxiv.org/pdf/2410.16803v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16801v1","updated":"2024-10-22T08:27:23Z","published":"2024-10-22T08:27:23Z","title":"Controlled Low-Rank Adaptation with Subspace Regularization for\n  Continued Training on Large Language Models","summary":"  Large language models (LLMs) exhibit remarkable capabilities in natural\nlanguage processing but face catastrophic forgetting when learning new tasks,\nwhere adaptation to a new domain leads to a substantial decline in performance\non previous tasks. In this paper, we propose Controlled LoRA (CLoRA), a\nsubspace regularization method on LoRA structure. Aiming to reduce the scale of\noutput change while introduce minimal constraint on model capacity, CLoRA\nimposes constraint on the direction of updating matrix null space. Experimental\nresults on commonly used LLM finetuning tasks reveal that CLoRA significantly\noutperforms existing LoRA subsequent methods on both in-domain and outdomain\nevaluations, highlighting the superority of CLoRA as a effective\nparameter-efficient finetuning method with catastrophic forgetting mitigating.\nFurther investigation for model parameters indicates that CLoRA effectively\nbalances the trade-off between model capacity and degree of forgetting.\n","authors":["Yuheng Lu","Bingshuo Qian","Caixia Yuan","Huixing Jiang","Xiaojie Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16801v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15052v2","updated":"2024-10-22T08:22:46Z","published":"2024-10-19T09:49:12Z","title":"Mining Glitch Tokens in Large Language Models via Gradient-based\n  Discrete Optimization","summary":"  Glitch tokens in Large Language Models (LLMs) can trigger unpredictable\nbehaviors, compromising model reliability and safety. Existing detection\nmethods often rely on manual observation to infer the prior distribution of\nglitch tokens, which is inefficient and lacks adaptability across diverse model\narchitectures. To address these limitations, we introduce GlitchMiner, a\ngradient-based discrete optimization framework designed for efficient glitch\ntoken detection in LLMs. GlitchMiner leverages an entropy-based loss function\nto quantify the uncertainty in model predictions and integrates first-order\nTaylor approximation with a local search strategy to effectively explore the\ntoken space. Our evaluation across various mainstream LLM architectures\ndemonstrates that GlitchMiner surpasses existing methods in both detection\nprecision and adaptability. In comparison to the previous state-of-the-art,\nGlitchMiner achieves an average improvement of 19.07% in precision@1000 for\nglitch token detection. By enabling efficient detection of glitch tokens,\nGlitchMiner provides a valuable tool for assessing and mitigating potential\nvulnerabilities in LLMs, contributing to their overall security.\n","authors":["Zihui Wu","Haichang Gao","Ping Wang","Shudong Zhang","Zhaoxiang Liu","Shiguo Lian"],"pdf_url":"https://arxiv.org/pdf/2410.15052v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16795v1","updated":"2024-10-22T08:17:33Z","published":"2024-10-22T08:17:33Z","title":"Traj-Explainer: An Explainable and Robust Multi-modal Trajectory\n  Prediction Approach","summary":"  Navigating complex traffic environments has been significantly enhanced by\nadvancements in intelligent technologies, enabling accurate environment\nperception and trajectory prediction for automated vehicles. However, existing\nresearch often neglects the consideration of the joint reasoning of scenario\nagents and lacks interpretability in trajectory prediction models, thereby\nlimiting their practical application in real-world scenarios. To this purpose,\nan explainability-oriented trajectory prediction model is designed in this\nwork, named Explainable Conditional Diffusion based Multimodal Trajectory\nPrediction Traj-Explainer, to retrieve the influencing factors of prediction\nand help understand the intrinsic mechanism of prediction. In Traj-Explainer, a\nmodified conditional diffusion is well designed to capture the scenario\nmultimodal trajectory pattern, and meanwhile, a modified Shapley Value model is\nassembled to rationally learn the importance of the global and scenario\nfeatures. Numerical experiments are carried out by several trajectory\nprediction datasets, including Waymo, NGSIM, HighD, and MoCAD datasets.\nFurthermore, we evaluate the identified input factors which indicates that they\nare in agreement with the human driving experience, indicating the capability\nof the proposed model in appropriately learning the prediction. Code available\nin our open-source repository:\n\\url{https://anonymous.4open.science/r/Interpretable-Prediction}.\n","authors":["Pei Liu","Haipeng Liu","Yiqun Li","Tianyu Shi","Meixin Zhu","Ziyuan Pu"],"pdf_url":"https://arxiv.org/pdf/2410.16795v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.09185v3","updated":"2024-10-22T08:17:21Z","published":"2022-07-19T10:46:02Z","title":"Multimodal hierarchical Variational AutoEncoders with Factor Analysis\n  latent space","summary":"  Purpose: Handling heterogeneous and mixed data types has become increasingly\ncritical with the exponential growth in real-world databases. While deep\ngenerative models attempt to merge diverse data views into a common latent\nspace, they often sacrifice interpretability, flexibility, and modularity. This\nstudy proposes a novel method to address these limitations by combining\nVariational AutoEncoders (VAEs) with a Factor Analysis latent space (FA-VAE).\n  Methods: The proposed FA-VAE method employs multiple VAEs to learn a private\nrepresentation for each heterogeneous data view in a continuous latent space.\nInformation is shared between views using a low-dimensional latent space,\ngenerated via a linear projection matrix. This modular design creates a\nhierarchical dependency between private and shared latent spaces, allowing for\nthe flexible addition of new views and conditioning of pre-trained models.\n  Results: The FA-VAE approach facilitates cross-generation of data from\ndifferent domains and enables transfer learning between generative models. This\nallows for effective integration of information across diverse data views while\npreserving their distinct characteristics.\n  Conclusions: By overcoming the limitations of existing methods, the FA-VAE\nprovides a more interpretable, flexible, and modular solution for managing\nheterogeneous data types. It offers a pathway to more efficient and scalable\ndata-handling strategies, enhancing the potential for cross-domain data\nsynthesis and model transferability.\n","authors":["Alejandro Guerrero-López","Carlos Sevilla-Salcedo","Vanessa Gómez-Verdejo","Pablo M. Olmos"],"pdf_url":"https://arxiv.org/pdf/2207.09185v3.pdf","comment":"21 pages main work, 2 pages supplementary, 14 figures"},{"id":"http://arxiv.org/abs/2410.16794v1","updated":"2024-10-22T08:17:20Z","published":"2024-10-22T08:17:20Z","title":"One-Step Diffusion Distillation through Score Implicit Matching","summary":"  Despite their strong performances on many generative tasks, diffusion models\nrequire a large number of sampling steps in order to generate realistic\nsamples. This has motivated the community to develop effective methods to\ndistill pre-trained diffusion models into more efficient models, but these\nmethods still typically require few-step inference or perform substantially\nworse than the underlying model. In this paper, we present Score Implicit\nMatching (SIM) a new approach to distilling pre-trained diffusion models into\nsingle-step generator models, while maintaining almost the same sample\ngeneration ability as the original model as well as being data-free with no\nneed of training samples for distillation. The method rests upon the fact that,\nalthough the traditional score-based loss is intractable to minimize for\ngenerator models, under certain conditions we can efficiently compute the\ngradients for a wide class of score-based divergences between a diffusion model\nand a generator. SIM shows strong empirical performances for one-step\ngenerators: on the CIFAR10 dataset, it achieves an FID of 2.06 for\nunconditional generation and 1.96 for class-conditional generation. Moreover,\nby applying SIM to a leading transformer-based diffusion model, we distill a\nsingle-step generator for text-to-image (T2I) generation that attains an\naesthetic score of 6.42 with no performance decline over the original\nmulti-step counterpart, clearly outperforming the other one-step generators\nincluding SDXL-TURBO of 5.33, SDXL-LIGHTNING of 5.34 and HYPER-SDXL of 5.85. We\nwill release this industry-ready one-step transformer-based T2I generator along\nwith this paper.\n","authors":["Weijian Luo","Zemin Huang","Zhengyang Geng","J. Zico Kolter","Guo-jun Qi"],"pdf_url":"https://arxiv.org/pdf/2410.16794v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.16788v1","updated":"2024-10-22T08:04:32Z","published":"2024-10-22T08:04:32Z","title":"Correct after Answer: Enhancing Multi-Span Question Answering with\n  Post-Processing Method","summary":"  Multi-Span Question Answering (MSQA) requires models to extract one or\nmultiple answer spans from a given context to answer a question. Prior work\nmainly focuses on designing specific methods or applying heuristic strategies\nto encourage models to predict more correct predictions. However, these models\nare trained on gold answers and fail to consider the incorrect predictions.\nThrough a statistical analysis, we observe that models with stronger abilities\ndo not predict less incorrect predictions compared with other models. In this\nwork, we propose Answering-Classifying-Correcting (ACC) framework, which\nemploys a post-processing strategy to handle incorrect predictions.\nSpecifically, the ACC framework first introduces a classifier to classify the\npredictions into three types and exclude \"wrong predictions\", then introduces a\ncorrector to modify \"partially correct predictions\". Experiments on several\nMSQA datasets show that ACC framework significantly improves the Exact Match\n(EM) scores, and further analysis demostrates that ACC framework efficiently\nreduces the number of incorrect predictions, improving the quality of\npredictions.\n","authors":["Jiayi Lin","Chenyang Zhang","Haibo Tong","Dongyu Zhang","Qingqing Hong","Bingxuan Hou","Junli Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16788v1.pdf","comment":"Accepted by EMNLP 2024 Findings"},{"id":"http://arxiv.org/abs/2410.15859v2","updated":"2024-10-22T08:00:00Z","published":"2024-10-21T10:39:05Z","title":"Mesa-Extrapolation: A Weave Position Encoding Method for Enhanced\n  Extrapolation in LLMs","summary":"  Large language models (LLMs), although having revolutionized many fields,\nstill suffer from the challenging extrapolation problem, where the inference\nability of LLMs sharply declines beyond their max training lengths. In this\nwork, we conduct a theoretical analysis to better understand why No Position\nEncoding (NoPE) fails outside its effective range, as well as examining the\npower of Position Encoding (PE) in this context. Our findings reveal that with\nmeticulous weave position, PE can indeed be extended beyond effective range.\nOur theorems establish that LLMs equipped with weave PE can achieve improved\nextrapolation performance without additional cost. Furthermore, we introduce a\nnovel weave PE method, Mesa-Extrapolation, which utilizes a chunk-based\ntriangular attention matrix and applies Stair PE to manage the final chunk.\nThis method not only retains competitive performance but also offers\nsubstantial benefits such as significantly reduced memory demand and faster\ninference speed. Extensive experiments validate the effectiveness of\nMesa-Extrapolation, demonstrating its potential as a scalable solution to\nenhancing LLMs applicative reach.\n","authors":["Xin Ma","Yang Liu","Jingjing Liu","Xiaoxu Ma"],"pdf_url":"https://arxiv.org/pdf/2410.15859v2.pdf","comment":"Accepted by NeurIPS 2024; 13 pages and 30 pages appendix"},{"id":"http://arxiv.org/abs/2211.12702v2","updated":"2024-10-22T07:57:55Z","published":"2022-11-23T04:48:49Z","title":"Evaluating Feature Attribution Methods for Electrocardiogram","summary":"  The performance of cardiac arrhythmia detection with electrocardiograms(ECGs)\nhas been considerably improved since the introduction of deep learning models.\nIn practice, the high performance alone is not sufficient and a proper\nexplanation is also required. Recently, researchers have started adopting\nfeature attribution methods to address this requirement, but it has been\nunclear which of the methods are appropriate for ECG. In this work, we identify\nand customize three evaluation metrics for feature attribution methods based on\nthe characteristics of ECG: localization score, pointing game, and degradation\nscore. Using the three evaluation metrics, we evaluate and analyze eleven\nwidely-used feature attribution methods. We find that some of the feature\nattribution methods are much more adequate for explaining ECG, where Grad-CAM\noutperforms the second-best method by a large margin.\n","authors":["Jangwon Suh","Jimyeong Kim","Euna Jung","Wonjong Rhee"],"pdf_url":"https://arxiv.org/pdf/2211.12702v2.pdf","comment":"This is preliminary research related to\n  https://www.sciencedirect.com/science/article/pii/S0010482524011739 . Code is\n  available at https://github.com/SNU-DRL/Attribution-ECG"},{"id":"http://arxiv.org/abs/2410.16780v1","updated":"2024-10-22T07:53:41Z","published":"2024-10-22T07:53:41Z","title":"Beyond Retrieval: Generating Narratives in Conversational Recommender\n  Systems","summary":"  The recent advances in Large Language Model's generation and reasoning\ncapabilities present an opportunity to develop truly conversational\nrecommendation systems. However, effectively integrating recommender system\nknowledge into LLMs for natural language generation which is tailored towards\nrecommendation tasks remains a challenge. This paper addresses this challenge\nby making two key contributions.\n  First, we introduce a new dataset (REGEN) for natural language generation\ntasks in conversational recommendations. REGEN (Reviews Enhanced with\nGEnerative Narratives) extends the Amazon Product Reviews dataset with rich\nuser narratives, including personalized explanations of product preferences,\nproduct endorsements for recommended items, and summaries of user purchase\nhistory. REGEN is made publicly available to facilitate further research.\nFurthermore, we establish benchmarks using well-known generative metrics, and\nperform an automated evaluation of the new dataset using a rater LLM. Second,\nthe paper introduces a fusion architecture (CF model with an LLM) which serves\nas a baseline for REGEN. And to the best of our knowledge, represents the first\nattempt to analyze the capabilities of LLMs in understanding recommender\nsignals and generating rich narratives. We demonstrate that LLMs can\neffectively learn from simple fusion architectures utilizing interaction-based\nCF embeddings, and this can be further enhanced using the metadata and\npersonalization data associated with items. Our experiments show that combining\nCF and content embeddings leads to improvements of 4-12% in key language\nmetrics compared to using either type of embedding individually. We also\nprovide an analysis to interpret how CF and content embeddings contribute to\nthis new generative task.\n","authors":["Krishna Sayana","Raghavendra Vasudeva","Yuri Vasilevski","Kun Su","Liam Hebert","Hubert Pham","Ambarish Jash","Sukhdeep Sodhi"],"pdf_url":"https://arxiv.org/pdf/2410.16780v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15490v2","updated":"2024-10-22T07:46:35Z","published":"2024-10-20T20:07:36Z","title":"Dynamic Intelligence Assessment: Benchmarking LLMs on the Road to AGI\n  with a Focus on Model Confidence","summary":"  As machine intelligence evolves, the need to test and compare the\nproblem-solving abilities of different AI models grows. However, current\nbenchmarks are often overly simplistic, allowing models to perform uniformly\nwell, making it difficult to distinguish their capabilities. Additionally,\nbenchmarks typically rely on static question-answer pairs, which models might\nmemorize or guess. To address these limitations, we introduce the Dynamic\nIntelligence Assessment (DIA), a novel methodology for testing AI models using\ndynamic question templates and improved metrics across multiple disciplines\nsuch as mathematics, cryptography, cybersecurity, and computer science. The\naccompanying DIA-Bench dataset, which includes 150 diverse and challenging task\ntemplates with mutable parameters, is presented in various formats such as\ntext, PDFs, compiled binaries, and visual puzzles. Our framework introduces\nfour new metrics to assess a model's reliability and confidence across multiple\nattempts. These metrics revealed that even simple questions are frequently\nanswered incorrectly when posed in varying forms, highlighting significant gaps\nin models' reliability. Notably, models like GPT-4o tended to overestimate\ntheir mathematical abilities, while ChatGPT-4o demonstrated better\ndecision-making and performance through effective tool usage. We evaluated\neight state-of-the-art large language models (LLMs) using DIA-Bench, showing\nthat current models struggle with complex tasks and often display unexpectedly\nlow confidence, even with simpler questions. The DIA framework sets a new\nstandard for assessing not only problem-solving but also a model's adaptive\nintelligence and ability to assess its own limitations. The dataset is publicly\navailable on our project's website.\n","authors":["Norbert Tihanyi","Tamas Bisztray","Richard A. Dubniczky","Rebeka Toth","Bertalan Borsos","Bilel Cherif","Mohamed Amine Ferrag","Lajos Muzsai","Ridhi Jain","Ryan Marinelli","Lucas C. Cordeiro","Merouane Debbah"],"pdf_url":"https://arxiv.org/pdf/2410.15490v2.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2410.17242v1","updated":"2024-10-22T17:58:28Z","published":"2024-10-22T17:58:28Z","title":"LVSM: A Large View Synthesis Model with Minimal 3D Inductive Bias","summary":"  We propose the Large View Synthesis Model (LVSM), a novel transformer-based\napproach for scalable and generalizable novel view synthesis from sparse-view\ninputs. We introduce two architectures: (1) an encoder-decoder LVSM, which\nencodes input image tokens into a fixed number of 1D latent tokens, functioning\nas a fully learned scene representation, and decodes novel-view images from\nthem; and (2) a decoder-only LVSM, which directly maps input images to\nnovel-view outputs, completely eliminating intermediate scene representations.\nBoth models bypass the 3D inductive biases used in previous methods -- from 3D\nrepresentations (e.g., NeRF, 3DGS) to network designs (e.g., epipolar\nprojections, plane sweeps) -- addressing novel view synthesis with a fully\ndata-driven approach. While the encoder-decoder model offers faster inference\ndue to its independent latent representation, the decoder-only LVSM achieves\nsuperior quality, scalability, and zero-shot generalization, outperforming\nprevious state-of-the-art methods by 1.5 to 3.5 dB PSNR. Comprehensive\nevaluations across multiple datasets demonstrate that both LVSM variants\nachieve state-of-the-art novel view synthesis quality. Notably, our models\nsurpass all previous methods even with reduced computational resources (1-2\nGPUs). Please see our website for more details:\nhttps://haian-jin.github.io/projects/LVSM/ .\n","authors":["Haian Jin","Hanwen Jiang","Hao Tan","Kai Zhang","Sai Bi","Tianyuan Zhang","Fujun Luan","Noah Snavely","Zexiang Xu"],"pdf_url":"https://arxiv.org/pdf/2410.17242v1.pdf","comment":"project page: https://haian-jin.github.io/projects/LVSM/"},{"id":"http://arxiv.org/abs/2410.17238v1","updated":"2024-10-22T17:56:08Z","published":"2024-10-22T17:56:08Z","title":"SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning","summary":"  Automated Machine Learning (AutoML) approaches encompass traditional methods\nthat optimize fixed pipelines for model selection and ensembling, as well as\nnewer LLM-based frameworks that autonomously build pipelines. While LLM-based\nagents have shown promise in automating machine learning tasks, they often\ngenerate low-diversity and suboptimal code, even after multiple iterations. To\novercome these limitations, we introduce Tree-Search Enhanced LLM Agents\n(SELA), an innovative agent-based system that leverages Monte Carlo Tree Search\n(MCTS) to optimize the AutoML process. By representing pipeline configurations\nas trees, our framework enables agents to conduct experiments intelligently and\niteratively refine their strategies, facilitating a more effective exploration\nof the machine learning solution space. This novel approach allows SELA to\ndiscover optimal pathways based on experimental feedback, improving the overall\nquality of the solutions. In an extensive evaluation across 20 machine learning\ndatasets, we compare the performance of traditional and agent-based AutoML\nmethods, demonstrating that SELA achieves a win rate of 65% to 80% against each\nbaseline across all datasets. These results underscore the significant\npotential of agent-based strategies in AutoML, offering a fresh perspective on\ntackling complex machine learning challenges.\n","authors":["Yizhou Chi","Yizhang Lin","Sirui Hong","Duyi Pan","Yaying Fei","Guanghao Mei","Bangbang Liu","Tianqi Pang","Jacky Kwok","Ceyao Zhang","Bang Liu","Chenglin Wu"],"pdf_url":"https://arxiv.org/pdf/2410.17238v1.pdf","comment":"The code is available at https://github.com/geekan/MetaGPT"},{"id":"http://arxiv.org/abs/2410.17234v1","updated":"2024-10-22T17:54:03Z","published":"2024-10-22T17:54:03Z","title":"Fine-Tuning Large Language Models to Appropriately Abstain with Semantic\n  Entropy","summary":"  Large Language Models (LLMs) are known to hallucinate, whereby they generate\nplausible but inaccurate text. This phenomenon poses significant risks in\ncritical applications, such as medicine or law, necessitating robust\nhallucination mitigation strategies. While recent works have proposed\nfine-tuning methods to teach LLMs to abstain from answering questions beyond\ntheir knowledge or capabilities, these methods rely on the existence of\nground-truth labels or are limited to short-form responses. To address these\nlimitations, we propose fine-tuning using semantic entropy, an uncertainty\nmeasure derived from introspection into the model which does not require\nexternal labels. We demonstrate that our approach matches or outperforms models\nfine-tuned using prior work and achieves strong performance for both short and\nlong-form generations on a range of datasets.\n","authors":["Benedict Aaron Tjandra","Muhammed Razzak","Jannik Kossen","Kunal Handa","Yarin Gal"],"pdf_url":"https://arxiv.org/pdf/2410.17234v1.pdf","comment":"Accepted to NeurIPS Safe Generative AI Workshop 2024"},{"id":"http://arxiv.org/abs/2410.17233v1","updated":"2024-10-22T17:53:34Z","published":"2024-10-22T17:53:34Z","title":"Few-shot In-Context Preference Learning Using Large Language Models","summary":"  Designing reward functions is a core component of reinforcement learning but\ncan be challenging for truly complex behavior. Reinforcement Learning from\nHuman Feedback (RLHF) has been used to alleviate this challenge by replacing a\nhand-coded reward function with a reward function learned from preferences.\nHowever, it can be exceedingly inefficient to learn these rewards as they are\noften learned tabula rasa. We investigate whether Large Language Models (LLMs)\ncan reduce this query inefficiency by converting an iterative series of human\npreferences into code representing the rewards. We propose In-Context\nPreference Learning (ICPL), a method that uses the grounding of an LLM to\naccelerate learning reward functions from preferences. ICPL takes the\nenvironment context and task description, synthesizes a set of reward\nfunctions, and then repeatedly updates the reward functions using human\nrankings of videos of the resultant policies. Using synthetic preferences, we\ndemonstrate that ICPL is orders of magnitude more efficient than RLHF and is\neven competitive with methods that use ground-truth reward functions instead of\npreferences. Finally, we perform a series of human preference-learning trials\nand observe that ICPL extends beyond synthetic settings and can work\neffectively with humans-in-the-loop. Additional information and videos are\nprovided at https://sites.google.com/view/few-shot-icpl/home.\n","authors":["Chao Yu","Hong Lu","Jiaxuan Gao","Qixin Tan","Xinting Yang","Yu Wang","Yi Wu","Eugene Vinitsky"],"pdf_url":"https://arxiv.org/pdf/2410.17233v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17230v1","updated":"2024-10-22T17:51:23Z","published":"2024-10-22T17:51:23Z","title":"Optimal Robust Estimation under Local and Global Corruptions: Stronger\n  Adversary and Smaller Error","summary":"  Algorithmic robust statistics has traditionally focused on the contamination\nmodel where a small fraction of the samples are arbitrarily corrupted. We\nconsider a recent contamination model that combines two kinds of corruptions:\n(i) small fraction of arbitrary outliers, as in classical robust statistics,\nand (ii) local perturbations, where samples may undergo bounded shifts on\naverage. While each noise model is well understood individually, the combined\ncontamination model poses new algorithmic challenges, with only partial results\nknown. Existing efficient algorithms are limited in two ways: (i) they work\nonly for a weak notion of local perturbations, and (ii) they obtain suboptimal\nerror for isotropic subgaussian distributions (among others). The latter\nlimitation led [NGS24, COLT'24] to hypothesize that improving the error might,\nin fact, be computationally hard. Perhaps surprisingly, we show that\ninformation theoretically optimal error can indeed be achieved in polynomial\ntime, under an even \\emph{stronger} local perturbation model (the\nsliced-Wasserstein metric as opposed to the Wasserstein metric). Notably, our\nanalysis reveals that the entire family of stability-based robust mean\nestimators continues to work optimally in a black-box manner for the combined\ncontamination model. This generalization is particularly useful in real-world\nscenarios where the specific form of data corruption is not known in advance.\nWe also present efficient algorithms for distribution learning and principal\ncomponent analysis in the combined contamination model.\n","authors":["Thanasis Pittas","Ankit Pensia"],"pdf_url":"https://arxiv.org/pdf/2410.17230v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12101v2","updated":"2024-10-22T17:48:56Z","published":"2024-10-15T22:52:45Z","title":"The Persian Rug: solving toy models of superposition using large-scale\n  symmetries","summary":"  We present a complete mechanistic description of the algorithm learned by a\nminimal non-linear sparse data autoencoder in the limit of large input\ndimension. The model, originally presented in arXiv:2209.10652, compresses\nsparse data vectors through a linear layer and decompresses using another\nlinear layer followed by a ReLU activation. We notice that when the data is\npermutation symmetric (no input feature is privileged) large models reliably\nlearn an algorithm that is sensitive to individual weights only through their\nlarge-scale statistics. For these models, the loss function becomes\nanalytically tractable. Using this understanding, we give the explicit scalings\nof the loss at high sparsity, and show that the model is near-optimal among\nrecently proposed architectures. In particular, changing or adding to the\nactivation function any elementwise or filtering operation can at best improve\nthe model's performance by a constant factor. Finally, we forward-engineer a\nmodel with the requisite symmetries and show that its loss precisely matches\nthat of the trained models. Unlike the trained model weights, the low\nrandomness in the artificial weights results in miraculous fractal structures\nresembling a Persian rug, to which the algorithm is oblivious. Our work\ncontributes to neural network interpretability by introducing techniques for\nunderstanding the structure of autoencoders. Code to reproduce our results can\nbe found at https://github.com/KfirD/PersianRug .\n","authors":["Aditya Cowsik","Kfir Dolev","Alex Infanger"],"pdf_url":"https://arxiv.org/pdf/2410.12101v2.pdf","comment":"Improved arguments, presentation. No changes to results"},{"id":"http://arxiv.org/abs/2410.17225v1","updated":"2024-10-22T17:47:05Z","published":"2024-10-22T17:47:05Z","title":"Dhoroni: Exploring Bengali Climate Change and Environmental Views with a\n  Multi-Perspective News Dataset and Natural Language Processing","summary":"  Climate change poses critical challenges globally, disproportionately\naffecting low-income countries that often lack resources and linguistic\nrepresentation on the international stage. Despite Bangladesh's status as one\nof the most vulnerable nations to climate impacts, research gaps persist in\nBengali-language studies related to climate change and NLP. To address this\ndisparity, we introduce Dhoroni, a novel Bengali (Bangla) climate change and\nenvironmental news dataset, comprising a 2300 annotated Bangla news articles,\noffering multiple perspectives such as political influence,\nscientific/statistical data, authenticity, stance detection, and stakeholder\ninvolvement. Furthermore, we present an in-depth exploratory analysis of\nDhoroni and introduce BanglaBERT-Dhoroni family, a novel baseline model family\nfor climate and environmental opinion detection in Bangla, fine-tuned on our\ndataset. This research contributes significantly to enhancing accessibility and\nanalysis of climate discourse in Bengali (Bangla), addressing crucial\ncommunication and research gaps in climate-impacted regions like Bangladesh\nwith 180 million people.\n","authors":["Azmine Toushik Wasi","Wahid Faisal","Taj Ahmad","Abdur Rahman","Mst Rafia Islam"],"pdf_url":"https://arxiv.org/pdf/2410.17225v1.pdf","comment":"In Review"},{"id":"http://arxiv.org/abs/2410.17221v1","updated":"2024-10-22T17:45:45Z","published":"2024-10-22T17:45:45Z","title":"Scalable spectral representations for network multiagent control","summary":"  Network Markov Decision Processes (MDPs), a popular model for multi-agent\ncontrol, pose a significant challenge to efficient learning due to the\nexponential growth of the global state-action space with the number of agents.\nIn this work, utilizing the exponential decay property of network dynamics, we\nfirst derive scalable spectral local representations for network MDPs, which\ninduces a network linear subspace for the local $Q$-function of each agent.\nBuilding on these local spectral representations, we design a scalable\nalgorithmic framework for continuous state-action network MDPs, and provide\nend-to-end guarantees for the convergence of our algorithm. Empirically, we\nvalidate the effectiveness of our scalable representation-based approach on two\nbenchmark problems, and demonstrate the advantages of our approach over generic\nfunction approximation approaches to representing the local $Q$-functions.\n","authors":["Zhaolin Ren"," Runyu"," Zhang","Bo Dai","Na Li"],"pdf_url":"https://arxiv.org/pdf/2410.17221v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17216v1","updated":"2024-10-22T17:41:14Z","published":"2024-10-22T17:41:14Z","title":"Hierarchical Upper Confidence Bounds for Constrained Online Learning","summary":"  The multi-armed bandit (MAB) problem is a foundational framework in\nsequential decision-making under uncertainty, extensively studied for its\napplications in areas such as clinical trials, online advertising, and resource\nallocation. Traditional MAB formulations, however, do not adequately capture\nscenarios where decisions are structured hierarchically, involve multi-level\nconstraints, or feature context-dependent action spaces. In this paper, we\nintroduce the hierarchical constrained bandits (HCB) framework, which extends\nthe contextual bandit problem to incorporate hierarchical decision structures\nand multi-level constraints. We propose the hierarchical constrained upper\nconfidence bound (HC-UCB) algorithm, designed to address the complexities of\nthe HCB problem by leveraging confidence bounds within a hierarchical setting.\nOur theoretical analysis establishes sublinear regret bounds for HC-UCB and\nprovides high-probability guarantees for constraint satisfaction at all\nhierarchical levels. Furthermore, we derive a minimax lower bound on the regret\nfor the HCB problem, demonstrating the near-optimality of our algorithm. The\nresults are significant for real-world applications where decision-making\nprocesses are inherently hierarchical and constrained, offering a robust and\nefficient solution that balances exploration and exploitation across multiple\nlevels of decision-making.\n","authors":["Ali Baheri"],"pdf_url":"https://arxiv.org/pdf/2410.17216v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.05145v2","updated":"2024-10-22T17:39:13Z","published":"2024-07-06T17:53:53Z","title":"On high-dimensional modifications of the nearest neighbor classifier","summary":"  Nearest neighbor classifier is arguably the most simple and popular\nnonparametric classifier available in the literature. However, due to the\nconcentration of pairwise distances and the violation of the neighborhood\nstructure, this classifier often suffers in high-dimension, low-sample size\n(HDLSS) situations, especially when the scale difference between the competing\nclasses dominates their location difference. Several attempts have been made in\nthe literature to take care of this problem. In this article, we discuss some\nof these existing methods and propose some new ones. We carry out some\ntheoretical investigations in this regard and analyze several simulated and\nbenchmark datasets to compare the empirical performances of proposed methods\nwith some of the existing ones.\n","authors":["Annesha Ghosh","Bilol Banerjee","Anil K. Ghosh"],"pdf_url":"https://arxiv.org/pdf/2407.05145v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17212v1","updated":"2024-10-22T17:37:18Z","published":"2024-10-22T17:37:18Z","title":"Neuroevolution Neural Architecture Search for Evolving RNNs in Stock\n  Return Prediction and Portfolio Trading","summary":"  Stock return forecasting is a major component of numerous finance\napplications. Predicted stock returns can be incorporated into portfolio\ntrading algorithms to make informed buy or sell decisions which can optimize\nreturns. In such portfolio trading applications, the predictive performance of\na time series forecasting model is crucial. In this work, we propose the use of\nthe Evolutionary eXploration of Augmenting Memory Models (EXAMM) algorithm to\nprogressively evolve recurrent neural networks (RNNs) for stock return\npredictions. RNNs are evolved independently for each stocks and portfolio\ntrading decisions are made based on the predicted stock returns. The portfolio\nused for testing consists of the 30 companies in the Dow-Jones Index (DJI) with\neach stock have the same weight. Results show that using these evolved RNNs and\na simple daily long-short strategy can generate higher returns than both the\nDJI index and the S&P 500 Index for both 2022 (bear market) and 2023 (bull\nmarket).\n","authors":["Zimeng Lyu","Amulya Saxena","Rohaan Nadeem","Hao Zhang","Travis Desell"],"pdf_url":"https://arxiv.org/pdf/2410.17212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10796v2","updated":"2024-10-22T17:35:03Z","published":"2024-10-14T17:57:09Z","title":"Context-Parametric Inversion: Why Instruction Finetuning May Not\n  Actually Improve Context Reliance","summary":"  A standard practice when using large language models is for users to\nsupplement their instruction with an input context containing new information\nfor the model to process. However, models struggle to reliably follow the input\ncontext, especially when it conflicts with their parametric knowledge from\npretraining. In-principle, one would expect models to adapt to the user context\nbetter after instruction finetuning, particularly when handling knowledge\nconflicts. However, we observe a surprising failure mode: during instruction\ntuning, the context reliance under knowledge conflicts initially increases as\nexpected, but then gradually decreases as instruction finetuning progresses.\nThis happens while the performance on standard benchmarks keeps on increasing\nfar after this drop. We call this phenomenon context-parametric inversion and\nobserve it across multiple general purpose instruction tuning datasets such as\nTULU, Alpaca and Ultrachat, across different model families like Llama,\nMistral, and Pythia. We perform various controlled studies and theoretical\nanalysis to show that context-parametric inversion occurs due to examples in\nthe instruction finetuning data where the input context provides information\nthat aligns with model's parametric knowledge. Our analysis suggests some\nnatural mitigation strategies with limited but insightful gains, and serves as\na useful starting point in addressing this deficiency in instruction\nfinetuning.\n","authors":["Sachin Goyal","Christina Baek","J. Zico Kolter","Aditi Raghunathan"],"pdf_url":"https://arxiv.org/pdf/2410.10796v2.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2406.15291v2","updated":"2024-10-22T17:31:39Z","published":"2024-06-21T16:35:27Z","title":"Pessimistic asynchronous sampling in high-cost Bayesian optimization","summary":"  Asynchronous Bayesian optimization is a recently implemented technique that\nallows for parallel operation of experimental systems and disjointed workflows.\nContrasting with serial Bayesian optimization which individually selects\nexperiments one at a time after conducting a measurement for each experiment,\nasynchronous policies sequentially assign multiple experiments before\nmeasurements can be taken and evaluate new measurements continuously as they\nare made available. This technique allows for faster data generation and\ntherefore faster optimization of an experimental space. This work extends the\ncapabilities of asynchronous optimization methods beyond prior studies by\nevaluating four additional policies that incorporate pessimistic predictions in\nthe training data set. Combined with a conventional policy that uses model\npredictions, the five total policies were evaluated in a simulated environment\nand benchmarked with serial sampling. Under some conditions and parameter space\ndimensionalities, the pessimistic prediction asynchronous policy reached\noptimum experimental conditions in significantly fewer experiments than\nequivalent serial policies and proved to be less susceptible to convergence\nonto local optima at higher dimensions. Without accounting for the faster\nsampling rate, the pessimistic asynchronous algorithm presented in this work\ncould result in more efficient algorithm driven optimization of high-cost\nexperimental spaces. Accounting for sampling rate, the presented asynchronous\nalgorithm could allow for faster optimization in experimental spaces where\nmultiple experiments can be run before results are collected.\n","authors":["Amanda A. Volk","Kristofer G. Reyes","Jeffrey G. Ethier","Luke A. Baldwin"],"pdf_url":"https://arxiv.org/pdf/2406.15291v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17209v1","updated":"2024-10-22T17:31:37Z","published":"2024-10-22T17:31:37Z","title":"Audio-to-Score Conversion Model Based on Whisper methodology","summary":"  This thesis develops a Transformer model based on Whisper, which extracts\nmelodies and chords from music audio and records them into ABC notation. A\ncomprehensive data processing workflow is customized for ABC notation,\nincluding data cleansing, formatting, and conversion, and a mutation mechanism\nis implemented to increase the diversity and quality of training data. This\nthesis innovatively introduces the \"Orpheus' Score\", a custom notation system\nthat converts music information into tokens, designs a custom vocabulary\nlibrary, and trains a corresponding custom tokenizer. Experiments show that\ncompared to traditional algorithms, the model has significantly improved\naccuracy and performance. While providing a convenient audio-to-score tool for\nmusic enthusiasts, this work also provides new ideas and tools for research in\nmusic information processing.\n","authors":["Hongyao Zhang","Bohang Sun"],"pdf_url":"https://arxiv.org/pdf/2410.17209v1.pdf","comment":"5 pages, 7 figures"},{"id":"http://arxiv.org/abs/2308.02594v4","updated":"2024-10-22T17:29:53Z","published":"2023-08-03T21:08:51Z","title":"SMARLA: A Safety Monitoring Approach for Deep Reinforcement Learning\n  Agents","summary":"  Deep Reinforcement Learning (DRL) has made significant advancements in\nvarious fields, such as autonomous driving, healthcare, and robotics, by\nenabling agents to learn optimal policies through interactions with their\nenvironments. However, the application of DRL in safety-critical domains\npresents challenges, particularly concerning the safety of the learned\npolicies. DRL agents, which are focused on maximizing rewards, may select\nunsafe actions, leading to safety violations. Runtime safety monitoring is thus\nessential to ensure the safe operation of these agents, especially in\nunpredictable and dynamic environments. This paper introduces SMARLA, a\nblack-box safety monitoring approach specifically designed for DRL agents.\nSMARLA utilizes machine learning to predict safety violations by observing the\nagent's behavior during execution. The approach is based on Q-values, which\nreflect the expected reward for taking actions in specific states. SMARLA\nemploys state abstraction to reduce the complexity of the state space,\nenhancing the predictive capabilities of the monitoring model. Such abstraction\nenables the early detection of unsafe states, allowing for the implementation\nof corrective and preventive measures before incidents occur. We quantitatively\nand qualitatively validated SMARLA on three well-known case studies widely used\nin DRL research. Empirical results reveal that SMARLA is accurate at predicting\nsafety violations, with a low false positive rate, and can predict violations\nat an early stage, approximately halfway through the execution of the agent,\nbefore violations occur. We also discuss different decision criteria, based on\nconfidence intervals of the predicted violation probabilities, to trigger\nsafety mechanisms aiming at a trade-off between early detection and low false\npositive rates.\n","authors":["Amirhossein Zolfagharian","Manel Abdellatif","Lionel C. Briand","Ramesh S"],"pdf_url":"https://arxiv.org/pdf/2308.02594v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.08410v3","updated":"2024-10-22T17:29:47Z","published":"2023-12-13T11:27:15Z","title":"Universal approximation property of Banach space-valued random feature\n  models including random neural networks","summary":"  We introduce a Banach space-valued extension of random feature learning, a\ndata-driven supervised machine learning technique for large-scale kernel\napproximation. By randomly initializing the feature maps, only the linear\nreadout needs to be trained, which reduces the computational complexity\nsubstantially. Viewing random feature models as Banach space-valued random\nvariables, we prove a universal approximation result in the corresponding\nBochner space. Moreover, we derive approximation rates and an explicit\nalgorithm to learn an element of the given Banach space by such models. The\nframework of this paper includes random trigonometric/Fourier regression and in\nparticular random neural networks which are single-hidden-layer feedforward\nneural networks whose weights and biases are randomly initialized, whence only\nthe linear readout needs to be trained. For the latter, we can then lift the\nuniversal approximation property of deterministic neural networks to random\nneural networks, even within function spaces over non-compact domains, e.g.,\nweighted spaces, $L^p$-spaces, and (weighted) Sobolev spaces, where the latter\nincludes the approximation of the (weak) derivatives. In addition, we analyze\nwhen the training costs for approximating a given function grow polynomially in\nboth the input/output dimension and the reciprocal of a pre-specified tolerated\napproximation error. Furthermore, we demonstrate in a numerical example the\nempirical advantages of random feature models over their deterministic\ncounterparts.\n","authors":["Ariel Neufeld","Philipp Schmocker"],"pdf_url":"https://arxiv.org/pdf/2312.08410v3.pdf","comment":"64 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.14062v2","updated":"2024-10-22T17:23:30Z","published":"2024-10-17T22:07:53Z","title":"Data-driven rainfall prediction at a regional scale: a case study with\n  Ghana","summary":"  With a warming planet, tropical regions are expected to experience the brunt\nof climate change, with more intense and more volatile rainfall events.\nCurrently, state-of-the-art numerical weather prediction (NWP) models are known\nto struggle to produce skillful rainfall forecasts in tropical regions of\nAfrica. There is thus a pressing need for improved rainfall forecasting in\nthese regions. Over the last decade or so, the increased availability of\nlarge-scale meteorological datasets and the development of powerful machine\nlearning models have opened up new opportunities for data-driven weather\nforecasting. Focusing on Ghana in this study, we use these tools to develop two\nU-Net convolutional neural network (CNN) models, to predict 24h rainfall at 12h\nand 30h lead-time. The models were trained using data from the ERA5 reanalysis\ndataset, and the GPM-IMERG dataset. A special attention was paid to\ninterpretability. We developed a novel statistical methodology that allowed us\nto probe the relative importance of the meteorological variables input in our\nmodel, offering useful insights into the factors that drive precipitation in\nthe Ghana region. Empirically, we found that our 12h lead-time model has\nperformances that match, and in some accounts are better than the 18h lead-time\nforecasts produced by the ECMWF (as available in the TIGGE dataset). We also\nfound that combining our data-driven model with classical NWP further improves\nforecast accuracy.\n","authors":["Indrajit Kalita","Lucia Vilallonga","Yves Atchade"],"pdf_url":"https://arxiv.org/pdf/2410.14062v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17932v2","updated":"2024-10-22T17:16:43Z","published":"2024-09-26T15:08:52Z","title":"Sample Compression Unleashed: New Generalization Bounds for Real Valued\n  Losses","summary":"  The sample compression theory provides generalization guarantees for\npredictors that can be fully defined using a subset of the training dataset and\na (short) message string, generally defined as a binary sequence. Previous\nworks provided generalization bounds for the zero-one loss, which is\nrestrictive notably when applied to deep learning approaches. In this paper, we\npresent a general framework for deriving new sample compression bounds that\nhold for real-valued unbounded losses. Using the Pick-To-Learn (P2L)\nmeta-algorithm, which transforms the training method of any machine-learning\npredictor to yield sample-compressed predictors, we empirically demonstrate the\ntightness of the bounds and their versatility by evaluating them on random\nforests and multiple types of neural networks.\n","authors":["Mathieu Bazinet","Valentina Zantedeschi","Pascal Germain"],"pdf_url":"https://arxiv.org/pdf/2409.17932v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17194v1","updated":"2024-10-22T17:13:34Z","published":"2024-10-22T17:13:34Z","title":"Representation Shattering in Transformers: A Synthetic Study with\n  Knowledge Editing","summary":"  Knowledge Editing (KE) algorithms alter models' internal weights to perform\ntargeted updates to incorrect, outdated, or otherwise unwanted factual\nassociations. In order to better define the possibilities and limitations of\nthese approaches, recent work has shown that applying KE can adversely affect\nmodels' factual recall accuracy and diminish their general reasoning abilities.\nWhile these studies give broad insights into the potential harms of KE\nalgorithms, e.g., via performance evaluations on benchmarks, we argue little is\nunderstood as to why such destructive failures occur. Is it possible KE methods\ndistort representations of concepts beyond the targeted fact, hence hampering\nabilities at broad? If so, what is the extent of this distortion? To take a\nstep towards addressing such questions, we define a novel synthetic task\nwherein a Transformer is trained from scratch to internalize a ``structured''\nknowledge graph. The structure enforces relationships between entities of the\ngraph, such that editing a factual association has \"trickling effects\" on other\nentities in the graph (e.g., altering X's parent is Y to Z affects who X's\nsiblings' parent is). Through evaluations of edited models and analysis of\nextracted representations, we show that KE inadvertently affects\nrepresentations of entities beyond the targeted one, distorting relevant\nstructures that allow a model to infer unseen knowledge about an entity. We\ncall this phenomenon representation shattering and demonstrate that it results\nin degradation of factual recall and reasoning performance more broadly. To\ncorroborate our findings in a more naturalistic setup, we perform preliminary\nexperiments with a pretrained GPT-2-XL model and reproduce the representation\nshattering effect therein as well. Overall, our work yields a precise\nmechanistic hypothesis to explain why KE has adverse effects on model\ncapabilities.\n","authors":["Kento Nishi","Maya Okawa","Rahul Ramesh","Mikail Khona","Ekdeep Singh Lubana","Hidenori Tanaka"],"pdf_url":"https://arxiv.org/pdf/2410.17194v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2410.17191v1","updated":"2024-10-22T17:12:21Z","published":"2024-10-22T17:12:21Z","title":"On Functional Dimension and Persistent Pseudodimension","summary":"  For any fixed feedforward ReLU neural network architecture, it is well-known\nthat many different parameter settings can determine the same function. It is\nless well-known that the degree of this redundancy is inhomogeneous across\nparameter space. In this work, we discuss two locally applicable complexity\nmeasures for ReLU network classes and what we know about the relationship\nbetween them: (1) the local functional dimension [14, 18], and (2) a local\nversion of VC dimension that we call persistent pseudodimension. The former is\neasy to compute on finite batches of points; the latter should give local\nbounds on the generalization gap, which would inform an understanding of the\nmechanics of the double descent phenomenon [7].\n","authors":["J. Elisenda Grigsby","Kathryn Lindsey"],"pdf_url":"https://arxiv.org/pdf/2410.17191v1.pdf","comment":"41 pages"},{"id":"http://arxiv.org/abs/2409.13686v2","updated":"2024-10-22T17:06:17Z","published":"2024-09-20T17:54:16Z","title":"The Impact of Large Language Models in Academia: from Writing to\n  Speaking","summary":"  Large language models (LLMs) are increasingly impacting human society,\nparticularly in textual information. Based on more than 30,000 papers and 1,000\npresentations from machine learning conferences, we examined and compared the\nwords used in writing and speaking, representing the first large-scale study of\nhow LLMs influence the two main modes of verbal communication and expression\nwithin the same group of people. Our empirical results show that LLM-style\nwords such as \"significant\" have been used more frequently in abstracts and\noral presentations. The impact on speaking is beginning to emerge and is likely\nto grow in the future, calling attention to the implicit influence and ripple\neffect of LLMs on human society.\n","authors":["Mingmeng Geng","Caixi Chen","Yanru Wu","Dongping Chen","Yao Wan","Pan Zhou"],"pdf_url":"https://arxiv.org/pdf/2409.13686v2.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2410.15473v2","updated":"2024-10-22T16:57:37Z","published":"2024-10-20T19:11:24Z","title":"A Bayesian Framework for Clustered Federated Learning","summary":"  One of the main challenges of federated learning (FL) is handling\nnon-independent and identically distributed (non-IID) client data, which may\noccur in practice due to unbalanced datasets and use of different data sources\nacross clients. Knowledge sharing and model personalization are key strategies\nfor addressing this issue. Clustered federated learning is a class of FL\nmethods that groups clients that observe similarly distributed data into\nclusters, such that every client is typically associated with one data\ndistribution and participates in training a model for that distribution along\ntheir cluster peers. In this paper, we present a unified Bayesian framework for\nclustered FL which associates clients to clusters. Then we propose several\npractical algorithms to handle the, otherwise growing, data associations in a\nway that trades off performance and computational complexity. This work\nprovides insights on client-cluster associations and enables client knowledge\nsharing in new ways. The proposed framework circumvents the need for unique\nclient-cluster associations, which is seen to increase the performance of the\nresulting models in a variety of experiments.\n","authors":["Peng Wu","Tales Imbiriba","Pau Closas"],"pdf_url":"https://arxiv.org/pdf/2410.15473v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17175v1","updated":"2024-10-22T16:51:36Z","published":"2024-10-22T16:51:36Z","title":"Remote Timing Attacks on Efficient Language Model Inference","summary":"  Scaling up language models has significantly increased their capabilities.\nBut larger models are slower models, and so there is now an extensive body of\nwork (e.g., speculative sampling or parallel decoding) that improves the\n(average case) efficiency of language model generation. But these techniques\nintroduce data-dependent timing characteristics. We show it is possible to\nexploit these timing differences to mount a timing attack. By monitoring the\n(encrypted) network traffic between a victim user and a remote language model,\nwe can learn information about the content of messages by noting when responses\nare faster or slower. With complete black-box access, on open source systems we\nshow how it is possible to learn the topic of a user's conversation (e.g.,\nmedical advice vs. coding assistance) with 90%+ precision, and on production\nsystems like OpenAI's ChatGPT and Anthropic's Claude we can distinguish between\nspecific messages or infer the user's language. We further show that an active\nadversary can leverage a boosting attack to recover PII placed in messages\n(e.g., phone numbers or credit card numbers) for open source systems. We\nconclude with potential defenses and directions for future work.\n","authors":["Nicholas Carlini","Milad Nasr"],"pdf_url":"https://arxiv.org/pdf/2410.17175v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11338v3","updated":"2024-10-22T16:39:19Z","published":"2023-06-20T07:14:37Z","title":"FDINet: Protecting against DNN Model Extraction via Feature Distortion\n  Index","summary":"  Machine Learning as a Service (MLaaS) platforms have gained popularity due to\ntheir accessibility, cost-efficiency, scalability, and rapid development\ncapabilities. However, recent research has highlighted the vulnerability of\ncloud-based models in MLaaS to model extraction attacks. In this paper, we\nintroduce FDINET, a novel defense mechanism that leverages the feature\ndistribution of deep neural network (DNN) models. Concretely, by analyzing the\nfeature distribution from the adversary's queries, we reveal that the feature\ndistribution of these queries deviates from that of the model's training set.\nBased on this key observation, we propose Feature Distortion Index (FDI), a\nmetric designed to quantitatively measure the feature distribution deviation of\nreceived queries. The proposed FDINET utilizes FDI to train a binary detector\nand exploits FDI similarity to identify colluding adversaries from distributed\nextraction attacks. We conduct extensive experiments to evaluate FDINET against\nsix state-of-the-art extraction attacks on four benchmark datasets and four\npopular model architectures. Empirical results demonstrate the following\nfindings FDINET proves to be highly effective in detecting model extraction,\nachieving a 100% detection accuracy on DFME and DaST. FDINET is highly\nefficient, using just 50 queries to raise an extraction alarm with an average\nconfidence of 96.08% for GTSRB. FDINET exhibits the capability to identify\ncolluding adversaries with an accuracy exceeding 91%. Additionally, it\ndemonstrates the ability to detect two types of adaptive attacks.\n","authors":["Hongwei Yao","Zheng Li","Haiqin Weng","Feng Xue","Zhan Qin","Kui Ren"],"pdf_url":"https://arxiv.org/pdf/2306.11338v3.pdf","comment":"Accepted to IEEE Transactions on Dependable and Secure Computing"},{"id":"http://arxiv.org/abs/2410.17161v1","updated":"2024-10-22T16:34:36Z","published":"2024-10-22T16:34:36Z","title":"Interchangeable Token Embeddings for Extendable Vocabulary and\n  Alpha-Equivalence","summary":"  We propose a novel approach for learning interchangeable tokens in language\nmodels to obtain an extendable vocabulary that can generalize to new tokens.\nOur method is designed to address alpha-equivalence, the principle that\nrenaming bound variables in a syntactic expression preserves semantics. This\nproperty arises in many formal languages such as temporal logics, in which all\nproposition symbols represent the same concept but are distinguishable from\neach other. To handle such tokens, we develop a dual-part embedding approach.\nThe first part is shared across all interchangeable tokens, thereby enforcing\nthat they represent the same core concept. The second part is randomly\ngenerated for each token, which enables distinguishability. We evaluate our\nmethod in a Transformer encoder-decoder model on two tasks: solving linear\ntemporal logic formulae and copying with extendable vocabulary. Our method\ndemonstrates promising generalization capabilities in addition to introducing a\nfavorable inductive bias for alpha-equivalence.\n","authors":["İlker Işık","Ramazan Gokberk Cinbis","Ebru Aydin Gol"],"pdf_url":"https://arxiv.org/pdf/2410.17161v1.pdf","comment":"14 pages, 5 figures"},{"id":"http://arxiv.org/abs/2410.17159v1","updated":"2024-10-22T16:33:54Z","published":"2024-10-22T16:33:54Z","title":"LiNo: Advancing Recursive Residual Decomposition of Linear and Nonlinear\n  Patterns for Robust Time Series Forecasting","summary":"  Forecasting models are pivotal in a data-driven world with vast volumes of\ntime series data that appear as a compound of vast Linear and Nonlinear\npatterns. Recent deep time series forecasting models struggle to utilize\nseasonal and trend decomposition to separate the entangled components. Such a\nstrategy only explicitly extracts simple linear patterns like trends, leaving\nthe other linear modes and vast unexplored nonlinear patterns to the residual.\nTheir flawed linear and nonlinear feature extraction models and shallow-level\ndecomposition limit their adaptation to the diverse patterns present in\nreal-world scenarios. Given this, we innovate Recursive Residual Decomposition\nby introducing explicit extraction of both linear and nonlinear patterns. This\ndeeper-level decomposition framework, which is named LiNo, captures linear\npatterns using a Li block which can be a moving average kernel, and models\nnonlinear patterns using a No block which can be a Transformer encoder. The\nextraction of these two patterns is performed alternatively and recursively. To\nachieve the full potential of LiNo, we develop the current simple linear\npattern extractor to a general learnable autoregressive model, and design a\nnovel No block that can handle all essential nonlinear patterns. Remarkably,\nthe proposed LiNo achieves state-of-the-art on thirteen real-world benchmarks\nunder univariate and multivariate forecasting scenarios. Experiments show that\ncurrent forecasting models can deliver more robust and precise results through\nthis advanced Recursive Residual Decomposition. We hope this work could offer\ninsight into designing more effective forecasting models. Code is available at\nthis Repository: https://github.com/Levi-Ackman/LiNo.\n","authors":["Guoqi Yu","Yaoming Li","Xiaoyu Guo","Dayu Wang","Zirui Liu","Shujun Wang","Tong Yang"],"pdf_url":"https://arxiv.org/pdf/2410.17159v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17147v1","updated":"2024-10-22T16:27:29Z","published":"2024-10-22T16:27:29Z","title":"Covariance estimation using Markov chain Monte Carlo","summary":"  We investigate the complexity of covariance matrix estimation for Gibbs\ndistributions based on dependent samples from a Markov chain. We show that when\n$\\pi$ satisfies a Poincar\\'e inequality and the chain possesses a spectral gap,\nwe can achieve similar sample complexity using MCMC as compared to an estimator\nconstructed using i.i.d. samples, with potentially much better query\ncomplexity. As an application of our methods, we show improvements for the\nquery complexity in both constrained and unconstrained settings for concrete\ninstances of MCMC. In particular, we provide guarantees regarding isotropic\nrounding procedures for sampling uniformly on convex bodies.\n","authors":["Yunbum Kook","Matthew S. Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.17147v1.pdf","comment":"30 pages"},{"id":"http://arxiv.org/abs/2406.01205v2","updated":"2024-10-22T16:26:55Z","published":"2024-06-03T11:15:16Z","title":"ControlSpeech: Towards Simultaneous Zero-shot Speaker Cloning and\n  Zero-shot Language Style Control With Decoupled Codec","summary":"  In this paper, we present ControlSpeech, a text-to-speech (TTS) system\ncapable of fully cloning the speaker's voice and enabling arbitrary control and\nadjustment of speaking style, merely based on a few seconds of audio prompt and\na simple textual style description prompt. Prior zero-shot TTS models and\ncontrollable TTS models either could only mimic the speaker's voice without\nfurther control and adjustment capabilities or were unrelated to\nspeaker-specific voice generation. Therefore, ControlSpeech focuses on a more\nchallenging new task-a TTS system with controllable timbre, content, and style\nat the same time. ControlSpeech takes speech prompts, content prompts, and\nstyle prompts as inputs and utilizes bidirectional attention and mask-based\nparallel decoding to capture corresponding codec representations in a discrete\ndecoupling codec space. Moreover, we discovered the issue of text style\ncontrollability in a many-to-many mapping fashion and proposed the Style\nMixture Semantic Density (SMSD) model to resolve this problem. SMSD module\nwhich is based on Gaussian mixture density networks, is designed to enhance the\nfine-grained partitioning and sampling capabilities of style semantic\ninformation and generate speech with more diverse styles. In terms of\nexperiments, we make available a controllable model toolkit called\nControlToolkit with a new style controllable dataset, some replicated baseline\nmodels and propose new metrics to evaluate both the control capability and the\nquality of generated audio in ControlSpeech. The relevant ablation studies\nvalidate the necessity of each component in ControlSpeech is necessary. We hope\nthat ControlSpeech can establish the next foundation paradigm of controllable\nspeech synthesis. The relevant code and demo are available at\nhttps://github.com/jishengpeng/ControlSpeech .\n","authors":["Shengpeng Ji","Jialong Zuo","Wen Wang","Minghui Fang","Siqi Zheng","Qian Chen","Ziyue Jiang","Hai Huang","Zehan Wang","Xize Cheng","Zhou Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.01205v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02581v3","updated":"2024-10-22T16:26:40Z","published":"2024-10-03T15:25:37Z","title":"Boosting Sample Efficiency and Generalization in Multi-agent\n  Reinforcement Learning via Equivariance","summary":"  Multi-Agent Reinforcement Learning (MARL) struggles with sample inefficiency\nand poor generalization [1]. These challenges are partially due to a lack of\nstructure or inductive bias in the neural networks typically used in learning\nthe policy. One such form of structure that is commonly observed in multi-agent\nscenarios is symmetry. The field of Geometric Deep Learning has developed\nEquivariant Graph Neural Networks (EGNN) that are equivariant (or symmetric) to\nrotations, translations, and reflections of nodes. Incorporating equivariance\nhas been shown to improve learning efficiency and decrease error [ 2 ]. In this\npaper, we demonstrate that EGNNs improve the sample efficiency and\ngeneralization in MARL. However, we also show that a naive application of EGNNs\nto MARL results in poor early exploration due to a bias in the EGNN structure.\nTo mitigate this bias, we present Exploration-enhanced Equivariant Graph Neural\nNetworks or E2GN2. We compare E2GN2 to other common function approximators\nusing common MARL benchmarks MPE and SMACv2. E2GN2 demonstrates a significant\nimprovement in sample efficiency, greater final reward convergence, and a 2x-5x\ngain in over standard GNNs in our generalization tests. These results pave the\nway for more reliable and effective solutions in complex multi-agent systems.\n","authors":["Joshua McClellan","Naveed Haghani","John Winder","Furong Huang","Pratap Tokekar"],"pdf_url":"https://arxiv.org/pdf/2410.02581v3.pdf","comment":"accepted as a poster at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.17146v1","updated":"2024-10-22T16:26:05Z","published":"2024-10-22T16:26:05Z","title":"LiNeS: Post-training Layer Scaling Prevents Forgetting and Enhances\n  Model Merging","summary":"  Large pre-trained models exhibit impressive zero-shot performance across\ndiverse tasks, but fine-tuning often leads to catastrophic forgetting, where\nimprovements on a target domain degrade generalization on other tasks. To\naddress this challenge, we introduce LiNeS, Layer-increasing Network Scaling, a\npost-training editing technique designed to preserve pre-trained generalization\nwhile enhancing fine-tuned task performance. LiNeS scales parameter updates\nlinearly based on their layer depth within the network, maintaining shallow\nlayers close to their pre-trained values to preserve general features while\nallowing deeper layers to retain task-specific representations. We further\nextend this approach to multi-task model merging scenarios, where layer-wise\nscaling of merged parameters reduces negative task interference. LiNeS\ndemonstrates significant improvements in both single-task and multi-task\nsettings across various benchmarks in vision and natural language processing.\nIt mitigates forgetting, enhances out-of-distribution generalization,\nintegrates seamlessly with existing multi-task model merging baselines\nimproving their performance across benchmarks and model sizes, and can boost\ngeneralization when merging LLM policies aligned with different rewards via\nRLHF. Importantly, our method is simple to implement and complementary to many\nexisting techniques.\n","authors":["Ke Wang","Nikolaos Dimitriadis","Alessandro Favero","Guillermo Ortiz-Jimenez","Francois Fleuret","Pascal Frossard"],"pdf_url":"https://arxiv.org/pdf/2410.17146v1.pdf","comment":"The first two authors contributed equally to this work; Project\n  website: \\url{https://lines-merging.github.io/}"},{"id":"http://arxiv.org/abs/2410.17145v1","updated":"2024-10-22T16:26:03Z","published":"2024-10-22T16:26:03Z","title":"Can General-Purpose Large Language Models Generalize to English-Thai\n  Machine Translation ?","summary":"  Large language models (LLMs) perform well on common tasks but struggle with\ngeneralization in low-resource and low-computation settings. We examine this\nlimitation by testing various LLMs and specialized translation models on\nEnglish-Thai machine translation and code-switching datasets. Our findings\nreveal that under more strict computational constraints, such as 4-bit\nquantization, LLMs fail to translate effectively. In contrast, specialized\nmodels, with comparable or lower computational requirements, consistently\noutperform LLMs. This underscores the importance of specialized models for\nmaintaining performance under resource constraints.\n","authors":["Jirat Chiaranaipanich","Naiyarat Hanmatheekuna","Jitkapat Sawatphol","Krittamate Tiankanon","Jiramet Kinchagawat","Amrest Chinkamol","Parinthapat Pengpun","Piyalitt Ittichaiwong","Peerat Limkonchotiwat"],"pdf_url":"https://arxiv.org/pdf/2410.17145v1.pdf","comment":"Accepted in GenBench EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.17142v1","updated":"2024-10-22T16:19:13Z","published":"2024-10-22T16:19:13Z","title":"Coniferest: a complete active anomaly detection framework","summary":"  We present coniferest, an open source generic purpose active anomaly\ndetection framework written in Python. The package design and implemented\nalgorithms are described. Currently, static outlier detection analysis is\nsupported via the Isolation forest algorithm. Moreover, Active Anomaly\nDiscovery (AAD) and Pineforest algorithms are available to tackle active\nanomaly detection problems. The algorithms and package performance are\nevaluated on a series of synthetic datasets. We also describe a few success\ncases which resulted from applying the package to real astronomical data in\nactive anomaly detection tasks within the SNAD project.\n","authors":["M. V. Kornilov","V. S. Korolev","K. L. Malanchev","A. D. Lavrukhina","E. Russeil","T. A. Semenikhin","E. Gangler","E. E. O. Ishida","M. V. Pruzhinskaya","A. A. Volnova","S. Sreejith"],"pdf_url":"https://arxiv.org/pdf/2410.17142v1.pdf","comment":"13 pages, 1 figure"},{"id":"http://arxiv.org/abs/2410.17135v1","updated":"2024-10-22T16:07:55Z","published":"2024-10-22T16:07:55Z","title":"Reinforcement Learning for Data-Driven Workflows in Radio\n  Interferometry. I. Principal Demonstration in Calibration","summary":"  Radio interferometry is an observational technique used to study\nastrophysical phenomena. Data gathered by an interferometer requires\nsubstantial processing before astronomers can extract the scientific\ninformation from it. Data processing consists of a sequence of calibration and\nanalysis procedures where choices must be made about the sequence of procedures\nas well as the specific configuration of the procedure itself. These choices\nare typically based on a combination of measurable data characteristics, an\nunderstanding of the instrument itself, an appreciation of the trade-offs\nbetween compute cost and accuracy, and a learned understanding of what is\nconsidered \"best practice\". A metric of absolute correctness is not always\navailable and validity is often subject to human judgment. The underlying\nprinciples and software configurations to discern a reasonable workflow for a\ngiven dataset is the subject of training workshops for students and scientists.\nOur goal is to use objective metrics that quantify best practice, and\nnumerically map out the decision space with respect to our metrics. With these\nobjective metrics we demonstrate an automated, data-driven, decision system\nthat is capable of sequencing the optimal action(s) for processing\ninterferometric data. This paper introduces a simplified description of the\nprinciples behind interferometry and the procedures required for data\nprocessing. We highlight the issues with current automation approaches and\npropose our ideas for solving these bottlenecks. A prototype is demonstrated\nand the results are discussed.\n","authors":["Brian M. Kirk","Urvashi Rau","Ramyaa Ramyaa"],"pdf_url":"https://arxiv.org/pdf/2410.17135v1.pdf","comment":"22 pages, 13 figures; accepted for publication in The Astronomical\n  Journal October 18, 2024"},{"id":"http://arxiv.org/abs/2410.17128v1","updated":"2024-10-22T16:00:44Z","published":"2024-10-22T16:00:44Z","title":"Understanding Transfer Learning via Mean-field Analysis","summary":"  We propose a novel framework for exploring generalization errors of transfer\nlearning through the lens of differential calculus on the space of probability\nmeasures. In particular, we consider two main transfer learning scenarios,\n$\\alpha$-ERM and fine-tuning with the KL-regularized empirical risk\nminimization and establish generic conditions under which the generalization\nerror and the population risk convergence rates for these scenarios are\nstudied. Based on our theoretical results, we show the benefits of transfer\nlearning with a one-hidden-layer neural network in the mean-field regime under\nsome suitable integrability and regularity assumptions on the loss and\nactivation functions.\n","authors":["Gholamali Aminian","Samuel N. Cohen","Łukasz Szpruch"],"pdf_url":"https://arxiv.org/pdf/2410.17128v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2410.17126v1","updated":"2024-10-22T15:59:58Z","published":"2024-10-22T15:59:58Z","title":"Exploring RL-based LLM Training for Formal Language Tasks with\n  Programmed Rewards","summary":"  Proximal Policy Optimization (PPO) is commonly used in Reinforcement Learning\nfrom Human Feedback to align large language models (LLMs) with downstream\ntasks. This paper investigates the feasibility of using PPO for direct\nreinforcement learning (RL) from explicitly programmed reward signals, as\nopposed to indirect learning from human feedback via an intermediary reward\nmodel. We focus on tasks expressed through formal languages, such as\nmathematics and programming, where explicit reward functions can be programmed\nto automatically assess the quality of generated outputs. We apply this\napproach to a sentiment alignment task, a simple arithmetic task, and a more\ncomplex game synthesis task. The sentiment alignment task replicates prior\nresearch and serves to validate our experimental setup. Our results show that\npure RL-based training for the two formal language tasks is challenging, with\nsuccess being limited even for the simple arithmetic task. We propose a novel\nbatch-entropy regularization term to aid exploration, although training is not\nyet entirely stable. Our findings suggest that direct RL training of LLMs may\nbe more suitable for relatively minor changes, such as alignment, than for\nlearning new tasks altogether, even if an informative reward signal can be\nexpressed programmatically.\n","authors":["Alexander G. Padula","Dennis J. N. J. Soemers"],"pdf_url":"https://arxiv.org/pdf/2410.17126v1.pdf","comment":"Accepted at BNAIC 2024"},{"id":"http://arxiv.org/abs/2410.17118v1","updated":"2024-10-22T15:49:53Z","published":"2024-10-22T15:49:53Z","title":"Learning Load Balancing with GNN in MPTCP-Enabled Heterogeneous Networks","summary":"  Hybrid light fidelity (LiFi) and wireless fidelity (WiFi) networks are a\npromising paradigm of heterogeneous network (HetNet), attributed to the\ncomplementary physical properties of optical spectra and radio frequency.\nHowever, the current development of such HetNets is mostly bottlenecked by the\nexisting transmission control protocol (TCP), which restricts the user\nequipment (UE) to connecting one access point (AP) at a time. While the ongoing\ninvestigation on multipath TCP (MPTCP) can bring significant benefits, it\ncomplicates the network topology of HetNets, making the existing load balancing\n(LB) learning models less effective. Driven by this, we propose a graph neural\nnetwork (GNN)-based model to tackle the LB problem for MPTCP-enabled HetNets,\nwhich results in a partial mesh topology. Such a topology can be modeled as a\ngraph, with the channel state information and data rate requirement embedded as\nnode features, while the LB solutions are deemed as edge labels. Compared to\nthe conventional deep neural network (DNN), the proposed GNN-based model\nexhibits two key strengths: i) it can better interpret a complex network\ntopology; and ii) it can handle various numbers of APs and UEs with a single\ntrained model. Simulation results show that against the traditional\noptimisation method, the proposed learning model can achieve near-optimal\nthroughput within a gap of 11.5%, while reducing the inference time by 4 orders\nof magnitude. In contrast to the DNN model, the new method can improve the\nnetwork throughput by up to 21.7%, at a similar inference time level.\n","authors":["Han Ji","Xiping Wu","Zhihong Zeng","Chen Chen"],"pdf_url":"https://arxiv.org/pdf/2410.17118v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.09656v5","updated":"2024-10-22T15:36:34Z","published":"2023-02-19T19:03:26Z","title":"Credal Bayesian Deep Learning","summary":"  Uncertainty quantification and robustness to distribution shifts are\nimportant goals in machine learning and artificial intelligence. Although\nBayesian Neural Networks (BNNs) allow for uncertainty in the predictions to be\nassessed, different sources of predictive uncertainty cannot be distinguished\nproperly. We present Credal Bayesian Deep Learning (CBDL). Heuristically, CBDL\nallows to train an (uncountably) infinite ensemble of BNNs, using only finitely\nmany elements. This is possible thanks to prior and likelihood finitely\ngenerated credal sets (FGCSs), a concept from the imprecise probability\nliterature. Intuitively, convex combinations of a finite collection of\nprior-likelihood pairs are able to represent infinitely many such pairs. After\ntraining, CBDL outputs a set of posteriors on the parameters of the neural\nnetwork. At inference time, such posterior set is used to derive a set of\npredictive distributions that is in turn utilized to distinguish between\n(predictive) aleatoric and epistemic uncertainties, and to quantify them. The\npredictive set also produces either (i) a collection of outputs enjoying\ndesirable probabilistic guarantees, or (ii) the single output that is deemed\nthe best, that is, the one having the highest predictive lower probability --\nanother imprecise-probabilistic concept. CBDL is more robust than single BNNs\nto prior and likelihood misspecification, and to distribution shift. We show\nthat CBDL is better at quantifying and disentangling different types of\n(predictive) uncertainties than single BNNs and ensemble of BNNs. In addition,\nwe apply CBDL to two case studies to demonstrate its downstream tasks\ncapabilities: one, for motion prediction in autonomous driving scenarios, and\ntwo, to model blood glucose and insulin dynamics for artificial pancreas\ncontrol. We show that CBDL performs better when compared to an ensemble of BNNs\nbaseline.\n","authors":["Michele Caprio","Souradeep Dutta","Kuk Jin Jang","Vivian Lin","Radoslav Ivanov","Oleg Sokolsky","Insup Lee"],"pdf_url":"https://arxiv.org/pdf/2302.09656v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17111v1","updated":"2024-10-22T15:36:04Z","published":"2024-10-22T15:36:04Z","title":"Permutation Picture of Graph Combinatorial Optimization Problems","summary":"  This paper proposes a framework that formulates a wide range of graph\ncombinatorial optimization problems using permutation-based representations.\nThese problems include the travelling salesman problem, maximum independent\nset, maximum cut, and various other related problems. This work potentially\nopens up new avenues for algorithm design in neural combinatorial optimization,\nbridging the gap between discrete and continuous optimization techniques.\n","authors":["Yimeng Min"],"pdf_url":"https://arxiv.org/pdf/2410.17111v1.pdf","comment":"15 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.17099v1","updated":"2024-10-22T15:22:58Z","published":"2024-10-22T15:22:58Z","title":"Human-LLM Hybrid Text Answer Aggregation for Crowd Annotations","summary":"  The quality is a crucial issue for crowd annotations. Answer aggregation is\nan important type of solution. The aggregated answers estimated from multiple\ncrowd answers to the same instance are the eventually collected annotations,\nrather than the individual crowd answers themselves. Recently, the capability\nof Large Language Models (LLMs) on data annotation tasks has attracted interest\nfrom researchers. Most of the existing studies mainly focus on the average\nperformance of individual crowd workers; several recent works studied the\nscenarios of aggregation on categorical labels and LLMs used as label creators.\nHowever, the scenario of aggregation on text answers and the role of LLMs as\naggregators are not yet well-studied. In this paper, we investigate the\ncapability of LLMs as aggregators in the scenario of close-ended crowd text\nanswer aggregation. We propose a human-LLM hybrid text answer aggregation\nmethod with a Creator-Aggregator Multi-Stage (CAMS) crowdsourcing framework. We\nmake the experiments based on public crowdsourcing datasets. The results show\nthe effectiveness of our approach based on the collaboration of crowd workers\nand LLMs.\n","authors":["Jiyi Li"],"pdf_url":"https://arxiv.org/pdf/2410.17099v1.pdf","comment":"Accepted in EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.17086v1","updated":"2024-10-22T15:13:13Z","published":"2024-10-22T15:13:13Z","title":"Exploration and Persuasion","summary":"  How to incentivize self-interested agents to explore when they prefer to\nexploit? Consider a population of self-interested agents that make decisions\nunder uncertainty. They \"explore\" to acquire new information and \"exploit\" this\ninformation to make good decisions. Collectively they need to balance these two\nobjectives, but their incentives are skewed toward exploitation. This is\nbecause exploration is costly, but its benefits are spread over many agents in\nthe future.\n  \"Incentivized Exploration\" addresses this issue via strategic communication.\nConsider a benign ``principal\" which can communicate with the agents and make\nrecommendations, but cannot force the agents to comply. Moreover, suppose the\nprincipal can observe the agents' decisions and the outcomes of these\ndecisions. The goal is to design a communication and recommendation policy\nwhich (i) achieves a desirable balance between exploration and exploitation,\nand (ii) incentivizes the agents to follow recommendations. What makes it\nfeasible is \"information asymmetry\": the principal knows more than any one\nagent, as it collects information from many. It is essential that the principal\ndoes not fully reveal all its knowledge to the agents.\n  Incentivized exploration combines two important problems in, resp., machine\nlearning and theoretical economics. First, if agents always follow\nrecommendations, the principal faces a multi-armed bandit problem: essentially,\ndesign an algorithm that balances exploration and exploitation. Second,\ninteraction with a single agent corresponds to \"Bayesian persuasion\", where a\nprincipal leverages information asymmetry to convince an agent to take a\nparticular action. We provide a brief but self-contained introduction to each\nproblem through the lens of incentivized exploration, solving a key special\ncase of the former as a sub-problem of the latter.\n","authors":["Aleksandrs Slivkins"],"pdf_url":"https://arxiv.org/pdf/2410.17086v1.pdf","comment":"This is a chapter published in \"Online and Matching-Based Markets\",\n  Cambridge University Press, 2023. It has been available from the author's\n  website since 2021"},{"id":"http://arxiv.org/abs/2401.00691v3","updated":"2024-10-22T15:06:05Z","published":"2024-01-01T08:03:52Z","title":"Stochastic Gradient Descent for Nonparametric Regression","summary":"  This paper introduces an iterative algorithm for training nonparametric\nadditive models that enjoys favorable memory storage and computational\nrequirements. The algorithm can be viewed as the functional counterpart of\nstochastic gradient descent, applied to the coefficients of a truncated basis\nexpansion of the component functions. We show that the resulting estimator\nsatisfies an oracle inequality that allows for model mis-specification. In the\nwell-specified setting, by choosing the learning rate carefully across three\ndistinct stages of training, we demonstrate that its risk is minimax optimal in\nterms of the dependence on the dimensionality of the data and the size of the\ntraining sample. We also provide polynomial convergence rates even when the\ncovariates do not have full support on their domain.\n","authors":["Xin Chen","Jason M. Klusowski"],"pdf_url":"https://arxiv.org/pdf/2401.00691v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.05180v2","updated":"2024-10-22T14:54:42Z","published":"2024-04-22T10:33:06Z","title":"ReCAP: Recursive Cross Attention Network for Pseudo-Label Generation in\n  Robotic Surgical Skill Assessment","summary":"  In surgical skill assessment, Objective Structured Assessments of Technical\nSkills (OSATS scores) and the Global Rating Scale (GRS) are established tools\nfor evaluating the performance of surgeons during training. These metrics,\ncoupled with feedback on their performance, enable surgeons to improve and\nachieve standards of practice. Recent studies on the open-source dataset\nJIGSAW, which contains both GRS and OSATS labels, have focused on regressing\nGRS scores from kinematic signals, video data, or a combination of both. In\nthis paper, we argue that regressing the GRS score, a unitless value, by itself\nis too restrictive, and variations throughout the surgical trial do not hold\nsignificant clinical meaning. To address this gap, we developed a recurrent\ntransformer model that outputs the surgeon's performance throughout their\ntraining session by relating the model's hidden states to five OSATS scores\nderived from kinematic signals. These scores are averaged and aggregated to\nproduce a GRS prediction, enabling assessment of the model's performance\nagainst the state-of-the-art (SOTA). We report Spearman's Correlation\nCoefficient (SCC), demonstrating that our model outperforms SOTA models for all\ntasks, except for Suturing under the leave-one-subject-out (LOSO) scheme (SCC\n0.68-0.89), while achieving comparable performance for suturing and across\ntasks under the leave-one-user-out (LOUO) scheme (SCC 0.45-0.68) and beating\nSOTA for Needle Passing (0.69). We argue that relating final OSATS scores to\nshort instances throughout a surgeon's procedure is more clinically meaningful\nthan a single GRS score. This approach also allows us to translate quantitative\npredictions into qualitative feedback, which is crucial for any automated\nsurgical skill assessment pipeline. A senior surgeon validated our model's\nbehaviour and agreed with the semi-supervised predictions 77 \\% (p = 0.006) of\nthe time.\n","authors":["Julien Quarez","Matthew Elliot","Oscar Maccormac","Marc Modat","Sebastien Ourselin","Jonathan Shapey","Alejandro Granados"],"pdf_url":"https://arxiv.org/pdf/2407.05180v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17075v1","updated":"2024-10-22T14:52:46Z","published":"2024-10-22T14:52:46Z","title":"Combinatorial Logistic Bandits","summary":"  We introduce a novel framework called combinatorial logistic bandits (CLogB),\nwhere in each round, a subset of base arms (called the super arm) is selected,\nwith the outcome of each base arm being binary and its expectation following a\nlogistic parametric model. The feedback is governed by a general arm triggering\nprocess. Our study covers CLogB with reward functions satisfying two smoothness\nconditions, capturing application scenarios such as online content delivery,\nonline learning to rank, and dynamic channel allocation. We first propose a\nsimple yet efficient algorithm, CLogUCB, utilizing a variance-agnostic\nexploration bonus. Under the 1-norm triggering probability modulated (TPM)\nsmoothness condition, CLogUCB achieves a regret bound of\n$\\tilde{O}(d\\sqrt{\\kappa KT})$, where $\\tilde{O}$ ignores logarithmic factors,\n$d$ is the dimension of the feature vector, $\\kappa$ represents the\nnonlinearity of the logistic model, and $K$ is the maximum number of base arms\na super arm can trigger. This result improves on prior work by a factor of\n$\\tilde{O}(\\sqrt{\\kappa})$. We then enhance CLogUCB with a variance-adaptive\nversion, VA-CLogUCB, which attains a regret bound of $\\tilde{O}(d\\sqrt{KT})$\nunder the same 1-norm TPM condition, improving another\n$\\tilde{O}(\\sqrt{\\kappa})$ factor. VA-CLogUCB shows even greater promise under\nthe stronger triggering probability and variance modulated (TPVM) condition,\nachieving a leading $\\tilde{O}(d\\sqrt{T})$ regret, thus removing the additional\ndependency on the action-size $K$. Furthermore, we enhance the computational\nefficiency of VA-CLogUCB by eliminating the nonconvex optimization process when\nthe context feature map is time-invariant while maintaining the tight\n$\\tilde{O}(d\\sqrt{T})$ regret. Finally, experiments on synthetic and real-world\ndatasets demonstrate the superior performance of our algorithms compared to\nbenchmark algorithms.\n","authors":["Xutong Liu","Xiangxiang Dai","Xuchuang Wang","Mohammad Hajiesmaili","John C. S. Lui"],"pdf_url":"https://arxiv.org/pdf/2410.17075v1.pdf","comment":"Accepted to ACM SIGMETRICS 2025"},{"id":"http://arxiv.org/abs/2401.03069v4","updated":"2024-10-22T14:50:29Z","published":"2024-01-05T21:30:13Z","title":"Towards Enhancing the Reproducibility of Deep Learning Bugs: An\n  Empirical Study","summary":"  Context: Deep learning has achieved remarkable progress in various domains.\nHowever, like any software system, deep learning systems contain bugs, some of\nwhich can have severe impacts, as evidenced by crashes involving autonomous\nvehicles. Despite substantial advancements in deep learning techniques, little\nresearch has focused on reproducing deep learning bugs, which is an essential\nstep for their resolution. Existing literature suggests that only 3% of deep\nlearning bugs are reproducible, underscoring the need for further research.\n  Objective: This paper examines the reproducibility of deep learning bugs. We\nidentify edit actions and useful information that could improve the\nreproducibility of deep learning bugs.\n  Method: First, we construct a dataset of 668 deep-learning bugs from Stack\nOverflow and GitHub across three frameworks and 22 architectures. Second, out\nof the 668 bugs, we select 165 bugs using stratified sampling and attempt to\ndetermine their reproducibility. While reproducing these bugs, we identify edit\nactions and useful information for their reproduction. Third, we used the\nApriori algorithm to identify useful information and edit actions required to\nreproduce specific types of bugs. Finally, we conducted a user study involving\n22 developers to assess the effectiveness of our findings in real-life\nsettings.\n  Results: We successfully reproduced 148 out of 165 bugs attempted. We\nidentified ten edit actions and five useful types of component information that\ncan help us reproduce the deep learning bugs. With the help of our findings,\nthe developers were able to reproduce 22.92% more bugs and reduce their\nreproduction time by 24.35%.\n  Conclusions: Our research addresses the critical issue of deep learning bug\nreproducibility. Practitioners and researchers can leverage our findings to\nimprove deep learning bug reproducibility.\n","authors":["Mehil B. Shah","Mohammad Masudur Rahman","Foutse Khomh"],"pdf_url":"https://arxiv.org/pdf/2401.03069v4.pdf","comment":"Accepted at the Journal of Empirical Software Engineering (EMSE)"},{"id":"http://arxiv.org/abs/2410.17066v1","updated":"2024-10-22T14:46:20Z","published":"2024-10-22T14:46:20Z","title":"Neuronal Competition Groups with Supervised STDP for Spike-Based\n  Classification","summary":"  Spike Timing-Dependent Plasticity (STDP) is a promising substitute to\nbackpropagation for local training of Spiking Neural Networks (SNNs) on\nneuromorphic hardware. STDP allows SNNs to address classification tasks by\ncombining unsupervised STDP for feature extraction and supervised STDP for\nclassification. Unsupervised STDP is usually employed with Winner-Takes-All\n(WTA) competition to learn distinct patterns. However, WTA for supervised STDP\nclassification faces unbalanced competition challenges. In this paper, we\npropose a method to effectively implement WTA competition in a spiking\nclassification layer employing first-spike coding and supervised STDP training.\nWe introduce the Neuronal Competition Group (NCG), an architecture that\nimproves classification capabilities by promoting the learning of various\npatterns per class. An NCG is a group of neurons mapped to a specific class,\nimplementing intra-class WTA and a novel competition regulation mechanism based\non two-compartment thresholds. We incorporate our proposed architecture into\nspiking classification layers trained with state-of-the-art supervised STDP\nrules. On top of two different unsupervised feature extractors, we obtain\nsignificant accuracy improvements on image recognition datasets such as\nCIFAR-10 and CIFAR-100. We show that our competition regulation mechanism is\ncrucial for ensuring balanced competition and improved class separation.\n","authors":["Gaspard Goupy","Pierre Tirilly","Ioan Marius Bilasco"],"pdf_url":"https://arxiv.org/pdf/2410.17066v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.16532v2","updated":"2024-10-22T14:40:15Z","published":"2024-08-29T13:43:36Z","title":"WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio\n  Language Modeling","summary":"  Language models have been effectively applied to modeling natural signals,\nsuch as images, video, speech, and audio. A crucial component of these models\nis the codec tokenizer, which compresses high-dimensional natural signals into\nlower-dimensional discrete tokens. In this paper, we introduce WavTokenizer,\nwhich offers several advantages over previous SOTA acoustic codec models in the\naudio domain: 1)extreme compression. By compressing the layers of quantizers\nand the temporal dimension of the discrete codec, one-second audio of 24kHz\nsampling rate requires only a single quantizer with 40 or 75 tokens. 2)improved\nsubjective quality. Despite the reduced number of tokens, WavTokenizer achieves\nstate-of-the-art reconstruction quality with outstanding UTMOS scores and\ninherently contains richer semantic information. Specifically, we achieve these\nresults by designing a broader VQ space, extended contextual windows, and\nimproved attention networks, as well as introducing a powerful multi-scale\ndiscriminator and an inverse Fourier transform structure. We conducted\nextensive reconstruction experiments in the domains of speech, audio, and\nmusic. WavTokenizer exhibited strong performance across various objective and\nsubjective metrics compared to state-of-the-art models. We also tested semantic\ninformation, VQ utilization, and adaptability to generative models.\nComprehensive ablation studies confirm the necessity of each module in\nWavTokenizer. The related code, demos, and pre-trained models are available at\nhttps://github.com/jishengpeng/WavTokenizer.\n","authors":["Shengpeng Ji","Ziyue Jiang","Wen Wang","Yifu Chen","Minghui Fang","Jialong Zuo","Qian Yang","Xize Cheng","Zehan Wang","Ruiqi Li","Ziang Zhang","Xiaoda Yang","Rongjie Huang","Yidi Jiang","Qian Chen","Siqi Zheng","Wen Wang","Zhou Zhao"],"pdf_url":"https://arxiv.org/pdf/2408.16532v2.pdf","comment":"Working in progress"},{"id":"http://arxiv.org/abs/2410.17055v1","updated":"2024-10-22T14:36:44Z","published":"2024-10-22T14:36:44Z","title":"Optimal Design for Reward Modeling in RLHF","summary":"  Reinforcement Learning from Human Feedback (RLHF) has become a popular\napproach to align language models (LMs) with human preferences. This method\ninvolves collecting a large dataset of human pairwise preferences across\nvarious text generations and using it to infer (implicitly or explicitly) a\nreward model. Numerous methods have been proposed to learn the reward model and\nalign a LM with it. However, the costly process of collecting human preferences\nhas received little attention and could benefit from theoretical insights. This\npaper addresses this issue and aims to formalize the reward training model in\nRLHF. We frame the selection of an effective dataset as a simple regret\nminimization task, using a linear contextual dueling bandit method. Given the\npotentially large number of arms, this approach is more coherent than the\nbest-arm identification setting. We then propose an offline framework for\nsolving this problem. Under appropriate assumptions - linearity of the reward\nmodel in the embedding space, and boundedness of the reward parameter - we\nderive bounds on the simple regret. Finally, we provide a lower bound that\nmatches our upper bound up to constant and logarithmic terms. To our knowledge,\nthis is the first theoretical contribution in this area to provide an offline\napproach as well as worst-case guarantees.\n","authors":["Antoine Scheid","Etienne Boursier","Alain Durmus","Michael I. Jordan","Pierre Ménard","Eric Moulines","Michal Valko"],"pdf_url":"https://arxiv.org/pdf/2410.17055v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17050v1","updated":"2024-10-22T14:30:03Z","published":"2024-10-22T14:30:03Z","title":"UnStar: Unlearning with Self-Taught Anti-Sample Reasoning for LLMs","summary":"  The key components of machine learning are data samples for training, model\nfor learning patterns, and loss function for optimizing accuracy. Analogously,\nunlearning can potentially be achieved through anti-data samples (or\nanti-samples), unlearning method, and reversed loss function. While prior\nresearch has explored unlearning methods and reversed loss functions, the\npotential of anti-samples remains largely untapped. In this paper, we introduce\nUnSTAR: Unlearning with Self-Taught Anti-Sample Reasoning for large language\nmodels (LLMs). Our contributions are threefold; first, we propose a novel\nconcept of anti-sample-induced unlearning; second, we generate anti-samples by\nleveraging misleading rationales, which help reverse learned associations and\naccelerate the unlearning process; and third, we enable fine-grained targeted\nunlearning, allowing for the selective removal of specific associations without\nimpacting related knowledge - something not achievable by previous works.\nResults demonstrate that anti-samples offer an efficient, targeted unlearning\nstrategy for LLMs, opening new avenues for privacy-preserving machine learning\nand model modification.\n","authors":["Yash Sinha","Murari Mandal","Mohan Kankanhalli"],"pdf_url":"https://arxiv.org/pdf/2410.17050v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17049v1","updated":"2024-10-22T14:27:43Z","published":"2024-10-22T14:27:43Z","title":"A Comparison of Baseline Models and a Transformer Network for SOC\n  Prediction in Lithium-Ion Batteries","summary":"  Accurately predicting the state of charge of Lithium-ion batteries is\nessential to the performance of battery management systems of electric\nvehicles. One of the main reasons for the slow global adoption of electric cars\nis driving range anxiety. The ability of a battery management system to\naccurately estimate the state of charge can help alleviate this problem. In\nthis paper, a comparison between data-driven state-of-charge estimation methods\nis conducted. The paper compares different neural network-based models and\ncommon regression models for SOC estimation. These models include several\nablated transformer networks, a neural network, a lasso regression model, a\nlinear regression model and a decision tree. Results of various experiments\nconducted on data obtained from natural driving cycles of the BMW i3 battery\nshow that the decision tree outperformed all other models including the more\ncomplex transformer network with self-attention and positional encoding.\n","authors":["Hadeel Aboueidah","Abdulrahman Altahhan"],"pdf_url":"https://arxiv.org/pdf/2410.17049v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03372v3","updated":"2024-10-22T14:24:55Z","published":"2023-06-06T03:21:28Z","title":"Online Tensor Learning: Computational and Statistical Trade-offs,\n  Adaptivity and Optimal Regret","summary":"  Large tensor learning algorithms are typically computationally expensive and\nrequire storing a vast amount of data. In this paper, we propose a unified\nonline Riemannian gradient descent (oRGrad) algorithm for tensor learning,\nwhich is computationally efficient, consumes much less memory, and can handle\nsequentially arriving data while making timely predictions. The algorithm is\napplicable to both linear and generalized linear models. If the time horizon T\nis known, oRGrad achieves statistical optimality by choosing an appropriate\nfixed step size. We find that noisy tensor completion particularly benefits\nfrom online algorithms by avoiding the trimming procedure and ensuring sharp\nentry-wise statistical error, which is often technically challenging for\noffline methods. The regret of oRGrad is analyzed, revealing a fascinating\ntrilemma concerning the computational convergence rate, statistical error, and\nregret bound. By selecting an appropriate constant step size, oRGrad achieves\nan $O(T^{1/2})$ regret. We then introduce the adaptive-oRGrad algorithm, which\ncan achieve the optimal $O(\\log T)$ regret by adaptively selecting step sizes,\nregardless of whether the time horizon is known. The adaptive-oRGrad algorithm\ncan attain a statistically optimal error rate without knowing the horizon.\nComprehensive numerical simulations corroborate our theoretical findings. We\nshow that oRGrad significantly outperforms its offline counterpart in\npredicting the solar F10.7 index with tensor predictors that monitor space\nweather impacts.\n","authors":["Jingyang Li","Jian-Feng Cai","Yang Chen","Dong Xia"],"pdf_url":"https://arxiv.org/pdf/2306.03372v3.pdf","comment":"Add initialization algorithms and new application"},{"id":"http://arxiv.org/abs/2405.14677v2","updated":"2024-10-22T14:21:19Z","published":"2024-05-23T15:12:15Z","title":"RectifID: Personalizing Rectified Flow with Anchored Classifier Guidance","summary":"  Customizing diffusion models to generate identity-preserving images from\nuser-provided reference images is an intriguing new problem. The prevalent\napproaches typically require training on extensive domain-specific images to\nachieve identity preservation, which lacks flexibility across different use\ncases. To address this issue, we exploit classifier guidance, a training-free\ntechnique that steers diffusion models using an existing classifier, for\npersonalized image generation. Our study shows that based on a recent rectified\nflow framework, the major limitation of vanilla classifier guidance in\nrequiring a special classifier can be resolved with a simple fixed-point\nsolution, allowing flexible personalization with off-the-shelf image\ndiscriminators. Moreover, its solving procedure proves to be stable when\nanchored to a reference flow trajectory, with a convergence guarantee. The\nderived method is implemented on rectified flow with different off-the-shelf\nimage discriminators, delivering advantageous personalization results for human\nfaces, live subjects, and certain objects. Code is available at\nhttps://github.com/feifeiobama/RectifID.\n","authors":["Zhicheng Sun","Zhenhao Yang","Yang Jin","Haozhe Chi","Kun Xu","Kun Xu","Liwei Chen","Hao Jiang","Yang Song","Kun Gai","Yadong Mu"],"pdf_url":"https://arxiv.org/pdf/2405.14677v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.17043v1","updated":"2024-10-22T14:19:29Z","published":"2024-10-22T14:19:29Z","title":"Optimizing Mixture-of-Experts Inference Time Combining Model Deployment\n  and Communication Scheduling","summary":"  As machine learning models scale in size and complexity, their computational\nrequirements become a significant barrier. Mixture-of-Experts (MoE) models\nalleviate this issue by selectively activating relevant experts. Despite this,\nMoE models are hindered by high communication overhead from all-to-all\noperations, low GPU utilization due to the synchronous communication\nconstraint, and complications from heterogeneous GPU environments.\n  This paper presents Aurora, which optimizes both model deployment and\nall-to-all communication scheduling to address these challenges in MoE\ninference. Aurora achieves minimal communication times by strategically\nordering token transmissions in all-to-all communications. It improves GPU\nutilization by colocating experts from different models on the same device,\navoiding the limitations of synchronous all-to-all communication. We analyze\nAurora's optimization strategies theoretically across four common GPU cluster\nsettings: exclusive vs. colocated models on GPUs, and homogeneous vs.\nheterogeneous GPUs. Aurora provides optimal solutions for three cases, and for\nthe remaining NP-hard scenario, it offers a polynomial-time sub-optimal\nsolution with only a 1.07x degradation from the optimal.\n  Aurora is the first approach to minimize MoE inference time via optimal model\ndeployment and communication scheduling across various scenarios. Evaluations\ndemonstrate that Aurora significantly accelerates inference, achieving speedups\nof up to 2.38x in homogeneous clusters and 3.54x in heterogeneous environments.\nMoreover, Aurora enhances GPU utilization by up to 1.5x compared to existing\nmethods.\n","authors":["Jialong Li","Shreyansh Tripathi","Lakshay Rastogi","Yiming Lei","Rui Pan","Yiting Xia"],"pdf_url":"https://arxiv.org/pdf/2410.17043v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17042v1","updated":"2024-10-22T14:16:49Z","published":"2024-10-22T14:16:49Z","title":"Deep Memory Search: A Metaheuristic Approach for Optimizing Heuristic\n  Search","summary":"  Metaheuristic search methods have proven to be essential tools for tackling\ncomplex optimization challenges, but their full potential is often constrained\nby conventional algorithmic frameworks. In this paper, we introduce a novel\napproach called Deep Heuristic Search (DHS), which models metaheuristic search\nas a memory-driven process. DHS employs multiple search layers and memory-based\nexploration-exploitation mechanisms to navigate large, dynamic search spaces.\nBy utilizing model-free memory representations, DHS enhances the ability to\ntraverse temporal trajectories without relying on probabilistic transition\nmodels. The proposed method demonstrates significant improvements in search\nefficiency and performance across a range of heuristic optimization problems.\n","authors":["Abdel-Rahman Hedar","Alaa E. Abdel-Hakim","Wael Deabes","Youseef Alotaibi","Kheir Eddine Bouazza"],"pdf_url":"https://arxiv.org/pdf/2410.17042v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2404.06997v3","updated":"2024-10-22T14:09:57Z","published":"2024-04-10T13:24:27Z","title":"Agent-driven Generative Semantic Communication with Cross-Modality and\n  Prediction","summary":"  In the era of 6G, with compelling visions of intelligent transportation\nsystems and digital twins, remote surveillance is poised to become a ubiquitous\npractice. Substantial data volume and frequent updates present challenges in\nwireless networks. To address these challenges, we propose a novel agent-driven\ngenerative semantic communication (A-GSC) framework based on reinforcement\nlearning. In contrast to the existing research on semantic communication\n(SemCom), which mainly focuses on either semantic extraction or semantic\nsampling, we seamlessly integrate both by jointly considering the intrinsic\nattributes of source information and the contextual information regarding the\ntask. Notably, the introduction of generative artificial intelligence (GAI)\nenables the independent design of semantic encoders and decoders. In this work,\nwe develop an agent-assisted semantic encoder with cross-modality capability,\nwhich can track the semantic changes, channel condition, to perform adaptive\nsemantic extraction and sampling. Accordingly, we design a semantic decoder\nwith both predictive and generative capabilities, consisting of two tailored\nmodules. Moreover, the effectiveness of the designed models has been verified\nusing the UA-DETRAC dataset, demonstrating the performance gains of the overall\nA-GSC framework in both energy saving and reconstruction accuracy.\n","authors":["Wanting Yang","Zehui Xiong","Yanli Yuan","Wenchao Jiang","Tony Q. S. Quek","Merouane Debbah"],"pdf_url":"https://arxiv.org/pdf/2404.06997v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.16320v2","updated":"2024-10-22T14:09:10Z","published":"2024-09-21T03:45:05Z","title":"Developing a Thailand solar irradiance map using Himawari-8 satellite\n  imageries and deep learning models","summary":"  This paper presents an online platform that shows Thailand's solar irradiance\nmap every 30 minutes. It is available at https://www.cusolarforecast.com. The\nmethodology for estimating global horizontal irradiance (GHI) across Thailand\nrelies on cloud index extracted from Himawari-8 satellite imagery, Ineichen\nclear-sky model with locally-tuned Linke turbidity, and machine learning\nmodels. The methods take clear-sky irradiance, cloud index, re-analyzed GHI and\ntemperature data from the MERRA-2 database, and date-time as inputs for GHI\nestimation models, including LightGBM, LSTM, Informer, and Transformer. These\nare benchmarked with the estimate from a commercial service X by evaluating\n15-minute ground GHI data from 53 ground stations over 1.5 years from\n2022-2023. The results show that the four models have competitive performances\nand outperform the service X. The best model is LightGBM, with an MAE of 78.58\nW/sqm and RMSE of 118.97 W/sqm. Obtaining re-analyzed MERRA-2 data for Thailand\nis not economically feasible for deployment. When removing these features, the\nInformer model has a winning performance of 78.67 W/sqm in MAE. The obtained\nperformance aligns with existing literature by taking the climate zone and time\ngranularity of data into consideration. As the map shows an estimate of GHI\nover 93,000 grids with a frequent update, the paper also describes a\ncomputational framework for displaying the entire map. It tests the runtime\nperformance of deep learning models in the GHI estimation process.\n","authors":["Suwichaya Suwanwimolkul","Natanon Tongamrak","Nuttamon Thungka","Naebboon Hoonchareon","Jitkomut Songsiri"],"pdf_url":"https://arxiv.org/pdf/2409.16320v2.pdf","comment":"23 pages, 14 figures"},{"id":"http://arxiv.org/abs/2410.15608v2","updated":"2024-10-22T13:55:26Z","published":"2024-10-21T03:13:20Z","title":"Moonshine: Speech Recognition for Live Transcription and Voice Commands","summary":"  This paper introduces Moonshine, a family of speech recognition models\noptimized for live transcription and voice command processing. Moonshine is\nbased on an encoder-decoder transformer architecture and employs Rotary\nPosition Embedding (RoPE) instead of traditional absolute position embeddings.\nThe model is trained on speech segments of various lengths, but without using\nzero-padding, leading to greater efficiency for the encoder during inference\ntime. When benchmarked against OpenAI's Whisper tiny-en, Moonshine Tiny\ndemonstrates a 5x reduction in compute requirements for transcribing a\n10-second speech segment while incurring no increase in word error rates across\nstandard evaluation datasets. These results highlight Moonshine's potential for\nreal-time and resource-constrained applications.\n","authors":["Nat Jeffries","Evan King","Manjunath Kudlur","Guy Nicholson","James Wang","Pete Warden"],"pdf_url":"https://arxiv.org/pdf/2410.15608v2.pdf","comment":"7 pages, 6 figures, 3 tables"},{"id":"http://arxiv.org/abs/2410.17028v1","updated":"2024-10-22T13:52:51Z","published":"2024-10-22T13:52:51Z","title":"Can a Machine Distinguish High and Low Amount of Social Creak in Speech?","summary":"  Objectives: ncreased prevalence of social creak particularly among female\nspeakers has been reported in several studies. The study of social creak has\nbeen previously conducted by combining perceptual evaluation of speech with\nconventional acoustical parameters such as the harmonic-to-noise ratio and\ncepstral peak prominence. In the current study, machine learning (ML) was used\nto automatically distinguish speech of low amount of social creak from speech\nof high amount of social creak.\n  Methods: The amount of creak in continuous speech samples produced in Finnish\nby 90 female speakers was first perceptually assessed by two voice specialists.\nBased on their assessments, the speech samples were divided into two categories\n(low $vs$. high amount of creak). Using the speech signals and their creak\nlabels, seven different ML models were trained. Three spectral representations\nwere used as feature for each model.\n  Results: The results show that the best performance (accuracy of 71.1\\%) was\nobtained by the following two systems: an Adaboost classifier using the\nmel-spectrogram feature and a decision tree classifier using the mel-frequency\ncepstral coefficient feature.\n  Conclusions: The study of social creak is becoming increasingly popular in\nsociolinguistic and vocological research. The conventional human perceptual\nassessment of the amount of creak is laborious and therefore ML technology\ncould be used to assist researchers studying social creak. The classification\nsystems reported in this study could be considered as baselines in future\nML-based studies on social creak.\n","authors":["Anne-Maria Laukkanen","Sudarsana Reddy Kadiri","Shrikanth Narayanan","Paavo Alku"],"pdf_url":"https://arxiv.org/pdf/2410.17028v1.pdf","comment":"Accepted in Journal of Voice"},{"id":"http://arxiv.org/abs/2410.17020v1","updated":"2024-10-22T13:44:10Z","published":"2024-10-22T13:44:10Z","title":"LFME: A Simple Framework for Learning from Multiple Experts in Domain\n  Generalization","summary":"  Domain generalization (DG) methods aim to maintain good performance in an\nunseen target domain by using training data from multiple source domains. While\nsuccess on certain occasions are observed, enhancing the baseline across most\nscenarios remains challenging. This work introduces a simple yet effective\nframework, dubbed learning from multiple experts (LFME), that aims to make the\ntarget model an expert in all source domains to improve DG. Specifically,\nbesides learning the target model used in inference, LFME will also train\nmultiple experts specialized in different domains, whose output probabilities\nprovide professional guidance by simply regularizing the logit of the target\nmodel. Delving deep into the framework, we reveal that the introduced logit\nregularization term implicitly provides effects of enabling the target model to\nharness more information, and mining hard samples from the experts during\ntraining. Extensive experiments on benchmarks from different DG tasks\ndemonstrate that LFME is consistently beneficial to the baseline and can\nachieve comparable performance to existing arts. Code is available\nat~\\url{https://github.com/liangchen527/LFME}.\n","authors":["Liang Chen","Yong Zhang","Yibing Song","Zhiqiang Shen","Lingqiao Liu"],"pdf_url":"https://arxiv.org/pdf/2410.17020v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2406.02362v3","updated":"2024-10-22T13:43:01Z","published":"2024-06-04T14:39:51Z","title":"Temporal Graph Rewiring with Expander Graphs","summary":"  Evolving relations in real-world networks are often modelled by temporal\ngraphs. Temporal Graph Neural Networks (TGNNs) emerged to model evolutionary\nbehaviour of such graphs by leveraging the message passing primitive at the\ncore of Graph Neural Networks (GNNs). It is well-known that GNNs are vulnerable\nto several issues directly related to the input graph topology, such as\nunder-reaching and over-squashing - we argue that these issues can often get\nexacerbated in temporal graphs, particularly as the result of stale nodes and\nedges. While graph rewiring techniques have seen frequent usage in GNNs to make\nthe graph topology more favourable for message passing, they have not seen any\nmainstream usage on TGNNs. In this work, we propose Temporal Graph Rewiring\n(TGR), the first approach for graph rewiring on temporal graphs, to the best of\nour knowledge. TGR constructs message passing highways between temporally\ndistant nodes in a continuous-time dynamic graph by utilizing expander graph\npropagation, a prominent framework used for graph rewiring on static graphs\nwhich makes minimal assumptions on the underlying graph structure. On the\nchallenging TGB benchmark, TGR achieves state-of-the-art results on\ntgbl-review, tgbl-coin, tgbl-comment and tgbl-flight datasets at the time of\nwriting. For tgbl-review, TGR has 50.5% improvement in MRR over the base TGN\nmodel and 22.2% improvement over the base TNCN model. The significant\nimprovement over base models demonstrates clear benefits of temporal graph\nrewiring.\n","authors":["Katarina Petrović","Shenyang Huang","Farimah Poursafaei","Petar Veličković"],"pdf_url":"https://arxiv.org/pdf/2406.02362v3.pdf","comment":"14 pages, 2 figures"},{"id":"http://arxiv.org/abs/2311.18460v3","updated":"2024-10-22T13:37:04Z","published":"2023-11-30T11:11:26Z","title":"Causal Fairness under Unobserved Confounding: A Neural Sensitivity\n  Framework","summary":"  Fairness for machine learning predictions is widely required in practice for\nlegal, ethical, and societal reasons. Existing work typically focuses on\nsettings without unobserved confounding, even though unobserved confounding can\nlead to severe violations of causal fairness and, thus, unfair predictions. In\nthis work, we analyze the sensitivity of causal fairness to unobserved\nconfounding. Our contributions are three-fold. First, we derive bounds for\ncausal fairness metrics under different sources of unobserved confounding. This\nenables practitioners to examine the sensitivity of their machine learning\nmodels to unobserved confounding in fairness-critical applications. Second, we\npropose a novel neural framework for learning fair predictions, which allows us\nto offer worst-case guarantees of the extent to which causal fairness can be\nviolated due to unobserved confounding. Third, we demonstrate the effectiveness\nof our framework in a series of experiments, including a real-world case study\nabout predicting prison sentences. To the best of our knowledge, ours is the\nfirst work to study causal fairness under unobserved confounding. To this end,\nour work is of direct practical value as a refutation strategy to ensure the\nfairness of predictions in high-stakes applications.\n","authors":["Maresa Schröder","Dennis Frauen","Stefan Feuerriegel"],"pdf_url":"https://arxiv.org/pdf/2311.18460v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10060v2","updated":"2024-10-22T13:35:07Z","published":"2024-06-14T14:16:39Z","title":"PRIMER: Perception-Aware Robust Learning-based Multiagent Trajectory\n  Planner","summary":"  In decentralized multiagent trajectory planners, agents need to communicate\nand exchange their positions to generate collision-free trajectories. However,\ndue to localization errors/uncertainties, trajectory deconfliction can fail\neven if trajectories are perfectly shared between agents. To address this\nissue, we first present PARM and PARM*, perception-aware, decentralized,\nasynchronous multiagent trajectory planners that enable a team of agents to\nnavigate uncertain environments while deconflicting trajectories and avoiding\nobstacles using perception information. PARM* differs from PARM as it is less\nconservative, using more computation to find closer-to-optimal solutions. While\nthese methods achieve state-of-the-art performance, they suffer from high\ncomputational costs as they need to solve large optimization problems onboard,\nmaking it difficult for agents to replan at high rates. To overcome this\nchallenge, we present our second key contribution, PRIMER, a learning-based\nplanner trained with imitation learning (IL) using PARM* as the expert\ndemonstrator. PRIMER leverages the low computational requirements at deployment\nof neural networks and achieves a computation speed up to 5500 times faster\nthan optimization-based approaches.\n","authors":["Kota Kondo","Claudius T. Tewari","Andrea Tagliabue","Jesus Tordesillas","Parker C. Lusk","Jonathan P. How"],"pdf_url":"https://arxiv.org/pdf/2406.10060v2.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2405.15551v2","updated":"2024-10-22T13:32:59Z","published":"2024-05-24T13:37:48Z","title":"Thinking Forward: Memory-Efficient Federated Finetuning of Language\n  Models","summary":"  Finetuning large language models (LLMs) in federated learning (FL) settings\nhas become increasingly important as it allows resource-constrained devices to\nfinetune a model using private data. However, finetuning LLMs using\nbackpropagation requires excessive memory (especially from intermediate\nactivations) for resource-constrained devices. While Forward-mode\nAuto-Differentiation (AD) can significantly reduce memory footprint from\nactivations, we observe that directly applying it to LLM finetuning results in\nslow convergence and poor accuracy. In this paper, we introduce Spry, an FL\nalgorithm that splits trainable weights of an LLM among participating clients,\nsuch that each client computes gradients using forward-mode AD that are closer\nestimations of the true gradients. Spry achieves a low memory footprint, high\naccuracy, and fast convergence. We formally prove that the global gradients in\nSpry are unbiased estimators of true global gradients for homogeneous data\ndistributions across clients, while heterogeneity increases bias of the\nestimates. We also derive Spry's convergence rate, showing that the gradients\ndecrease inversely proportional to the number of FL rounds, indicating the\nconvergence up to the limits of heterogeneity. Empirically, Spry reduces the\nmemory footprint during training by 1.4-7.1x in contrast to backpropagation,\nwhile reaching comparable accuracy, across a wide range of language tasks,\nmodels, and FL settings. Spry reduces the convergence time by 1.2-20.3x and\nachieves 5.2-13.5% higher accuracy against zero-order methods. When finetuning\nLlama2-7B with LoRA, compared to the peak memory consumption of 33.9GB of\nbackpropagation, Spry only consumes 6.2GB of peak memory. For OPT13B, the\nreduction is from 76.5GB to 10.8GB. Spry makes feasible previously impossible\nFL deployments on commodity edge devices. Our source code is available at\nhttps://github.com/Astuary/Spry.\n","authors":["Kunjal Panchal","Nisarg Parikh","Sunav Choudhary","Lijun Zhang","Yuriy Brun","Hui Guan"],"pdf_url":"https://arxiv.org/pdf/2405.15551v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2406.12142v2","updated":"2024-10-22T13:32:34Z","published":"2024-06-17T23:08:46Z","title":"Slicing Through Bias: Explaining Performance Gaps in Medical Image\n  Analysis using Slice Discovery Methods","summary":"  Machine learning models have achieved high overall accuracy in medical image\nanalysis. However, performance disparities on specific patient groups pose\nchallenges to their clinical utility, safety, and fairness. This can affect\nknown patient groups - such as those based on sex, age, or disease subtype - as\nwell as previously unknown and unlabeled groups. Furthermore, the root cause of\nsuch observed performance disparities is often challenging to uncover,\nhindering mitigation efforts. In this paper, to address these issues, we\nleverage Slice Discovery Methods (SDMs) to identify interpretable\nunderperforming subsets of data and formulate hypotheses regarding the cause of\nobserved performance disparities. We introduce a novel SDM and apply it in a\ncase study on the classification of pneumothorax and atelectasis from chest\nx-rays. Our study demonstrates the effectiveness of SDMs in hypothesis\nformulation and yields an explanation of previously observed but unexplained\nperformance disparities between male and female patients in widely used chest\nX-ray datasets and models. Our findings indicate shortcut learning in both\nclassification tasks, through the presence of chest drains and ECG wires,\nrespectively. Sex-based differences in the prevalence of these shortcut\nfeatures appear to cause the observed classification performance gap,\nrepresenting a previously underappreciated interaction between shortcut\nlearning and model fairness analyses.\n","authors":["Vincent Olesen","Nina Weng","Aasa Feragen","Eike Petersen"],"pdf_url":"https://arxiv.org/pdf/2406.12142v2.pdf","comment":"MICCAI 2024 Workshop on Fairness of AI in Medical Imaging"},{"id":"http://arxiv.org/abs/2302.05765v3","updated":"2024-10-22T13:31:16Z","published":"2023-02-11T19:30:55Z","title":"Adversarial Online Collaborative Filtering","summary":"  We investigate the problem of online collaborative filtering under\nno-repetition constraints, whereby users need to be served content in an online\nfashion and a given user cannot be recommended the same content item more than\nonce. We start by designing and analyzing an algorithm that works under\nbiclustering assumptions on the user-item preference matrix, and show that this\nalgorithm exhibits an optimal regret guarantee, while being fully adaptive, in\nthat it is oblivious to any prior knowledge about the sequence of users, the\nuniverse of items, as well as the biclustering parameters of the preference\nmatrix. We then propose a more robust version of this algorithm which operates\nwith general matrices. Also this algorithm is parameter free, and we prove\nregret guarantees that scale with the amount by which the preference matrix\ndeviates from a biclustered structure. To our knowledge, these are the first\nresults on online collaborative filtering that hold at this level of generality\nand adaptivity under no-repetition constraints. Finally, we complement our\ntheoretical findings with simple experiments on real-world datasets aimed at\nboth validating the theory and empirically comparing to standard baselines.\nThis comparison shows the competitive advantage of our approach over these\nbaselines.\n","authors":["Stephen Pasteris","Fabio Vitale","Mark Herbster","Claudio Gentile","Andre' Panisson"],"pdf_url":"https://arxiv.org/pdf/2302.05765v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.17704v2","updated":"2024-10-22T13:19:36Z","published":"2024-02-27T17:30:33Z","title":"Transfer Learning Bayesian Optimization to Design Competitor DNA\n  Molecules for Use in Diagnostic Assays","summary":"  With the rise in engineered biomolecular devices, there is an increased need\nfor tailor-made biological sequences. Often, many similar biological sequences\nneed to be made for a specific application meaning numerous, sometimes\nprohibitively expensive, lab experiments are necessary for their optimization.\nThis paper presents a transfer learning design of experiments workflow to make\nthis development feasible. By combining a transfer learning surrogate model\nwith Bayesian optimization, we show how the total number of experiments can be\nreduced by sharing information between optimization tasks. We demonstrate the\nreduction in the number of experiments using data from the development of DNA\ncompetitors for use in an amplification-based diagnostic assay. We use\ncross-validation to compare the predictive accuracy of different transfer\nlearning models, and then compare the performance of the models for both single\nobjective and penalized optimization tasks.\n","authors":["Ruby Sedgwick","John P. Goertz","Molly M. Stevens","Ruth Misener","Mark van der Wilk"],"pdf_url":"https://arxiv.org/pdf/2402.17704v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10851v2","updated":"2024-10-22T13:08:02Z","published":"2024-10-06T12:53:07Z","title":"LLM Gesticulator: Leveraging Large Language Models for Scalable and\n  Controllable Co-Speech Gesture Synthesis","summary":"  In this work, we present LLM Gesticulator, an LLM-based audio-driven\nco-speech gesture generation framework that synthesizes full-body animations\nthat are rhythmically aligned with the input audio while exhibiting natural\nmovements and editability. Compared to previous work, our model demonstrates\nsubstantial scalability. As the size of the backbone LLM model increases, our\nframework shows proportional improvements in evaluation metrics (a.k.a. scaling\nlaw). Our method also exhibits strong controllability where the content, style\nof the generated gestures can be controlled by text prompt. To the best of our\nknowledge, LLM gesticulator is the first work that use LLM on the co-speech\ngeneration task. Evaluation with existing objective metrics and user studies\nindicate that our framework outperforms prior works.\n","authors":["Haozhou Pang","Tianwei Ding","Lanshan He","Ming Tao","Lu Zhang","Qi Gan"],"pdf_url":"https://arxiv.org/pdf/2410.10851v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16982v1","updated":"2024-10-22T13:02:12Z","published":"2024-10-22T13:02:12Z","title":"Sample-Efficient Geometry Reconstruction from Euclidean Distances using\n  Non-Convex Optimization","summary":"  The problem of finding suitable point embedding or geometric configurations\ngiven only Euclidean distance information of point pairs arises both as a core\ntask and as a sub-problem in a variety of machine learning applications. In\nthis paper, we aim to solve this problem given a minimal number of distance\nsamples. To this end, we leverage continuous and non-convex rank minimization\nformulations of the problem and establish a local convergence guarantee for a\nvariant of iteratively reweighted least squares (IRLS), which applies if a\nminimal random set of observed distances is provided. As a technical tool, we\nestablish a restricted isometry property (RIP) restricted to a tangent space of\nthe manifold of symmetric rank-$r$ matrices given random Euclidean distance\nmeasurements, which might be of independent interest for the analysis of other\nnon-convex approaches. Furthermore, we assess data efficiency, scalability and\ngeneralizability of different reconstruction algorithms through numerical\nexperiments with simulated data as well as real-world data, demonstrating the\nproposed algorithm's ability to identify the underlying geometry from fewer\ndistance samples compared to the state-of-the-art.\n","authors":["Ipsita Ghosh","Abiy Tasissa","Christian Kümmerle"],"pdf_url":"https://arxiv.org/pdf/2410.16982v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16975v1","updated":"2024-10-22T12:55:02Z","published":"2024-10-22T12:55:02Z","title":"Publishing Neural Networks in Drug Discovery Might Compromise Training\n  Data Privacy","summary":"  This study investigates the risks of exposing confidential chemical\nstructures when machine learning models trained on these structures are made\npublicly available. We use membership inference attacks, a common method to\nassess privacy that is largely unexplored in the context of drug discovery, to\nexamine neural networks for molecular property prediction in a black-box\nsetting. Our results reveal significant privacy risks across all evaluated\ndatasets and neural network architectures. Combining multiple attacks increases\nthese risks. Molecules from minority classes, often the most valuable in drug\ndiscovery, are particularly vulnerable. We also found that representing\nmolecules as graphs and using message-passing neural networks may mitigate\nthese risks. We provide a framework to assess privacy risks of classification\nmodels and molecular representations. Our findings highlight the need for\ncareful consideration when sharing neural networks trained on proprietary\nchemical structures, informing organisations and researchers about the\ntrade-offs between data confidentiality and model openness.\n","authors":["Fabian P. Krüger","Johan Östman","Lewis Mervin","Igor V. Tetko","Ola Engkvist"],"pdf_url":"https://arxiv.org/pdf/2410.16975v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16973v1","updated":"2024-10-22T12:51:51Z","published":"2024-10-22T12:51:51Z","title":"Learning Mathematical Rules with Large Language Models","summary":"  In this paper, we study the ability of large language models to learn\nspecific mathematical rules such as distributivity or simplifying equations. We\npresent an empirical analysis of their ability to generalize these rules, as\nwell as to reuse them in the context of word problems. For this purpose, we\nprovide a rigorous methodology to build synthetic data incorporating such\nrules, and perform fine-tuning of large language models on such data. Our\nexperiments show that our model can learn and generalize these rules to some\nextent, as well as suitably reuse them in the context of word problems.\n","authors":["Antoine Gorceix","Bastien Le Chenadec","Ahmad Rammal","Nelson Vadori","Manuela Veloso"],"pdf_url":"https://arxiv.org/pdf/2410.16973v1.pdf","comment":"4th MATH-AI Workshop at NeurIPS'24"},{"id":"http://arxiv.org/abs/2410.16972v1","updated":"2024-10-22T12:51:46Z","published":"2024-10-22T12:51:46Z","title":"Sample-efficient Bayesian Optimisation Using Known Invariances","summary":"  Bayesian optimisation (BO) is a powerful framework for global optimisation of\ncostly functions, using predictions from Gaussian process models (GPs). In this\nwork, we apply BO to functions that exhibit invariance to a known group of\ntransformations. We show that vanilla and constrained BO algorithms are\ninefficient when optimising such invariant objectives, and provide a method for\nincorporating group invariances into the kernel of the GP to produce\ninvariance-aware algorithms that achieve significant improvements in sample\nefficiency. We derive a bound on the maximum information gain of these\ninvariant kernels, and provide novel upper and lower bounds on the number of\nobservations required for invariance-aware BO algorithms to achieve\n$\\epsilon$-optimality. We demonstrate our method's improved performance on a\nrange of synthetic invariant and quasi-invariant functions. We also apply our\nmethod in the case where only some of the invariance is incorporated into the\nkernel, and find that these kernels achieve similar gains in sample efficiency\nat significantly reduced computational cost. Finally, we use invariant BO to\ndesign a current drive system for a nuclear fusion reactor, finding a\nhigh-performance solution where non-invariant methods failed.\n","authors":["Theodore Brown","Alexandru Cioba","Ilija Bogunovic"],"pdf_url":"https://arxiv.org/pdf/2410.16972v1.pdf","comment":"Accepted as a poster at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2202.08967v2","updated":"2024-10-22T12:46:44Z","published":"2022-02-12T21:39:29Z","title":"Beyond Trading Data: The Hidden Influence of Public Awareness and\n  Interest on Cryptocurrency Volatility","summary":"  Since Bitcoin first appeared on the scene in 2009, cryptocurrencies have\nbecome a worldwide phenomenon as important decentralized financial assets.\nTheir decentralized nature, however, leads to notable volatility against\ntraditional fiat currencies, making the task of accurately forecasting the\ncrypto-fiat exchange rate complex. This study examines the various independent\nfactors that affect the volatility of the Bitcoin-Dollar exchange rate. To this\nend, we propose CoMForE, a multimodal AdaBoost-LSTM ensemble model, which not\nonly utilizes historical trading data but also incorporates public sentiments\nfrom related tweets, public interest demonstrated by search volumes, and\nblockchain hash-rate data. Our developed model goes a step further by\npredicting fluctuations in the overall cryptocurrency value distribution, thus\nincreasing its value for investment decision-making. We have subjected this\nmethod to extensive testing via comprehensive experiments, thereby validating\nthe importance of multimodal combination over exclusive reliance on trading\ndata. Further experiments show that our method significantly surpasses existing\nforecasting tools and methodologies, demonstrating a 19.29% improvement. This\nresult underscores the influence of external independent factors on\ncryptocurrency volatility.\n","authors":["Zeyd Boukhers","Azeddine Bouabdallah","Cong Yang","Jan Jürjens"],"pdf_url":"https://arxiv.org/pdf/2202.08967v2.pdf","comment":"Published at the 32nd ACM International Conference on Information and\n  Knowledge Management (CIKM 2023)"},{"id":"http://arxiv.org/abs/2402.02017v2","updated":"2024-10-22T12:46:09Z","published":"2024-02-03T04:17:09Z","title":"Adaptive $Q$-Aid for Conditional Supervised Learning in Offline\n  Reinforcement Learning","summary":"  Offline reinforcement learning (RL) has progressed with return-conditioned\nsupervised learning (RCSL), but its lack of stitching ability remains a\nlimitation. We introduce $Q$-Aided Conditional Supervised Learning (QCS), which\neffectively combines the stability of RCSL with the stitching capability of\n$Q$-functions. By analyzing $Q$-function over-generalization, which impairs\nstable stitching, QCS adaptively integrates $Q$-aid into RCSL's loss function\nbased on trajectory return. Empirical results show that QCS significantly\noutperforms RCSL and value-based methods, consistently achieving or exceeding\nthe maximum trajectory returns across diverse offline RL benchmarks.\n","authors":["Jeonghye Kim","Suyoung Lee","Woojun Kim","Youngchul Sung"],"pdf_url":"https://arxiv.org/pdf/2402.02017v2.pdf","comment":"Accepted to NeurIPS2024. The project page is available at\n  https://beanie00.com/publications/qcs"},{"id":"http://arxiv.org/abs/2209.12835v4","updated":"2024-10-22T12:38:35Z","published":"2022-09-26T16:41:16Z","title":"Targeted Separation and Convergence with Kernel Discrepancies","summary":"  Maximum mean discrepancies (MMDs) like the kernel Stein discrepancy (KSD)\nhave grown central to a wide range of applications, including hypothesis\ntesting, sampler selection, distribution approximation, and variational\ninference. In each setting, these kernel-based discrepancy measures are\nrequired to (i) separate a target P from other probability measures or even\n(ii) control weak convergence to P. In this article we derive new sufficient\nand necessary conditions to ensure (i) and (ii). For MMDs on separable metric\nspaces, we characterize those kernels that separate Bochner embeddable measures\nand introduce simple conditions for separating all measures with unbounded\nkernels and for controlling convergence with bounded kernels. We use these\nresults on $\\mathbb{R}^d$ to substantially broaden the known conditions for KSD\nseparation and convergence control and to develop the first KSDs known to\nexactly metrize weak convergence to P. Along the way, we highlight the\nimplications of our results for hypothesis testing, measuring and improving\nsample quality, and sampling with Stein variational gradient descent.\n","authors":["Alessandro Barp","Carl-Johann Simon-Gabriel","Mark Girolami","Lester Mackey"],"pdf_url":"https://arxiv.org/pdf/2209.12835v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.07063v4","updated":"2024-10-22T12:28:13Z","published":"2023-04-14T11:35:35Z","title":"Rethinking Complex Queries on Knowledge Graphs with Neural Link\n  Predictors","summary":"  Reasoning on knowledge graphs is a challenging task because it utilizes\nobserved information to predict the missing one. Particularly, answering\ncomplex queries based on first-order logic is one of the crucial tasks to\nverify learning to reason abilities for generalization and composition.\nRecently, the prevailing method is query embedding which learns the embedding\nof a set of entities and treats logic operations as set operations and has\nshown great empirical success. Though there has been much research following\nthe same formulation, many of its claims lack a formal and systematic\ninspection. In this paper, we rethink this formulation and justify many of the\nprevious claims by characterizing the scope of queries investigated previously\nand precisely identifying the gap between its formulation and its goal, as well\nas providing complexity analysis for the currently investigated queries.\nMoreover, we develop a new dataset containing ten new types of queries with\nfeatures that have never been considered and therefore can provide a thorough\ninvestigation of complex queries. Finally, we propose a new neural-symbolic\nmethod, Fuzzy Inference with Truth value (FIT), where we equip the neural link\npredictors with fuzzy logic theory to support end-to-end learning using complex\nqueries with provable reasoning capability. Empirical results show that our\nmethod outperforms previous methods significantly in the new dataset and also\nsurpasses previous methods in the existing dataset at the same time.\n","authors":["Hang Yin","Zihao Wang","Yangqiu Song"],"pdf_url":"https://arxiv.org/pdf/2304.07063v4.pdf","comment":"Received in ICLR 2024"},{"id":"http://arxiv.org/abs/2410.16947v1","updated":"2024-10-22T12:21:39Z","published":"2024-10-22T12:21:39Z","title":"ISImed: A Framework for Self-Supervised Learning using Intrinsic Spatial\n  Information in Medical Images","summary":"  This paper demonstrates that spatial information can be used to learn\ninterpretable representations in medical images using Self-Supervised Learning\n(SSL). Our proposed method, ISImed, is based on the observation that medical\nimages exhibit a much lower variability among different images compared to\nclassic data vision benchmarks. By leveraging this resemblance of human body\nstructures across multiple images, we establish a self-supervised objective\nthat creates a latent representation capable of capturing its location in the\nphysical realm. More specifically, our method involves sampling image crops and\ncreating a distance matrix that compares the learned representation vectors of\nall possible combinations of these crops to the true distance between them. The\nintuition is, that the learned latent space is a positional encoding for a\ngiven image crop. We hypothesize, that by learning these positional encodings,\ncomprehensive image representations have to be generated. To test this\nhypothesis and evaluate our method, we compare our learned representation with\ntwo state-of-the-art SSL benchmarking methods on two publicly available medical\nimaging datasets. We show that our method can efficiently learn representations\nthat capture the underlying structure of the data and can be used to transfer\nto a downstream classification task.\n","authors":["Nabil Jabareen","Dongsheng Yuan","Sören Lukassen"],"pdf_url":"https://arxiv.org/pdf/2410.16947v1.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.16941v1","updated":"2024-10-22T12:16:11Z","published":"2024-10-22T12:16:11Z","title":"Business Process Simulation: Probabilistic Modeling of Intermittent\n  Resource Availability and Multitasking Behavior","summary":"  In business process simulation, resource availability is typically modeled by\nassigning a calendar to each resource, e.g., Monday-Friday, 9:00-18:00.\nResources are assumed to be always available during each time slot in their\navailability calendar. This assumption often becomes invalid due to\ninterruptions, breaks, or time-sharing across processes. In other words,\nexisting approaches fail to capture intermittent availability. Another\nlimitation of existing approaches is that they either do not consider\nmultitasking behavior, or if they do, they assume that resources always\nmultitask (up to a maximum capacity) whenever available. However, studies have\nshown that the multitasking patterns vary across days. This paper introduces a\nprobabilistic approach to model resource availability and multitasking behavior\nfor business process simulation. In this approach, each time slot in a resource\ncalendar has an associated availability probability and a multitasking\nprobability per multitasking level. For example, a resource may be available on\nFridays between 14:00-15:00 with 90\\% probability, and given that they are\nperforming one task during this slot, they may take on a second concurrent task\nwith 60\\% probability. We propose algorithms to discover probabilistic\ncalendars and probabilistic multitasking capacities from event logs. An\nevaluation shows that, with these enhancements, simulation models discovered\nfrom event logs better replicate the distribution of activities and cycle\ntimes, relative to approaches with crisp calendars and monotasking assumptions.\n","authors":["Orlenys López-Pintado","Marlon Dumas"],"pdf_url":"https://arxiv.org/pdf/2410.16941v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16100v2","updated":"2024-10-22T12:16:03Z","published":"2024-10-21T15:27:18Z","title":"ExDBN: Exact learning of Dynamic Bayesian Networks","summary":"  Causal learning from data has received much attention in recent years. One\nway of capturing causal relationships is by utilizing Bayesian networks. There,\none recovers a weighted directed acyclic graph, in which random variables are\nrepresented by vertices, and the weights associated with each edge represent\nthe strengths of the causal relationships between them. This concept is\nextended to capture dynamic effects by introducing a dependency on past data,\nwhich may be captured by the structural equation model, which is utilized in\nthe present contribution to formulate a score-based learning approach. A\nmixed-integer quadratic program is formulated and an algorithmic solution\nproposed, in which the pre-generation of exponentially many acyclicity\nconstraints is avoided by utilizing the so-called branch-and-cut (\"lazy\nconstraint\") method. Comparing the novel approach to the state of the art, we\nshow that the proposed approach turns out to produce excellent results when\napplied to small and medium-sized synthetic instances of up to 25 time-series.\nLastly, two interesting applications in bio-science and finance, to which the\nmethod is directly applied, further stress the opportunities in developing\nhighly accurate, globally convergent solvers that can handle modest instances.\n","authors":["Pavel Rytir","Ales Wodecki","Georgios Korpas","Jakub Marecek"],"pdf_url":"https://arxiv.org/pdf/2410.16100v2.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2410.16935v1","updated":"2024-10-22T12:12:43Z","published":"2024-10-22T12:12:43Z","title":"Graph Neural Networks for Edge Signals: Orientation Equivariance and\n  Invariance","summary":"  Many applications in traffic, civil engineering, or electrical engineering\nrevolve around edge-level signals. Such signals can be categorized as\ninherently directed, for example, the water flow in a pipe network, and\nundirected, like the diameter of a pipe. Topological methods model edge signals\nwith inherent direction by representing them relative to a so-called\norientation assigned to each edge. These approaches can neither model\nundirected edge signals nor distinguish if an edge itself is directed or\nundirected. We address these shortcomings by (i) revising the notion of\norientation equivariance to enable edge direction-aware topological models,\n(ii) proposing orientation invariance as an additional requirement to describe\nsignals without inherent direction, and (iii) developing EIGN, an architecture\ncomposed of novel direction-aware edge-level graph shift operators, that\nprovably fulfills the aforementioned desiderata. It is the first\ngeneral-purpose topological GNN for edge-level signals that can model directed\nand undirected signals while distinguishing between directed and undirected\nedges. A comprehensive evaluation shows that EIGN outperforms prior work in\nedge-level tasks, for example, improving in RMSE on flow simulation tasks by up\nto 43.5%.\n","authors":["Dominik Fuchsgruber","Tim Poštuvan","Stephan Günnemann","Simon Geisler"],"pdf_url":"https://arxiv.org/pdf/2410.16935v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.04157v2","updated":"2024-10-22T12:04:49Z","published":"2024-07-04T21:23:12Z","title":"Finite Operator Learning: Bridging Neural Operators and Numerical\n  Methods for Efficient Parametric Solution and Optimization of PDEs","summary":"  We introduce a method that combines neural operators, physics-informed\nmachine learning, and standard numerical methods for solving PDEs. The proposed\napproach extends each of the aforementioned methods and unifies them within a\nsingle framework. We can parametrically solve partial differential equations in\na data-free manner and provide accurate sensitivities, meaning the derivatives\nof the solution space with respect to the design space. These capabilities\nenable gradient-based optimization without the typical sensitivity analysis\ncosts, unlike adjoint methods that scale directly with the number of response\nfunctions. Our Finite Operator Learning (FOL) approach uses an uncomplicated\nfeed-forward neural network model to directly map the discrete design space\n(i.e. parametric input space) to the discrete solution space (i.e. finite\nnumber of sensor points in the arbitrary shape domain) ensuring compliance with\nphysical laws by designing them into loss functions. The discretized governing\nequations, as well as the design and solution spaces, can be derived from any\nwell-established numerical techniques. In this work, we employ the Finite\nElement Method (FEM) to approximate fields and their spatial derivatives.\nSubsequently, we conduct Sobolev training to minimize a multi-objective loss\nfunction, which includes the discretized weak form of the energy functional,\nboundary conditions violations, and the stationarity of the residuals with\nrespect to the design variables. Our study focuses on the steady-state heat\nequation within heterogeneous materials that exhibits significant phase\ncontrast and possibly temperature-dependent conductivity. The network's tangent\nmatrix is directly used for gradient-based optimization to improve the\nmicrostructure's heat transfer characteristics. ...\n","authors":["Shahed Rezaei","Reza Najian Asl","Kianoosh Taghikhani","Ahmad Moeineddin","Michael Kaliske","Markus Apel"],"pdf_url":"https://arxiv.org/pdf/2407.04157v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2401.02363"},{"id":"http://arxiv.org/abs/2405.15330v2","updated":"2024-10-22T12:01:45Z","published":"2024-05-24T08:12:41Z","title":"Towards Understanding the Working Mechanism of Text-to-Image Diffusion\n  Model","summary":"  Recently, the strong latent Diffusion Probabilistic Model (DPM) has been\napplied to high-quality Text-to-Image (T2I) generation (e.g., Stable\nDiffusion), by injecting the encoded target text prompt into the gradually\ndenoised diffusion image generator. Despite the success of DPM in practice, the\nmechanism behind it remains to be explored. To fill this blank, we begin by\nexamining the intermediate statuses during the gradual denoising generation\nprocess in DPM. The empirical observations indicate, the shape of image is\nreconstructed after the first few denoising steps, and then the image is filled\nwith details (e.g., texture). The phenomenon is because the low-frequency\nsignal (shape relevant) of the noisy image is not corrupted until the final\nstage in the forward process (initial stage of generation) of adding noise in\nDPM. Inspired by the observations, we proceed to explore the influence of each\ntoken in the text prompt during the two stages. After a series of experiments\nof T2I generations conditioned on a set of text prompts. We conclude that in\nthe earlier generation stage, the image is mostly decided by the special token\n[\\texttt{EOS}] in the text prompt, and the information in the text prompt is\nalready conveyed in this stage. After that, the diffusion model completes the\ndetails of generated images by information from themselves. Finally, we propose\nto apply this observation to accelerate the process of T2I generation by\nproperly removing text guidance, which finally accelerates the sampling up to\n25\\%+.\n","authors":["Mingyang Yi","Aoxue Li","Yi Xin","Zhenguo Li"],"pdf_url":"https://arxiv.org/pdf/2405.15330v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16928v1","updated":"2024-10-22T11:59:36Z","published":"2024-10-22T11:59:36Z","title":"xLSTM-Mixer: Multivariate Time Series Forecasting by Mixing via Scalar\n  Memories","summary":"  Time series data is prevalent across numerous fields, necessitating the\ndevelopment of robust and accurate forecasting models. Capturing patterns both\nwithin and between temporal and multivariate components is crucial for reliable\npredictions. We introduce xLSTM-Mixer, a model designed to effectively\nintegrate temporal sequences, joint time-variate information, and multiple\nperspectives for robust forecasting. Our approach begins with a linear forecast\nshared across variates, which is then refined by xLSTM blocks. These blocks\nserve as key elements for modeling the complex dynamics of challenging time\nseries data. xLSTM-Mixer ultimately reconciles two distinct views to produce\nthe final forecast. Our extensive evaluations demonstrate xLSTM-Mixer's\nsuperior long-term forecasting performance compared to recent state-of-the-art\nmethods. A thorough model analysis provides further insights into its key\ncomponents and confirms its robustness and effectiveness. This work contributes\nto the resurgence of recurrent models in time series forecasting.\n","authors":["Maurice Kraus","Felix Divo","Devendra Singh Dhami","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2410.16928v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16926v1","updated":"2024-10-22T11:57:32Z","published":"2024-10-22T11:57:32Z","title":"Pyramid Vector Quantization for LLMs","summary":"  Recent works on compression of large language models (LLM) using quantization\nconsidered reparameterizing the architecture such that weights are distributed\non the sphere. This demonstratively improves the ability to quantize by\nincreasing the mathematical notion of coherence, resulting in fewer weight\noutliers without affecting the network output. In this work, we aim to further\nexploit this spherical geometry of the weights when performing quantization by\nconsidering Pyramid Vector Quantization (PVQ) for large language models.\nArranging points evenly on the sphere is notoriously difficult, especially in\nhigh dimensions, and in case approximate solutions exists, representing points\nexplicitly in a codebook is typically not feasible due to its additional memory\ncost. Instead, PVQ uses a fixed integer lattice on the sphere by projecting\npoints onto the 1-sphere, which allows for efficient encoding and decoding\nwithout requiring an explicit codebook in memory. To obtain a practical\nalgorithm, we propose to combine PVQ with scale quantization for which we\nderive theoretically optimal quantizations, under empirically verified\nassumptions. Further, we extend pyramid vector quantization to use Hessian\ninformation to minimize quantization error under expected feature activations,\ninstead of only relying on weight magnitudes. Experimentally, we achieves\nstate-of-the-art quantization performance with pareto-optimal trade-off between\nperformance and bits per weight and bits per activation, compared to compared\nmethods. On weight-only, we find that we can quantize a Llama-3 70B model to\n3.25 bits per weight and retain 98\\% accuracy on downstream tasks.\n","authors":["Tycho F. A. van der Ouderaa","Maximilian L. Croci","Agrin Hilmkil","James Hensman"],"pdf_url":"https://arxiv.org/pdf/2410.16926v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16747v2","updated":"2024-10-22T11:53:58Z","published":"2024-05-27T01:31:40Z","title":"Understanding Linear Probing then Fine-tuning Language Models from NTK\n  Perspective","summary":"  The two-stage fine-tuning (FT) method, linear probing (LP) then fine-tuning\n(LP-FT), outperforms linear probing and FT alone. This holds true for both\nin-distribution (ID) and out-of-distribution (OOD) data. One key reason for its\nsuccess is the preservation of pre-trained features, achieved by obtaining a\nnear-optimal linear head during LP. However, despite the widespread use of\nlarge language models, there has been limited exploration of more complex\narchitectures such as Transformers. In this paper, we analyze the training\ndynamics of LP-FT for classification tasks on the basis of the neural tangent\nkernel (NTK) theory. Our analysis decomposes the NTK matrix into two\ncomponents. This decomposition highlights the importance of the linear head\nnorm alongside the prediction accuracy at the start of the FT stage. We also\nobserve a significant increase in the linear head norm during LP, which stems\nfrom training with the cross-entropy (CE) loss. This increase in the linear\nhead norm effectively reduces changes in learned features. Furthermore, we find\nthat this increased norm can adversely affect model calibration, which can be\ncorrected using temperature scaling. Additionally, we extend our analysis with\nthe NTK to the low-rank adaptation (LoRA) method and validate its\neffectiveness. Our experiments using a Transformer-based model on multiple\nnatural language processing datasets confirm our theoretical analysis. Our\nstudy demonstrates the effectiveness of LP-FT for fine-tuning language models.\nCode is available at https://github.com/tom4649/lp-ft_ntk.\n","authors":["Akiyoshi Tomihari","Issei Sato"],"pdf_url":"https://arxiv.org/pdf/2405.16747v2.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.16919v1","updated":"2024-10-22T11:52:22Z","published":"2024-10-22T11:52:22Z","title":"EnvBridge: Bridging Diverse Environments with Cross-Environment\n  Knowledge Transfer for Embodied AI","summary":"  In recent years, Large Language Models (LLMs) have demonstrated high\nreasoning capabilities, drawing attention for their applications as agents in\nvarious decision-making processes. One notably promising application of LLM\nagents is robotic manipulation. Recent research has shown that LLMs can\ngenerate text planning or control code for robots, providing substantial\nflexibility and interaction capabilities. However, these methods still face\nchallenges in terms of flexibility and applicability across different\nenvironments, limiting their ability to adapt autonomously. Current approaches\ntypically fall into two categories: those relying on environment-specific\npolicy training, which restricts their transferability, and those generating\ncode actions based on fixed prompts, which leads to diminished performance when\nconfronted with new environments. These limitations significantly constrain the\ngeneralizability of agents in robotic manipulation. To address these\nlimitations, we propose a novel method called EnvBridge. This approach involves\nthe retention and transfer of successful robot control codes from source\nenvironments to target environments. EnvBridge enhances the agent's\nadaptability and performance across diverse settings by leveraging insights\nfrom multiple environments. Notably, our approach alleviates environmental\nconstraints, offering a more flexible and generalizable solution for robotic\nmanipulation tasks. We validated the effectiveness of our method using robotic\nmanipulation benchmarks: RLBench, MetaWorld, and CALVIN. Our experiments\ndemonstrate that LLM agents can successfully leverage diverse knowledge sources\nto solve complex tasks. Consequently, our approach significantly enhances the\nadaptability and robustness of robotic manipulation agents in planning across\ndiverse environments.\n","authors":["Tomoyuki Kagaya","Yuxuan Lou","Thong Jing Yuan","Subramanian Lakshmi","Jayashree Karlekar","Sugiri Pranata","Natsuki Murakami","Akira Kinose","Koki Oguri","Felix Wick","Yang You"],"pdf_url":"https://arxiv.org/pdf/2410.16919v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16917v1","updated":"2024-10-22T11:51:09Z","published":"2024-10-22T11:51:09Z","title":"DNAHLM -- DNA sequence and Human Language mixed large language Model","summary":"  There are already many DNA large language models, but most of them still\nfollow traditional uses, such as extracting sequence features for\nclassification tasks. More innovative applications of large language models,\nsuch as prompt engineering, RAG, and zero-shot or few-shot prediction, remain\nchallenging for DNA-based models. The key issue lies in the fact that DNA\nmodels and human natural language models are entirely separate; however,\ntechniques like prompt engineering require the use of natural language, thereby\nsignificantly limiting the application of DNA large language models. This paper\nintroduces a hybrid model trained on the GPT-2 network, combining DNA sequences\nand English text to explore the potential of using prompts and fine-tuning in\nDNA models. The model has demonstrated its effectiveness in DNA related\nzero-shot prediction and multitask application.\n","authors":["Wang Liang"],"pdf_url":"https://arxiv.org/pdf/2410.16917v1.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2306.09805v3","updated":"2024-10-22T11:33:36Z","published":"2023-06-16T12:43:47Z","title":"Mimicking Better by Matching the Approximate Action Distribution","summary":"  In this paper, we introduce MAAD, a novel, sample-efficient on-policy\nalgorithm for Imitation Learning from Observations. MAAD utilizes a surrogate\nreward signal, which can be derived from various sources such as adversarial\ngames, trajectory matching objectives, or optimal transport criteria. To\ncompensate for the non-availability of expert actions, we rely on an inverse\ndynamics model that infers plausible actions distribution given the expert's\nstate-state transitions; we regularize the imitator's policy by aligning it to\nthe inferred action distribution. MAAD leads to significantly improved sample\nefficiency and stability. We demonstrate its effectiveness in a number of\nMuJoCo environments, both int the OpenAI Gym and the DeepMind Control Suite. We\nshow that it requires considerable fewer interactions to achieve expert\nperformance, outperforming current state-of-the-art on-policy methods.\nRemarkably, MAAD often stands out as the sole method capable of attaining\nexpert performance levels, underscoring its simplicity and efficacy.\n","authors":["João A. Cândido Ramos","Lionel Blondé","Naoya Takeishi","Alexandros Kalousis"],"pdf_url":"https://arxiv.org/pdf/2306.09805v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.13467v2","updated":"2024-10-22T11:32:23Z","published":"2024-09-20T12:55:43Z","title":"Higher-Order Message Passing for Glycan Representation Learning","summary":"  Glycans are the most complex biological sequence, with monosaccharides\nforming extended, non-linear sequences. As post-translational modifications,\nthey modulate protein structure, function, and interactions. Due to their\ndiversity and complexity, predictive models of glycan properties and functions\nare still insufficient. Graph Neural Networks (GNNs) are deep learning models\ndesigned to process and analyze graph-structured data. These architectures\nleverage the connectivity and relational information in graphs to learn\neffective representations of nodes, edges, and entire graphs. Iteratively\naggregating information from neighboring nodes, GNNs capture complex patterns\nwithin graph data, making them particularly well-suited for tasks such as link\nprediction or graph classification across domains. This work presents a new\nmodel architecture based on combinatorial complexes and higher-order message\npassing to extract features from glycan structures into a latent space\nrepresentation. The architecture is evaluated on an improved GlycanML benchmark\nsuite, establishing a new state-of-the-art performance. We envision that these\nimprovements will spur further advances in computational glycosciences and\nreveal the roles of glycans in biology.\n","authors":["Roman Joeres","Daniel Bojar"],"pdf_url":"https://arxiv.org/pdf/2409.13467v2.pdf","comment":"Accepted to MLSB Workshop at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.11488v2","updated":"2024-10-22T11:18:29Z","published":"2024-10-15T10:46:03Z","title":"Advancing Training Efficiency of Deep Spiking Neural Networks through\n  Rate-based Backpropagation","summary":"  Recent insights have revealed that rate-coding is a primary form of\ninformation representation captured by surrogate-gradient-based Backpropagation\nThrough Time (BPTT) in training deep Spiking Neural Networks (SNNs). Motivated\nby these findings, we propose rate-based backpropagation, a training strategy\nspecifically designed to exploit rate-based representations to reduce the\ncomplexity of BPTT. Our method minimizes reliance on detailed temporal\nderivatives by focusing on averaged dynamics, streamlining the computational\ngraph to reduce memory and computational demands of SNNs training. We\nsubstantiate the rationality of the gradient approximation between BPTT and the\nproposed method through both theoretical analysis and empirical observations.\nComprehensive experiments on CIFAR-10, CIFAR-100, ImageNet, and CIFAR10-DVS\nvalidate that our method achieves comparable performance to BPTT counterparts,\nand surpasses state-of-the-art efficient training techniques. By leveraging the\ninherent benefits of rate-coding, this work sets the stage for more scalable\nand efficient SNNs training within resource-constrained environments. Our code\nis available at https://github.com/Tab-ct/rate-based-backpropagation.\n","authors":["Chengting Yu","Lei Liu","Gaoang Wang","Erping Li","Aili Wang"],"pdf_url":"https://arxiv.org/pdf/2410.11488v2.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.16901v1","updated":"2024-10-22T11:15:07Z","published":"2024-10-22T11:15:07Z","title":"Bayes without Underfitting: Fully Correlated Deep Learning Posteriors\n  via Alternating Projections","summary":"  Bayesian deep learning all too often underfits so that the Bayesian\nprediction is less accurate than a simple point estimate. Uncertainty\nquantification then comes at the cost of accuracy. For linearized models, the\nnull space of the generalized Gauss-Newton matrix corresponds to parameters\nthat preserve the training predictions of the point estimate. We propose to\nbuild Bayesian approximations in this null space, thereby guaranteeing that the\nBayesian predictive does not underfit. We suggest a matrix-free algorithm for\nprojecting onto this null space, which scales linearly with the number of\nparameters and quadratically with the number of output dimensions. We further\npropose an approximation that only scales linearly with parameters to make the\nmethod applicable to generative models. An extensive empirical evaluation shows\nthat the approach scales to large models, including vision transformers with 28\nmillion parameters.\n","authors":["Marco Miani","Hrittik Roy","Søren Hauberg"],"pdf_url":"https://arxiv.org/pdf/2410.16901v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16898v1","updated":"2024-10-22T11:03:06Z","published":"2024-10-22T11:03:06Z","title":"MBD: Multi b-value Denoising of Diffusion Magnetic Resonance Images","summary":"  We propose a novel approach to denoising diffusion magnetic resonance images\n(dMRI) using convolutional neural networks, that exploits the benefits of data\nacquired at multiple b-values to offset the need for many redundant\nobservations. Denoising is especially relevant in dMRI since noise can have a\ndeleterious impact on both quantification accuracy and image preprocessing. The\nmost successful methods proposed to date, like Marchenko-Pastur Principal\nComponent Analysis (MPPCA) denoising, are tailored to diffusion-weighting\nrepeated for many encoding directions. They exploit high redundancy of the\ndataset that oversamples the diffusion-encoding direction space, since many\ndirections have collinear components.\n  However, there are many dMRI techniques that do not entail a large number of\nencoding directions or repetitions, and are therefore less suited to this\napproach. For example, clinical dMRI exams may include as few as three encoding\ndirections, with low or negligible data redundancy across directions. Moreover,\npromising new dMRI approaches, like spherical b-tensor encoding (STE), benefit\nfrom high b-values while sensitizing the signal to diffusion along all\ndirections in just a single shot.\n  We introduce a convolutional neural network approach that we call\nmulti-b-value-based denoising (MBD). MBD exploits the similarity in\ndiffusion-weighted images (DWI) across different b-values but along the same\ndiffusion encoding direction. It allows denoising of diffusion images with high\nnoise variance while avoiding blurring, and using just a small number input\nimages.\n","authors":["Jakub Jurek","Andrzej Materka","Kamil Ludwisiak","Agata Majos","Filip Szczepankiewicz"],"pdf_url":"https://arxiv.org/pdf/2410.16898v1.pdf","comment":"this is a biomedical engineering work using machine learning to\n  enhance medical images"},{"id":"http://arxiv.org/abs/2410.16893v1","updated":"2024-10-22T10:56:52Z","published":"2024-10-22T10:56:52Z","title":"Global Optimization of Gaussian Process Acquisition Functions Using a\n  Piecewise-Linear Kernel Approximation","summary":"  Bayesian optimization relies on iteratively constructing and optimizing an\nacquisition function. The latter turns out to be a challenging, non-convex\noptimization problem itself. Despite the relative importance of this step, most\nalgorithms employ sampling- or gradient-based methods, which do not provably\nconverge to global optima. This work investigates mixed-integer programming\n(MIP) as a paradigm for \\textit{global} acquisition function optimization.\nSpecifically, our Piecewise-linear Kernel Mixed Integer Quadratic Programming\n(PK-MIQP) formulation introduces a piecewise-linear approximation for Gaussian\nprocess kernels and admits a corresponding MIQP representation for acquisition\nfunctions. We analyze the theoretical regret bounds of the proposed\napproximation, and empirically demonstrate the framework on synthetic\nfunctions, constrained benchmarks, and a hyperparameter tuning task.\n","authors":["Yilin Xie","Shiqiang Zhang","Joel Paulson","Calvin Tsay"],"pdf_url":"https://arxiv.org/pdf/2410.16893v1.pdf","comment":"16 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2407.07457v3","updated":"2024-10-22T10:54:15Z","published":"2024-07-10T08:20:47Z","title":"GLBench: A Comprehensive Benchmark for Graph with Large Language Models","summary":"  The emergence of large language models (LLMs) has revolutionized the way we\ninteract with graphs, leading to a new paradigm called GraphLLM. Despite the\nrapid development of GraphLLM methods in recent years, the progress and\nunderstanding of this field remain unclear due to the lack of a benchmark with\nconsistent experimental protocols. To bridge this gap, we introduce GLBench,\nthe first comprehensive benchmark for evaluating GraphLLM methods in both\nsupervised and zero-shot scenarios. GLBench provides a fair and thorough\nevaluation of different categories of GraphLLM methods, along with traditional\nbaselines such as graph neural networks. Through extensive experiments on a\ncollection of real-world datasets with consistent data processing and splitting\nstrategies, we have uncovered several key findings. Firstly, GraphLLM methods\noutperform traditional baselines in supervised settings, with LLM-as-enhancers\nshowing the most robust performance. However, using LLMs as predictors is less\neffective and often leads to uncontrollable output issues. We also notice that\nno clear scaling laws exist for current GraphLLM methods. In addition, both\nstructures and semantics are crucial for effective zero-shot transfer, and our\nproposed simple baseline can even outperform several models tailored for\nzero-shot scenarios. The data and code of the benchmark can be found at\nhttps://github.com/NineAbyss/GLBench.\n","authors":["Yuhan Li","Peisong Wang","Xiao Zhu","Aochuan Chen","Haiyun Jiang","Deng Cai","Victor Wai Kin Chan","Jia Li"],"pdf_url":"https://arxiv.org/pdf/2407.07457v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16888v1","updated":"2024-10-22T10:46:36Z","published":"2024-10-22T10:46:36Z","title":"Unsupervised Time Series Anomaly Prediction with Importance-based\n  Generative Contrastive Learning","summary":"  Time series anomaly prediction plays an essential role in many real-world\nscenarios, such as environmental prevention and prompt maintenance of\ncyber-physical systems. However, existing time series anomaly prediction\nmethods mainly require supervised training with plenty of manually labeled\ndata, which are difficult to obtain in practice. Besides, unseen anomalies can\noccur during inference, which could differ from the labeled training data and\nmake these models fail to predict such new anomalies. In this paper, we study a\nnovel problem of unsupervised time series anomaly prediction. We provide a\ntheoretical analysis and propose Importance-based Generative Contrastive\nLearning (IGCL) to address the aforementioned problems. IGCL distinguishes\nbetween normal and anomaly precursors, which are generated by our anomaly\nprecursor pattern generation module. To address the efficiency issues caused by\nthe potential complex anomaly precursor combinations, we propose a memory bank\nwith importance-based scores to adaptively store representative anomaly\nprecursors and generate more complicated anomaly precursors. Extensive\nexperiments on seven benchmark datasets show our method outperforms\nstate-of-the-art baselines on unsupervised time series anomaly prediction\nproblems.\n","authors":["Kai Zhao","Zhihao Zhuang","Chenjuan Guo","Hao Miao","Yunyao Cheng","Bin Yang"],"pdf_url":"https://arxiv.org/pdf/2410.16888v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2409.15955v4","updated":"2024-10-22T10:41:58Z","published":"2024-09-24T10:36:40Z","title":"A Historical Trajectory Assisted Optimization Method for Zeroth-Order\n  Federated Learning","summary":"  Federated learning heavily relies on distributed gradient descent techniques.\nIn the situation where gradient information is not available, the gradients\nneed to be estimated from zeroth-order information, which typically involves\ncomputing finite-differences along isotropic random directions. This method\nsuffers from high estimation errors, as the geometric features of the objective\nlandscape may be overlooked during the isotropic sampling. In this work, we\npropose a non-isotropic sampling method to improve the gradient estimation\nprocedure. Gradients in our method are estimated in a subspace spanned by\nhistorical trajectories of solutions, aiming to encourage the exploration of\npromising regions and hence improve the convergence. The proposed method uses a\ncovariance matrix for sampling which is a convex combination of two parts. The\nfirst part is a thin projection matrix containing the basis of the subspace\nwhich is designed to improve the exploitation ability. The second part is the\nhistorical trajectories. We implement this method in zeroth-order federated\nsettings, and show that the convergence rate aligns with existing ones while\nintroducing no significant overheads in communication or local computation. The\neffectiveness of our proposal is verified on several numerical experiments in\ncomparison to several commonly-used zeroth-order federated optimization\nalgorithms.\n","authors":["Chenlin Wu","Xiaoyu He","Zike Li","Jing Gong","Zibin Zheng"],"pdf_url":"https://arxiv.org/pdf/2409.15955v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16882v1","updated":"2024-10-22T10:36:15Z","published":"2024-10-22T10:36:15Z","title":"Large Language Model-based Augmentation for Imbalanced Node\n  Classification on Text-Attributed Graphs","summary":"  Node classification on graphs frequently encounters the challenge of class\nimbalance, leading to biased performance and posing significant risks in\nreal-world applications. Although several data-centric solutions have been\nproposed, none of them focus on Text-Attributed Graphs (TAGs), and therefore\noverlook the potential of leveraging the rich semantics encoded in textual\nfeatures for boosting the classification of minority nodes. Given this crucial\ngap, we investigate the possibility of augmenting graph data in the text space,\nleveraging the textual generation power of Large Language Models (LLMs) to\nhandle imbalanced node classification on TAGs. Specifically, we propose a novel\napproach called LA-TAG (LLM-based Augmentation on Text-Attributed Graphs),\nwhich prompts LLMs to generate synthetic texts based on existing node texts in\nthe graph. Furthermore, to integrate these synthetic text-attributed nodes into\nthe graph, we introduce a text-based link predictor to connect the synthesized\nnodes with the existing nodes. Our experiments across multiple datasets and\nevaluation metrics show that our framework significantly outperforms\ntraditional non-textual-based data augmentation strategies and specific node\nimbalance solutions. This highlights the promise of using LLMs to resolve\nimbalance issues on TAGs.\n","authors":["Leyao Wang","Yu Wang","Bo Ni","Yuying Zhao","Tyler Derr"],"pdf_url":"https://arxiv.org/pdf/2410.16882v1.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.16881v1","updated":"2024-10-22T10:33:00Z","published":"2024-10-22T10:33:00Z","title":"Just In Time Transformers","summary":"  Precise energy load forecasting in residential households is crucial for\nmitigating carbon emissions and enhancing energy efficiency; indeed, accurate\nforecasting enables utility companies and policymakers, who advocate\nsustainable energy practices, to optimize resource utilization. Moreover, smart\nmeters provide valuable information by allowing for granular insights into\nconsumption patterns. Building upon available smart meter data, our study aims\nto cluster consumers into distinct groups according to their energy usage\nbehaviours, effectively capturing a diverse spectrum of consumption patterns.\nNext, we design JITtrans (Just In Time transformer), a novel transformer deep\nlearning model that significantly improves energy consumption forecasting\naccuracy, with respect to traditional forecasting methods. Extensive\nexperimental results validate our claims using proprietary smart meter data.\nOur findings highlight the potential of advanced predictive technologies to\nrevolutionize energy management and advance sustainable power systems: the\ndevelopment of efficient and eco-friendly energy solutions critically depends\non such technologies.\n","authors":["Ahmed Ala Eddine Benali","Massimo Cafaro","Italo Epicoco","Marco Pulimeno","Enrico Junior Schioppa"],"pdf_url":"https://arxiv.org/pdf/2410.16881v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16879v1","updated":"2024-10-22T10:31:23Z","published":"2024-10-22T10:31:23Z","title":"Contrasting Attitudes Towards Current and Future AI Applications for\n  Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study","summary":"  Objectives: To investigate clinicians' attitudes towards current automated\ninterpretation of ECG and novel AI technologies and their perception of\ncomputer-assisted interpretation. Materials and Methods: We conducted a series\nof interviews with clinicians in the UK. Our study: (i) explores the potential\nfor AI, specifically future 'human-like' computing approaches, to facilitate\nECG interpretation and support clinical decision making, and (ii) elicits their\nopinions about the importance of explainability and trustworthiness of AI\nalgorithms. Results: We performed inductive thematic analysis on interview\ntranscriptions from 23 clinicians and identified the following themes: (i) a\nlack of trust in current systems, (ii) positive attitudes towards future AI\napplications and requirements for these, (iii) the relationship between the\naccuracy and explainability of algorithms, and (iv) opinions on education,\npossible deskilling, and the impact of AI on clinical competencies. Discussion:\nClinicians do not trust current computerised methods, but welcome future 'AI'\ntechnologies. Where clinicians trust future AI interpretation to be accurate,\nthey are less concerned that it is explainable. They also preferred ECG\ninterpretation that demonstrated the results of the algorithm visually. Whilst\nclinicians do not fear job losses, they are concerned about deskilling and the\nneed to educate the workforce to use AI responsibly. Conclusion: Clinicians are\npositive about the future application of AI in clinical decision-making.\nAccuracy is a key factor of uptake and visualisations are preferred over\ncurrent computerised methods. This is viewed as a potential means of training\nand upskilling, in contrast to the deskilling that automation might be\nperceived to bring.\n","authors":["Lukas Hughes-Noehrer","Leda Channer","Gabriel Strain","Gregory Yates","Richard Body","Caroline Jay"],"pdf_url":"https://arxiv.org/pdf/2410.16879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16872v1","updated":"2024-10-22T10:20:20Z","published":"2024-10-22T10:20:20Z","title":"CK4Gen: A Knowledge Distillation Framework for Generating High-Utility\n  Synthetic Survival Datasets in Healthcare","summary":"  Access to real clinical data is heavily restricted by privacy regulations,\nhindering both healthcare research and education. These constraints slow\nprogress in developing new treatments and data-driven healthcare solutions,\nwhile also limiting students' access to real-world datasets, leaving them\nwithout essential practical skills. High-utility synthetic datasets are\ntherefore critical for advancing research and providing meaningful training\nmaterial. However, current generative models -- such as Variational\nAutoencoders (VAEs) and Generative Adversarial Networks (GANs) -- produce\nsurface-level realism at the expense of healthcare utility, blending distinct\npatient profiles and producing synthetic data of limited practical relevance.\nTo overcome these limitations, we introduce CK4Gen (Cox Knowledge for\nGeneration), a novel framework that leverages knowledge distillation from Cox\nProportional Hazards (CoxPH) models to create synthetic survival datasets that\npreserve key clinical characteristics, including hazard ratios and survival\ncurves. CK4Gen avoids the interpolation issues seen in VAEs and GANs by\nmaintaining distinct patient risk profiles, ensuring realistic and reliable\noutputs for research and educational use. Validated across four benchmark\ndatasets -- GBSG2, ACTG320, WHAS500, and FLChain -- CK4Gen outperforms\ncompeting techniques by better aligning real and synthetic data, enhancing\nsurvival model performance in both discrimination and calibration via data\naugmentation. As CK4Gen is scalable across clinical conditions, and with code\nto be made publicly available, future researchers can apply it to their own\ndatasets to generate synthetic versions suitable for open sharing.\n","authors":["Nicholas I-Hsien Kuo","Blanca Gallego","Louisa Jorm"],"pdf_url":"https://arxiv.org/pdf/2410.16872v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16871v1","updated":"2024-10-22T10:19:27Z","published":"2024-10-22T10:19:27Z","title":"Error Feedback under $(L_0,L_1)$-Smoothness: Normalization and Momentum","summary":"  We provide the first proof of convergence for normalized error feedback\nalgorithms across a wide range of machine learning problems. Despite their\npopularity and efficiency in training deep neural networks, traditional\nanalyses of error feedback algorithms rely on the smoothness assumption that\ndoes not capture the properties of objective functions in these problems.\nRather, these problems have recently been shown to satisfy generalized\nsmoothness assumptions, and the theoretical understanding of error feedback\nalgorithms under these assumptions remains largely unexplored. Moreover, to the\nbest of our knowledge, all existing analyses under generalized smoothness\neither i) focus on single-node settings or ii) make unrealistically strong\nassumptions for distributed settings, such as requiring data heterogeneity, and\nalmost surely bounded stochastic gradient noise variance. In this paper, we\npropose distributed error feedback algorithms that utilize normalization to\nachieve the $O(1/\\sqrt{K})$ convergence rate for nonconvex problems under\ngeneralized smoothness. Our analyses apply for distributed settings without\ndata heterogeneity conditions, and enable stepsize tuning that is independent\nof problem parameters. Additionally, we provide strong convergence guarantees\nof normalized error feedback algorithms for stochastic settings. Finally, we\nshow that due to their larger allowable stepsizes, our new normalized error\nfeedback algorithms outperform their non-normalized counterparts on various\ntasks, including the minimization of polynomial functions, logistic regression,\nand ResNet-20 training.\n","authors":["Sarit Khirirat","Abdurakhmon Sadiev","Artem Riabinin","Eduard Gorbunov","Peter Richtárik"],"pdf_url":"https://arxiv.org/pdf/2410.16871v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16870v1","updated":"2024-10-22T10:19:17Z","published":"2024-10-22T10:19:17Z","title":"Federated Causal Inference: Multi-Centric ATE Estimation beyond\n  Meta-Analysis","summary":"  We study Federated Causal Inference, an approach to estimate treatment\neffects from decentralized data across centers. We compare three classes of\nAverage Treatment Effect (ATE) estimators derived from the Plug-in G-Formula,\nranging from simple meta-analysis to one-shot and multi-shot federated\nlearning, the latter leveraging the full data to learn the outcome model\n(albeit requiring more communication). Focusing on Randomized Controlled Trials\n(RCTs), we derive the asymptotic variance of these estimators for linear\nmodels. Our results provide practical guidance on selecting the appropriate\nestimator for various scenarios, including heterogeneity in sample sizes,\ncovariate distributions, treatment assignment schemes, and center effects. We\nvalidate these findings with a simulation study.\n","authors":["Rémi Khellaf","Aurélien Bellet","Julie Josse"],"pdf_url":"https://arxiv.org/pdf/2410.16870v1.pdf","comment":null}]},"2024-10-23T00:00:00Z":{"Robotics":[{"id":"http://arxiv.org/abs/2410.18084v1","updated":"2024-10-23T17:59:58Z","published":"2024-10-23T17:59:58Z","title":"DynamicCity: Large-Scale LiDAR Generation from Dynamic Scenes","summary":"  LiDAR scene generation has been developing rapidly recently. However,\nexisting methods primarily focus on generating static and single-frame scenes,\noverlooking the inherently dynamic nature of real-world driving environments.\nIn this work, we introduce DynamicCity, a novel 4D LiDAR generation framework\ncapable of generating large-scale, high-quality LiDAR scenes that capture the\ntemporal evolution of dynamic environments. DynamicCity mainly consists of two\nkey models. 1) A VAE model for learning HexPlane as the compact 4D\nrepresentation. Instead of using naive averaging operations, DynamicCity\nemploys a novel Projection Module to effectively compress 4D LiDAR features\ninto six 2D feature maps for HexPlane construction, which significantly\nenhances HexPlane fitting quality (up to 12.56 mIoU gain). Furthermore, we\nutilize an Expansion & Squeeze Strategy to reconstruct 3D feature volumes in\nparallel, which improves both network training efficiency and reconstruction\naccuracy than naively querying each 3D point (up to 7.05 mIoU gain, 2.06x\ntraining speedup, and 70.84% memory reduction). 2) A DiT-based diffusion model\nfor HexPlane generation. To make HexPlane feasible for DiT generation, a Padded\nRollout Operation is proposed to reorganize all six feature planes of the\nHexPlane as a squared 2D feature map. In particular, various conditions could\nbe introduced in the diffusion or sampling process, supporting versatile 4D\ngeneration applications, such as trajectory- and command-driven generation,\ninpainting, and layout-conditioned generation. Extensive experiments on the\nCarlaSC and Waymo datasets demonstrate that DynamicCity significantly\noutperforms existing state-of-the-art 4D LiDAR generation methods across\nmultiple metrics. The code will be released to facilitate future research.\n","authors":["Hengwei Bian","Lingdong Kong","Haozhe Xie","Liang Pan","Yu Qiao","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2410.18084v1.pdf","comment":"Preprint; 29 pages, 15 figures, 7 tables; Project Page at\n  https://dynamic-city.github.io/"},{"id":"http://arxiv.org/abs/2410.18065v1","updated":"2024-10-23T17:42:07Z","published":"2024-10-23T17:42:07Z","title":"SPIRE: Synergistic Planning, Imitation, and Reinforcement Learning for\n  Long-Horizon Manipulation","summary":"  Robot learning has proven to be a general and effective technique for\nprogramming manipulators. Imitation learning is able to teach robots solely\nfrom human demonstrations but is bottlenecked by the capabilities of the\ndemonstrations. Reinforcement learning uses exploration to discover better\nbehaviors; however, the space of possible improvements can be too large to\nstart from scratch. And for both techniques, the learning difficulty increases\nproportional to the length of the manipulation task. Accounting for this, we\npropose SPIRE, a system that first uses Task and Motion Planning (TAMP) to\ndecompose tasks into smaller learning subproblems and second combines imitation\nand reinforcement learning to maximize their strengths. We develop novel\nstrategies to train learning agents when deployed in the context of a planning\nsystem. We evaluate SPIRE on a suite of long-horizon and contact-rich robot\nmanipulation problems. We find that SPIRE outperforms prior approaches that\nintegrate imitation learning, reinforcement learning, and planning by 35% to\n50% in average task performance, is 6 times more data efficient in the number\nof human demonstrations needed to train proficient agents, and learns to\ncomplete tasks nearly twice as efficiently. View\nhttps://sites.google.com/view/spire-corl-2024 for more details.\n","authors":["Zihan Zhou","Animesh Garg","Dieter Fox","Caelan Garrett","Ajay Mandlekar"],"pdf_url":"https://arxiv.org/pdf/2410.18065v1.pdf","comment":"Conference on Robot Learning (CoRL) 2024"},{"id":"http://arxiv.org/abs/2403.05489v2","updated":"2024-10-23T16:39:15Z","published":"2024-03-08T17:54:38Z","title":"JointMotion: Joint Self-Supervision for Joint Motion Prediction","summary":"  We present JointMotion, a self-supervised pre-training method for joint\nmotion prediction in self-driving vehicles. Our method jointly optimizes a\nscene-level objective connecting motion and environments, and an instance-level\nobjective to refine learned representations. Scene-level representations are\nlearned via non-contrastive similarity learning of past motion sequences and\nenvironment context. At the instance level, we use masked autoencoding to\nrefine multimodal polyline representations. We complement this with an adaptive\npre-training decoder that enables JointMotion to generalize across different\nenvironment representations, fusion mechanisms, and dataset characteristics.\nNotably, our method reduces the joint final displacement error of Wayformer,\nHPTR, and Scene Transformer models by 3\\%, 8\\%, and 12\\%, respectively; and\nenables transfer learning between the Waymo Open Motion and the Argoverse 2\nMotion Forecasting datasets. Code: https://github.com/kit-mrt/future-motion\n","authors":["Royden Wagner","Omer Sahin Tas","Marvin Klemp","Carlos Fernandez"],"pdf_url":"https://arxiv.org/pdf/2403.05489v2.pdf","comment":"CoRL'24 camera-ready"},{"id":"http://arxiv.org/abs/2410.17988v1","updated":"2024-10-23T16:01:31Z","published":"2024-10-23T16:01:31Z","title":"A Pipeline for Segmenting and Structuring RGB-D Data for Robotics\n  Applications","summary":"  We introduce a novel pipeline for segmenting and structuring color and depth\n(RGB-D) data. Existing processing pipelines for RGB-D data have focused on\nextracting geometric information alone. This approach precludes the development\nof more advanced robotic navigation and manipulation algorithms, which benefit\nfrom a semantic understanding of their environment. Our pipeline can segment\nRGB-D data into accurate semantic masks. These masks are then used to fuse raw\ncaptured point clouds into semantically separated point clouds. We store this\ninformation using the Universal Scene Description (USD) file format, a format\nsuitable for easy querying by downstream robotics algorithms, human-friendly\nvisualization, and robotics simulation.\n","authors":["Zhiwu Zheng","Lauren Mentzer","Berk Iskender","Michael Price","Colm Prendergast","Audren Cloitre"],"pdf_url":"https://arxiv.org/pdf/2410.17988v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17983v1","updated":"2024-10-23T15:51:33Z","published":"2024-10-23T15:51:33Z","title":"Robust Two-View Geometry Estimation with Implicit Differentiation","summary":"  We present a novel two-view geometry estimation framework which is based on a\ndifferentiable robust loss function fitting. We propose to treat the robust\nfundamental matrix estimation as an implicit layer, which allows us to avoid\nbackpropagation through time and significantly improves the numerical\nstability. To take full advantage of the information from the feature matching\nstage we incorporate learnable weights that depend on the matching confidences.\nIn this way our solution brings together feature extraction, matching and\ntwo-view geometry estimation in a unified end-to-end trainable pipeline. We\nevaluate our approach on the camera pose estimation task in both outdoor and\nindoor scenarios. The experiments on several datasets show that the proposed\nmethod outperforms both classic and learning-based state-of-the-art methods by\na large margin. The project webpage is available at:\nhttps://github.com/VladPyatov/ihls\n","authors":["Vladislav Pyatov","Iaroslav Koshelev","Stamatis Lefkimmiatis"],"pdf_url":"https://arxiv.org/pdf/2410.17983v1.pdf","comment":"IROS 2024 Accepted"},{"id":"http://arxiv.org/abs/2410.17936v1","updated":"2024-10-23T15:01:19Z","published":"2024-10-23T15:01:19Z","title":"Reconfigurable Hydrostatics: Toward Multifunctional and Powerful\n  Wearable Robotics","summary":"  Wearable and locomotive robot designers face multiple challenges when\nchoosing actuation. Traditional fully actuated designs using electric motors\nare multifunctional but oversized and inefficient for bearing conservative\nloads and for being backdrivable. Alternatively, quasi-passive and\nunderactuated designs reduce the size of motorization and energy storage, but\nare often designed for specific tasks. Designers of versatile and stronger\nwearable robots will face these challenges unless future actuators become very\ntorque-dense, backdrivable and efficient.\n  This paper explores a design paradigm for addressing this issue:\nreconfigurable hydrostatics. We show that a hydrostatic actuator can integrate\na passive force mechanism and a sharing mechanism in the fluid domain and still\nbe multifunctional. First, an analytical study compares how these two\nmechanisms can relax the motorization requirements in the context of a\nload-bearing exoskeleton. Then, the hydrostatic concept integrating these two\nmechanisms using hydraulic components is presented. A case study analysis shows\nthe mass/efficiency/inertia benefits of the concept over a fully actuated one.\nThen, the feasibility of the concept is partially validated with a\nproof-of-concept that actuates the knees of an exoskeleton. The experiments\nshow that it can track the vertical ground reaction force (GRF) profiles of\nwalking, running, squatting, and jumping, and that the energy consumption is 6x\nlower. The transient force behaviors due to switching from one leg to the other\nare also analyzed along with some mitigation to improve them.\n","authors":["Jeff Denis","Frederic Laberge","Jean-Sebastien Plante","Alexandre Girard"],"pdf_url":"https://arxiv.org/pdf/2410.17936v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15997v2","updated":"2024-10-23T14:21:26Z","published":"2024-05-25T01:09:49Z","title":"UniSaT: Unified-Objective Belief Model and Planner to Search for and\n  Track Multiple Objects","summary":"  Path planning for autonomous search and tracking of multiple objects is a\ncritical problem in applications such as reconnaissance, surveillance, and data\ngathering. Due to the inherent competing objectives of searching for new\nobjects while maintaining tracks for found objects, most current approaches\nrely on multi-objective planning methods, leaving it up to the user to tune\nparameters to balance between the two objectives, usually based on heuristics\nor trial and error. In this paper, we introduce UniSaT (Unified Search and\nTrack), a novel unified-objective formulation for the search and track problem\nbased on Random Finite Sets (RFS). Our approach models unknown and known\nobjects using a combined generalized labeled multi-Bernoulli (GLMB) filter. For\nunseen objects, UniSaT leverages both cardinality and spatial prior\ndistributions, allowing it to operate without prior knowledge of the exact\nnumber of objects in the search space. The planner maximizes the mutual\ninformation of this unified belief model, creating balanced search and tracking\nbehaviors. We demonstrate our work in a simulated environment, presenting both\nqualitative results and quantitative improvements over a multi-objective\nmethod.\n","authors":["Leonardo Santos","Brady Moon","Sebastian Scherer","Hoa Van Nguyen"],"pdf_url":"https://arxiv.org/pdf/2405.15997v2.pdf","comment":"13 pages, AIAA SCITECH 2025 Forum"},{"id":"http://arxiv.org/abs/2407.09899v2","updated":"2024-10-23T13:01:38Z","published":"2024-07-13T14:29:12Z","title":"DexGrasp-Diffusion: Diffusion-based Unified Functional Grasp Synthesis\n  Method for Multi-Dexterous Robotic Hands","summary":"  The versatility and adaptability of human grasping catalyze advancing\ndexterous robotic manipulation. While significant strides have been made in\ndexterous grasp generation, current research endeavors pivot towards optimizing\nobject manipulation while ensuring functional integrity, emphasizing the\nsynthesis of functional grasps following desired affordance instructions. This\npaper addresses the challenge of synthesizing functional grasps tailored to\ndiverse dexterous robotic hands by proposing DexGrasp-Diffusion, an end-to-end\nmodularized diffusion-based method. DexGrasp-Diffusion integrates\nMultiHandDiffuser, a novel unified data-driven diffusion model for\nmulti-dexterous hands grasp estimation, with DexDiscriminator, which employs a\nPhysics Discriminator and a Functional Discriminator with open-vocabulary\nsetting to filter physically plausible functional grasps based on object\naffordances. The experimental evaluation conducted on the MultiDex dataset\nprovides substantiating evidence supporting the superior performance of\nMultiHandDiffuser over the baseline model in terms of success rate, grasp\ndiversity, and collision depth. Moreover, we demonstrate the capacity of\nDexGrasp-Diffusion to reliably generate functional grasps for household objects\naligned with specific affordance instructions.\n","authors":["Zhengshen Zhang","Lei Zhou","Chenchen Liu","Zhiyang Liu","Chengran Yuan","Sheng Guo","Ruiteng Zhao","Marcelo H. Ang Jr.","Francis EH Tay"],"pdf_url":"https://arxiv.org/pdf/2407.09899v2.pdf","comment":"15 pages, 5 figures"},{"id":"http://arxiv.org/abs/2410.17831v1","updated":"2024-10-23T12:49:44Z","published":"2024-10-23T12:49:44Z","title":"Gaussian Process Distance Fields Obstacle and Ground Constraints for\n  Safe Navigation","summary":"  Navigating cluttered environments is a challenging task for any mobile\nsystem. Existing approaches for ground-based mobile systems primarily focus on\nsmall wheeled robots, which face minimal constraints with overhanging obstacles\nand cannot manage steps or stairs, making the problem effectively 2D. However,\nnavigation for legged robots (or even humans) has to consider an extra\ndimension. This paper proposes a tailored scene representation coupled with an\nadvanced trajectory optimisation algorithm to enable safe navigation. Our 3D\nnavigation approach is suitable for any ground-based mobile robot, whether\nwheeled or legged, as well as for human assistance. Given a 3D point cloud of\nthe scene and the segmentation of the ground and non-ground points, we\nformulate two Gaussian Process distance fields to ensure a collision-free path\nand maintain distance to the ground constraints. Our method adeptly handles\nuneven terrain, steps, and overhanging objects through an innovative use of a\nquadtree structure, constructing a multi-resolution map of the free space and\nits connectivity graph based on a 2D projection of the relevant scene.\nEvaluations with both synthetic and real-world datasets demonstrate that this\napproach provides safe and smooth paths, accommodating a wide range of\nground-based mobile systems.\n","authors":["Monisha Mushtary Uttsha","Cedric Le Gentil","Lan Wu","Teresa Vidal-Calleja"],"pdf_url":"https://arxiv.org/pdf/2410.17831v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17772v1","updated":"2024-10-23T11:19:48Z","published":"2024-10-23T11:19:48Z","title":"Scaling Robot Policy Learning via Zero-Shot Labeling with Foundation\n  Models","summary":"  A central challenge towards developing robots that can relate human language\nto their perception and actions is the scarcity of natural language annotations\nin diverse robot datasets. Moreover, robot policies that follow natural\nlanguage instructions are typically trained on either templated language or\nexpensive human-labeled instructions, hindering their scalability. To this end,\nwe introduce NILS: Natural language Instruction Labeling for Scalability. NILS\nautomatically labels uncurated, long-horizon robot data at scale in a zero-shot\nmanner without any human intervention. NILS combines pretrained vision-language\nfoundation models in order to detect objects in a scene, detect object-centric\nchanges, segment tasks from large datasets of unlabelled interaction data and\nultimately label behavior datasets. Evaluations on BridgeV2, Fractal, and a\nkitchen play dataset show that NILS can autonomously annotate diverse robot\ndemonstrations of unlabeled and unstructured datasets while alleviating several\nshortcomings of crowdsourced human annotations, such as low data quality and\ndiversity. We use NILS to label over 115k trajectories obtained from over 430\nhours of robot data. We open-source our auto-labeling code and generated\nannotations on our website: http://robottasklabeling.github.io.\n","authors":["Nils Blank","Moritz Reuss","Marcel Rühle","Ömer Erdinç Yağmurlu","Fabian Wenzel","Oier Mees","Rudolf Lioutikov"],"pdf_url":"https://arxiv.org/pdf/2410.17772v1.pdf","comment":"Project Website at https://robottasklabeling.github.io/"},{"id":"http://arxiv.org/abs/2403.14626v2","updated":"2024-10-23T11:05:01Z","published":"2024-03-21T17:59:55Z","title":"ODTFormer: Efficient Obstacle Detection and Tracking with Stereo Cameras\n  Based on Transformer","summary":"  Obstacle detection and tracking represent a critical component in robot\nautonomous navigation. In this paper, we propose ODTFormer, a Transformer-based\nmodel to address both obstacle detection and tracking problems. For the\ndetection task, our approach leverages deformable attention to construct a 3D\ncost volume, which is decoded progressively in the form of voxel occupancy\ngrids. We further track the obstacles by matching the voxels between\nconsecutive frames. The entire model can be optimized in an end-to-end manner.\nThrough extensive experiments on DrivingStereo and KITTI benchmarks, our model\nachieves state-of-the-art performance in the obstacle detection task. We also\nreport comparable accuracy to state-of-the-art obstacle tracking models while\nrequiring only a fraction of their computation cost, typically ten-fold to\ntwenty-fold less. The code and model weights will be publicly released.\n","authors":["Tianye Ding","Hongyu Li","Huaizu Jiang"],"pdf_url":"https://arxiv.org/pdf/2403.14626v2.pdf","comment":"8 pages. Accepted by IROS 2024"},{"id":"http://arxiv.org/abs/2410.17742v1","updated":"2024-10-23T10:16:08Z","published":"2024-10-23T10:16:08Z","title":"Multi-Layered Safety of Redundant Robot Manipulators via Task-Oriented\n  Planning and Control","summary":"  Ensuring safety is crucial to promote the application of robot manipulators\nin open workspace. Factors such as sensor errors or unpredictable collisions\nmake the environment full of uncertainties. In this work, we investigate these\npotential safety challenges on redundant robot manipulators, and propose a\ntask-oriented planning and control framework to achieve multi-layered safety\nwhile maintaining efficient task execution. Our approach consists of two main\nparts: a task-oriented trajectory planner based on multiple-shooting model\npredictive control method, and a torque controller that allows safe and\nefficient collision reaction using only proprioceptive data. Through extensive\nsimulations and real-hardware experiments, we demonstrate that the proposed\nframework can effectively handle uncertain static or dynamic obstacles, and\nperform disturbance resistance in manipulation tasks when unforeseen contacts\noccur. All code will be open-sourced to benefit the community.\n","authors":["Xinyu Jia","Wenxin Wang","Jun Yang","Yongping Pan","Haoyong Yu"],"pdf_url":"https://arxiv.org/pdf/2410.17742v1.pdf","comment":"7 pages, 8 figures. This work has been submitted to the IEEE for\n  possible publication"},{"id":"http://arxiv.org/abs/2410.17738v1","updated":"2024-10-23T10:12:14Z","published":"2024-10-23T10:12:14Z","title":"Towards Safer Planetary Exploration: A Hybrid Architecture for Terrain\n  Traversability Analysis in Mars Rovers","summary":"  The field of autonomous navigation for unmanned ground vehicles (UGVs) is in\ncontinuous growth and increasing levels of autonomy have been reached in the\nlast few years. However, the task becomes more challenging when the focus is on\nthe exploration of planet surfaces such as Mars. In those situations, UGVs are\nforced to navigate through unstable and rugged terrains which, inevitably, open\nthe vehicle to more hazards, accidents, and, in extreme cases, complete mission\nfailure. The paper addresses the challenges of autonomous navigation for\nunmanned ground vehicles in planetary exploration, particularly on Mars,\nintroducing a hybrid architecture for terrain traversability analysis that\ncombines two approaches: appearance-based and geometry-based. The\nappearance-based method uses semantic segmentation via deep neural networks to\nclassify different terrain types. This is further refined by pixel-level\nterrain roughness classification obtained from the same RGB image, assigning\ndifferent costs based on the physical properties of the soil. The\ngeometry-based method complements the appearance-based approach by evaluating\nthe terrain's geometrical features, identifying hazards that may not be\ndetectable by the appearance-based side. The outputs of both methods are\ncombined into a comprehensive hybrid cost map. The proposed architecture was\ntrained on synthetic datasets and developed as a ROS2 application to integrate\ninto broader autonomous navigation systems for harsh environments. Simulations\nhave been performed in Unity, showing the ability of the method to assess\nonline traversability analysis.\n","authors":["Achille Chiuchiarelli","Giacomo Franchini","Francesco Messina","Marcello Chiaberge"],"pdf_url":"https://arxiv.org/pdf/2410.17738v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17690v1","updated":"2024-10-23T09:13:02Z","published":"2024-10-23T09:13:02Z","title":"Markov Potential Game with Final-time Reach-Avoid Objectives","summary":"  We formulate a Markov potential game with final-time reach-avoid objectives\nby integrating potential game theory with stochastic reach-avoid control. Our\nfocus is on multi-player trajectory planning where players maximize the same\nmulti-player reach-avoid objective: the probability of all participants\nreaching their designated target states by a specified time, while avoiding\ncollisions with one another. Existing approaches require centralized\ncomputation of actions via a global policy, which may have prohibitively\nexpensive communication costs. Instead, we focus on approximations of the\nglobal policy via local state feedback policies. First, we adapt the recursive\nsingle player reach-avoid value iteration to the multi-player framework with\nlocal policies, and show that the same recursion holds on the joint state\nspace. To find each player's optimal local policy, the multi-player reach-avoid\nvalue function is projected from the joint state to the local state using the\nother players' occupancy measures. Then, we propose an iterative best response\nscheme for the multi-player value iteration to converge to a pure Nash\nequilibrium. We demonstrate the utility of our approach in finding\ncollision-free policies for multi-player motion planning in simulation.\n","authors":["Sarah H. Q. Li","Abraham P. Vinod"],"pdf_url":"https://arxiv.org/pdf/2410.17690v1.pdf","comment":"8 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.17685v1","updated":"2024-10-23T09:00:04Z","published":"2024-10-23T09:00:04Z","title":"Human-Robot Collaboration System Setup for Weed Harvesting Scenarios in\n  Aquatic Lakes","summary":"  Artificial Water Bodies (AWBs) are human-made and require continuous\nmonitoring due to their artificial biological processes. These systems\nnecessitate regular maintenance to manage their ecosystems effectively.\nUnmanned Surface Vehicle (USV) offers a collaborative approach for monitoring\nthese environments, working alongside human operators such as boat skippers to\nidentify specific locations. This paper discusses a weed harvesting scenario,\ndemonstrating how human-robot collaboration can be achieved, supported by\npreliminary results. The USV mainly utilises multibeam SOund NAvigation and\nRanging (SONAR) for underwater weed monitoring, showing promising outcomes in\nthese scenarios.\n","authors":["Ahmed H. Elsayed","Andrej Lejman","Frederic Stahl"],"pdf_url":"https://arxiv.org/pdf/2410.17685v1.pdf","comment":"3 pages, 5 figures. This paper was accepted for poster presentation\n  at IROS 2024 Workshop on Maritime Heteregenous Unmanned Robotic Systems\n  (MHURS)"},{"id":"http://arxiv.org/abs/2407.13432v3","updated":"2024-10-23T08:07:05Z","published":"2024-07-18T12:01:09Z","title":"The Art of Imitation: Learning Long-Horizon Manipulation Tasks from Few\n  Demonstrations","summary":"  Task Parametrized Gaussian Mixture Models (TP-GMM) are a sample-efficient\nmethod for learning object-centric robot manipulation tasks. However, there are\nseveral open challenges to applying TP-GMMs in the wild. In this work, we\ntackle three crucial challenges synergistically. First, end-effector velocities\nare non-Euclidean and thus hard to model using standard GMMs. We thus propose\nto factorize the robot's end-effector velocity into its direction and\nmagnitude, and model them using Riemannian GMMs. Second, we leverage the\nfactorized velocities to segment and sequence skills from complex demonstration\ntrajectories. Through the segmentation, we further align skill trajectories and\nhence leverage time as a powerful inductive bias. Third, we present a method to\nautomatically detect relevant task parameters per skill from visual\nobservations. Our approach enables learning complex manipulation tasks from\njust five demonstrations while using only RGB-D observations. Extensive\nexperimental evaluations on RLBench demonstrate that our approach achieves\nstate-of-the-art performance with 20-fold improved sample efficiency. Our\npolicies generalize across different environments, object instances, and object\npositions, while the learned skills are reusable.\n","authors":["Jan Ole von Hartz","Tim Welschehold","Abhinav Valada","Joschka Boedecker"],"pdf_url":"https://arxiv.org/pdf/2407.13432v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15799v2","updated":"2024-10-23T08:02:51Z","published":"2024-10-21T09:13:07Z","title":"Flying through Moving Gates without Full State Estimation","summary":"  Autonomous drone racing requires powerful perception, planning, and control\nand has become a benchmark and test field for autonomous, agile flight.\nExisting work usually assumes static race tracks with known maps, which enables\noffline planning of time-optimal trajectories, performing localization to the\ngates to reduce the drift in visual-inertial odometry (VIO) for state\nestimation or training learning-based methods for the particular race track and\noperating environment. In contrast, many real-world tasks like disaster\nresponse or delivery need to be performed in unknown and dynamic environments.\nTo close this gap and make drone racing more robust against unseen environments\nand moving gates, we propose a control algorithm that does not require a race\ntrack map or VIO and uses only monocular measurements of the line of sight\n(LOS) to the gates. For this purpose, we adopt the law of proportional\nnavigation (PN) to accurately fly through the gates despite gate motions or\nwind. We formulate the PN-informed vision-based control problem for drone\nracing as a constrained optimization problem and derive a closed-form optimal\nsolution. We demonstrate through extensive simulations and real-world\nexperiments that our method can navigate through moving gates at high speeds\nwhile being robust to different gate movements, model errors, wind, and delays.\n","authors":["Ralf Römer","Tim Emmert","Angela P. Schoellig"],"pdf_url":"https://arxiv.org/pdf/2410.15799v2.pdf","comment":"7 pages, 6 figures"},{"id":"http://arxiv.org/abs/2405.08310v3","updated":"2024-10-23T07:29:30Z","published":"2024-05-14T04:23:44Z","title":"Cross-Category Functional Grasp Transfer","summary":"  Generating grasps for a dexterous hand often requires numerous grasping\nannotations. However, annotating high DoF dexterous hand poses is quite\nchallenging. Especially for functional grasps, requiring the hand to grasp the\nobject in a specific pose to facilitate subsequent manipulations. This prompts\nus to explore how people achieve manipulations on new objects based on past\ngrasp experiences. We find that when grasping new items, people are adept at\ndiscovering and leveraging various similarities between objects, including\nshape, layout, and grasp type. Considering this, we analyze and collect\ngrasp-related similarity relationships among 51 common tool-like object\ncategories and annotate semantic grasp representation for 1768 objects. These\nobjects are connected through similarities to form a knowledge graph, which\nhelps infer our proposed cross-category functional grasp synthesis. Through\nextensive experiments, we demonstrate that the grasp-related knowledge indeed\ncontributed to achieving functional grasp transfer across unknown or entirely\nnew categories of objects.\n","authors":["Rina Wu","Tianqiang Zhu","Xiangbo Lin","Yi Sun"],"pdf_url":"https://arxiv.org/pdf/2405.08310v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17624v1","updated":"2024-10-23T07:29:30Z","published":"2024-10-23T07:29:30Z","title":"Incremental Learning of Affordances using Markov Logic Networks","summary":"  Affordances enable robots to have a semantic understanding of their\nsurroundings. This allows them to have more acting flexibility when completing\na given task. Capturing object affordances in a machine learning model is a\ndifficult task, because of their dependence on contextual information. Markov\nLogic Networks (MLN) combine probabilistic reasoning with logic that is able to\ncapture such context. Mobile robots operate in partially known environments\nwherein unseen object affordances can be observed. This new information must be\nincorporated into the existing knowledge, without having to retrain the MLN\nfrom scratch. We introduce the MLN Cumulative Learning Algorithm (MLN-CLA).\nMLN-CLA learns new relations in various knowledge domains by retaining\nknowledge and only updating the changed knowledge, for which the MLN is\nretrained. We show that MLN-CLA is effective for accumulative learning and\nzero-shot affordance inference, outperforming strong baselines.\n","authors":["George Potter","Gertjan Burghouts","Joris Sijs"],"pdf_url":"https://arxiv.org/pdf/2410.17624v1.pdf","comment":"accepted at IEEE IRC 2024"},{"id":"http://arxiv.org/abs/2410.17610v1","updated":"2024-10-23T07:06:08Z","published":"2024-10-23T07:06:08Z","title":"ImDy: Human Inverse Dynamics from Imitated Observations","summary":"  Inverse dynamics (ID), which aims at reproducing the driven torques from\nhuman kinematic observations, has been a critical tool for gait analysis.\nHowever, it is hindered from wider application to general motion due to its\nlimited scalability. Conventional optimization-based ID requires expensive\nlaboratory setups, restricting its availability. To alleviate this problem, we\npropose to exploit the recently progressive human motion imitation algorithms\nto learn human inverse dynamics in a data-driven manner. The key insight is\nthat the human ID knowledge is implicitly possessed by motion imitators, though\nnot directly applicable. In light of this, we devise an efficient data\ncollection pipeline with state-of-the-art motion imitation algorithms and\nphysics simulators, resulting in a large-scale human inverse dynamics benchmark\nas Imitated Dynamics (ImDy). ImDy contains over 150 hours of motion with joint\ntorque and full-body ground reaction force data. With ImDy, we train a\ndata-driven human inverse dynamics solver ImDyS(olver) in a fully supervised\nmanner, which conducts ID and ground reaction force estimation simultaneously.\nExperiments on ImDy and real-world data demonstrate the impressive competency\nof ImDyS in human inverse dynamics and ground reaction force estimation.\nMoreover, the potential of ImDy(-S) as a fundamental motion analysis tool is\nexhibited with downstream applications. The project page is\nhttps://foruck.github.io/ImDy/.\n","authors":["Xinpeng Liu","Junxuan Liang","Zili Lin","Haowen Hou","Yong-Lu Li","Cewu Lu"],"pdf_url":"https://arxiv.org/pdf/2410.17610v1.pdf","comment":"Yong-Lu Li and Cewu Lu are the corresponding authors"},{"id":"http://arxiv.org/abs/2406.14927v2","updated":"2024-10-23T07:01:34Z","published":"2024-06-21T07:37:17Z","title":"Gaussian-Informed Continuum for Physical Property Identification and\n  Simulation","summary":"  This paper studies the problem of estimating physical properties (system\nidentification) through visual observations. To facilitate geometry-aware\nguidance in physical property estimation, we introduce a novel hybrid framework\nthat leverages 3D Gaussian representation to not only capture explicit shapes\nbut also enable the simulated continuum to render object masks as 2D shape\nsurrogates during training.\n  We propose a new dynamic 3D Gaussian framework based on motion factorization\nto recover the object as 3D Gaussian point sets across different time states.\n  Furthermore, we develop a coarse-to-fine filling strategy to generate the\ndensity fields of the object from the Gaussian reconstruction, allowing for the\nextraction of object continuums along with their surfaces and the integration\nof Gaussian attributes into these continuums.\n  In addition to the extracted object surfaces, the Gaussian-informed continuum\nalso enables the rendering of object masks during simulations, serving as\n2D-shape guidance for physical property estimation.\n  Extensive experimental evaluations demonstrate that our pipeline achieves\nstate-of-the-art performance across multiple benchmarks and metrics.\nAdditionally, we illustrate the effectiveness of the proposed method through\nreal-world demonstrations, showcasing its practical utility.\n  Our project page is at https://jukgei.github.io/project/gic.\n","authors":["Junhao Cai","Yuji Yang","Weihao Yuan","Yisheng He","Zilong Dong","Liefeng Bo","Hui Cheng","Qifeng Chen"],"pdf_url":"https://arxiv.org/pdf/2406.14927v2.pdf","comment":"21 pages, 8 figures, NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.17602v1","updated":"2024-10-23T06:56:53Z","published":"2024-10-23T06:56:53Z","title":"Integrating Large Language Models for UAV Control in Simulated\n  Environments: A Modular Interaction Approach","summary":"  The intersection of LLMs (Large Language Models) and UAV (Unoccupied Aerial\nVehicles) technology represents a promising field of research with the\npotential to enhance UAV capabilities significantly. This study explores the\napplication of LLMs in UAV control, focusing on the opportunities for\nintegrating advanced natural language processing into autonomous aerial\nsystems. By enabling UAVs to interpret and respond to natural language\ncommands, LLMs simplify the UAV control and usage, making them accessible to a\nbroader user base and facilitating more intuitive human-machine interactions.\nThe paper discusses several key areas where LLMs can impact UAV technology,\nincluding autonomous decision-making, dynamic mission planning, enhanced\nsituational awareness, and improved safety protocols. Through a comprehensive\nreview of current developments and potential future directions, this study aims\nto highlight how LLMs can transform UAV operations, making them more adaptable,\nresponsive, and efficient in complex environments. A template development\nframework for integrating LLMs in UAV control is also described. Proof of\nConcept results that integrate existing LLM models and popular robotic\nsimulation platforms are demonstrated. The findings suggest that while there\nare substantial technical and ethical challenges to address, integrating LLMs\ninto UAV control holds promising implications for advancing autonomous aerial\nsystems.\n","authors":["Abhishek Phadke","Alihan Hadimlioglu","Tianxing Chu","Chandra N Sekharan"],"pdf_url":"https://arxiv.org/pdf/2410.17602v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17585v1","updated":"2024-10-23T06:19:53Z","published":"2024-10-23T06:19:53Z","title":"Energy-Optimal Planning of Waypoint-Based UAV Missions -- Does Minimum\n  Distance Mean Minimum Energy?","summary":"  Multirotor unmanned aerial vehicle is a prevailing type of aerial robots with\nwide real-world applications. The energy efficiency of the robot is a critical\naspect of its performance, determining the range and duration of the missions\nthat can be performed. This paper studies the energy-optimal planning of the\nmultirotor, which aims at finding the optimal ordering of waypoints with the\nminimum energy consumption for missions in 3D space. The study is performed\nbased on a previously developed model capturing first-principle energy dynamics\nof the multirotor. We found that in majority of the cases (up to 95%) the\nsolutions of the energy-optimal planning are different from those of the\ntraditional traveling salesman problem which minimizes the total distance. The\ndifference can be as high as 14.9%, with the average at 1.6%-3.3% and 90th\npercentile at 3.7%-6.5% depending on the range and number of waypoints in the\nmission. We then identified and explained the key features of the\nminimum-energy order by correlating to the underlying flight energy dynamics.\nIt is shown that instead of minimizing the distance, coordination of vertical\nand horizontal motion to promote aerodynamic efficiency is the key to\noptimizing energy consumption.\n","authors":["Nicolas Michel","Ayush Patnaik","Zhaodan Kong","Xinfan Lin"],"pdf_url":"https://arxiv.org/pdf/2410.17585v1.pdf","comment":"This paper has been accepted for presentation at the IEEE/RSJ\n  International Conference on Intelligent Robots and Systems (IROS) 2024"},{"id":"http://arxiv.org/abs/2410.17576v1","updated":"2024-10-23T05:59:55Z","published":"2024-10-23T05:59:55Z","title":"Real-time Vehicle-to-Vehicle Communication Based Network Cooperative\n  Control System through Distributed Database and Multimodal Perception:\n  Demonstrated in Crossroads","summary":"  The autonomous driving industry is rapidly advancing, with Vehicle-to-Vehicle\n(V2V) communication systems highlighting as a key component of enhanced road\nsafety and traffic efficiency. This paper introduces a novel Real-time\nVehicle-to-Vehicle Communication Based Network Cooperative Control System\n(VVCCS), designed to revolutionize macro-scope traffic planning and collision\navoidance in autonomous driving. Implemented on Quanser Car (Qcar) hardware\nplatform, our system integrates the distributed databases into individual\nautonomous vehicles and an optional central server. We also developed a\ncomprehensive multi-modal perception system with multi-objective tracking and\nradar sensing. Through a demonstration within a physical crossroad environment,\nour system showcases its potential to be applied in congested and complex urban\nenvironments.\n","authors":["Xinwen Zhu","Zihao Li","Yuxuan Jiang","Jiazhen Xu","Jie Wang","Xuyang Bai"],"pdf_url":"https://arxiv.org/pdf/2410.17576v1.pdf","comment":"ICICT 2024, 18 pages"},{"id":"http://arxiv.org/abs/2405.16194v3","updated":"2024-10-23T05:47:21Z","published":"2024-05-25T11:53:23Z","title":"Diffusion-Reward Adversarial Imitation Learning","summary":"  Imitation learning aims to learn a policy from observing expert\ndemonstrations without access to reward signals from environments. Generative\nadversarial imitation learning (GAIL) formulates imitation learning as\nadversarial learning, employing a generator policy learning to imitate expert\nbehaviors and discriminator learning to distinguish the expert demonstrations\nfrom agent trajectories. Despite its encouraging results, GAIL training is\noften brittle and unstable. Inspired by the recent dominance of diffusion\nmodels in generative modeling, we propose Diffusion-Reward Adversarial\nImitation Learning (DRAIL), which integrates a diffusion model into GAIL,\naiming to yield more robust and smoother rewards for policy learning.\nSpecifically, we propose a diffusion discriminative classifier to construct an\nenhanced discriminator, and design diffusion rewards based on the classifier's\noutput for policy learning. Extensive experiments are conducted in navigation,\nmanipulation, and locomotion, verifying DRAIL's effectiveness compared to prior\nimitation learning methods. Moreover, additional experimental results\ndemonstrate the generalizability and data efficiency of DRAIL. Visualized\nlearned reward functions of GAIL and DRAIL suggest that DRAIL can produce more\nrobust and smoother rewards. Project page:\nhttps://nturobotlearninglab.github.io/DRAIL/\n","authors":["Chun-Mao Lai","Hsiang-Chun Wang","Ping-Chun Hsieh","Yu-Chiang Frank Wang","Min-Hung Chen","Shao-Hua Sun"],"pdf_url":"https://arxiv.org/pdf/2405.16194v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15815v2","updated":"2024-10-23T05:32:34Z","published":"2024-07-22T17:29:02Z","title":"Learning to Manipulate Anywhere: A Visual Generalizable Framework For\n  Reinforcement Learning","summary":"  Can we endow visuomotor robots with generalization capabilities to operate in\ndiverse open-world scenarios? In this paper, we propose \\textbf{Maniwhere}, a\ngeneralizable framework tailored for visual reinforcement learning, enabling\nthe trained robot policies to generalize across a combination of multiple\nvisual disturbance types. Specifically, we introduce a multi-view\nrepresentation learning approach fused with Spatial Transformer Network (STN)\nmodule to capture shared semantic information and correspondences among\ndifferent viewpoints. In addition, we employ a curriculum-based randomization\nand augmentation approach to stabilize the RL training process and strengthen\nthe visual generalization ability. To exhibit the effectiveness of Maniwhere,\nwe meticulously design 8 tasks encompassing articulate objects, bi-manual, and\ndexterous hand manipulation tasks, demonstrating Maniwhere's strong visual\ngeneralization and sim2real transfer abilities across 3 hardware platforms. Our\nexperiments show that Maniwhere significantly outperforms existing\nstate-of-the-art methods. Videos are provided at\nhttps://gemcollector.github.io/maniwhere/.\n","authors":["Zhecheng Yuan","Tianming Wei","Shuiqi Cheng","Gu Zhang","Yuanpei Chen","Huazhe Xu"],"pdf_url":"https://arxiv.org/pdf/2407.15815v2.pdf","comment":"Webpage: https://gemcollector.github.io/maniwhere/"},{"id":"http://arxiv.org/abs/2309.12029v2","updated":"2024-10-23T04:36:26Z","published":"2023-09-21T12:51:11Z","title":"Exploring Self-Supervised Skeleton-Based Human Action Recognition under\n  Occlusions","summary":"  To integrate self-supervised skeleton-based action recognition methods into\nautonomous robotic systems, it is crucial to consider adverse situations\ninvolving target occlusions. Such a scenario, despite its practical relevance,\nis rarely addressed in existing self-supervised skeleton-based action\nrecognition methods. To empower models with the capacity to address occlusion,\nwe propose a simple and effective method. We first pre-train using occluded\nskeleton sequences, then use k-means clustering (KMeans) on sequence embeddings\nto group semantically similar samples. Next, we propose KNN-Imputation to fill\nin missing skeleton data based on the closest sample neighbors. Imputing\nincomplete skeleton sequences to create relatively complete sequences as input\nprovides significant benefits to existing skeleton-based self-supervised\nmethods. Meanwhile, building on the state-of-the-art Partial Spatio-Temporal\nLearning (PSTL), we introduce an Occluded Partial Spatio-Temporal Learning\n(OPSTL) framework. This enhancement utilizes Adaptive Spatial Masking (ASM) for\nbetter use of high-quality, intact skeletons. The new proposed method is\nverified on the challenging occluded versions of the NTURGB+D 60 and NTURGB+D\n120. The source code is publicly available at https://github.com/cyfml/OPSTL.\n","authors":["Yifei Chen","Kunyu Peng","Alina Roitberg","David Schneider","Jiaming Zhang","Junwei Zheng","Ruiping Liu","Yufan Chen","Kailun Yang","Rainer Stiefelhagen"],"pdf_url":"https://arxiv.org/pdf/2309.12029v2.pdf","comment":"The source code is publicly available at\n  https://github.com/cyfml/OPSTL"},{"id":"http://arxiv.org/abs/2410.17551v1","updated":"2024-10-23T04:32:37Z","published":"2024-10-23T04:32:37Z","title":"Multimodal Information Bottleneck for Deep Reinforcement Learning with\n  Multiple Sensors","summary":"  Reinforcement learning has achieved promising results on robotic control\ntasks but struggles to leverage information effectively from multiple sensory\nmodalities that differ in many characteristics. Recent works construct\nauxiliary losses based on reconstruction or mutual information to extract joint\nrepresentations from multiple sensory inputs to improve the sample efficiency\nand performance of reinforcement learning algorithms. However, the\nrepresentations learned by these methods could capture information irrelevant\nto learning a policy and may degrade the performance. We argue that compressing\ninformation in the learned joint representations about raw multimodal\nobservations is helpful, and propose a multimodal information bottleneck model\nto learn task-relevant joint representations from egocentric images and\nproprioception. Our model compresses and retains the predictive information in\nmultimodal observations for learning a compressed joint representation, which\nfuses complementary information from visual and proprioceptive feedback and\nmeanwhile filters out task-irrelevant information in raw multimodal\nobservations. We propose to minimize the upper bound of our multimodal\ninformation bottleneck objective for computationally tractable optimization.\nExperimental evaluations on several challenging locomotion tasks with\negocentric images and proprioception show that our method achieves better\nsample efficiency and zero-shot robustness to unseen white noise than leading\nbaselines. We also empirically demonstrate that leveraging information from\negocentric images and proprioception is more helpful for learning policies on\nlocomotion tasks than solely using one single modality.\n","authors":["Bang You","Huaping Liu"],"pdf_url":"https://arxiv.org/pdf/2410.17551v1.pdf","comment":"31 pages"},{"id":"http://arxiv.org/abs/2410.17547v1","updated":"2024-10-23T04:06:35Z","published":"2024-10-23T04:06:35Z","title":"Generalizable Motion Planning via Operator Learning","summary":"  In this work, we introduce a planning neural operator (PNO) for predicting\nthe value function of a motion planning problem. We recast value function\napproximation as learning a single operator from the cost function space to the\nvalue function space, which is defined by an Eikonal partial differential\nequation (PDE). Specifically, we recast computing value functions as learning a\nsingle operator across continuous function spaces which prove is equivalent to\nsolving an Eikonal PDE. Through this reformulation, our learned PNO is able to\ngeneralize to new motion planning problems without retraining. Therefore, our\nPNO model, despite being trained with a finite number of samples at coarse\nresolution, inherits the zero-shot super-resolution property of neural\noperators. We demonstrate accurate value function approximation at 16 times the\ntraining resolution on the MovingAI lab's 2D city dataset and compare with\nstate-of-the-art neural value function predictors on 3D scenes from the iGibson\nbuilding dataset. Lastly, we investigate employing the value function output of\nPNO as a heuristic function to accelerate motion planning. We show\ntheoretically that the PNO heuristic is $\\epsilon$-consistent by introducing an\ninductive bias layer that guarantees our value functions satisfy the triangle\ninequality. With our heuristic, we achieve a 30% decrease in nodes visited\nwhile obtaining near optimal path lengths on the MovingAI lab 2D city dataset,\ncompared to classical planning methods (A*, RRT*).\n","authors":["Sharath Matada","Luke Bhan","Yuanyuan Shi","Nikolay Atanasov"],"pdf_url":"https://arxiv.org/pdf/2410.17547v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.09988v3","updated":"2024-10-23T03:58:18Z","published":"2024-03-15T03:17:50Z","title":"Interactive Distance Field Mapping and Planning to Enable Human-Robot\n  Collaboration","summary":"  Human-robot collaborative applications require scene representations that are\nkept up-to-date and facilitate safe motions in dynamic scenes. In this letter,\nwe present an interactive distance field mapping and planning (IDMP) framework\nthat handles dynamic objects and collision avoidance through an efficient\nrepresentation. We define interactive mapping and planning as the process of\ncreating and updating the representation of the scene online while\nsimultaneously planning and adapting the robot's actions based on that\nrepresentation. The key aspect of this work is an efficient Gaussian Process\nfield that performs incremental updates and handles dynamic objects reliably by\nidentifying moving points via a simple and elegant formulation based on queries\nfrom a temporary latent model. In terms of mapping, IDMP is able to fuse point\ncloud data from single and multiple sensors, query the free space at any\nspatial resolution, and deal with moving objects without semantics. In terms of\nplanning, IDMP allows seamless integration with gradient-based reactive\nplanners facilitating dynamic obstacle avoidance for safe human-robot\ninteractions. Our mapping performance is evaluated on both real and synthetic\ndatasets. A comparison with similar state-of-the-art frameworks shows superior\nperformance when handling dynamic objects and comparable or better performance\nin the accuracy of the computed distance and gradient field. Finally, we show\nhow the framework can be used for fast motion planning in the presence of\nmoving objects both in simulated and real-world scenes. An accompanying video,\ncode, and datasets are made publicly available https://uts-ri.github.io/IDMP.\n","authors":["Usama Ali","Lan Wu","Adrian Mueller","Fouad Sukkar","Tobias Kaupp","Teresa Vidal-Calleja"],"pdf_url":"https://arxiv.org/pdf/2403.09988v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.05741v2","updated":"2024-10-23T03:39:00Z","published":"2024-02-08T15:19:50Z","title":"Real-World Robot Applications of Foundation Models: A Review","summary":"  Recent developments in foundation models, like Large Language Models (LLMs)\nand Vision-Language Models (VLMs), trained on extensive data, facilitate\nflexible application across different tasks and modalities. Their impact spans\nvarious fields, including healthcare, education, and robotics. This paper\nprovides an overview of the practical application of foundation models in\nreal-world robotics, with a primary emphasis on the replacement of specific\ncomponents within existing robot systems. The summary encompasses the\nperspective of input-output relationships in foundation models, as well as\ntheir role in perception, motion planning, and control within the field of\nrobotics. This paper concludes with a discussion of future challenges and\nimplications for practical robot applications.\n","authors":["Kento Kawaharazuka","Tatsuya Matsushima","Andrew Gambardella","Jiaxian Guo","Chris Paxton","Andy Zeng"],"pdf_url":"https://arxiv.org/pdf/2402.05741v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.09506v3","updated":"2024-10-23T03:34:29Z","published":"2022-06-19T23:30:18Z","title":"Log-GPIS-MOP: A Unified Representation for Mapping, Odometry and\n  Planning","summary":"  Whereas dedicated scene representations are required for each different task\nin conventional robotic systems, this paper demonstrates that a unified\nrepresentation can be used directly for multiple key tasks. We propose the\nLog-Gaussian Process Implicit Surface for Mapping, Odometry and Planning\n(Log-GPIS-MOP): a probabilistic framework for surface reconstruction,\nlocalisation and navigation based on a unified representation. Our framework\napplies a logarithmic transformation to a Gaussian Process Implicit Surface\n(GPIS) formulation to recover a global representation that accurately captures\nthe Euclidean distance field with gradients and, at the same time, the implicit\nsurface. By directly estimating the distance field and its gradient through\nLog-GPIS inference, the proposed incremental odometry technique computes the\noptimal alignment of an incoming frame and fuses it globally to produce a map.\nConcurrently, an optimisation-based planner computes a safe collision-free path\nusing the same Log-GPIS surface representation. We validate the proposed\nframework on simulated and real datasets in 2D and 3D and benchmark against the\nstate-of-the-art approaches. Our experiments show that Log-GPIS-MOP produces\ncompetitive results in sequential odometry, surface mapping and obstacle\navoidance.\n","authors":["Lan Wu","Ki Myung Brian Lee","Cedric Le Gentil","Teresa Vidal-Calleja"],"pdf_url":"https://arxiv.org/pdf/2206.09506v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15922v2","updated":"2024-10-23T03:22:48Z","published":"2024-09-24T09:45:20Z","title":"The Dark Side of Rich Rewards: Understanding and Mitigating Noise in VLM\n  Rewards","summary":"  While Vision-Language Models (VLMs) are increasingly used to generate reward\nsignals for training embodied agents to follow instructions, our research\nreveals that agents guided by VLM rewards often underperform compared to those\nemploying only intrinsic (exploration-driven) rewards, contradicting\nexpectations set by recent work. We hypothesize that false positive rewards --\ninstances where unintended trajectories are incorrectly rewarded -- are more\ndetrimental than false negatives. Our analysis confirms this hypothesis,\nrevealing that the widely used cosine similarity metric is prone to false\npositive reward estimates. To address this, we introduce BiMI ({Bi}nary\n{M}utual {I}nformation), a novel reward function designed to mitigate noise.\nBiMI significantly enhances learning efficiency across diverse and challenging\nembodied navigation environments. Our findings offer a nuanced understanding of\nhow different types of reward noise impact agent learning and highlight the\nimportance of addressing multimodal reward signal noise when training embodied\nagents\n","authors":["Sukai Huang","Nir Lipovetzky","Trevor Cohn"],"pdf_url":"https://arxiv.org/pdf/2409.15922v2.pdf","comment":"10 main body pages, 11 appendix pages"},{"id":"http://arxiv.org/abs/2410.17524v1","updated":"2024-10-23T03:01:43Z","published":"2024-10-23T03:01:43Z","title":"Mechanisms and Computational Design of Multi-Modal End-Effector with\n  Force Sensing using Gated Networks","summary":"  In limbed robotics, end-effectors must serve dual functions, such as both\nfeet for locomotion and grippers for grasping, which presents design\nchallenges. This paper introduces a multi-modal end-effector capable of\ntransitioning between flat and line foot configurations while providing\ngrasping capabilities. MAGPIE integrates 8-axis force sensing using proposed\nmechanisms with hall effect sensors, enabling both contact and tactile force\nmeasurements. We present a computational design framework for our sensing\nmechanism that accounts for noise and interference, allowing for desired\nsensitivity and force ranges and generating ideal inverse models. The hardware\nimplementation of MAGPIE is validated through experiments, demonstrating its\ncapability as a foot and verifying the performance of the sensing mechanisms,\nideal models, and gated network-based models.\n","authors":["Yusuke Tanaka","Alvin Zhu","Richard Lin","Ankur Mehta","Dennis Hong"],"pdf_url":"https://arxiv.org/pdf/2410.17524v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.09156v2","updated":"2024-10-23T02:56:07Z","published":"2022-11-16T19:08:05Z","title":"OA-MPC: Occlusion-Aware MPC for Guaranteed Safe Robot Navigation with\n  Unseen Dynamic Obstacles","summary":"  For safe navigation in dynamic uncertain environments, robotic systems rely\non the perception and prediction of other agents. Particularly, in occluded\nareas where cameras and LiDAR give no data, the robot must be able to reason\nabout potential movements of invisible dynamic agents. This work presents a\nprovably safe motion planning scheme for real-time navigation in an a priori\nunmapped environment, where occluded dynamic agents are present. Safety\nguarantees are provided based on reachability analysis. Forward reachable sets\nassociated with potential occluded agents, such as pedestrians, are computed\nand incorporated into planning. An iterative optimization-based planner is\npresented that alternates between two optimizations: nonlinear Model Predictive\nControl (NMPC) and collision avoidance. Recursive feasibility of the MPC is\nguaranteed by introducing a terminal stopping constraint. The effectiveness of\nthe proposed algorithm is demonstrated through simulation studies and hardware\nexperiments with a TurtleBot robot. A video of experimental results is\navailable at \\url{https://youtu.be/OUnkB5Feyuk}.\n","authors":["Roya Firoozi","Alexandre Mir","Gadi Sznaier Camps","Mac Schwager"],"pdf_url":"https://arxiv.org/pdf/2211.09156v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.06239v2","updated":"2024-10-23T02:20:52Z","published":"2024-10-08T17:54:11Z","title":"OrionNav: Online Planning for Robot Autonomy with Context-Aware LLM and\n  Open-Vocabulary Semantic Scene Graphs","summary":"  Enabling robots to autonomously navigate unknown, complex, dynamic\nenvironments and perform diverse tasks remains a fundamental challenge in\ndeveloping robust autonomous physical agents. These agents must effectively\nperceive their surroundings while leveraging world knowledge for\ndecision-making. Although recent approaches utilize vision-language and large\nlanguage models for scene understanding and planning, they often rely on\noffline processing, offboard compute, make simplifying assumptions about the\nenvironment and perception, limiting real-world applicability. We present a\nnovel framework for real-time onboard autonomous navigation in unknown\nenvironments that change over time by integrating multi-level abstraction in\nboth perception and planning pipelines. Our system fuses data from multiple\nonboard sensors for localization and mapping and integrates it with\nopen-vocabulary semantics to generate hierarchical scene graphs from\ncontinuously updated semantic object map. The LLM-based planner uses these\ngraphs to create multi-step plans that guide low-level controllers in executing\nnavigation tasks specified in natural language. The system's real-time\noperation enables the LLM to adjust its plans based on updates to the scene\ngraph and task execution status, ensuring continuous adaptation to new\nsituations or when the current plan cannot accomplish the task, a key advantage\nover static or rule-based systems. We demonstrate our system's efficacy on a\nquadruped navigating dynamic environments, showcasing its adaptability and\nrobustness in diverse scenarios.\n","authors":["Venkata Naren Devarakonda","Raktim Gautam Goswami","Ali Umut Kaypak","Naman Patel","Rooholla Khorrambakht","Prashanth Krishnamurthy","Farshad Khorrami"],"pdf_url":"https://arxiv.org/pdf/2410.06239v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17491v1","updated":"2024-10-23T01:11:29Z","published":"2024-10-23T01:11:29Z","title":"X-MOBILITY: End-To-End Generalizable Navigation via World Modeling","summary":"  General-purpose navigation in challenging environments remains a significant\nproblem in robotics, with current state-of-the-art approaches facing myriad\nlimitations. Classical approaches struggle with cluttered settings and require\nextensive tuning, while learning-based methods face difficulties generalizing\nto out-of-distribution environments. This paper introduces X-Mobility, an\nend-to-end generalizable navigation model that overcomes existing challenges by\nleveraging three key ideas. First, X-Mobility employs an auto-regressive world\nmodeling architecture with a latent state space to capture world dynamics.\nSecond, a diverse set of multi-head decoders enables the model to learn a rich\nstate representation that correlates strongly with effective navigation skills.\nThird, by decoupling world modeling from action policy, our architecture can\ntrain effectively on a variety of data sources, both with and without expert\npolicies: off-policy data allows the model to learn world dynamics, while\non-policy data with supervisory control enables optimal action policy learning.\nThrough extensive experiments, we demonstrate that X-Mobility not only\ngeneralizes effectively but also surpasses current state-of-the-art navigation\napproaches. Additionally, X-Mobility also achieves zero-shot Sim2Real\ntransferability and shows strong potential for cross-embodiment generalization.\n","authors":["Wei Liu","Huihua Zhao","Chenran Li","Joydeep Biswas","Billy Okal","Pulkit Goyal","Yan Chang","Soha Pouya"],"pdf_url":"https://arxiv.org/pdf/2410.17491v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17488v1","updated":"2024-10-23T00:51:47Z","published":"2024-10-23T00:51:47Z","title":"GenDP: 3D Semantic Fields for Category-Level Generalizable Diffusion\n  Policy","summary":"  Diffusion-based policies have shown remarkable capability in executing\ncomplex robotic manipulation tasks but lack explicit characterization of\ngeometry and semantics, which often limits their ability to generalize to\nunseen objects and layouts. To enhance the generalization capabilities of\nDiffusion Policy, we introduce a novel framework that incorporates explicit\nspatial and semantic information via 3D semantic fields. We generate 3D\ndescriptor fields from multi-view RGBD observations with large foundational\nvision models, then compare these descriptor fields against reference\ndescriptors to obtain semantic fields. The proposed method explicitly considers\ngeometry and semantics, enabling strong generalization capabilities in tasks\nrequiring category-level generalization, resolving geometric ambiguities, and\nattention to subtle geometric details. We evaluate our method across eight\ntasks involving articulated objects and instances with varying shapes and\ntextures from multiple object categories. Our method demonstrates its\neffectiveness by increasing Diffusion Policy's average success rate on unseen\ninstances from 20% to 93%. Additionally, we provide a detailed analysis and\nvisualization to interpret the sources of performance gain and explain how our\nmethod can generalize to novel instances.\n","authors":["Yixuan Wang","Guang Yin","Binghao Huang","Tarik Kelestemur","Jiuguang Wang","Yunzhu Li"],"pdf_url":"https://arxiv.org/pdf/2410.17488v1.pdf","comment":"Accepted to Conference on Robot Learning (CoRL 2024). Project Page:\n  https://robopil.github.io/GenDP/"},{"id":"http://arxiv.org/abs/2404.16986v3","updated":"2024-10-23T00:42:50Z","published":"2024-04-25T19:16:16Z","title":"Piecewise Stochastic Barrier Functions","summary":"  This paper presents a novel stochastic barrier function (SBF) framework for\nsafety analysis of stochastic systems based on piecewise (PW) functions. We\nfirst outline a general formulation of PW-SBFs. Then, we focus on PW-Constant\n(PWC) SBFs and show how their simplicity yields computational advantages for\ngeneral stochastic systems. Specifically, we prove that synthesis of PWC-SBFs\nreduces to a minimax optimization problem. Then, we introduce three efficient\nalgorithms to solve this problem, each offering distinct advantages and\ndisadvantages. The first algorithm is based on dual linear programming (LP),\nwhich provides an exact solution to the minimax optimization problem. The\nsecond is a more scalable algorithm based on iterative counter-example guided\nsynthesis, which involves solving two smaller LPs. The third algorithm solves\nthe minimax problem using gradient descent, which admits even better\nscalability. We provide an extensive evaluation of these methods on various\ncase studies, including neural network dynamic models, nonlinear switched\nsystems, and high-dimensional linear systems. Our benchmarks demonstrate that\nPWC-SBFs outperform state-of-the-art methods, namely sum-of-squares and neural\nbarrier functions, and can scale to eight dimensional systems.\n","authors":["Rayan Mazouz","Frederik Baymler Mathiesen","Luca Laurenti","Morteza Lahijanian"],"pdf_url":"https://arxiv.org/pdf/2404.16986v3.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2410.18084v1","updated":"2024-10-23T17:59:58Z","published":"2024-10-23T17:59:58Z","title":"DynamicCity: Large-Scale LiDAR Generation from Dynamic Scenes","summary":"  LiDAR scene generation has been developing rapidly recently. However,\nexisting methods primarily focus on generating static and single-frame scenes,\noverlooking the inherently dynamic nature of real-world driving environments.\nIn this work, we introduce DynamicCity, a novel 4D LiDAR generation framework\ncapable of generating large-scale, high-quality LiDAR scenes that capture the\ntemporal evolution of dynamic environments. DynamicCity mainly consists of two\nkey models. 1) A VAE model for learning HexPlane as the compact 4D\nrepresentation. Instead of using naive averaging operations, DynamicCity\nemploys a novel Projection Module to effectively compress 4D LiDAR features\ninto six 2D feature maps for HexPlane construction, which significantly\nenhances HexPlane fitting quality (up to 12.56 mIoU gain). Furthermore, we\nutilize an Expansion & Squeeze Strategy to reconstruct 3D feature volumes in\nparallel, which improves both network training efficiency and reconstruction\naccuracy than naively querying each 3D point (up to 7.05 mIoU gain, 2.06x\ntraining speedup, and 70.84% memory reduction). 2) A DiT-based diffusion model\nfor HexPlane generation. To make HexPlane feasible for DiT generation, a Padded\nRollout Operation is proposed to reorganize all six feature planes of the\nHexPlane as a squared 2D feature map. In particular, various conditions could\nbe introduced in the diffusion or sampling process, supporting versatile 4D\ngeneration applications, such as trajectory- and command-driven generation,\ninpainting, and layout-conditioned generation. Extensive experiments on the\nCarlaSC and Waymo datasets demonstrate that DynamicCity significantly\noutperforms existing state-of-the-art 4D LiDAR generation methods across\nmultiple metrics. The code will be released to facilitate future research.\n","authors":["Hengwei Bian","Lingdong Kong","Haozhe Xie","Liang Pan","Yu Qiao","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2410.18084v1.pdf","comment":"Preprint; 29 pages, 15 figures, 7 tables; Project Page at\n  https://dynamic-city.github.io/"},{"id":"http://arxiv.org/abs/2410.18083v1","updated":"2024-10-23T17:59:57Z","published":"2024-10-23T17:59:57Z","title":"FIPER: Generalizable Factorized Fields for Joint Image Compression and\n  Super-Resolution","summary":"  In this work, we propose a unified representation for Super-Resolution (SR)\nand Image Compression, termed **Factorized Fields**, motivated by the shared\nprinciples between these two tasks. Both SISR and Image Compression require\nrecovering and preserving fine image details--whether by enhancing resolution\nor reconstructing compressed data. Unlike previous methods that mainly focus on\nnetwork architecture, our proposed approach utilizes a basis-coefficient\ndecomposition to explicitly capture multi-scale visual features and structural\ncomponents in images, addressing the core challenges of both tasks. We first\nderive our SR model, which includes a Coefficient Backbone and Basis Swin\nTransformer for generalizable Factorized Fields. Then, to further unify these\ntwo tasks, we leverage the strong information-recovery capabilities of the\ntrained SR modules as priors in the compression pipeline, improving both\ncompression efficiency and detail reconstruction. Additionally, we introduce a\nmerged-basis compression branch that consolidates shared structures, further\noptimizing the compression process. Extensive experiments show that our unified\nrepresentation delivers state-of-the-art performance, achieving an average\nrelative improvement of 204.4% in PSNR over the baseline in Super-Resolution\n(SR) and 9.35% BD-rate reduction in Image Compression compared to the previous\nSOTA.\n","authors":["Yang-Che Sun","Cheng Yu Yeo","Ernie Chu","Jun-Cheng Chen","Yu-Lun Liu"],"pdf_url":"https://arxiv.org/pdf/2410.18083v1.pdf","comment":"Project page: https://jayisaking.github.io/FIPER/"},{"id":"http://arxiv.org/abs/2410.18079v1","updated":"2024-10-23T17:59:11Z","published":"2024-10-23T17:59:11Z","title":"FreeVS: Generative View Synthesis on Free Driving Trajectory","summary":"  Existing reconstruction-based novel view synthesis methods for driving scenes\nfocus on synthesizing camera views along the recorded trajectory of the ego\nvehicle. Their image rendering performance will severely degrade on viewpoints\nfalling out of the recorded trajectory, where camera rays are untrained. We\npropose FreeVS, a novel fully generative approach that can synthesize camera\nviews on free new trajectories in real driving scenes. To control the\ngeneration results to be 3D consistent with the real scenes and accurate in\nviewpoint pose, we propose the pseudo-image representation of view priors to\ncontrol the generation process. Viewpoint transformation simulation is applied\non pseudo-images to simulate camera movement in each direction. Once trained,\nFreeVS can be applied to any validation sequences without reconstruction\nprocess and synthesis views on novel trajectories. Moreover, we propose two new\nchallenging benchmarks tailored to driving scenes, which are novel camera\nsynthesis and novel trajectory synthesis, emphasizing the freedom of\nviewpoints. Given that no ground truth images are available on novel\ntrajectories, we also propose to evaluate the consistency of images synthesized\non novel trajectories with 3D perception models. Experiments on the Waymo Open\nDataset show that FreeVS has a strong image synthesis performance on both the\nrecorded trajectories and novel trajectories. Project Page:\nhttps://freevs24.github.io/\n","authors":["Qitai Wang","Lue Fan","Yuqi Wang","Yuntao Chen","Zhaoxiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.18079v1.pdf","comment":"Project Page: https://freevs24.github.io/"},{"id":"http://arxiv.org/abs/2410.18074v1","updated":"2024-10-23T17:56:33Z","published":"2024-10-23T17:56:33Z","title":"UnCLe: Unsupervised Continual Learning of Depth Completion","summary":"  We propose UnCLe, a standardized benchmark for Unsupervised Continual\nLearning of a multimodal depth estimation task: Depth completion aims to infer\na dense depth map from a pair of synchronized RGB image and sparse depth map.\nWe benchmark depth completion models under the practical scenario of\nunsupervised learning over continuous streams of data. Existing methods are\ntypically trained on a static, or stationary, dataset. However, when adapting\nto novel non-stationary distributions, they \"catastrophically forget\"\npreviously learned information. UnCLe simulates these non-stationary\ndistributions by adapting depth completion models to sequences of datasets\ncontaining diverse scenes captured from distinct domains using different visual\nand range sensors. We adopt representative methods from continual learning\nparadigms and translate them to enable unsupervised continual learning of depth\ncompletion. We benchmark these models for indoor and outdoor and investigate\nthe degree of catastrophic forgetting through standard quantitative metrics.\nFurthermore, we introduce model inversion quality as an additional measure of\nforgetting. We find that unsupervised continual learning of depth completion is\nan open problem, and we invite researchers to leverage UnCLe as a development\nplatform.\n","authors":["Suchisrit Gangopadhyay","Xien Chen","Michael Chu","Patrick Rim","Hyoungseob Park","Alex Wong"],"pdf_url":"https://arxiv.org/pdf/2410.18074v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.18072v1","updated":"2024-10-23T17:56:11Z","published":"2024-10-23T17:56:11Z","title":"WorldSimBench: Towards Video Generation Models as World Simulators","summary":"  Recent advancements in predictive models have demonstrated exceptional\ncapabilities in predicting the future state of objects and scenes. However, the\nlack of categorization based on inherent characteristics continues to hinder\nthe progress of predictive model development. Additionally, existing benchmarks\nare unable to effectively evaluate higher-capability, highly embodied\npredictive models from an embodied perspective. In this work, we classify the\nfunctionalities of predictive models into a hierarchy and take the first step\nin evaluating World Simulators by proposing a dual evaluation framework called\nWorldSimBench. WorldSimBench includes Explicit Perceptual Evaluation and\nImplicit Manipulative Evaluation, encompassing human preference assessments\nfrom the visual perspective and action-level evaluations in embodied tasks,\ncovering three representative embodied scenarios: Open-Ended Embodied\nEnvironment, Autonomous, Driving, and Robot Manipulation. In the Explicit\nPerceptual Evaluation, we introduce the HF-Embodied Dataset, a video assessment\ndataset based on fine-grained human feedback, which we use to train a Human\nPreference Evaluator that aligns with human perception and explicitly assesses\nthe visual fidelity of World Simulators. In the Implicit Manipulative\nEvaluation, we assess the video-action consistency of World Simulators by\nevaluating whether the generated situation-aware video can be accurately\ntranslated into the correct control signals in dynamic environments. Our\ncomprehensive evaluation offers key insights that can drive further innovation\nin video generation models, positioning World Simulators as a pivotal\nadvancement toward embodied artificial intelligence.\n","authors":["Yiran Qin","Zhelun Shi","Jiwen Yu","Xijun Wang","Enshen Zhou","Lijun Li","Zhenfei Yin","Xihui Liu","Lu Sheng","Jing Shao","Lei Bai","Wanli Ouyang","Ruimao Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.18072v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18071v1","updated":"2024-10-23T17:54:43Z","published":"2024-10-23T17:54:43Z","title":"TP-Eval: Tap Multimodal LLMs' Potential in Evaluation by Customizing\n  Prompts","summary":"  Recently, multimodal large language models (MLLMs) have received much\nattention for their impressive capabilities. The evaluation of MLLMs is\nbecoming critical to analyzing attributes of MLLMs and providing valuable\ninsights. However, current benchmarks overlook the problem of prompt\nsensitivity - minor prompt variations may lead to significant performance\nfluctuations. Thus, inappropriate prompts may obscure the models' capabilities,\nunderestimating the models' performance. Moreover, different models have\ndifferent preferences for different prompts, and thus, using the same prompt\nfor all models will cause evaluation bias. This paper analyzes this deficiency\nin existing benchmarks and further introduces a new evaluation framework named\nTP-Eval, which introduces a prompt customization method to reduce evaluation\nbiases and tap models' potential. TP-Eval will rewrite the original prompts to\ndifferent customized prompts for different models. In particular, we propose\nsome well-designed modules for prompt customization tailored to the scenario of\nMLLM evaluation. Extensive experiments demonstrate the effectiveness of our\napproach to uncovering models' capabilities, and TP-Eval should benefit the\ncommunity in developing more comprehensive and convincing MLLM evaluation\nbenchmarks.\n","authors":["Yuxuan Xie","Tianhua Li","Wenqi Shao","Kaipeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.18071v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.12568v2","updated":"2024-10-23T17:53:24Z","published":"2024-08-22T17:35:18Z","title":"Pruning By Explaining Revisited: Optimizing Attribution Methods to Prune\n  CNNs and Transformers","summary":"  To solve ever more complex problems, Deep Neural Networks are scaled to\nbillions of parameters, leading to huge computational costs. An effective\napproach to reduce computational requirements and increase efficiency is to\nprune unnecessary components of these often over-parameterized networks.\nPrevious work has shown that attribution methods from the field of eXplainable\nAI serve as effective means to extract and prune the least relevant network\ncomponents in a few-shot fashion. We extend the current state by proposing to\nexplicitly optimize hyperparameters of attribution methods for the task of\npruning, and further include transformer-based networks in our analysis. Our\napproach yields higher model compression rates of large transformer- and\nconvolutional architectures (VGG, ResNet, ViT) compared to previous works,\nwhile still attaining high performance on ImageNet classification tasks. Here,\nour experiments indicate that transformers have a higher degree of\nover-parameterization compared to convolutional neural networks. Code is\navailable at https://github.com/erfanhatefi/Pruning-by-eXplaining-in-PyTorch.\n","authors":["Sayed Mohammad Vakilzadeh Hatefi","Maximilian Dreyer","Reduan Achtibat","Thomas Wiegand","Wojciech Samek","Sebastian Lapuschkin"],"pdf_url":"https://arxiv.org/pdf/2408.12568v2.pdf","comment":"Accepted as a workshop paper at ECCV 2024, 26 pages (11 pages\n  manuscript, 3 pages references, 12 pages appendix)"},{"id":"http://arxiv.org/abs/2410.18065v1","updated":"2024-10-23T17:42:07Z","published":"2024-10-23T17:42:07Z","title":"SPIRE: Synergistic Planning, Imitation, and Reinforcement Learning for\n  Long-Horizon Manipulation","summary":"  Robot learning has proven to be a general and effective technique for\nprogramming manipulators. Imitation learning is able to teach robots solely\nfrom human demonstrations but is bottlenecked by the capabilities of the\ndemonstrations. Reinforcement learning uses exploration to discover better\nbehaviors; however, the space of possible improvements can be too large to\nstart from scratch. And for both techniques, the learning difficulty increases\nproportional to the length of the manipulation task. Accounting for this, we\npropose SPIRE, a system that first uses Task and Motion Planning (TAMP) to\ndecompose tasks into smaller learning subproblems and second combines imitation\nand reinforcement learning to maximize their strengths. We develop novel\nstrategies to train learning agents when deployed in the context of a planning\nsystem. We evaluate SPIRE on a suite of long-horizon and contact-rich robot\nmanipulation problems. We find that SPIRE outperforms prior approaches that\nintegrate imitation learning, reinforcement learning, and planning by 35% to\n50% in average task performance, is 6 times more data efficient in the number\nof human demonstrations needed to train proficient agents, and learns to\ncomplete tasks nearly twice as efficiently. View\nhttps://sites.google.com/view/spire-corl-2024 for more details.\n","authors":["Zihan Zhou","Animesh Garg","Dieter Fox","Caelan Garrett","Ajay Mandlekar"],"pdf_url":"https://arxiv.org/pdf/2410.18065v1.pdf","comment":"Conference on Robot Learning (CoRL) 2024"},{"id":"http://arxiv.org/abs/2410.18057v1","updated":"2024-10-23T17:30:50Z","published":"2024-10-23T17:30:50Z","title":"CLEAR: Character Unlearning in Textual and Visual Modalities","summary":"  Machine Unlearning (MU) is critical for enhancing privacy and security in\ndeep learning models, particularly in large multimodal language models (MLLMs),\nby removing specific private or hazardous information. While MU has made\nsignificant progress in textual and visual modalities, multimodal unlearning\n(MMU) remains significantly underexplored, partially due to the absence of a\nsuitable open-source benchmark. To address this, we introduce CLEAR, a new\nbenchmark designed to evaluate MMU methods. CLEAR contains 200 fictitious\nindividuals and 3,700 images linked with corresponding question-answer pairs,\nenabling a thorough evaluation across modalities. We assess 10 MU methods,\nadapting them for MMU, and highlight new challenges specific to multimodal\nforgetting. We also demonstrate that simple $\\ell_1$ regularization on LoRA\nweights significantly mitigates catastrophic forgetting, preserving model\nperformance on retained data. The dataset is available at\nhttps://huggingface.co/datasets/therem/CLEAR\n","authors":["Alexey Dontsov","Dmitrii Korzh","Alexey Zhavoronkin","Boris Mikheev","Denis Bobkov","Aibek Alanov","Oleg Y. Rogov","Ivan Oseledets","Elena Tutubalina"],"pdf_url":"https://arxiv.org/pdf/2410.18057v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18052v1","updated":"2024-10-23T17:26:22Z","published":"2024-10-23T17:26:22Z","title":"In-Pixel Foreground and Contrast Enhancement Circuits with Customizable\n  Mapping","summary":"  This paper presents an innovative in-pixel contrast enhancement circuit that\nperforms image processing directly within the pixel circuit. The circuit can be\ntuned for different modes of operation. In foreground enhancement mode, it\nsuppresses low-intensity background pixels to nearly zero, isolating the\nforeground for better object visibility. In contrast enhancement mode, it\nimproves overall image contrast. The contrast enhancement function is\ncustomizable both during the design phase and in real-time, allowing the\ncircuit to adapt to specific applications and varying lighting conditions. A\nmodel of the designed pixel circuit is developed and applied to a full pixel\narray, demonstrating significant improvements in image quality. Simulations\nperformed in HSPICE show a nearly 6x increase in Michelson Contrast Ratio (CR)\nin the foreground enhancement mode. The simulation results indicate its\npotential for real-time, adaptive contrast enhancement across various imaging\nenvironments.\n","authors":["Md Rahatul Islam Udoy","Md Mazharul Islam","Elijah Johnson","Ahmedullah Aziz"],"pdf_url":"https://arxiv.org/pdf/2410.18052v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18051v1","updated":"2024-10-23T17:25:26Z","published":"2024-10-23T17:25:26Z","title":"Real time anomalies detection on video","summary":"  Nowadays, many places use security cameras. Unfortunately, when an incident\noccurs, these technologies are used to show past events. So it can be\nconsidered as a deterrence tool than a detection tool. In this article, we will\npropose a deep learning approach trying to solve this problematic. This\napproach uses convolutional models (CNN) to extract relevant characteristics\nlinked to the video images, theses characteristics will form times series to be\nanalyzed by LSTM / GRU models.\n","authors":["Fabien Poirier"],"pdf_url":"https://arxiv.org/pdf/2410.18051v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18013v1","updated":"2024-10-23T16:42:56Z","published":"2024-10-23T16:42:56Z","title":"Scalable Ranked Preference Optimization for Text-to-Image Generation","summary":"  Direct Preference Optimization (DPO) has emerged as a powerful approach to\nalign text-to-image (T2I) models with human feedback. Unfortunately, successful\napplication of DPO to T2I models requires a huge amount of resources to collect\nand label large-scale datasets, e.g., millions of generated paired images\nannotated with human preferences. In addition, these human preference datasets\ncan get outdated quickly as the rapid improvements of T2I models lead to higher\nquality images. In this work, we investigate a scalable approach for collecting\nlarge-scale and fully synthetic datasets for DPO training. Specifically, the\npreferences for paired images are generated using a pre-trained reward\nfunction, eliminating the need for involving humans in the annotation process,\ngreatly improving the dataset collection efficiency. Moreover, we demonstrate\nthat such datasets allow averaging predictions across multiple models and\ncollecting ranked preferences as opposed to pairwise preferences. Furthermore,\nwe introduce RankDPO to enhance DPO-based methods using the ranking feedback.\nApplying RankDPO on SDXL and SD3-Medium models with our synthetically generated\npreference dataset ``Syn-Pic'' improves both prompt-following (on benchmarks\nlike T2I-Compbench, GenEval, and DPG-Bench) and visual quality (through user\nstudies). This pipeline presents a practical and scalable solution to develop\nbetter preference datasets to enhance the performance of text-to-image models.\n","authors":["Shyamgopal Karthik","Huseyin Coskun","Zeynep Akata","Sergey Tulyakov","Jian Ren","Anil Kag"],"pdf_url":"https://arxiv.org/pdf/2410.18013v1.pdf","comment":"Project Page: https://snap-research.github.io/RankDPO/"},{"id":"http://arxiv.org/abs/2409.04429v2","updated":"2024-10-23T16:42:06Z","published":"2024-09-06T17:49:56Z","title":"VILA-U: a Unified Foundation Model Integrating Visual Understanding and\n  Generation","summary":"  VILA-U is a Unified foundation model that integrates Video, Image, Language\nunderstanding and generation. Traditional visual language models (VLMs) use\nseparate modules for understanding and generating visual content, which can\nlead to misalignment and increased complexity. In contrast, VILA-U employs a\nsingle autoregressive next-token prediction framework for both tasks,\neliminating the need for additional components like diffusion models. This\napproach not only simplifies the model but also achieves near state-of-the-art\nperformance in visual language understanding and generation. The success of\nVILA-U is attributed to two main factors: the unified vision tower that aligns\ndiscrete visual tokens with textual inputs during pretraining, which enhances\nvisual perception, and autoregressive image generation can achieve similar\nquality as diffusion models with high-quality dataset. This allows VILA-U to\nperform comparably to more complex models using a fully token-based\nautoregressive framework.\n","authors":["Yecheng Wu","Zhuoyang Zhang","Junyu Chen","Haotian Tang","Dacheng Li","Yunhao Fang","Ligeng Zhu","Enze Xie","Hongxu Yin","Li Yi","Song Han","Yao Lu"],"pdf_url":"https://arxiv.org/pdf/2409.04429v2.pdf","comment":"Code: https://github.com/mit-han-lab/vila-u. The first two authors\n  contributed equally to this work"},{"id":"http://arxiv.org/abs/2403.05489v2","updated":"2024-10-23T16:39:15Z","published":"2024-03-08T17:54:38Z","title":"JointMotion: Joint Self-Supervision for Joint Motion Prediction","summary":"  We present JointMotion, a self-supervised pre-training method for joint\nmotion prediction in self-driving vehicles. Our method jointly optimizes a\nscene-level objective connecting motion and environments, and an instance-level\nobjective to refine learned representations. Scene-level representations are\nlearned via non-contrastive similarity learning of past motion sequences and\nenvironment context. At the instance level, we use masked autoencoding to\nrefine multimodal polyline representations. We complement this with an adaptive\npre-training decoder that enables JointMotion to generalize across different\nenvironment representations, fusion mechanisms, and dataset characteristics.\nNotably, our method reduces the joint final displacement error of Wayformer,\nHPTR, and Scene Transformer models by 3\\%, 8\\%, and 12\\%, respectively; and\nenables transfer learning between the Waymo Open Motion and the Argoverse 2\nMotion Forecasting datasets. Code: https://github.com/kit-mrt/future-motion\n","authors":["Royden Wagner","Omer Sahin Tas","Marvin Klemp","Carlos Fernandez"],"pdf_url":"https://arxiv.org/pdf/2403.05489v2.pdf","comment":"CoRL'24 camera-ready"},{"id":"http://arxiv.org/abs/2309.17327v2","updated":"2024-10-23T16:25:17Z","published":"2023-09-29T15:34:39Z","title":"Telling Stories for Common Sense Zero-Shot Action Recognition","summary":"  Video understanding has long suffered from reliance on large labeled\ndatasets, motivating research into zero-shot learning. Recent progress in\nlanguage modeling presents opportunities to advance zero-shot video analysis,\nbut constructing an effective semantic space relating action classes remains\nchallenging. We address this by introducing a novel dataset, Stories, which\ncontains rich textual descriptions for diverse action classes extracted from\nWikiHow articles. For each class, we extract multi-sentence narratives\ndetailing the necessary steps, scenes, objects, and verbs that characterize the\naction. This contextual data enables modeling of nuanced relationships between\nactions, paving the way for zero-shot transfer. We also propose an approach\nthat harnesses Stories to improve feature generation for training zero-shot\nclassification. Without any target dataset fine-tuning, our method achieves new\nstate-of-the-art on multiple benchmarks, improving top-1 accuracy by up to\n6.1%. We believe Stories provides a valuable resource that can catalyze\nprogress in zero-shot action recognition. The textual narratives forge\nconnections between seen and unseen classes, overcoming the bottleneck of\nlabeled data that has long impeded advancements in this exciting domain. The\ndata can be found here: https://github.com/kini5gowda/Stories .\n","authors":["Shreyank N Gowda","Laura Sevilla-Lara"],"pdf_url":"https://arxiv.org/pdf/2309.17327v2.pdf","comment":"Accepted in ACCV 2024!"},{"id":"http://arxiv.org/abs/2410.03189v2","updated":"2024-10-23T16:22:59Z","published":"2024-10-04T07:02:13Z","title":"Generalizable Prompt Tuning for Vision-Language Models","summary":"  Prompt tuning for vision-language models such as CLIP involves optimizing the\ntext prompts used to generate image-text pairs for specific downstream tasks.\nWhile hand-crafted or template-based prompts are generally applicable to a\nwider range of unseen classes, they tend to perform poorly in downstream tasks\n(i.e., seen classes). Learnable soft prompts, on the other hand, often perform\nwell in downstream tasks but lack generalizability. Additionally, prior\nresearch has predominantly concentrated on the textual modality, with very few\nstudies attempting to explore the prompt's generalization potential from the\nvisual modality. Keeping these limitations in mind, we investigate how to\nprompt tuning to obtain both a competitive downstream performance and\ngeneralization. The study shows that by treating soft and hand-crafted prompts\nas dual views of the textual modality, and maximizing their mutual information,\nwe can better ensemble task-specific and general semantic information.\nMoreover, to generate more expressive prompts, the study introduces a\nclass-wise augmentation from the visual modality, resulting in significant\nrobustness to a wider range of unseen classes. Extensive evaluations on several\nbenchmarks report that the proposed approach achieves competitive results in\nterms of both task-specific performance and general abilities.\n","authors":["Qian Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.03189v2.pdf","comment":"in progress"},{"id":"http://arxiv.org/abs/2410.17997v1","updated":"2024-10-23T16:12:03Z","published":"2024-10-23T16:12:03Z","title":"Characterization of the multiplicity of solutions for camera pose given\n  two vertically-aligned landmarks and accelerometer","summary":"  We consider the problem of recovering the position and orientation of a\ncamera equipped with an accelerometer from sensor images of two labeled\nlandmarks whose positions in a coordinate system aligned in a known way with\ngravity are known. This a variant on the much studied P$n$P problem of\nrecovering camera position and orientation from $n$ points without any\ngravitational data. It is proved that in three types of singular cases there\nare infinitely many solutions, in another type of case there is one, and in a\nfinal type of case there are two. A precise characterization of each type of\ncase. In particular, there is always a unique solution in the practically\ninteresting case where the two landmarks are at the same altitude and the\ncamera is at a different altitude. This case is studied by numerical simulation\nand an implementation on a consumer cellphone. It is also proved that if the\ntwo landmarks are unlabeled, then apart from the same singular cases, there are\nstill always one or two solutions.\n","authors":["Alexander R. Pruss"],"pdf_url":"https://arxiv.org/pdf/2410.17997v1.pdf","comment":"32 pages, 8 figures"},{"id":"http://arxiv.org/abs/2407.19553v2","updated":"2024-10-23T16:06:32Z","published":"2024-07-28T18:20:08Z","title":"Exploring the Adversarial Robustness of CLIP for AI-generated Image\n  Detection","summary":"  In recent years, many forensic detectors have been proposed to detect\nAI-generated images and prevent their use for malicious purposes. Convolutional\nneural networks (CNNs) have long been the dominant architecture in this field\nand have been the subject of intense study. However, recently proposed\nTransformer-based detectors have been shown to match or even outperform\nCNN-based detectors, especially in terms of generalization. In this paper, we\nstudy the adversarial robustness of AI-generated image detectors, focusing on\nContrastive Language-Image Pretraining (CLIP)-based methods that rely on Visual\nTransformer (ViT) backbones and comparing their performance with CNN-based\nmethods. We study the robustness to different adversarial attacks under a\nvariety of conditions and analyze both numerical results and frequency-domain\npatterns. CLIP-based detectors are found to be vulnerable to white-box attacks\njust like CNN-based detectors. However, attacks do not easily transfer between\nCNN-based and CLIP-based methods. This is also confirmed by the different\ndistribution of the adversarial noise patterns in the frequency domain.\nOverall, this analysis provides new insights into the properties of forensic\ndetectors that can help to develop more effective strategies.\n","authors":["Vincenzo De Rosa","Fabrizio Guillaro","Giovanni Poggi","Davide Cozzolino","Luisa Verdoliva"],"pdf_url":"https://arxiv.org/pdf/2407.19553v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17988v1","updated":"2024-10-23T16:01:31Z","published":"2024-10-23T16:01:31Z","title":"A Pipeline for Segmenting and Structuring RGB-D Data for Robotics\n  Applications","summary":"  We introduce a novel pipeline for segmenting and structuring color and depth\n(RGB-D) data. Existing processing pipelines for RGB-D data have focused on\nextracting geometric information alone. This approach precludes the development\nof more advanced robotic navigation and manipulation algorithms, which benefit\nfrom a semantic understanding of their environment. Our pipeline can segment\nRGB-D data into accurate semantic masks. These masks are then used to fuse raw\ncaptured point clouds into semantically separated point clouds. We store this\ninformation using the Universal Scene Description (USD) file format, a format\nsuitable for easy querying by downstream robotics algorithms, human-friendly\nvisualization, and robotics simulation.\n","authors":["Zhiwu Zheng","Lauren Mentzer","Berk Iskender","Michael Price","Colm Prendergast","Audren Cloitre"],"pdf_url":"https://arxiv.org/pdf/2410.17988v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17983v1","updated":"2024-10-23T15:51:33Z","published":"2024-10-23T15:51:33Z","title":"Robust Two-View Geometry Estimation with Implicit Differentiation","summary":"  We present a novel two-view geometry estimation framework which is based on a\ndifferentiable robust loss function fitting. We propose to treat the robust\nfundamental matrix estimation as an implicit layer, which allows us to avoid\nbackpropagation through time and significantly improves the numerical\nstability. To take full advantage of the information from the feature matching\nstage we incorporate learnable weights that depend on the matching confidences.\nIn this way our solution brings together feature extraction, matching and\ntwo-view geometry estimation in a unified end-to-end trainable pipeline. We\nevaluate our approach on the camera pose estimation task in both outdoor and\nindoor scenarios. The experiments on several datasets show that the proposed\nmethod outperforms both classic and learning-based state-of-the-art methods by\na large margin. The project webpage is available at:\nhttps://github.com/VladPyatov/ihls\n","authors":["Vladislav Pyatov","Iaroslav Koshelev","Stamatis Lefkimmiatis"],"pdf_url":"https://arxiv.org/pdf/2410.17983v1.pdf","comment":"IROS 2024 Accepted"},{"id":"http://arxiv.org/abs/2410.17966v1","updated":"2024-10-23T15:34:06Z","published":"2024-10-23T15:34:06Z","title":"A Wavelet Diffusion GAN for Image Super-Resolution","summary":"  In recent years, diffusion models have emerged as a superior alternative to\ngenerative adversarial networks (GANs) for high-fidelity image generation, with\nwide applications in text-to-image generation, image-to-image translation, and\nsuper-resolution. However, their real-time feasibility is hindered by slow\ntraining and inference speeds. This study addresses this challenge by proposing\na wavelet-based conditional Diffusion GAN scheme for Single-Image\nSuper-Resolution (SISR). Our approach utilizes the diffusion GAN paradigm to\nreduce the timesteps required by the reverse diffusion process and the Discrete\nWavelet Transform (DWT) to achieve dimensionality reduction, decreasing\ntraining and inference times significantly. The results of an experimental\nvalidation on the CelebA-HQ dataset confirm the effectiveness of our proposed\nscheme. Our approach outperforms other state-of-the-art methodologies\nsuccessfully ensuring high-fidelity output while overcoming inherent drawbacks\nassociated with diffusion models in time-sensitive applications.\n","authors":["Lorenzo Aloisi","Luigi Sigillo","Aurelio Uncini","Danilo Comminiello"],"pdf_url":"https://arxiv.org/pdf/2410.17966v1.pdf","comment":"The paper has been accepted at Italian Workshop on Neural Networks\n  (WIRN) 2024"},{"id":"http://arxiv.org/abs/2408.15205v2","updated":"2024-10-23T15:33:47Z","published":"2024-08-27T17:06:22Z","title":"Leveraging Hallucinations to Reduce Manual Prompt Dependency in\n  Promptable Segmentation","summary":"  Promptable segmentation typically requires instance-specific manual prompts\nto guide the segmentation of each desired object. To minimize such a need,\ntask-generic promptable segmentation has been introduced, which employs a\nsingle task-generic prompt to segment various images of different objects in\nthe same task. Current methods use Multimodal Large Language Models (MLLMs) to\nreason detailed instance-specific prompts from a task-generic prompt for\nimproving segmentation accuracy. The effectiveness of this segmentation heavily\ndepends on the precision of these derived prompts. However, MLLMs often suffer\nhallucinations during reasoning, resulting in inaccurate prompting. While\nexisting methods focus on eliminating hallucinations to improve a model, we\nargue that MLLM hallucinations can reveal valuable contextual insights when\nleveraged correctly, as they represent pre-trained large-scale knowledge beyond\nindividual images. In this paper, we utilize hallucinations to mine\ntask-related information from images and verify its accuracy for enhancing\nprecision of the generated prompts. Specifically, we introduce an iterative\nPrompt-Mask Cycle generation framework (ProMaC) with a prompt generator and a\nmask generator.The prompt generator uses a multi-scale chain of thought\nprompting, initially exploring hallucinations for extracting extended\ncontextual knowledge on a test image.These hallucinations are then reduced to\nformulate precise instance-specific prompts, directing the mask generator to\nproduce masks that are consistent with task semantics by mask semantic\nalignment. The generated masks iteratively induce the prompt generator to focus\nmore on task-relevant image areas and reduce irrelevant hallucinations,\nresulting jointly in better prompts and masks. Experiments on 5 benchmarks\ndemonstrate the effectiveness of ProMaC. Code given in\nhttps://lwpyh.github.io/ProMaC/.\n","authors":["Jian Hu","Jiayi Lin","Junchi Yan","Shaogang Gong"],"pdf_url":"https://arxiv.org/pdf/2408.15205v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.17959v1","updated":"2024-10-23T15:28:25Z","published":"2024-10-23T15:28:25Z","title":"Medical Imaging Complexity and its Effects on GAN Performance","summary":"  The proliferation of machine learning models in diverse clinical applications\nhas led to a growing need for high-fidelity, medical image training data. Such\ndata is often scarce due to cost constraints and privacy concerns. Alleviating\nthis burden, medical image synthesis via generative adversarial networks (GANs)\nemerged as a powerful method for synthetically generating photo-realistic\nimages based on existing sets of real medical images. However, the exact image\nset size required to efficiently train such a GAN is unclear. In this work, we\nexperimentally establish benchmarks that measure the relationship between a\nsample dataset size and the fidelity of the generated images, given the\ndataset's distribution of image complexities. We analyze statistical metrics\nbased on delentropy, an image complexity measure rooted in Shannon's entropy in\ninformation theory. For our pipeline, we conduct experiments with two\nstate-of-the-art GANs, StyleGAN 3 and SPADE-GAN, trained on multiple medical\nimaging datasets with variable sample sizes. Across both GANs, general\nperformance improved with increasing training set size but suffered with\nincreasing complexity.\n","authors":["William Cagas","Chan Ko","Blake Hsiao","Shryuk Grandhi","Rishi Bhattacharya","Kevin Zhu","Michael Lam"],"pdf_url":"https://arxiv.org/pdf/2410.17959v1.pdf","comment":"Accepted to ACCV, Workshop on Generative AI for Synthetic Medical\n  Data"},{"id":"http://arxiv.org/abs/2410.12018v2","updated":"2024-10-23T15:21:54Z","published":"2024-10-15T19:33:57Z","title":"LocoMotion: Learning Motion-Focused Video-Language Representations","summary":"  This paper strives for motion-focused video-language representations.\nExisting methods to learn video-language representations use spatial-focused\ndata, where identifying the objects and scene is often enough to distinguish\nthe relevant caption. We instead propose LocoMotion to learn from\nmotion-focused captions that describe the movement and temporal progression of\nlocal object motions. We achieve this by adding synthetic motions to videos and\nusing the parameters of these motions to generate corresponding captions.\nFurthermore, we propose verb-variation paraphrasing to increase the caption\nvariety and learn the link between primitive motions and high-level verbs. With\nthis, we are able to learn a motion-focused video-language representation.\nExperiments demonstrate our approach is effective for a variety of downstream\ntasks, particularly when limited data is available for fine-tuning. Code is\navailable: https://hazeldoughty.github.io/Papers/LocoMotion/\n","authors":["Hazel Doughty","Fida Mohammad Thoker","Cees G. M. Snoek"],"pdf_url":"https://arxiv.org/pdf/2410.12018v2.pdf","comment":"ACCV 2024 Oral"},{"id":"http://arxiv.org/abs/2406.14856v2","updated":"2024-10-23T15:08:59Z","published":"2024-06-21T04:02:19Z","title":"Accessible, At-Home Detection of Parkinson's Disease via Multi-task\n  Video Analysis","summary":"  Limited accessibility to neurological care leads to underdiagnosed\nParkinson's Disease (PD), preventing early intervention. Existing AI-based PD\ndetection methods primarily focus on unimodal analysis of motor or speech\ntasks, overlooking the multifaceted nature of the disease. To address this, we\nintroduce a large-scale, multi-task video dataset consisting of 1102 sessions\n(each containing videos of finger tapping, facial expression, and speech tasks\ncaptured via webcam) from 845 participants (272 with PD). We propose a novel\nUncertainty-calibrated Fusion Network (UFNet) that leverages this multimodal\ndata to enhance diagnostic accuracy. UFNet employs independent task-specific\nnetworks, trained with Monte Carlo Dropout for uncertainty quantification,\nfollowed by self-attended fusion of features, with attention weights\ndynamically adjusted based on task-specific uncertainties. To ensure\npatient-centered evaluation, the participants were randomly split into three\nsets: 60% for training, 20% for model selection, and 20% for final performance\nevaluation. UFNet significantly outperformed single-task models in terms of\naccuracy, area under the ROC curve (AUROC), and sensitivity while maintaining\nnon-inferior specificity. Withholding uncertain predictions further boosted the\nperformance, achieving 88.0+-0.3%$ accuracy, 93.0+-0.2% AUROC, 79.3+-0.9%\nsensitivity, and 92.6+-0.3% specificity, at the expense of not being able to\npredict for 2.3+-0.3% data (+- denotes 95% confidence interval). Further\nanalysis suggests that the trained model does not exhibit any detectable bias\nacross sex and ethnic subgroups and is most effective for individuals aged\nbetween 50 and 80. Requiring only a webcam and microphone, our approach\nfacilitates accessible home-based PD screening, especially in regions with\nlimited healthcare resources.\n","authors":["Md Saiful Islam","Tariq Adnan","Jan Freyberg","Sangwu Lee","Abdelrahman Abdelkader","Meghan Pawlik","Cathe Schwartz","Karen Jaffe","Ruth B. Schneider","E Ray Dorsey","Ehsan Hoque"],"pdf_url":"https://arxiv.org/pdf/2406.14856v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17932v1","updated":"2024-10-23T14:54:48Z","published":"2024-10-23T14:54:48Z","title":"VR-Splatting: Foveated Radiance Field Rendering via 3D Gaussian\n  Splatting and Neural Points","summary":"  Recent advances in novel view synthesis (NVS), particularly neural radiance\nfields (NeRF) and Gaussian splatting (3DGS), have demonstrated impressive\nresults in photorealistic scene rendering. These techniques hold great\npotential for applications in virtual tourism and teleportation, where\nimmersive realism is crucial. However, the high-performance demands of virtual\nreality (VR) systems present challenges in directly utilizing even such\nfast-to-render scene representations like 3DGS due to latency and computational\nconstraints.\n  In this paper, we propose foveated rendering as a promising solution to these\nobstacles. We analyze state-of-the-art NVS methods with respect to their\nrendering performance and compatibility with the human visual system. Our\napproach introduces a novel foveated rendering approach for Virtual Reality,\nthat leverages the sharp, detailed output of neural point rendering for the\nfoveal region, fused with a smooth rendering of 3DGS for the peripheral vision.\n  Our evaluation confirms that perceived sharpness and detail-richness are\nincreased by our approach compared to a standard VR-ready 3DGS configuration.\nOur system meets the necessary performance requirements for real-time VR\ninteractions, ultimately enhancing the user's immersive experience.\n  Project page: https://lfranke.github.io/vr_splatting\n","authors":["Linus Franke","Laura Fink","Marc Stamminger"],"pdf_url":"https://arxiv.org/pdf/2410.17932v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02240v4","updated":"2024-10-23T14:53:38Z","published":"2024-10-03T06:25:53Z","title":"SCA: Highly Efficient Semantic-Consistent Unrestricted Adversarial\n  Attack","summary":"  Deep neural network based systems deployed in sensitive environments are\nvulnerable to adversarial attacks. Unrestricted adversarial attacks typically\nmanipulate the semantic content of an image (e.g., color or texture) to create\nadversarial examples that are both effective and photorealistic. Recent works\nhave utilized the diffusion inversion process to map images into a latent\nspace, where high-level semantics are manipulated by introducing perturbations.\nHowever, they often results in substantial semantic distortions in the denoised\noutput and suffers from low efficiency. In this study, we propose a novel\nframework called Semantic-Consistent Unrestricted Adversarial Attacks (SCA),\nwhich employs an inversion method to extract edit-friendly noise maps and\nutilizes Multimodal Large Language Model (MLLM) to provide semantic guidance\nthroughout the process. Under the condition of rich semantic information\nprovided by MLLM, we perform the DDPM denoising process of each step using a\nseries of edit-friendly noise maps, and leverage DPM Solver++ to accelerate\nthis process, enabling efficient sampling with semantic consistency. Compared\nto existing methods, our framework enables the efficient generation of\nadversarial examples that exhibit minimal discernible semantic changes.\nConsequently, we for the first time introduce Semantic-Consistent Adversarial\nExamples (SCAE). Extensive experiments and visualizations have demonstrated the\nhigh efficiency of SCA, particularly in being on average 12 times faster than\nthe state-of-the-art attacks. Our research can further draw attention to the\nsecurity of multimedia information.\n","authors":["Zihao Pan","Weibin Wu","Yuhang Cao","Zibin Zheng"],"pdf_url":"https://arxiv.org/pdf/2410.02240v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.08401v3","updated":"2024-10-23T14:48:44Z","published":"2024-04-12T11:15:15Z","title":"PnLCalib: Sports Field Registration via Points and Lines Optimization","summary":"  Camera calibration in broadcast sports videos presents numerous challenges\nfor accurate sports field registration due to multiple camera angles, varying\ncamera parameters, and frequent occlusions of the field. Traditional\nsearch-based methods depend on initial camera pose estimates, which can\nstruggle in non-standard positions and dynamic environments. In response, we\npropose an optimization-based calibration pipeline that leverages a 3D soccer\nfield model and a predefined set of keypoints to overcome these limitations.\nOur method also introduces a novel refinement module that improves initial\ncalibration by using detected field lines in a non-linear optimization process.\nThis approach outperforms existing techniques in both multi-view and\nsingle-view 3D camera calibration tasks, while maintaining competitive\nperformance in homography estimation. Extensive experimentation on real-world\nsoccer datasets, including SoccerNet-Calibration, WorldCup 2014, and\nTS-WorldCup, highlights the robustness and accuracy of our method across\ndiverse broadcast scenarios. Our approach offers significant improvements in\ncamera calibration precision and reliability.\n","authors":["Marc Gutiérrez-Pérez","Antonio Agudo"],"pdf_url":"https://arxiv.org/pdf/2404.08401v3.pdf","comment":"Extended version of \"No Bells, Just Whistles: Sports Field\n  Registration Leveraging Geometric Properties\""},{"id":"http://arxiv.org/abs/2312.05349v3","updated":"2024-10-23T14:47:10Z","published":"2023-12-08T20:12:26Z","title":"PixLore: A Dataset-driven Approach to Rich Image Captioning","summary":"  In the domain of vision-language integration, generating detailed image\ncaptions poses a significant challenge due to the lack of curated and rich\ndatasets. This study introduces PixLore, a novel method that leverages Querying\nTransformers through the fine-tuning of the BLIP-2 model using the LoRa method\non a standard commercial GPU. The followed approach, which involves training on\na carefully assembled dataset from state-of-the-art Computer Vision models\ncombined and augmented by ChatGPT, addresses the question of whether intricate\nimage understanding can be achieved with an ensemble of smaller-scale models,\nreferred to as Knowledge Stitching. Comparative evaluations against major\nmodels such as GPT-4 and Google Bard demonstrate that PixLore-2.7B, despite\nhaving considerably fewer parameters, is rated higher than the existing\nState-of-the-Art models in over half of the assessments. Precisely, PixLore\noutperform Bard and BLIP-2, which score approximately 35.18% and 27.98% lower\nthan PixLore in the task of image captioning. This research not only presents a\ngroundbreaking approach but also highlights the importance of well-curated\ndatasets in enhancing the performance of smaller models.\n","authors":["Diego Bonilla-Salvador","Marcelino Martínez-Sober","Joan Vila-Francés","Antonio José Serrano-López","Pablo Rodríguez-Belenguer","Fernando Mateo"],"pdf_url":"https://arxiv.org/pdf/2312.05349v3.pdf","comment":"Paper in preprint pending of publication"},{"id":"http://arxiv.org/abs/2402.17307v2","updated":"2024-10-23T14:42:07Z","published":"2024-02-27T08:31:39Z","title":"Denoising Diffusion Models for Inpainting of Healthy Brain Tissue","summary":"  This paper is a contribution to the \"BraTS 2023 Local Synthesis of Healthy\nBrain Tissue via Inpainting Challenge\". The task of this challenge is to\ntransform tumor tissue into healthy tissue in brain magnetic resonance (MR)\nimages. This idea originates from the problem that MR images can be evaluated\nusing automatic processing tools, however, many of these tools are optimized\nfor the analysis of healthy tissue. By solving the given inpainting task, we\nenable the automatic analysis of images featuring lesions, and further\ndownstream tasks. Our approach builds on denoising diffusion probabilistic\nmodels. We use a 2D model that is trained using slices in which healthy tissue\nwas cropped out and is learned to be inpainted again. This allows us to use the\nground truth healthy tissue during training. In the sampling stage, we replace\nthe slices containing diseased tissue in the original 3D volume with the slices\ncontaining the healthy tissue inpainting. With our approach, we achieve\ncomparable results to the competing methods. On the validation set our model\nachieves a mean SSIM of 0.7804, a PSNR of 20.3525 and a MSE of 0.0113. In\nfuture we plan to extend our 2D model to a 3D model, allowing to inpaint the\nregion of interest as a whole without losing context information of neighboring\nslices.\n","authors":["Alicia Durrer","Philippe C. Cattin","Julia Wolleb"],"pdf_url":"https://arxiv.org/pdf/2402.17307v2.pdf","comment":"12 pages, 5 figures, MICCAI challenge submission"},{"id":"http://arxiv.org/abs/2410.17920v1","updated":"2024-10-23T14:38:57Z","published":"2024-10-23T14:38:57Z","title":"Gaze-Assisted Medical Image Segmentation","summary":"  The annotation of patient organs is a crucial part of various diagnostic and\ntreatment procedures, such as radiotherapy planning. Manual annotation is\nextremely time-consuming, while its automation using modern image analysis\ntechniques has not yet reached levels sufficient for clinical adoption. This\npaper investigates the idea of semi-supervised medical image segmentation using\nhuman gaze as interactive input for segmentation correction. In particular, we\nfine-tuned the Segment Anything Model in Medical Images (MedSAM), a public\nsolution that uses various prompt types as additional input for semi-automated\nsegmentation correction. We used human gaze data from reading abdominal images\nas a prompt for fine-tuning MedSAM. The model was validated on a public WORD\ndatabase, which consists of 120 CT scans of 16 abdominal organs. The results of\nthe gaze-assisted MedSAM were shown to be superior to the results of the\nstate-of-the-art segmentation models. In particular, the average Dice\ncoefficient for 16 abdominal organs was 85.8%, 86.7%, 81.7%, and 90.5% for\nnnUNetV2, ResUNet, original MedSAM, and our gaze-assisted MedSAM model,\nrespectively.\n","authors":["Leila Khaertdinova","Ilya Pershin","Tatiana Shmykova","Bulat Ibragimov"],"pdf_url":"https://arxiv.org/pdf/2410.17920v1.pdf","comment":"16 pages, 4 figures, Accepted to AIM-FM Workshop @ NeurIPS'24"},{"id":"http://arxiv.org/abs/2410.17918v1","updated":"2024-10-23T14:34:39Z","published":"2024-10-23T14:34:39Z","title":"Addressing Asynchronicity in Clinical Multimodal Fusion via\n  Individualized Chest X-ray Generation","summary":"  Integrating multi-modal clinical data, such as electronic health records\n(EHR) and chest X-ray images (CXR), is particularly beneficial for clinical\nprediction tasks. However, in a temporal setting, multi-modal data are often\ninherently asynchronous. EHR can be continuously collected but CXR is generally\ntaken with a much longer interval due to its high cost and radiation dose. When\nclinical prediction is needed, the last available CXR image might have been\noutdated, leading to suboptimal predictions. To address this challenge, we\npropose DDL-CXR, a method that dynamically generates an up-to-date latent\nrepresentation of the individualized CXR images. Our approach leverages latent\ndiffusion models for patient-specific generation strategically conditioned on a\nprevious CXR image and EHR time series, providing information regarding\nanatomical structures and disease progressions, respectively. In this way, the\ninteraction across modalities could be better captured by the latent CXR\ngeneration process, ultimately improving the prediction performance.\nExperiments using MIMIC datasets show that the proposed model could effectively\naddress asynchronicity in multimodal fusion and consistently outperform\nexisting methods.\n","authors":["Wenfang Yao","Chen Liu","Kejing Yin","William K. Cheung","Jing Qin"],"pdf_url":"https://arxiv.org/pdf/2410.17918v1.pdf","comment":"Accepted by NeurIPS-24"},{"id":"http://arxiv.org/abs/2403.08511v3","updated":"2024-10-23T14:21:40Z","published":"2024-03-13T13:16:26Z","title":"A Multimodal Fusion Network For Student Emotion Recognition Based on\n  Transformer and Tensor Product","summary":"  This paper introduces a new multi-modal model based on the Transformer\narchitecture and tensor product fusion strategy, combining BERT's text vectors\nand ViT's image vectors to classify students' psychological conditions, with an\naccuracy of 93.65%. The purpose of the study is to accurately analyze the\nmental health status of students from various data sources. This paper\ndiscusses modal fusion methods, including early, late and intermediate fusion,\nto overcome the challenges of integrating multi-modal information. Ablation\nstudies compare the performance of different models and fusion techniques,\nshowing that the proposed model outperforms existing methods such as CLIP and\nViLBERT in terms of accuracy and inference speed. Conclusions indicate that\nwhile this model has significant advantages in emotion recognition, its\npotential to incorporate other data modalities provides areas for future\nresearch.\n","authors":["Ao Xiang","Zongqing Qi","Han Wang","Qin Yang","Danqing Ma"],"pdf_url":"https://arxiv.org/pdf/2403.08511v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19472v2","updated":"2024-10-23T14:02:12Z","published":"2024-09-28T22:41:49Z","title":"Towards Croppable Implicit Neural Representations","summary":"  Implicit Neural Representations (INRs) have peaked interest in recent years\ndue to their ability to encode natural signals using neural networks. While\nINRs allow for useful applications such as interpolating new coordinates and\nsignal compression, their black-box nature makes it difficult to modify them\npost-training. In this paper we explore the idea of editable INRs, and\nspecifically focus on the widely used cropping operation. To this end, we\npresent Local-Global SIRENs -- a novel INR architecture that supports cropping\nby design. Local-Global SIRENs are based on combining local and global feature\nextraction for signal encoding. What makes their design unique is the ability\nto effortlessly remove specific portions of an encoded signal, with a\nproportional weight decrease. This is achieved by eliminating the corresponding\nweights from the network, without the need for retraining. We further show how\nthis architecture can be used to support the straightforward extension of\npreviously encoded signals. Beyond signal editing, we examine how the\nLocal-Global approach can accelerate training, enhance encoding of various\nsignals, improve downstream performance, and be applied to modern INRs such as\nINCODE, highlighting its potential and flexibility. Code is available at\nhttps://github.com/maorash/Local-Global-INRs.\n","authors":["Maor Ashkenazi","Eran Treister"],"pdf_url":"https://arxiv.org/pdf/2409.19472v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2408.06927v2","updated":"2024-10-23T14:01:27Z","published":"2024-08-13T14:29:00Z","title":"Breaking Class Barriers: Efficient Dataset Distillation via Inter-Class\n  Feature Compensator","summary":"  Dataset distillation has emerged as a technique aiming to condense\ninformative features from large, natural datasets into a compact and synthetic\nform. While recent advancements have refined this technique, its performance is\nbottlenecked by the prevailing class-specific synthesis paradigm. Under this\nparadigm, synthetic data is optimized exclusively for a pre-assigned one-hot\nlabel, creating an implicit class barrier in feature condensation. This leads\nto inefficient utilization of the distillation budget and oversight of\ninter-class feature distributions, which ultimately limits the effectiveness\nand efficiency, as demonstrated in our analysis. To overcome these constraints,\nthis paper presents the Inter-class Feature Compensator (INFER), an innovative\ndistillation approach that transcends the class-specific data-label framework\nwidely utilized in current dataset distillation methods. Specifically, INFER\nleverages a Universal Feature Compensator (UFC) to enhance feature integration\nacross classes, enabling the generation of multiple additional synthetic\ninstances from a single UFC input. This significantly improves the efficiency\nof the distillation budget. Moreover, INFER enriches inter-class interactions\nduring the distillation, thereby enhancing the effectiveness and\ngeneralizability of the distilled data. By allowing for the linear\ninterpolation of labels similar to those in the original dataset, INFER\nmeticulously optimizes the synthetic data and dramatically reduces the size of\nsoft labels in the synthetic dataset to almost zero, establishing a new\nbenchmark for efficiency and effectiveness in dataset distillation.\n","authors":["Xin Zhang","Jiawei Du","Ping Liu","Joey Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.06927v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17885v1","updated":"2024-10-23T13:58:39Z","published":"2024-10-23T13:58:39Z","title":"R-CoT: Reverse Chain-of-Thought Problem Generation for Geometric\n  Reasoning in Large Multimodal Models","summary":"  Existing Large Multimodal Models (LMMs) struggle with mathematical geometric\nreasoning due to a lack of high-quality image-text paired data. Current\ngeometric data generation approaches, which apply preset templates to generate\ngeometric data or use Large Language Models (LLMs) to rephrase questions and\nanswers (Q&A), unavoidably limit data accuracy and diversity. To synthesize\nhigher-quality data, we propose a two-stage Reverse Chain-of-Thought (R-CoT)\ngeometry problem generation pipeline. First, we introduce GeoChain to produce\nhigh-fidelity geometric images and corresponding descriptions highlighting\nrelations among geometric elements. We then design a Reverse A&Q method that\nreasons step-by-step based on the descriptions and generates questions in\nreverse from the reasoning results. Experiments demonstrate that the proposed\nmethod brings significant and consistent improvements on multiple LMM\nbaselines, achieving new performance records in the 2B, 7B, and 8B settings.\nNotably, R-CoT-8B significantly outperforms previous state-of-the-art\nopen-source mathematical models by 16.6% on MathVista and 9.2% on GeoQA, while\nalso surpassing the closed-source model GPT-4o by an average of 13% across both\ndatasets. The code is available at https://github.com/dle666/R-CoT.\n","authors":["Linger Deng","Yuliang Liu","Bohan Li","Dongliang Luo","Liang Wu","Chengquan Zhang","Pengyuan Lyu","Ziyang Zhang","Gang Zhang","Errui Ding","Yingying Zhu","Xiang Bai"],"pdf_url":"https://arxiv.org/pdf/2410.17885v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17880v1","updated":"2024-10-23T13:52:22Z","published":"2024-10-23T13:52:22Z","title":"A utility-based spatial analysis of residential street-level conditions;\n  A case study of Rotterdam","summary":"  Residential location choices are traditionally modelled using factors related\nto accessibility and socioeconomic environments, neglecting the importance of\nlocal street-level conditions. Arguably, this neglect is due to data practices.\nToday, however, street-level images -- which are highly effective at encoding\nstreet-level conditions -- are widely available. Additionally, recent advances\nin discrete choice models incorporating computer vision capabilities offer\nopportunities to integrate street-level conditions into residential location\nchoice analysis. This study leverages these developments to investigate the\nspatial distribution of utility derived from street-level conditions in\nresidential location choices on a city-wide scale. In our case study of\nRotterdam, the Netherlands, we find that the utility derived from street-level\nconditions varies significantly on a highly localised scale, with conditions\nrapidly changing even within neighbourhoods. Our results also reveal that the\nhigh real-estate prices in the city centre cannot be attributed to attractive\nstreet-level conditions. Furthermore, whereas the city centre is characterised\nby relatively unattractive residential street-level conditions, neighbourhoods\nin the southern part of the city -- often perceived as problematic -- exhibit\nsurprisingly appealing street-level environments. The methodological\ncontribution of this paper is that it advances the discrete choice models\nincorporating computer vision capabilities by introducing a semantic\nregularisation layer to the model. Thereby, it adds explainability and\neliminates the need for a separate pipeline to extract information from images,\nstreamlining the analysis. As such, this paper's findings and methodological\nadvancements pave the way for further studies to explore integrating\nstreet-level conditions in urban planning.\n","authors":["Sander van Cranenburgh","Francisco Garrido-Valenzuela"],"pdf_url":"https://arxiv.org/pdf/2410.17880v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17863v1","updated":"2024-10-23T13:35:18Z","published":"2024-10-23T13:35:18Z","title":"CASCRNet: An Atrous Spatial Pyramid Pooling and Shared Channel Residual\n  based Network for Capsule Endoscopy","summary":"  This manuscript summarizes work on the Capsule Vision Challenge 2024 by\nMISAHUB. To address the multi-class disease classification task, which is\nchallenging due to the complexity and imbalance in the Capsule Vision challenge\ndataset, this paper proposes CASCRNet (Capsule endoscopy-Aspp-SCR-Network), a\nparameter-efficient and novel model that uses Shared Channel Residual (SCR)\nblocks and Atrous Spatial Pyramid Pooling (ASPP) blocks. Further, the\nperformance of the proposed model is compared with other well-known approaches.\nThe experimental results yield that proposed model provides better disease\nclassification results. The proposed model was successful in classifying\ndiseases with an F1 Score of 78.5% and a Mean AUC of 98.3%, which is promising\ngiven its compact architecture.\n","authors":["K V Srinanda","M Manvith Prabhu","Shyam Lal"],"pdf_url":"https://arxiv.org/pdf/2410.17863v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.17858v1","updated":"2024-10-23T13:29:02Z","published":"2024-10-23T13:29:02Z","title":"Blendify -- Python rendering framework for Blender","summary":"  With the rapid growth of the volume of research fields like computer vision\nand computer graphics, researchers require effective and user-friendly\nrendering tools to visualize results. While advanced tools like Blender offer\npowerful capabilities, they also require a significant effort to master. This\ntechnical report introduces Blendify, a lightweight Python-based framework that\nseamlessly integrates with Blender, providing a high-level API for scene\ncreation and rendering. Blendify reduces the complexity of working with\nBlender's native API by automating object creation, handling the colors and\nmaterial linking, and implementing features such as shadow-catcher objects\nwhile maintaining support for high-quality ray-tracing rendering output. With a\nfocus on usability Blendify enables efficient and flexible rendering workflow\nfor rendering in common computer vision and computer graphics use cases. The\ncode is available at https://github.com/ptrvilya/blendify\n","authors":["Vladimir Guzov","Ilya A. Petrov","Gerard Pons-Moll"],"pdf_url":"https://arxiv.org/pdf/2410.17858v1.pdf","comment":"Project page: https://virtualhumans.mpi-inf.mpg.de/blendify/"},{"id":"http://arxiv.org/abs/2410.17856v1","updated":"2024-10-23T13:26:59Z","published":"2024-10-23T13:26:59Z","title":"ROCKET-1: Master Open-World Interaction with Visual-Temporal Context\n  Prompting","summary":"  Vision-language models (VLMs) have excelled in multimodal tasks, but adapting\nthem to embodied decision-making in open-world environments presents\nchallenges. A key issue is the difficulty in smoothly connecting individual\nentities in low-level observations with abstract concepts required for\nplanning. A common approach to address this problem is through the use of\nhierarchical agents, where VLMs serve as high-level reasoners that break down\ntasks into executable sub-tasks, typically specified using language and\nimagined observations. However, language often fails to effectively convey\nspatial information, while generating future images with sufficient accuracy\nremains challenging. To address these limitations, we propose visual-temporal\ncontext prompting, a novel communication protocol between VLMs and policy\nmodels. This protocol leverages object segmentation from both past and present\nobservations to guide policy-environment interactions. Using this approach, we\ntrain ROCKET-1, a low-level policy that predicts actions based on concatenated\nvisual observations and segmentation masks, with real-time object tracking\nprovided by SAM-2. Our method unlocks the full potential of VLMs\nvisual-language reasoning abilities, enabling them to solve complex creative\ntasks, especially those heavily reliant on spatial understanding. Experiments\nin Minecraft demonstrate that our approach allows agents to accomplish\npreviously unattainable tasks, highlighting the effectiveness of\nvisual-temporal context prompting in embodied decision-making. Codes and demos\nwill be available on the project page: https://craftjarvis.github.io/ROCKET-1.\n","authors":["Shaofei Cai","Zihao Wang","Kewei Lian","Zhancun Mu","Xiaojian Ma","Anji Liu","Yitao Liang"],"pdf_url":"https://arxiv.org/pdf/2410.17856v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17855v1","updated":"2024-10-23T13:26:19Z","published":"2024-10-23T13:26:19Z","title":"TAGE: Trustworthy Attribute Group Editing for Stable Few-shot Image\n  Generation","summary":"  Generative Adversarial Networks (GANs) have emerged as a prominent research\nfocus for image editing tasks, leveraging the powerful image generation\ncapabilities of the GAN framework to produce remarkable results.However,\nprevailing approaches are contingent upon extensive training datasets and\nexplicit supervision, presenting a significant challenge in manipulating the\ndiverse attributes of new image classes with limited sample availability. To\nsurmount this hurdle, we introduce TAGE, an innovative image generation network\ncomprising three integral modules: the Codebook Learning Module (CLM), the Code\nPrediction Module (CPM) and the Prompt-driven Semantic Module (PSM). The CPM\nmodule delves into the semantic dimensions of category-agnostic attributes,\nencapsulating them within a discrete codebook. This module is predicated on the\nconcept that images are assemblages of attributes, and thus, by editing these\ncategory-independent attributes, it is theoretically possible to generate\nimages from unseen categories. Subsequently, the CPM module facilitates\nnaturalistic image editing by predicting indices of category-independent\nattribute vectors within the codebook. Additionally, the PSM module generates\nsemantic cues that are seamlessly integrated into the Transformer architecture\nof the CPM, enhancing the model's comprehension of the targeted attributes for\nediting. With these semantic cues, the model can generate images that\naccentuate desired attributes more prominently while maintaining the integrity\nof the original category, even with a limited number of samples. We have\nconducted extensive experiments utilizing the Animal Faces, Flowers, and\nVGGFaces datasets. The results of these experiments demonstrate that our\nproposed method not only achieves superior performance but also exhibits a high\ndegree of stability when compared to other few-shot image generation\ntechniques.\n","authors":["Ruicheng Zhang","Guoheng Huang","Yejing Huo","Xiaochen Yuan","Zhizhen Zhou","Xuhang Chen","Guo Zhong"],"pdf_url":"https://arxiv.org/pdf/2410.17855v1.pdf","comment":"Accepted by International Conference on Signal Processing Systems\n  Conference"},{"id":"http://arxiv.org/abs/2410.15613v2","updated":"2024-10-23T13:07:41Z","published":"2024-10-21T03:17:25Z","title":"Exploring Stronger Transformer Representation Learning for Occluded\n  Person Re-Identification","summary":"  Due to some complex factors (e.g., occlusion, pose variation and diverse\ncamera perspectives), extracting stronger feature representation in person\nre-identification remains a challenging task. In this paper, we proposed a\nnovel self-supervision and supervision combining transformer-based person\nre-identification framework, namely SSSC-TransReID. Different from the general\ntransformer-based person re-identification models, we designed a\nself-supervised contrastive learning branch, which can enhance the feature\nrepresentation for person re-identification without negative samples or\nadditional pre-training. In order to train the contrastive learning branch, we\nalso proposed a novel random rectangle mask strategy to simulate the occlusion\nin real scenes, so as to enhance the feature representation for occlusion.\nFinally, we utilized the joint-training loss function to integrate the\nadvantages of supervised learning with ID tags and self-supervised contrastive\nlearning without negative samples, which can reinforce the ability of our model\nto excavate stronger discriminative features, especially for occlusion.\nExtensive experimental results on several benchmark datasets show our proposed\nmodel obtains superior Re-ID performance consistently and outperforms the\nstate-of-the-art ReID methods by large margins on the mean average accuracy\n(mAP) and Rank-1 accuracy.\n","authors":["Zhangjian Ji","Donglin Cheng","Kai Feng"],"pdf_url":"https://arxiv.org/pdf/2410.15613v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17839v1","updated":"2024-10-23T13:05:26Z","published":"2024-10-23T13:05:26Z","title":"Few-shot NeRF by Adaptive Rendering Loss Regularization","summary":"  Novel view synthesis with sparse inputs poses great challenges to Neural\nRadiance Field (NeRF). Recent works demonstrate that the frequency\nregularization of Positional Encoding (PE) can achieve promising results for\nfew-shot NeRF. In this work, we reveal that there exists an inconsistency\nbetween the frequency regularization of PE and rendering loss. This prevents\nfew-shot NeRF from synthesizing higher-quality novel views. To mitigate this\ninconsistency, we propose Adaptive Rendering loss regularization for few-shot\nNeRF, dubbed AR-NeRF. Specifically, we present a two-phase rendering\nsupervision and an adaptive rendering loss weight learning strategy to align\nthe frequency relationship between PE and 2D-pixel supervision. In this way,\nAR-NeRF can learn global structures better in the early training phase and\nadaptively learn local details throughout the training process. Extensive\nexperiments show that our AR-NeRF achieves state-of-the-art performance on\ndifferent datasets, including object-level and complex scenes.\n","authors":["Qingshan Xu","Xuanyu Yi","Jianyao Xu","Wenbing Tao","Yew-Soon Ong","Hanwang Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.17839v1.pdf","comment":"Accepted by ECCV2024"},{"id":"http://arxiv.org/abs/2410.13896v2","updated":"2024-10-23T13:01:22Z","published":"2024-10-15T02:41:52Z","title":"From Real Artifacts to Virtual Reference: A Robust Framework for\n  Translating Endoscopic Images","summary":"  Domain adaptation, which bridges the distributions across different\nmodalities, plays a crucial role in multimodal medical image analysis. In\nendoscopic imaging, combining pre-operative data with intra-operative imaging\nis important for surgical planning and navigation. However, existing domain\nadaptation methods are hampered by distribution shift caused by in vivo\nartifacts, necessitating robust techniques for aligning noisy and artifact\nabundant patient endoscopic videos with clean virtual images reconstructed from\npre-operative tomographic data for pose estimation during intraoperative\nguidance. This paper presents an artifact-resilient image translation method\nand an associated benchmark for this purpose. The method incorporates a novel\n``local-global'' translation framework and a noise-resilient feature extraction\nstrategy. For the former, it decouples the image translation process into a\nlocal step for feature denoising, and a global step for global style transfer.\nFor feature extraction, a new contrastive learning strategy is proposed, which\ncan extract noise-resilient features for establishing robust correspondence\nacross domains. Detailed validation on both public and in-house clinical\ndatasets has been conducted, demonstrating significantly improved performance\ncompared to the current state-of-the-art.\n","authors":["Junyang Wu","Fangfang Xie","Jiayuan Sun","Yun Gu","Guang-Zhong Yang"],"pdf_url":"https://arxiv.org/pdf/2410.13896v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14774v2","updated":"2024-10-23T13:01:14Z","published":"2024-03-21T18:28:43Z","title":"Few-Shot Adversarial Prompt Learning on Vision-Language Models","summary":"  The vulnerability of deep neural networks to imperceptible adversarial\nperturbations has attracted widespread attention. Inspired by the success of\nvision-language foundation models, previous efforts achieved zero-shot\nadversarial robustness by aligning adversarial visual features with text\nsupervision. However, in practice, they are still unsatisfactory due to several\nissues, including heavy adaptation cost, suboptimal text supervision, and\nuncontrolled natural generalization capacity. In this paper, to address these\nissues, we propose a few-shot adversarial prompt framework where adapting input\nsequences with limited data makes significant adversarial robustness\nimprovement. Specifically, we achieve this by providing adversarially\ncorrelated text supervision that is end-to-end learned from adversarial\nexamples. We also propose a novel training objective that enhances the\nconsistency of multi-modal features while encourages differentiated uni-modal\nfeatures between natural and adversarial examples. The proposed framework gives\naccess to learn adversarial text supervision, which provides superior\ncross-modal adversarial alignment and matches state-of-the-art zero-shot\nadversarial robustness with only 1% training data. Code is available at:\nhttps://github.com/lionel-w2/FAP.\n","authors":["Yiwei Zhou","Xiaobo Xia","Zhiwei Lin","Bo Han","Tongliang Liu"],"pdf_url":"https://arxiv.org/pdf/2403.14774v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2405.13152v3","updated":"2024-10-23T12:56:05Z","published":"2024-05-21T18:45:18Z","title":"Enhancing Interaction Modeling with Agent Selection and Physical\n  Coefficient for Trajectory Prediction","summary":"  A thorough understanding of the interaction between the target agent and\nsurrounding agents is a prerequisite for accurate trajectory prediction.\nAlthough many methods have been explored, they all assign correlation\ncoefficients to surrounding agents in a purely learning-based manner. In this\nstudy, we present ASPILin, which manually selects interacting agents and\ncalculates their correlations instead of attention scores. Surprisingly, these\nsimple modifications can significantly improve prediction performance and\nsubstantially reduce computational costs. Additionally, ASPILin models the\ninteracting agents at each past time step separately, rather than only modeling\nthe interacting agents at the current time step. This clarifies the causal\nchain of the target agent's historical trajectory and helps the model better\nunderstand dynamic interactions. We intentionally simplified our model in other\naspects, such as map encoding. Remarkably, experiments conducted on the\nINTERACTION, highD, and CitySim datasets demonstrate that our method is\nefficient and straightforward, outperforming other state-of-the-art methods.\n","authors":["Shiji Huang","Lei Ye","Min Chen","Wenhai Luo","Dihong Wang","Chenqi Xu","Deyuan Liang"],"pdf_url":"https://arxiv.org/pdf/2405.13152v3.pdf","comment":"code:https://github.com/kkk00714/ASPILin"},{"id":"http://arxiv.org/abs/2410.17832v1","updated":"2024-10-23T12:51:07Z","published":"2024-10-23T12:51:07Z","title":"Exploiting Text-Image Latent Spaces for the Description of Visual\n  Concepts","summary":"  Concept Activation Vectors (CAVs) offer insights into neural network\ndecision-making by linking human friendly concepts to the model's internal\nfeature extraction process. However, when a new set of CAVs is discovered, they\nmust still be translated into a human understandable description. For\nimage-based neural networks, this is typically done by visualizing the most\nrelevant images of a CAV, while the determination of the concept is left to\nhumans. In this work, we introduce an approach to aid the interpretation of\nnewly discovered concept sets by suggesting textual descriptions for each CAV.\nThis is done by mapping the most relevant images representing a CAV into a\ntext-image embedding where a joint description of these relevant images can be\ncomputed. We propose utilizing the most relevant receptive fields instead of\nfull images encoded. We demonstrate the capabilities of this approach in\nmultiple experiments with and without given CAV labels, showing that the\nproposed approach provides accurate descriptions for the CAVs and reduces the\nchallenge of concept interpretation.\n","authors":["Laines Schmalwasser","Jakob Gawlikowski","Joachim Denzler","Julia Niebling"],"pdf_url":"https://arxiv.org/pdf/2410.17832v1.pdf","comment":"19 pages, 7 figures, to be published in ICPR"},{"id":"http://arxiv.org/abs/2210.01708v4","updated":"2024-10-23T12:50:18Z","published":"2022-10-04T16:08:54Z","title":"Conquering the Communication Constraints to Enable Large Pre-Trained\n  Models in Federated Learning","summary":"  Federated learning (FL) has emerged as a promising paradigm for enabling the\ncollaborative training of models without centralized access to the raw data on\nlocal devices. In the typical FL paradigm (e.g., FedAvg), model weights are\nsent to and from the server each round to participating clients. Recently, the\nuse of small pre-trained models has been shown effective in federated learning\noptimization and improving convergence. However, recent state-of-the-art\npre-trained models are getting more capable but also have more parameters. In\nconventional FL, sharing the enormous model weights can quickly put a massive\ncommunication burden on the system, especially if more capable models are\nemployed. Can we find a solution to enable those strong and readily-available\npre-trained models in FL to achieve excellent performance while simultaneously\nreducing the communication burden? To this end, we investigate the use of\nparameter-efficient fine-tuning in federated learning and thus introduce a new\nframework: FedPEFT. Specifically, we systemically evaluate the performance of\nFedPEFT across a variety of client stability, data distribution, and\ndifferential privacy settings. By only locally tuning and globally sharing a\nsmall portion of the model weights, significant reductions in the total\ncommunication overhead can be achieved while maintaining competitive or even\nbetter performance in a wide range of federated learning scenarios, providing\ninsight into a new paradigm for practical and effective federated systems.\n","authors":["Guangyu Sun","Umar Khalid","Matias Mendieta","Taojiannan Yang","Pu Wang","Minwoo Lee","Chen Chen"],"pdf_url":"https://arxiv.org/pdf/2210.01708v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17823v1","updated":"2024-10-23T12:32:21Z","published":"2024-10-23T12:32:21Z","title":"Att2CPC: Attention-Guided Lossy Attribute Compression of Point Clouds","summary":"  With the great progress of 3D sensing and acquisition technology, the volume\nof point cloud data has grown dramatically, which urges the development of\nefficient point cloud compression methods. In this paper, we focus on the task\nof learned lossy point cloud attribute compression (PCAC). We propose an\nefficient attention-based method for lossy compression of point cloud\nattributes leveraging on an autoencoder architecture. Specifically, at the\nencoding side, we conduct multiple downsampling to best exploit the local\nattribute patterns, in which effective External Cross Attention (ECA) is\ndevised to hierarchically aggregate features by intergrating attributes and\ngeometry contexts. At the decoding side, the attributes of the point cloud are\nprogressively reconstructed based on the multi-scale representation and the\nzero-padding upsampling tactic. To the best of our knowledge, this is the first\napproach to introduce attention mechanism to point-based lossy PCAC task. We\nverify the compression efficiency of our model on various sequences, including\nhuman body frames, sparse objects, and large-scale point cloud scenes.\nExperiments show that our method achieves an average improvement of 1.15 dB and\n2.13 dB in BD-PSNR of Y channel and YUV channel, respectively, when comparing\nwith the state-of-the-art point-based method Deep-PCAC. Codes of this paper are\navailable at https://github.com/I2-Multimedia-Lab/Att2CPC.\n","authors":["Kai Liu","Kang You","Pan Gao","Manoranjan Paul"],"pdf_url":"https://arxiv.org/pdf/2410.17823v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17822v1","updated":"2024-10-23T12:32:20Z","published":"2024-10-23T12:32:20Z","title":"DREB-Net: Dual-stream Restoration Embedding Blur-feature Fusion Network\n  for High-mobility UAV Object Detection","summary":"  Object detection algorithms are pivotal components of unmanned aerial vehicle\n(UAV) imaging systems, extensively employed in complex fields. However, images\ncaptured by high-mobility UAVs often suffer from motion blur cases, which\nsignificantly impedes the performance of advanced object detection algorithms.\nTo address these challenges, we propose an innovative object detection\nalgorithm specifically designed for blurry images, named DREB-Net (Dual-stream\nRestoration Embedding Blur-feature Fusion Network). First, DREB-Net addresses\nthe particularities of blurry image object detection problem by incorporating a\nBlurry image Restoration Auxiliary Branch (BRAB) during the training phase.\nSecond, it fuses the extracted shallow features via Multi-level\nAttention-Guided Feature Fusion (MAGFF) module, to extract richer features.\nHere, the MAGFF module comprises local attention modules and global attention\nmodules, which assign different weights to the branches. Then, during the\ninference phase, the deep feature extraction of the BRAB can be removed to\nreduce computational complexity and improve detection speed. In loss function,\na combined loss of MSE and SSIM is added to the BRAB to restore blurry images.\nFinally, DREB-Net introduces Fast Fourier Transform in the early stages of\nfeature extraction, via a Learnable Frequency domain Amplitude Modulation\nModule (LFAMM), to adjust feature amplitude and enhance feature processing\ncapability. Experimental results indicate that DREB-Net can still effectively\nperform object detection tasks under motion blur in captured images, showcasing\nexcellent performance and broad application prospects. Our source code will be\navailable at https://github.com/EEIC-Lab/DREB-Net.git.\n","authors":["Qingpeng Li","Yuxin Zhang","Leyuan Fang","Yuhan Kang","Shutao Li","Xiao Xiang Zhu"],"pdf_url":"https://arxiv.org/pdf/2410.17822v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17816v1","updated":"2024-10-23T12:19:12Z","published":"2024-10-23T12:19:12Z","title":"Deep Learning for Active Region Classification: A Systematic Study from\n  Convolutional Neural Networks to Vision Transformers","summary":"  A solar active region can significantly disrupt the Sun Earth space\nenvironment, often leading to severe space weather events such as solar flares\nand coronal mass ejections. As a consequence, the automatic classification of\nactive region groups is the crucial starting point for accurately and promptly\npredicting solar activity. This study presents our results concerned with the\napplication of deep learning techniques to the classification of active region\ncutouts based on the Mount Wilson classification scheme. Specifically, we have\nexplored the latest advancements in image classification architectures, from\nConvolutional Neural Networks to Vision Transformers, and reported on their\nperformances for the active region classification task, showing that the\ncrucial point for their effectiveness consists in a robust training process\nbased on the latest advances in the field.\n","authors":["Edoardo Legnaro","Sabrina Guastavino","Michele Piana","Anna Maria Massone"],"pdf_url":"https://arxiv.org/pdf/2410.17816v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17814v1","updated":"2024-10-23T12:18:36Z","published":"2024-10-23T12:18:36Z","title":"Learning Lossless Compression for High Bit-Depth Volumetric Medical\n  Image","summary":"  Recent advances in learning-based methods have markedly enhanced the\ncapabilities of image compression. However, these methods struggle with high\nbit-depth volumetric medical images, facing issues such as degraded\nperformance, increased memory demand, and reduced processing speed. To address\nthese challenges, this paper presents the Bit-Division based Lossless\nVolumetric Image Compression (BD-LVIC) framework, which is tailored for high\nbit-depth medical volume compression. The BD-LVIC framework skillfully divides\nthe high bit-depth volume into two lower bit-depth segments: the Most\nSignificant Bit-Volume (MSBV) and the Least Significant Bit-Volume (LSBV). The\nMSBV concentrates on the most significant bits of the volumetric medical image,\ncapturing vital structural details in a compact manner. This reduction in\ncomplexity greatly improves compression efficiency using traditional codecs.\nConversely, the LSBV deals with the least significant bits, which encapsulate\nintricate texture details. To compress this detailed information effectively,\nwe introduce an effective learning-based compression model equipped with a\nTransformer-Based Feature Alignment Module, which exploits both intra-slice and\ninter-slice redundancies to accurately align features. Subsequently, a Parallel\nAutoregressive Coding Module merges these features to precisely estimate the\nprobability distribution of the least significant bit-planes. Our extensive\ntesting demonstrates that the BD-LVIC framework not only sets new performance\nbenchmarks across various datasets but also maintains a competitive coding\nspeed, highlighting its significant potential and practical utility in the\nrealm of volumetric medical image compression.\n","authors":["Kai Wang","Yuanchao Bai","Daxin Li","Deming Zhai","Junjun Jiang","Xianming Liu"],"pdf_url":"https://arxiv.org/pdf/2410.17814v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2410.17812v1","updated":"2024-10-23T12:17:03Z","published":"2024-10-23T12:17:03Z","title":"PGDiffSeg: Prior-Guided Denoising Diffusion Model with Parameter-Shared\n  Attention for Breast Cancer Segmentation","summary":"  Early detection through imaging and accurate diagnosis is crucial in\nmitigating the high mortality rate associated with breast cancer. However,\nlocating tumors from low-resolution and high-noise medical images is extremely\nchallenging. Therefore, this paper proposes a novel PGDiffSeg (Prior-Guided\nDiffusion Denoising Model with Parameter-Shared Attention) that applies\ndiffusion denoising methods to breast cancer medical image segmentation,\naccurately recovering the affected areas from Gaussian noise. Firstly, we\ndesign a parallel pipeline for noise processing and semantic information\nprocessing and propose a parameter-shared attention module (PSA) in multi-layer\nthat seamlessly integrates these two pipelines. This integration empowers\nPGDiffSeg to incorporate semantic details at multiple levels during the\ndenoising process, producing highly accurate segmentation maps. Secondly, we\nintroduce a guided strategy that leverages prior knowledge to simulate the\ndecision-making process of medical professionals, thereby enhancing the model's\nability to locate tumor positions precisely. Finally, we provide the first-ever\ndiscussion on the interpretability of the generative diffusion model in the\ncontext of breast cancer segmentation. Extensive experiments have demonstrated\nthe superiority of our model over the current state-of-the-art approaches,\nconfirming its effectiveness as a flexible diffusion denoising method suitable\nfor medical image research. Our code will be publicly available later.\n","authors":["Feiyan Feng","Tianyu Liu","Hong Wang","Jun Zhao","Wei Li","Yanshen Sun"],"pdf_url":"https://arxiv.org/pdf/2410.17812v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17810v1","updated":"2024-10-23T12:12:56Z","published":"2024-10-23T12:12:56Z","title":"EntityCLIP: Entity-Centric Image-Text Matching via Multimodal Attentive\n  Contrastive Learning","summary":"  Recent advancements in image-text matching have been notable, yet prevailing\nmodels predominantly cater to broad queries and struggle with accommodating\nfine-grained query intention. In this paper, we work towards the\n\\textbf{E}ntity-centric \\textbf{I}mage-\\textbf{T}ext \\textbf{M}atching (EITM),\na task that the text and image involve specific entity-related information. The\nchallenge of this task mainly lies in the larger semantic gap in entity\nassociation modeling, comparing with the general image-text matching problem.To\nnarrow the huge semantic gap between the entity-centric text and the images, we\ntake the fundamental CLIP as the backbone and devise a multimodal attentive\ncontrastive learning framework to tam CLIP to adapt EITM problem, developing a\nmodel named EntityCLIP. The key of our multimodal attentive contrastive\nlearning is to generate interpretive explanation text using Large Language\nModels (LLMs) as the bridge clues. In specific, we proceed by extracting\nexplanatory text from off-the-shelf LLMs. This explanation text, coupled with\nthe image and text, is then input into our specially crafted Multimodal\nAttentive Experts (MMAE) module, which effectively integrates explanation texts\nto narrow the gap of the entity-related text and image in a shared semantic\nspace. Building on the enriched features derived from MMAE, we further design\nan effective Gated Integrative Image-text Matching (GI-ITM) strategy. The\nGI-ITM employs an adaptive gating mechanism to aggregate MMAE's features,\nsubsequently applying image-text matching constraints to steer the alignment\nbetween the text and the image. Extensive experiments are conducted on three\nsocial media news benchmarks including N24News, VisualNews, and GoodNews, the\nresults shows that our method surpasses the competition methods with a clear\nmargin.\n","authors":["Yaxiong Wang","Yaxiong Wang","Lianwei Wu","Lechao Cheng","Zhun Zhong","Meng Wang"],"pdf_url":"https://arxiv.org/pdf/2410.17810v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17809v1","updated":"2024-10-23T12:11:26Z","published":"2024-10-23T12:11:26Z","title":"An Intelligent Agentic System for Complex Image Restoration Problems","summary":"  Real-world image restoration (IR) is inherently complex and often requires\ncombining multiple specialized models to address diverse degradations. Inspired\nby human problem-solving, we propose AgenticIR, an agentic system that mimics\nthe human approach to image processing by following five key stages:\nPerception, Scheduling, Execution, Reflection, and Rescheduling. AgenticIR\nleverages large language models (LLMs) and vision-language models (VLMs) that\ninteract via text generation to dynamically operate a toolbox of IR models. We\nfine-tune VLMs for image quality analysis and employ LLMs for reasoning,\nguiding the system step by step. To compensate for LLMs' lack of specific IR\nknowledge and experience, we introduce a self-exploration method, allowing the\nLLM to observe and summarize restoration results into referenceable documents.\nExperiments demonstrate AgenticIR's potential in handling complex IR tasks,\nrepresenting a promising path toward achieving general intelligence in visual\nprocessing.\n","authors":["Kaiwen Zhu","Jinjin Gu","Zhiyuan You","Yu Qiao","Chao Dong"],"pdf_url":"https://arxiv.org/pdf/2410.17809v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17802v1","updated":"2024-10-23T11:59:49Z","published":"2024-10-23T11:59:49Z","title":"GenUDC: High Quality 3D Mesh Generation with Unsigned Dual Contouring\n  Representation","summary":"  Generating high-quality meshes with complex structures and realistic surfaces\nis the primary goal of 3D generative models. Existing methods typically employ\nsequence data or deformable tetrahedral grids for mesh generation. However,\nsequence-based methods have difficulty producing complex structures with many\nfaces due to memory limits. The deformable tetrahedral grid-based method\nMeshDiffusion fails to recover realistic surfaces due to the inherent ambiguity\nin deformable grids. We propose the GenUDC framework to address these\nchallenges by leveraging the Unsigned Dual Contouring (UDC) as the mesh\nrepresentation. UDC discretizes a mesh in a regular grid and divides it into\nthe face and vertex parts, recovering both complex structures and fine details.\nAs a result, the one-to-one mapping between UDC and mesh resolves the ambiguity\nproblem. In addition, GenUDC adopts a two-stage, coarse-to-fine generative\nprocess for 3D mesh generation. It first generates the face part as a rough\nshape and then the vertex part to craft a detailed shape. Extensive evaluations\ndemonstrate the superiority of UDC as a mesh representation and the favorable\nperformance of GenUDC in mesh generation. The code and trained models are\navailable at https://github.com/TrepangCat/GenUDC.\n","authors":["Ruowei Wang","Jiaqi Li","Dan Zeng","Xueqi Ma","Zixiang Xu","Jianwei Zhang","Qijun Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.17802v1.pdf","comment":"ACMMM 2024, code:https://github.com/TrepangCat/GenUDC"},{"id":"http://arxiv.org/abs/2309.16515v3","updated":"2024-10-23T11:56:02Z","published":"2023-09-28T15:22:02Z","title":"Latent Noise Segmentation: How Neural Noise Leads to the Emergence of\n  Segmentation and Grouping","summary":"  Humans are able to segment images effortlessly without supervision using\nperceptual grouping. Here, we propose a counter-intuitive computational\napproach to solving unsupervised perceptual grouping and segmentation: that\nthey arise because of neural noise, rather than in spite of it. We (1)\nmathematically demonstrate that under realistic assumptions, neural noise can\nbe used to separate objects from each other; (2) that adding noise in a DNN\nenables the network to segment images even though it was never trained on any\nsegmentation labels; and (3) that segmenting objects using noise results in\nsegmentation performance that aligns with the perceptual grouping phenomena\nobserved in humans, and is sample-efficient. We introduce the Good Gestalt (GG)\ndatasets -- six datasets designed to specifically test perceptual grouping, and\nshow that our DNN models reproduce many important phenomena in human\nperception, such as illusory contours, closure, continuity, proximity, and\nocclusion. Finally, we (4) show that our model improves performance on our GG\ndatasets compared to other tested unsupervised models by $24.9\\%$. Together,\nour results suggest a novel unsupervised segmentation method requiring few\nassumptions, a new explanation for the formation of perceptual grouping, and a\nnovel potential benefit of neural noise.\n","authors":["Ben Lonnqvist","Zhengqing Wu","Michael H. Herzog"],"pdf_url":"https://arxiv.org/pdf/2309.16515v3.pdf","comment":"ICML 2024 camera ready version"},{"id":"http://arxiv.org/abs/2410.17785v1","updated":"2024-10-23T11:35:44Z","published":"2024-10-23T11:35:44Z","title":"TranSPORTmer: A Holistic Approach to Trajectory Understanding in\n  Multi-Agent Sports","summary":"  Understanding trajectories in multi-agent scenarios requires addressing\nvarious tasks, including predicting future movements, imputing missing\nobservations, inferring the status of unseen agents, and classifying different\nglobal states. Traditional data-driven approaches often handle these tasks\nseparately with specialized models. We introduce TranSPORTmer, a unified\ntransformer-based framework capable of addressing all these tasks, showcasing\nits application to the intricate dynamics of multi-agent sports scenarios like\nsoccer and basketball. Using Set Attention Blocks, TranSPORTmer effectively\ncaptures temporal dynamics and social interactions in an equivariant manner.\nThe model's tasks are guided by an input mask that conceals missing or\nyet-to-be-predicted observations. Additionally, we introduce a CLS extra agent\nto classify states along soccer trajectories, including passes, possessions,\nuncontrolled states, and out-of-play intervals, contributing to an enhancement\nin modeling trajectories. Evaluations on soccer and basketball datasets show\nthat TranSPORTmer outperforms state-of-the-art task-specific models in player\nforecasting, player forecasting-imputation, ball inference, and ball\nimputation. https://youtu.be/8VtSRm8oGoE\n","authors":["Guillem Capellera","Luis Ferraz","Antonio Rubio","Antonio Agudo","Francesc Moreno-Noguer"],"pdf_url":"https://arxiv.org/pdf/2410.17785v1.pdf","comment":"Accepted to ACCV 2024"},{"id":"http://arxiv.org/abs/2410.17779v1","updated":"2024-10-23T11:31:06Z","published":"2024-10-23T11:31:06Z","title":"ADEM-VL: Adaptive and Embedded Fusion for Efficient Vision-Language\n  Tuning","summary":"  Recent advancements in multimodal fusion have witnessed the remarkable\nsuccess of vision-language (VL) models, which excel in various multimodal\napplications such as image captioning and visual question answering. However,\nbuilding VL models requires substantial hardware resources, where efficiency is\nrestricted by two key factors: the extended input sequence of the language\nmodel with vision features demands more computational operations, and a large\nnumber of additional learnable parameters increase memory complexity. These\nchallenges significantly restrict the broader applicability of such models. To\nbridge this gap, we propose ADEM-VL, an efficient vision-language method that\ntunes VL models based on pretrained large language models (LLMs) by adopting a\nparameter-free cross-attention mechanism for similarity measurements in\nmultimodal fusion. This approach only requires embedding vision features into\nthe language space, significantly reducing the number of trainable parameters\nand accelerating both training and inference speeds. To enhance representation\nlearning in fusion module, we introduce an efficient multiscale feature\ngeneration scheme that requires only a single forward pass through the vision\nencoder. Moreover, we propose an adaptive fusion scheme that dynamically\ndiscards less relevant visual information for each text token based on its\nattention score. This ensures that the fusion process prioritizes the most\npertinent visual features. With experiments on various tasks including visual\nquestion answering, image captioning, and instruction-following, we demonstrate\nthat our framework outperforms existing approaches. Specifically, our method\nsurpasses existing methods by an average accuracy of 0.77% on ScienceQA\ndataset, with reduced training and inference latency, demonstrating the\nsuperiority of our framework. The code is available at\nhttps://github.com/Hao840/ADEM-VL.\n","authors":["Zhiwei Hao","Jianyuan Guo","Li Shen","Yong Luo","Han Hu","Yonggang Wen"],"pdf_url":"https://arxiv.org/pdf/2410.17779v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17774v1","updated":"2024-10-23T11:23:05Z","published":"2024-10-23T11:23:05Z","title":"Quasi-Medial Distance Field (Q-MDF): A Robust Method for Approximating\n  and Discretizing Neural Medial Axis","summary":"  The medial axis, a lower-dimensional shape descriptor, plays an important\nrole in the field of digital geometry processing. Despite its importance,\nrobust computation of the medial axis transform from diverse inputs, especially\npoint clouds with defects, remains a significant challenge. In this paper, we\ntackle the challenge by proposing a new implicit method that diverges from\nmainstream explicit medial axis computation techniques. Our key technical\ninsight is the difference between the signed distance field (SDF) and the\nmedial field (MF) of a solid shape is the unsigned distance field (UDF) of the\nshape's medial axis. This allows for formulating medial axis computation as an\nimplicit reconstruction problem. Utilizing a modified double covering method,\nwe extract the medial axis as the zero level-set of the UDF. Extensive\nexperiments show that our method has enhanced accuracy and robustness in\nlearning compact medial axis transform from thorny meshes and point clouds\ncompared to existing methods.\n","authors":["Jiayi Kong","Chen Zong","Jun Luo","Shiqing Xin","Fei Hou","Hanqing Jiang","Chen Qian","Ying He"],"pdf_url":"https://arxiv.org/pdf/2410.17774v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17772v1","updated":"2024-10-23T11:19:48Z","published":"2024-10-23T11:19:48Z","title":"Scaling Robot Policy Learning via Zero-Shot Labeling with Foundation\n  Models","summary":"  A central challenge towards developing robots that can relate human language\nto their perception and actions is the scarcity of natural language annotations\nin diverse robot datasets. Moreover, robot policies that follow natural\nlanguage instructions are typically trained on either templated language or\nexpensive human-labeled instructions, hindering their scalability. To this end,\nwe introduce NILS: Natural language Instruction Labeling for Scalability. NILS\nautomatically labels uncurated, long-horizon robot data at scale in a zero-shot\nmanner without any human intervention. NILS combines pretrained vision-language\nfoundation models in order to detect objects in a scene, detect object-centric\nchanges, segment tasks from large datasets of unlabelled interaction data and\nultimately label behavior datasets. Evaluations on BridgeV2, Fractal, and a\nkitchen play dataset show that NILS can autonomously annotate diverse robot\ndemonstrations of unlabeled and unstructured datasets while alleviating several\nshortcomings of crowdsourced human annotations, such as low data quality and\ndiversity. We use NILS to label over 115k trajectories obtained from over 430\nhours of robot data. We open-source our auto-labeling code and generated\nannotations on our website: http://robottasklabeling.github.io.\n","authors":["Nils Blank","Moritz Reuss","Marcel Rühle","Ömer Erdinç Yağmurlu","Fabian Wenzel","Oier Mees","Rudolf Lioutikov"],"pdf_url":"https://arxiv.org/pdf/2410.17772v1.pdf","comment":"Project Website at https://robottasklabeling.github.io/"},{"id":"http://arxiv.org/abs/2404.00362v2","updated":"2024-10-23T11:06:02Z","published":"2024-03-30T13:28:53Z","title":"STBA: Towards Evaluating the Robustness of DNNs for Query-Limited\n  Black-box Scenario","summary":"  Many attack techniques have been proposed to explore the vulnerability of\nDNNs and further help to improve their robustness. Despite the significant\nprogress made recently, existing black-box attack methods still suffer from\nunsatisfactory performance due to the vast number of queries needed to optimize\ndesired perturbations. Besides, the other critical challenge is that\nadversarial examples built in a noise-adding manner are abnormal and struggle\nto successfully attack robust models, whose robustness is enhanced by\nadversarial training against small perturbations. There is no doubt that these\ntwo issues mentioned above will significantly increase the risk of exposure and\nresult in a failure to dig deeply into the vulnerability of DNNs. Hence, it is\nnecessary to evaluate DNNs' fragility sufficiently under query-limited settings\nin a non-additional way. In this paper, we propose the Spatial Transform\nBlack-box Attack (STBA), a novel framework to craft formidable adversarial\nexamples in the query-limited scenario. Specifically, STBA introduces a flow\nfield to the high-frequency part of clean images to generate adversarial\nexamples and adopts the following two processes to enhance their naturalness\nand significantly improve the query efficiency: a) we apply an estimated flow\nfield to the high-frequency part of clean images to generate adversarial\nexamples instead of introducing external noise to the benign image, and b) we\nleverage an efficient gradient estimation method based on a batch of samples to\noptimize such an ideal flow field under query-limited settings. Compared to\nexisting score-based black-box baselines, extensive experiments indicated that\nSTBA could effectively improve the imperceptibility of the adversarial examples\nand remarkably boost the attack success rate under query-limited settings.\n","authors":["Renyang Liu","Kwok-Yan Lam","Wei Zhou","Sixing Wu","Jun Zhao","Dongting Hu","Mingming Gong"],"pdf_url":"https://arxiv.org/pdf/2404.00362v2.pdf","comment":"Accepted by T-MM"},{"id":"http://arxiv.org/abs/2403.14626v2","updated":"2024-10-23T11:05:01Z","published":"2024-03-21T17:59:55Z","title":"ODTFormer: Efficient Obstacle Detection and Tracking with Stereo Cameras\n  Based on Transformer","summary":"  Obstacle detection and tracking represent a critical component in robot\nautonomous navigation. In this paper, we propose ODTFormer, a Transformer-based\nmodel to address both obstacle detection and tracking problems. For the\ndetection task, our approach leverages deformable attention to construct a 3D\ncost volume, which is decoded progressively in the form of voxel occupancy\ngrids. We further track the obstacles by matching the voxels between\nconsecutive frames. The entire model can be optimized in an end-to-end manner.\nThrough extensive experiments on DrivingStereo and KITTI benchmarks, our model\nachieves state-of-the-art performance in the obstacle detection task. We also\nreport comparable accuracy to state-of-the-art obstacle tracking models while\nrequiring only a fraction of their computation cost, typically ten-fold to\ntwenty-fold less. The code and model weights will be publicly released.\n","authors":["Tianye Ding","Hongyu Li","Huaizu Jiang"],"pdf_url":"https://arxiv.org/pdf/2403.14626v2.pdf","comment":"8 pages. Accepted by IROS 2024"},{"id":"http://arxiv.org/abs/2405.15574v4","updated":"2024-10-23T10:54:16Z","published":"2024-05-24T14:04:03Z","title":"Meteor: Mamba-based Traversal of Rationale for Large Language and Vision\n  Models","summary":"  The rapid development of large language and vision models (LLVMs) has been\ndriven by advances in visual instruction tuning. Recently, open-source LLVMs\nhave curated high-quality visual instruction tuning datasets and utilized\nadditional vision encoders or multiple computer vision models in order to\nnarrow the performance gap with powerful closed-source LLVMs. These\nadvancements are attributed to multifaceted information required for diverse\ncapabilities, including fundamental image understanding, real-world knowledge\nabout common-sense and non-object concepts (e.g., charts, diagrams, symbols,\nsigns, and math problems), and step-by-step procedures for solving complex\nquestions. Drawing from the multifaceted information, we present a new\nefficient LLVM, Mamba-based traversal of rationales (Meteor), which leverages\nmultifaceted rationale to enhance understanding and answering capabilities. To\nembed lengthy rationales containing abundant information, we employ the Mamba\narchitecture, capable of processing sequential data with linear time\ncomplexity. We introduce a new concept of traversal of rationale that\nfacilitates efficient embedding of rationale. Subsequently, the backbone\nmultimodal language model (MLM) is trained to generate answers with the aid of\nrationale. Through these steps, Meteor achieves significant improvements in\nvision language performances across multiple evaluation benchmarks requiring\ndiverse capabilities, without scaling up the model size or employing additional\nvision encoders and computer vision models.\n","authors":["Byung-Kwan Lee","Chae Won Kim","Beomchan Park","Yong Man Ro"],"pdf_url":"https://arxiv.org/pdf/2405.15574v4.pdf","comment":"Code is available in https://github.com/ByungKwanLee/Meteor"},{"id":"http://arxiv.org/abs/2410.17752v1","updated":"2024-10-23T10:29:18Z","published":"2024-10-23T10:29:18Z","title":"AdaDiffSR: Adaptive Region-aware Dynamic Acceleration Diffusion Model\n  for Real-World Image Super-Resolution","summary":"  Diffusion models (DMs) have shown promising results on single-image\nsuper-resolution and other image-to-image translation tasks. Benefiting from\nmore computational resources and longer inference times, they are able to yield\nmore realistic images. Existing DMs-based super-resolution methods try to\nachieve an overall average recovery over all regions via iterative refinement,\nignoring the consideration that different input image regions require different\ntimesteps to reconstruct. In this work, we notice that previous DMs-based\nsuper-resolution methods suffer from wasting computational resources to\nreconstruct invisible details. To further improve the utilization of\ncomputational resources, we propose AdaDiffSR, a DMs-based SR pipeline with\ndynamic timesteps sampling strategy (DTSS). Specifically, by introducing the\nmulti-metrics latent entropy module (MMLE), we can achieve dynamic perception\nof the latent spatial information gain during the denoising process, thereby\nguiding the dynamic selection of the timesteps. In addition, we adopt a\nprogressive feature injection module (PFJ), which dynamically injects the\noriginal image features into the denoising process based on the current\ninformation gain, so as to generate images with both fidelity and realism.\nExperiments show that our AdaDiffSR achieves comparable performance over\ncurrent state-of-the-art DMs-based SR methods while consuming less\ncomputational resources and inference time on both synthetic and real-world\ndatasets.\n","authors":["Yuanting Fan","Chengxu Liu","Nengzhong Yin","Changlong Gao","Xueming Qian"],"pdf_url":"https://arxiv.org/pdf/2410.17752v1.pdf","comment":"18 pages, 6 figures, ECCV2024 accepted"},{"id":"http://arxiv.org/abs/2410.17751v1","updated":"2024-10-23T10:28:17Z","published":"2024-10-23T10:28:17Z","title":"VISAGE: Video Synthesis using Action Graphs for Surgery","summary":"  Surgical data science (SDS) is a field that analyzes patient data before,\nduring, and after surgery to improve surgical outcomes and skills. However,\nsurgical data is scarce, heterogeneous, and complex, which limits the\napplicability of existing machine learning methods. In this work, we introduce\nthe novel task of future video generation in laparoscopic surgery. This task\ncan augment and enrich the existing surgical data and enable various\napplications, such as simulation, analysis, and robot-aided surgery.\nUltimately, it involves not only understanding the current state of the\noperation but also accurately predicting the dynamic and often unpredictable\nnature of surgical procedures. Our proposed method, VISAGE (VIdeo Synthesis\nusing Action Graphs for Surgery), leverages the power of action scene graphs to\ncapture the sequential nature of laparoscopic procedures and utilizes diffusion\nmodels to synthesize temporally coherent video sequences. VISAGE predicts the\nfuture frames given only a single initial frame, and the action graph triplets.\nBy incorporating domain-specific knowledge through the action graph, VISAGE\nensures the generated videos adhere to the expected visual and motion patterns\nobserved in real laparoscopic procedures. The results of our experiments\ndemonstrate high-fidelity video generation for laparoscopy procedures, which\nenables various applications in SDS.\n","authors":["Yousef Yeganeh","Rachmadio Lazuardi","Amir Shamseddin","Emine Dari","Yash Thirani","Nassir Navab Azade Farshad"],"pdf_url":"https://arxiv.org/pdf/2410.17751v1.pdf","comment":"Accepted at MICCAI 2024 Embodied AI and Robotics for HealTHcare\n  (EARTH) Workshop"},{"id":"http://arxiv.org/abs/2410.17741v1","updated":"2024-10-23T10:16:01Z","published":"2024-10-23T10:16:01Z","title":"Efficient Neural Implicit Representation for 3D Human Reconstruction","summary":"  High-fidelity digital human representations are increasingly in demand in the\ndigital world, particularly for interactive telepresence, AR/VR, 3D graphics,\nand the rapidly evolving metaverse. Even though they work well in small spaces,\nconventional methods for reconstructing 3D human motion frequently require the\nuse of expensive hardware and have high processing costs. This study presents\nHumanAvatar, an innovative approach that efficiently reconstructs precise human\navatars from monocular video sources. At the core of our methodology, we\nintegrate the pre-trained HuMoR, a model celebrated for its proficiency in\nhuman motion estimation. This is adeptly fused with the cutting-edge neural\nradiance field technology, Instant-NGP, and the state-of-the-art articulated\nmodel, Fast-SNARF, to enhance the reconstruction fidelity and speed. By\ncombining these two technologies, a system is created that can render quickly\nand effectively while also providing estimation of human pose parameters that\nare unmatched in accuracy. We have enhanced our system with an advanced\nposture-sensitive space reduction technique, which optimally balances rendering\nquality with computational efficiency. In our detailed experimental analysis\nusing both artificial and real-world monocular videos, we establish the\nadvanced performance of our approach. HumanAvatar consistently equals or\nsurpasses contemporary leading-edge reconstruction techniques in quality.\nFurthermore, it achieves these complex reconstructions in minutes, a fraction\nof the time typically required by existing methods. Our models achieve a\ntraining speed that is 110X faster than that of State-of-The-Art (SoTA)\nNeRF-based models. Our technique performs noticeably better than SoTA dynamic\nhuman NeRF methods if given an identical runtime limit. HumanAvatar can provide\neffective visuals after only 30 seconds of training.\n","authors":["Zexu Huang","Sarah Monazam Erfani","Siying Lu","Mingming Gong"],"pdf_url":"https://arxiv.org/pdf/2410.17741v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17740v1","updated":"2024-10-23T10:14:37Z","published":"2024-10-23T10:14:37Z","title":"Emotion Recognition with Facial Attention and Objective Activation\n  Functions","summary":"  In this paper, we study the effect of introducing channel and spatial\nattention mechanisms, namely SEN-Net, ECA-Net, and CBAM, to existing CNN\nvision-based models such as VGGNet, ResNet, and ResNetV2 to perform the Facial\nEmotion Recognition task. We show that not only attention can significantly\nimprove the performance of these models but also that combining them with a\ndifferent activation function can further help increase the performance of\nthese models.\n","authors":["Andrzej Miskow","Abdulrahman Altahhan"],"pdf_url":"https://arxiv.org/pdf/2410.17740v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17735v1","updated":"2024-10-23T10:11:39Z","published":"2024-10-23T10:11:39Z","title":"New Insight in Cervical Cancer Diagnosis Using Convolution Neural\n  Network Architecture","summary":"  The Pap smear is a screening method for early cervical cancer diagnosis. The\nselection of the right optimizer in the convolutional neural network (CNN)\nmodel is key to the success of the CNN in image classification, including the\nclassification of cervical cancer Pap smear images. In this study, stochastic\ngradient descent (SGD), RMSprop, Adam, AdaGrad, AdaDelta, Adamax, and Nadam\noptimizers were used to classify cervical cancer Pap smear images from the\nSipakMed dataset. Resnet-18, Resnet-34, and VGG-16 are the CNN architectures\nused in this study, and each architecture uses a transfer-learning model. Based\non the test results, we conclude that the transfer learning model performs\nbetter on all CNNs and optimization techniques and that in the transfer\nlearning model, the optimization has little influence on the training of the\nmodel. Adamax, with accuracy values of 72.8% and 66.8%, had the best accuracy\nfor the VGG-16 and Resnet-18 architectures, respectively. Resnet-34 had 54.0%.\nThis is 0.034% lower than Nadam. Overall, Adamax is a suitable optimizer for\nCNN in cervical cancer classification on Resnet-18, Resnet-34, and VGG-16\narchitectures. This study provides new insights into the configuration of CNN\nmodels for Pap smear image analysis.\n","authors":["Ach. Khozaimi","Wayan Firdaus Mahmudy"],"pdf_url":"https://arxiv.org/pdf/2410.17735v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17734v1","updated":"2024-10-23T10:07:13Z","published":"2024-10-23T10:07:13Z","title":"YOLO-Vehicle-Pro: A Cloud-Edge Collaborative Framework for Object\n  Detection in Autonomous Driving under Adverse Weather Conditions","summary":"  With the rapid advancement of autonomous driving technology, efficient and\naccurate object detection capabilities have become crucial factors in ensuring\nthe safety and reliability of autonomous driving systems. However, in\nlow-visibility environments such as hazy conditions, the performance of\ntraditional object detection algorithms often degrades significantly, failing\nto meet the demands of autonomous driving. To address this challenge, this\npaper proposes two innovative deep learning models: YOLO-Vehicle and\nYOLO-Vehicle-Pro. YOLO-Vehicle is an object detection model tailored\nspecifically for autonomous driving scenarios, employing multimodal fusion\ntechniques to combine image and textual information for object detection.\nYOLO-Vehicle-Pro builds upon this foundation by introducing an improved image\ndehazing algorithm, enhancing detection performance in low-visibility\nenvironments. In addition to model innovation, this paper also designs and\nimplements a cloud-edge collaborative object detection system, deploying models\non edge devices and offloading partial computational tasks to the cloud in\ncomplex situations. Experimental results demonstrate that on the KITTI dataset,\nthe YOLO-Vehicle-v1s model achieved 92.1% accuracy while maintaining a\ndetection speed of 226 FPS and an inference time of 12ms, meeting the real-time\nrequirements of autonomous driving. When processing hazy images, the\nYOLO-Vehicle-Pro model achieved a high accuracy of 82.3% mAP@50 on the Foggy\nCityscapes dataset while maintaining a detection speed of 43 FPS.\n","authors":["Xiguang Li","Jiafu Chen","Yunhe Sun","Na Lin","Ammar Hawbani","Liang Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.17734v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17725v1","updated":"2024-10-23T09:55:22Z","published":"2024-10-23T09:55:22Z","title":"YOLOv11: An Overview of the Key Architectural Enhancements","summary":"  This study presents an architectural analysis of YOLOv11, the latest\niteration in the YOLO (You Only Look Once) series of object detection models.\nWe examine the models architectural innovations, including the introduction of\nthe C3k2 (Cross Stage Partial with kernel size 2) block, SPPF (Spatial Pyramid\nPooling - Fast), and C2PSA (Convolutional block with Parallel Spatial\nAttention) components, which contribute in improving the models performance in\nseveral ways such as enhanced feature extraction. The paper explores YOLOv11's\nexpanded capabilities across various computer vision tasks, including object\ndetection, instance segmentation, pose estimation, and oriented object\ndetection (OBB). We review the model's performance improvements in terms of\nmean Average Precision (mAP) and computational efficiency compared to its\npredecessors, with a focus on the trade-off between parameter count and\naccuracy. Additionally, the study discusses YOLOv11's versatility across\ndifferent model sizes, from nano to extra-large, catering to diverse\napplication needs from edge devices to high-performance computing environments.\nOur research provides insights into YOLOv11's position within the broader\nlandscape of object detection and its potential impact on real-time computer\nvision applications.\n","authors":["Rahima Khanam","Muhammad Hussain"],"pdf_url":"https://arxiv.org/pdf/2410.17725v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.15881v3","updated":"2024-10-23T09:52:23Z","published":"2024-08-28T15:52:23Z","title":"LLaVA-MoD: Making LLaVA Tiny via MoE Knowledge Distillation","summary":"  We introduce LLaVA-MoD, a novel framework designed to enable the efficient\ntraining of small-scale Multimodal Language Models (s-MLLM) by distilling\nknowledge from large-scale MLLM (l-MLLM). Our approach tackles two fundamental\nchallenges in MLLM distillation. First, we optimize the network structure of\ns-MLLM by integrating a sparse Mixture of Experts (MoE) architecture into the\nlanguage model, striking a balance between computational efficiency and model\nexpressiveness. Second, we propose a progressive knowledge transfer strategy to\nensure comprehensive knowledge migration. This strategy begins with mimic\ndistillation, where we minimize the Kullback-Leibler (KL) divergence between\noutput distributions to enable the student model to emulate the teacher\nnetwork's understanding. Following this, we introduce preference distillation\nvia Direct Preference Optimization (DPO), where the key lies in treating l-MLLM\nas the reference model. During this phase, the s-MLLM's ability to discriminate\nbetween superior and inferior examples is significantly enhanced beyond l-MLLM,\nleading to a better student that surpasses its teacher, particularly in\nhallucination benchmarks. Extensive experiments demonstrate that LLaVA-MoD\noutperforms existing models across various multimodal benchmarks while\nmaintaining a minimal number of activated parameters and low computational\ncosts. Remarkably, LLaVA-MoD, with only 2B activated parameters, surpasses\nQwen-VL-Chat-7B by an average of 8.8% across benchmarks, using merely 0.3% of\nthe training data and 23% trainable parameters. These results underscore\nLLaVA-MoD's ability to effectively distill comprehensive knowledge from its\nteacher model, paving the way for the development of more efficient MLLMs. The\ncode will be available on: https://github.com/shufangxun/LLaVA-MoD.\n","authors":["Fangxun Shu","Yue Liao","Le Zhuo","Chenning Xu","Lei Zhang","Guanghao Zhang","Haonan Shi","Long Chen","Tao Zhong","Wanggui He","Siming Fu","Haoyuan Li","Bolin Li","Zhelun Yu","Si Liu","Hongsheng Li","Hao Jiang"],"pdf_url":"https://arxiv.org/pdf/2408.15881v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.14693v2","updated":"2024-10-23T09:42:29Z","published":"2024-04-23T02:50:38Z","title":"DIP-Watermark: A Double Identity Protection Method Based on Robust\n  Adversarial Watermark","summary":"  The wide deployment of Face Recognition (FR) systems poses privacy risks. One\ncountermeasure is adversarial attack, deceiving unauthorized malicious FR, but\nit also disrupts regular identity verification of trusted authorizers,\nexacerbating the potential threat of identity impersonation. To address this,\nwe propose the first double identity protection scheme based on traceable\nadversarial watermarking, termed DIP-Watermark. DIP-Watermark employs a\none-time watermark embedding to deceive unauthorized FR models and allows\nauthorizers to perform identity verification by extracting the watermark.\nSpecifically, we propose an information-guided adversarial attack against FR\nmodels. The encoder embeds an identity-specific watermark into the deep feature\nspace of the carrier, guiding recognizable features of the image to deviate\nfrom the source identity. We further adopt a collaborative meta-optimization\nstrategy compatible with sub-tasks, which regularizes the joint optimization\ndirection of the encoder and decoder. This strategy enhances the representation\nof universal carrier features, mitigating multi-objective optimization\nconflicts in watermarking. Experiments confirm that DIP-Watermark achieves\nsignificant attack success rates and traceability accuracy on state-of-the-art\nFR models, exhibiting remarkable robustness that outperforms the existing\nprivacy protection methods using adversarial attacks and deep watermarking, or\nsimple combinations of the two. Our work potentially opens up new insights into\nproactive protection for FR privacy.\n","authors":["Yunming Zhang","Dengpan Ye","Caiyun Xie","Sipeng Shen","Ziyi Liu","Jiacheng Deng","Long Tang"],"pdf_url":"https://arxiv.org/pdf/2404.14693v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17715v1","updated":"2024-10-23T09:42:17Z","published":"2024-10-23T09:42:17Z","title":"Continual Learning on a Data Diet","summary":"  Continual Learning (CL) methods usually learn from all available data.\nHowever, this is not the case in human cognition which efficiently focuses on\nkey experiences while disregarding the redundant information. Similarly, not\nall data points in a dataset have equal potential; some can be more informative\nthan others. This disparity may significantly impact the performance, as both\nthe quality and quantity of samples directly influence the model's\ngeneralizability and efficiency. Drawing inspiration from this, we explore the\npotential of learning from important samples and present an empirical study for\nevaluating coreset selection techniques in the context of CL to stimulate\nresearch in this unexplored area. We train different continual learners on\nincreasing amounts of selected samples and investigate the learning-forgetting\ndynamics by shedding light on the underlying mechanisms driving their improved\nstability-plasticity balance. We present several significant observations:\nlearning from selectively chosen samples (i) enhances incremental accuracy,\n(ii) improves knowledge retention of previous tasks, and (iii) refines learned\nrepresentations. This analysis contributes to a deeper understanding of\nselective learning strategies in CL scenarios.\n","authors":["Elif Ceren Gok Yildirim","Murat Onur Yildirim","Joaquin Vanschoren"],"pdf_url":"https://arxiv.org/pdf/2410.17715v1.pdf","comment":"18 pages, 6 figures"},{"id":"http://arxiv.org/abs/2403.17678v2","updated":"2024-10-23T09:15:32Z","published":"2024-03-26T13:05:49Z","title":"Hierarchical Light Transformer Ensembles for Multimodal Trajectory\n  Forecasting","summary":"  Accurate trajectory forecasting is crucial for the performance of various\nsystems, such as advanced driver-assistance systems and self-driving vehicles.\nThese forecasts allow to anticipate events leading to collisions and,\ntherefore, to mitigate them. Deep Neural Networks have excelled in motion\nforecasting, but issues like overconfidence and uncertainty quantification\npersist. Deep Ensembles address these concerns, yet applying them to multimodal\ndistributions remains challenging. In this paper, we propose a novel approach\nnamed Hierarchical Light Transformer Ensembles (HLT-Ens), aimed at efficiently\ntraining an ensemble of Transformer architectures using a novel hierarchical\nloss function. HLT-Ens leverages grouped fully connected layers, inspired by\ngrouped convolution techniques, to capture multimodal distributions,\neffectively. Through extensive experimentation, we demonstrate that HLT-Ens\nachieves state-of-the-art performance levels, offering a promising avenue for\nimproving trajectory forecasting techniques.\n","authors":["Adrien Lafage","Mathieu Barbier","Gianni Franchi","David Filliat"],"pdf_url":"https://arxiv.org/pdf/2403.17678v2.pdf","comment":"acknowledgement added"},{"id":"http://arxiv.org/abs/2410.17691v1","updated":"2024-10-23T09:13:11Z","published":"2024-10-23T09:13:11Z","title":"Longitudinal Causal Image Synthesis","summary":"  Clinical decision-making relies heavily on causal reasoning and longitudinal\nanalysis. For example, for a patient with Alzheimer's disease (AD), how will\nthe brain grey matter atrophy in a year if intervened on the A-beta level in\ncerebrospinal fluid? The answer is fundamental to diagnosis and follow-up\ntreatment. However, this kind of inquiry involves counterfactual medical images\nwhich can not be acquired by instrumental or correlation-based image synthesis\nmodels. Yet, such queries require counterfactual medical images, not obtainable\nthrough standard image synthesis models. Hence, a causal longitudinal image\nsynthesis (CLIS) method, enabling the synthesis of such images, is highly\nvaluable. However, building a CLIS model confronts three primary yet unmet\nchallenges: mismatched dimensionality between high-dimensional images and\nlow-dimensional tabular variables, inconsistent collection intervals of\nfollow-up data, and inadequate causal modeling capability of existing causal\ngraph methods for image data. In this paper, we established a tabular-visual\ncausal graph (TVCG) for CLIS overcoming these challenges through a novel\nintegration of generative imaging, continuous-time modeling, and structural\ncausal models combined with a neural network. We train our CLIS based on the\nADNI dataset and evaluate it on two other AD datasets, which illustrate the\noutstanding yet controllable quality of the synthesized images and the\ncontributions of synthesized MRI to the characterization of AD progression,\nsubstantiating the reliability and utility in clinics.\n","authors":["Yujia Li","Han Li","ans S. Kevin Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.17691v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.13752v2","updated":"2024-10-23T08:53:05Z","published":"2023-05-23T07:09:09Z","title":"Pulling Target to Source: A New Perspective on Domain Adaptive Semantic\n  Segmentation","summary":"  Domain adaptive semantic segmentation aims to transfer knowledge from a\nlabeled source domain to an unlabeled target domain. However, existing methods\nprimarily focus on directly learning qualified target features, making it\nchallenging to guarantee their discrimination in the absence of target labels.\nThis work provides a new perspective. We observe that the features learned with\nsource data manage to keep categorically discriminative during training,\nthereby enabling us to implicitly learn adequate target representations by\nsimply \\textbf{pulling target features close to source features for each\ncategory}. To this end, we propose T2S-DA, which we interpret as a form of\npulling Target to Source for Domain Adaptation, encouraging the model in\nlearning similar cross-domain features. Also, considering the pixel categories\nare heavily imbalanced for segmentation datasets, we come up with a dynamic\nre-weighting strategy to help the model concentrate on those underperforming\nclasses. Extensive experiments confirm that T2S-DA learns a more discriminative\nand generalizable representation, significantly surpassing the\nstate-of-the-art. We further show that our method is quite qualified for the\ndomain generalization task, verifying its domain-invariant property.\n","authors":["Haochen Wang","Yujun Shen","Jingjing Fei","Wei Li","Liwei Wu","Yuxi Wang","Zhaoxiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.13752v2.pdf","comment":"Accepted by IJCV"},{"id":"http://arxiv.org/abs/2410.17664v1","updated":"2024-10-23T08:33:23Z","published":"2024-10-23T08:33:23Z","title":"Deep Generative Models for 3D Medical Image Synthesis","summary":"  Deep generative modeling has emerged as a powerful tool for synthesizing\nrealistic medical images, driving advances in medical image analysis, disease\ndiagnosis, and treatment planning. This chapter explores various deep\ngenerative models for 3D medical image synthesis, with a focus on Variational\nAutoencoders (VAEs), Generative Adversarial Networks (GANs), and Denoising\nDiffusion Models (DDMs). We discuss the fundamental principles, recent\nadvances, as well as strengths and weaknesses of these models and examine their\napplications in clinically relevant problems, including unconditional and\nconditional generation tasks like image-to-image translation and image\nreconstruction. We additionally review commonly used evaluation metrics for\nassessing image fidelity, diversity, utility, and privacy and provide an\noverview of current challenges in the field.\n","authors":["Paul Friedrich","Yannik Frisch","Philippe C. Cattin"],"pdf_url":"https://arxiv.org/pdf/2410.17664v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.00505v2","updated":"2024-10-23T08:28:53Z","published":"2024-06-01T17:27:34Z","title":"Improving Text Generation on Images with Synthetic Captions","summary":"  The recent emergence of latent diffusion models such as SDXL and SD 1.5 has\nshown significant capability in generating highly detailed and realistic\nimages. Despite their remarkable ability to produce images, generating accurate\ntext within images still remains a challenging task. In this paper, we examine\nthe validity of fine-tuning approaches in generating legible text within the\nimage. We propose a low-cost approach by leveraging SDXL without any\ntime-consuming training on large-scale datasets. The proposed strategy employs\na fine-tuning technique that examines the effects of data refinement levels and\nsynthetic captions. Moreover, our results demonstrate how our small scale\nfine-tuning approach can improve the accuracy of text generation in different\nscenarios without the need of additional multimodal encoders. Our experiments\nshow that with the addition of random letters to our raw dataset, our model's\nperformance improves in producing well-formed visual text.\n","authors":["Jun Young Koh","Sang Hyun Park","Joy Song"],"pdf_url":"https://arxiv.org/pdf/2406.00505v2.pdf","comment":"2024 16th IIAI International Congress on Advanced Applied Informatics\n  (IIAI-AAI)"},{"id":"http://arxiv.org/abs/2407.16364v2","updated":"2024-10-23T08:27:23Z","published":"2024-07-23T10:11:56Z","title":"Harmonizing Visual Text Comprehension and Generation","summary":"  In this work, we present TextHarmony, a unified and versatile multimodal\ngenerative model proficient in comprehending and generating visual text.\nSimultaneously generating images and texts typically results in performance\ndegradation due to the inherent inconsistency between vision and language\nmodalities. To overcome this challenge, existing approaches resort to\nmodality-specific data for supervised fine-tuning, necessitating distinct model\ninstances. We propose Slide-LoRA, which dynamically aggregates\nmodality-specific and modality-agnostic LoRA experts, partially decoupling the\nmultimodal generation space. Slide-LoRA harmonizes the generation of vision and\nlanguage within a singular model instance, thereby facilitating a more unified\ngenerative process. Additionally, we develop a high-quality image caption\ndataset, DetailedTextCaps-100K, synthesized with a sophisticated closed-source\nMLLM to enhance visual text generation capabilities further. Comprehensive\nexperiments across various benchmarks demonstrate the effectiveness of the\nproposed approach. Empowered by Slide-LoRA, TextHarmony achieves comparable\nperformance to modality-specific fine-tuning results with only a 2% increase in\nparameters and shows an average improvement of 2.5% in visual text\ncomprehension tasks and 4.0% in visual text generation tasks. Our work\ndelineates the viability of an integrated approach to multimodal generation\nwithin the visual text domain, setting a foundation for subsequent inquiries.\nCode is available at https://github.com/bytedance/TextHarmony.\n","authors":["Zhen Zhao","Jingqun Tang","Binghong Wu","Chunhui Lin","Shu Wei","Hao Liu","Xin Tan","Zhizhong Zhang","Can Huang","Yuan Xie"],"pdf_url":"https://arxiv.org/pdf/2407.16364v2.pdf","comment":"accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2312.12540v4","updated":"2024-10-23T08:20:12Z","published":"2023-12-19T19:19:19Z","title":"Lightning-Fast Image Inversion and Editing for Text-to-Image Diffusion\n  Models","summary":"  Diffusion inversion is the problem of taking an image and a text prompt that\ndescribes it and finding a noise latent that would generate the exact same\nimage. Most current deterministic inversion techniques operate by approximately\nsolving an implicit equation and may converge slowly or yield poor\nreconstructed images. We formulate the problem by finding the roots of an\nimplicit equation and devlop a method to solve it efficiently. Our solution is\nbased on Newton-Raphson (NR), a well-known technique in numerical analysis. We\nshow that a vanilla application of NR is computationally infeasible while\nnaively transforming it to a computationally tractable alternative tends to\nconverge to out-of-distribution solutions, resulting in poor reconstruction and\nediting. We therefore derive an efficient guided formulation that fastly\nconverges and provides high-quality reconstructions and editing. We showcase\nour method on real image editing with three popular open-sourced diffusion\nmodels: Stable Diffusion, SDXL-Turbo, and Flux with different deterministic\nschedulers. Our solution, Guided Newton-Raphson Inversion, inverts an image\nwithin 0.4 sec (on an A100 GPU) for few-step models (SDXL-Turbo and Flux.1),\nopening the door for interactive image editing. We further show improved\nresults in image interpolation and generation of rare objects.\n","authors":["Dvir Samuel","Barak Meiri","Haggai Maron","Yoad Tewel","Nir Darshan","Shai Avidan","Gal Chechik","Rami Ben-Ari"],"pdf_url":"https://arxiv.org/pdf/2312.12540v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17642v1","updated":"2024-10-23T07:58:47Z","published":"2024-10-23T07:58:47Z","title":"Surgical Scene Segmentation by Transformer With Asymmetric Feature\n  Enhancement","summary":"  Surgical scene segmentation is a fundamental task for robotic-assisted\nlaparoscopic surgery understanding. It often contains various anatomical\nstructures and surgical instruments, where similar local textures and\nfine-grained structures make the segmentation a difficult task. Vision-specific\ntransformer method is a promising way for surgical scene understanding.\nHowever, there are still two main challenges. Firstly, the absence of\ninner-patch information fusion leads to poor segmentation performance.\nSecondly, the specific characteristics of anatomy and instruments are not\nspecifically modeled. To tackle the above challenges, we propose a novel\nTransformer-based framework with an Asymmetric Feature Enhancement module\n(TAFE), which enhances local information and then actively fuses the improved\nfeature pyramid into the embeddings from transformer encoders by a multi-scale\ninteraction attention strategy. The proposed method outperforms the SOTA\nmethods in several different surgical segmentation tasks and additionally\nproves its ability of fine-grained structure recognition. Code is available at\nhttps://github.com/cyuan-sjtu/ViT-asym.\n","authors":["Cheng Yuan","Yutong Ban"],"pdf_url":"https://arxiv.org/pdf/2410.17642v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17637v1","updated":"2024-10-23T07:56:48Z","published":"2024-10-23T07:56:48Z","title":"MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large\n  Vision-Language Models","summary":"  Visual preference alignment involves training Large Vision-Language Models\n(LVLMs) to predict human preferences between visual inputs. This is typically\nachieved by using labeled datasets of chosen/rejected pairs and employing\noptimization algorithms like direct preference optimization (DPO). Existing\nvisual alignment methods, primarily designed for single-image scenarios,\nstruggle to effectively handle the complexity of multi-image tasks due to the\nscarcity of diverse training data and the high cost of annotating\nchosen/rejected pairs. We present Multi-Image Augmented Direct Preference\nOptimization (MIA-DPO), a visual preference alignment approach that effectively\nhandles multi-image inputs. MIA-DPO mitigates the scarcity of diverse\nmulti-image training data by extending single-image data with unrelated images\narranged in grid collages or pic-in-pic formats, significantly reducing the\ncosts associated with multi-image data annotations. Our observation reveals\nthat attention values of LVLMs vary considerably across different images. We\nuse attention values to identify and filter out rejected responses the model\nmay have mistakenly focused on. Our attention-aware selection for constructing\nthe chosen/rejected pairs without relying on (i) human annotation, (ii) extra\ndata, and (iii) external models or APIs. MIA-DPO is compatible with various\narchitectures and outperforms existing methods on five multi-image benchmarks,\nachieving an average performance boost of 3.0% on LLaVA-v1.5 and 4.3% on the\nrecent InternLM-XC2.5. Moreover, MIA-DPO has a minimal effect on the model's\nability to understand single images.\n","authors":["Ziyu Liu","Yuhang Zang","Xiaoyi Dong","Pan Zhang","Yuhang Cao","Haodong Duan","Conghui He","Yuanjun Xiong","Dahua Lin","Jiaqi Wang"],"pdf_url":"https://arxiv.org/pdf/2410.17637v1.pdf","comment":"Project URL: https://github.com/Liuziyu77/MIA-DPO"},{"id":"http://arxiv.org/abs/2410.15767v2","updated":"2024-10-23T07:55:10Z","published":"2024-10-21T08:27:13Z","title":"Improving Instance Optimization in Deformable Image Registration with\n  Gradient Projection","summary":"  Deformable image registration is inherently a multi-objective optimization\n(MOO) problem, requiring a delicate balance between image similarity and\ndeformation regularity. These conflicting objectives often lead to poor\noptimization outcomes, such as being trapped in unsatisfactory local minima or\nexperiencing slow convergence. Deep learning methods have recently gained\npopularity in this domain due to their efficiency in processing large datasets\nand achieving high accuracy. However, they often underperform during test time\ncompared to traditional optimization techniques, which further explore\niterative, instance-specific gradient-based optimization. This performance gap\nis more pronounced when a distribution shift between training and test data\nexists. To address this issue, we focus on the instance optimization (IO)\nparadigm, which involves additional optimization for test-time instances based\non a pre-trained model. IO effectively combines the generalization capabilities\nof deep learning with the fine-tuning advantages of instance-specific\noptimization. Within this framework, we emphasize the use of gradient\nprojection to mitigate conflicting updates in MOO. This technique projects\nconflicting gradients into a common space, better aligning the dual objectives\nand enhancing optimization stability. We validate our method using a\nstate-of-the-art foundation model on the 3D Brain inter-subject registration\ntask (LUMIR) from the Learn2Reg 2024 Challenge. Our results show significant\nimprovements over standard gradient descent, leading to more accurate and\nreliable registration results.\n","authors":["Yi Zhang","Yidong Zhao","Qian Tao"],"pdf_url":"https://arxiv.org/pdf/2410.15767v2.pdf","comment":"Learn2Reg Challenge at MICCAI 2024"},{"id":"http://arxiv.org/abs/2410.17622v1","updated":"2024-10-23T07:26:19Z","published":"2024-10-23T07:26:19Z","title":"Bridging the Gaps: Utilizing Unlabeled Face Recognition Datasets to\n  Boost Semi-Supervised Facial Expression Recognition","summary":"  In recent years, Facial Expression Recognition (FER) has gained increasing\nattention. Most current work focuses on supervised learning, which requires a\nlarge amount of labeled and diverse images, while FER suffers from the scarcity\nof large, diverse datasets and annotation difficulty. To address these\nproblems, we focus on utilizing large unlabeled Face Recognition (FR) datasets\nto boost semi-supervised FER. Specifically, we first perform face\nreconstruction pre-training on large-scale facial images without annotations to\nlearn features of facial geometry and expression regions, followed by two-stage\nfine-tuning on FER datasets with limited labels. In addition, to further\nalleviate the scarcity of labeled and diverse images, we propose a Mixup-based\ndata augmentation strategy tailored for facial images, and the loss weights of\nreal and virtual images are determined according to the intersection-over-union\n(IoU) of the faces in the two images. Experiments on RAF-DB, AffectNet, and\nFERPlus show that our method outperforms existing semi-supervised FER methods\nand achieves new state-of-the-art performance. Remarkably, with only 5%, 25%\ntraining sets,our method achieves 64.02% on AffectNet,and 88.23% on RAF-DB,\nwhich is comparable to fully supervised state-of-the-art methods. Codes will be\nmade publicly available at https://github.com/zhelishisongjie/SSFER.\n","authors":["Jie Song","Mengqiao He","Jinhua Feng","Bairong Shen"],"pdf_url":"https://arxiv.org/pdf/2410.17622v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.14947v2","updated":"2024-10-23T07:18:51Z","published":"2024-08-27T10:44:34Z","title":"ERX: A Fast Real-Time Anomaly Detection Algorithm for Hyperspectral Line\n  Scanning","summary":"  Detecting unexpected objects (anomalies) in real time has great potential for\nmonitoring, managing, and protecting the environment. Hyperspectral line-scan\ncameras are a low-cost solution that enhance confidence in anomaly detection\nover RGB and multispectral imagery. However, existing line-scan algorithms are\ntoo slow when using small computers (e.g. those onboard a drone or small\nsatellite), do not adapt to changing scenery, or lack robustness against\ngeometric distortions. This paper introduces the Exponentially moving RX\nalgorithm (ERX) to address these issues, and compares it with existing RX-based\nanomaly detection methods for hyperspectral line scanning. Three large and more\ncomplex datasets are also introduced to better assess the practical challenges\nwhen using line-scan cameras (two hyperspectral and one multispectral). ERX is\nevaluated using a Jetson Xavier NX compute module, achieving the best\ncombination of speed and detection performance. This research paves the way for\nfuture studies in grouping and locating anomalous objects, adaptive and\nautomatic threshold selection, and real-time field tests. The datasets and the\nPython code are available at: https://github.com/WiseGamgee/HyperAD.\n","authors":["Samuel Garske","Bradley Evans","Christopher Artlett","KC Wong"],"pdf_url":"https://arxiv.org/pdf/2408.14947v2.pdf","comment":"17 pages, 13 figures, 4 tables, code and datasets accessible at\n  https://github.com/WiseGamgee/HyperAD"},{"id":"http://arxiv.org/abs/2404.07554v2","updated":"2024-10-23T07:16:42Z","published":"2024-04-11T08:36:13Z","title":"CAT: Contrastive Adapter Training for Personalized Image Generation","summary":"  The emergence of various adapters, including Low-Rank Adaptation (LoRA)\napplied from the field of natural language processing, has allowed diffusion\nmodels to personalize image generation at a low cost. However, due to the\nvarious challenges including limited datasets and shortage of regularization\nand computation resources, adapter training often results in unsatisfactory\noutcomes, leading to the corruption of the backbone model's prior knowledge.\nOne of the well known phenomena is the loss of diversity in object generation,\nespecially within the same class which leads to generating almost identical\nobjects with minor variations. This poses challenges in generation\ncapabilities. To solve this issue, we present Contrastive Adapter Training\n(CAT), a simple yet effective strategy to enhance adapter training through the\napplication of CAT loss. Our approach facilitates the preservation of the base\nmodel's original knowledge when the model initiates adapters. Furthermore, we\nintroduce the Knowledge Preservation Score (KPS) to evaluate CAT's ability to\nkeep the former information. We qualitatively and quantitatively compare CAT's\nimprovement. Finally, we mention the possibility of CAT in the aspects of\nmulti-concept adapter and optimization.\n","authors":["Jae Wan Park","Sang Hyun Park","Jun Young Koh","Junha Lee","Min Song"],"pdf_url":"https://arxiv.org/pdf/2404.07554v2.pdf","comment":"CVPRW 2024"},{"id":"http://arxiv.org/abs/2410.17610v1","updated":"2024-10-23T07:06:08Z","published":"2024-10-23T07:06:08Z","title":"ImDy: Human Inverse Dynamics from Imitated Observations","summary":"  Inverse dynamics (ID), which aims at reproducing the driven torques from\nhuman kinematic observations, has been a critical tool for gait analysis.\nHowever, it is hindered from wider application to general motion due to its\nlimited scalability. Conventional optimization-based ID requires expensive\nlaboratory setups, restricting its availability. To alleviate this problem, we\npropose to exploit the recently progressive human motion imitation algorithms\nto learn human inverse dynamics in a data-driven manner. The key insight is\nthat the human ID knowledge is implicitly possessed by motion imitators, though\nnot directly applicable. In light of this, we devise an efficient data\ncollection pipeline with state-of-the-art motion imitation algorithms and\nphysics simulators, resulting in a large-scale human inverse dynamics benchmark\nas Imitated Dynamics (ImDy). ImDy contains over 150 hours of motion with joint\ntorque and full-body ground reaction force data. With ImDy, we train a\ndata-driven human inverse dynamics solver ImDyS(olver) in a fully supervised\nmanner, which conducts ID and ground reaction force estimation simultaneously.\nExperiments on ImDy and real-world data demonstrate the impressive competency\nof ImDyS in human inverse dynamics and ground reaction force estimation.\nMoreover, the potential of ImDy(-S) as a fundamental motion analysis tool is\nexhibited with downstream applications. The project page is\nhttps://foruck.github.io/ImDy/.\n","authors":["Xinpeng Liu","Junxuan Liang","Zili Lin","Haowen Hou","Yong-Lu Li","Cewu Lu"],"pdf_url":"https://arxiv.org/pdf/2410.17610v1.pdf","comment":"Yong-Lu Li and Cewu Lu are the corresponding authors"},{"id":"http://arxiv.org/abs/2406.14927v2","updated":"2024-10-23T07:01:34Z","published":"2024-06-21T07:37:17Z","title":"Gaussian-Informed Continuum for Physical Property Identification and\n  Simulation","summary":"  This paper studies the problem of estimating physical properties (system\nidentification) through visual observations. To facilitate geometry-aware\nguidance in physical property estimation, we introduce a novel hybrid framework\nthat leverages 3D Gaussian representation to not only capture explicit shapes\nbut also enable the simulated continuum to render object masks as 2D shape\nsurrogates during training.\n  We propose a new dynamic 3D Gaussian framework based on motion factorization\nto recover the object as 3D Gaussian point sets across different time states.\n  Furthermore, we develop a coarse-to-fine filling strategy to generate the\ndensity fields of the object from the Gaussian reconstruction, allowing for the\nextraction of object continuums along with their surfaces and the integration\nof Gaussian attributes into these continuums.\n  In addition to the extracted object surfaces, the Gaussian-informed continuum\nalso enables the rendering of object masks during simulations, serving as\n2D-shape guidance for physical property estimation.\n  Extensive experimental evaluations demonstrate that our pipeline achieves\nstate-of-the-art performance across multiple benchmarks and metrics.\nAdditionally, we illustrate the effectiveness of the proposed method through\nreal-world demonstrations, showcasing its practical utility.\n  Our project page is at https://jukgei.github.io/project/gic.\n","authors":["Junhao Cai","Yuji Yang","Weihao Yuan","Yisheng He","Zilong Dong","Liefeng Bo","Hui Cheng","Qifeng Chen"],"pdf_url":"https://arxiv.org/pdf/2406.14927v2.pdf","comment":"21 pages, 8 figures, NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.17606v1","updated":"2024-10-23T07:01:16Z","published":"2024-10-23T07:01:16Z","title":"Towards Effective Data-Free Knowledge Distillation via Diverse Diffusion\n  Augmentation","summary":"  Data-free knowledge distillation (DFKD) has emerged as a pivotal technique in\nthe domain of model compression, substantially reducing the dependency on the\noriginal training data. Nonetheless, conventional DFKD methods that employ\nsynthesized training data are prone to the limitations of inadequate diversity\nand discrepancies in distribution between the synthesized and original\ndatasets. To address these challenges, this paper introduces an innovative\napproach to DFKD through diverse diffusion augmentation (DDA). Specifically, we\nrevise the paradigm of common data synthesis in DFKD to a composite process\nthrough leveraging diffusion models subsequent to data synthesis for\nself-supervised augmentation, which generates a spectrum of data samples with\nsimilar distributions while retaining controlled variations. Furthermore, to\nmitigate excessive deviation in the embedding space, we introduce an image\nfiltering technique grounded in cosine similarity to maintain fidelity during\nthe knowledge distillation process. Comprehensive experiments conducted on\nCIFAR-10, CIFAR-100, and Tiny-ImageNet datasets showcase the superior\nperformance of our method across various teacher-student network\nconfigurations, outperforming the contemporary state-of-the-art DFKD methods.\nCode will be available at:https://github.com/SLGSP/DDA.\n","authors":["Muquan Li","Dongyang Zhang","Tao He","Xiurui Xie","Yuan-Fang Li","Ke Qin"],"pdf_url":"https://arxiv.org/pdf/2410.17606v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17598v1","updated":"2024-10-23T06:51:59Z","published":"2024-10-23T06:51:59Z","title":"PlantCamo: Plant Camouflage Detection","summary":"  Camouflaged Object Detection (COD) aims to detect objects with camouflaged\nproperties. Although previous studies have focused on natural (animals and\ninsects) and unnatural (artistic and synthetic) camouflage detection, plant\ncamouflage has been neglected. However, plant camouflage plays a vital role in\nnatural camouflage. Therefore, this paper introduces a new challenging problem\nof Plant Camouflage Detection (PCD). To address this problem, we introduce the\nPlantCamo dataset, which comprises 1,250 images with camouflaged plants\nrepresenting 58 object categories in various natural scenes. To investigate the\ncurrent status of plant camouflage detection, we conduct a large-scale\nbenchmark study using 20+ cutting-edge COD models on the proposed dataset. Due\nto the unique characteristics of plant camouflage, including holes and\nirregular borders, we developed a new framework, named PCNet, dedicated to PCD.\nOur PCNet surpasses performance thanks to its multi-scale global feature\nenhancement and refinement. Finally, we discuss the potential applications and\ninsights, hoping this work fills the gap in fine-grained COD research and\nfacilitates further intelligent ecology research. All resources will be\navailable on https://github.com/yjybuaa/PlantCamo.\n","authors":["Jinyu Yang","Qingwei Wang","Feng Zheng","Peng Chen","Aleš Leonardis","Deng-Ping Fan"],"pdf_url":"https://arxiv.org/pdf/2410.17598v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17594v1","updated":"2024-10-23T06:47:29Z","published":"2024-10-23T06:47:29Z","title":"How to Continually Adapt Text-to-Image Diffusion Models for Flexible\n  Customization?","summary":"  Custom diffusion models (CDMs) have attracted widespread attention due to\ntheir astonishing generative ability for personalized concepts. However, most\nexisting CDMs unreasonably assume that personalized concepts are fixed and\ncannot change over time. Moreover, they heavily suffer from catastrophic\nforgetting and concept neglect on old personalized concepts when continually\nlearning a series of new concepts. To address these challenges, we propose a\nnovel Concept-Incremental text-to-image Diffusion Model (CIDM), which can\nresolve catastrophic forgetting and concept neglect to learn new customization\ntasks in a concept-incremental manner. Specifically, to surmount the\ncatastrophic forgetting of old concepts, we develop a concept consolidation\nloss and an elastic weight aggregation module. They can explore task-specific\nand task-shared knowledge during training, and aggregate all low-rank weights\nof old concepts based on their contributions during inference. Moreover, in\norder to address concept neglect, we devise a context-controllable synthesis\nstrategy that leverages expressive region features and noise estimation to\ncontrol the contexts of generated images according to user conditions.\nExperiments validate that our CIDM surpasses existing custom diffusion models.\nThe source codes are available at https://github.com/JiahuaDong/CIFC.\n","authors":["Jiahua Dong","Wenqi Liang","Hongliu Li","Duzhen Zhang","Meng Cao","Henghui Ding","Salman Khan","Fahad Shahbaz Khan"],"pdf_url":"https://arxiv.org/pdf/2410.17594v1.pdf","comment":"Accepted to NeurIPS2024"},{"id":"http://arxiv.org/abs/2406.16592v3","updated":"2024-10-23T06:45:20Z","published":"2024-06-24T12:33:21Z","title":"Toward Fairer Face Recognition Datasets","summary":"  Face recognition and verification are two computer vision tasks whose\nperformance has progressed with the introduction of deep representations.\nHowever, ethical, legal, and technical challenges due to the sensitive\ncharacter of face data and biases in real training datasets hinder their\ndevelopment. Generative AI addresses privacy by creating fictitious identities,\nbut fairness problems persist. We promote fairness by introducing a demographic\nattributes balancing mechanism in generated training datasets. We experiment\nwith an existing real dataset, three generated training datasets, and the\nbalanced versions of a diffusion-based dataset. We propose a comprehensive\nevaluation that considers accuracy and fairness equally and includes a rigorous\nregression-based statistical analysis of attributes. The analysis shows that\nbalancing reduces demographic unfairness. Also, a performance gap persists\ndespite generation becoming more accurate with time. The proposed balancing\nmethod and comprehensive verification evaluation promote fairer and transparent\nface recognition and verification.\n","authors":["Alexandre Fournier-Montgieux","Michael Soumm","Adrian Popescu","Bertrand Luvison","Hervé Le Borgne"],"pdf_url":"https://arxiv.org/pdf/2406.16592v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.08035v2","updated":"2024-10-23T06:37:01Z","published":"2024-06-12T09:36:52Z","title":"LVBench: An Extreme Long Video Understanding Benchmark","summary":"  Recent progress in multimodal large language models has markedly enhanced the\nunderstanding of short videos (typically under one minute), and several\nevaluation datasets have emerged accordingly. However, these advancements fall\nshort of meeting the demands of real-world applications such as embodied\nintelligence for long-term decision-making, in-depth movie reviews and\ndiscussions, and live sports commentary, all of which require comprehension of\nlong videos spanning several hours. To address this gap, we introduce LVBench,\na benchmark specifically designed for long video understanding. Our dataset\ncomprises publicly sourced videos and encompasses a diverse set of tasks aimed\nat long video comprehension and information extraction. LVBench is designed to\nchallenge multimodal models to demonstrate long-term memory and extended\ncomprehension capabilities. Our extensive evaluations reveal that current\nmultimodal models still underperform on these demanding long video\nunderstanding tasks. Through LVBench, we aim to spur the development of more\nadvanced models capable of tackling the complexities of long video\ncomprehension. Our data and code are publicly available at:\nhttps://lvbench.github.io.\n","authors":["Weihan Wang","Zehai He","Wenyi Hong","Yean Cheng","Xiaohan Zhang","Ji Qi","Xiaotao Gu","Shiyu Huang","Bin Xu","Yuxiao Dong","Ming Ding","Jie Tang"],"pdf_url":"https://arxiv.org/pdf/2406.08035v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17555v2","updated":"2024-10-23T05:49:00Z","published":"2024-09-26T05:57:35Z","title":"Advancing Open-Set Domain Generalization Using Evidential Bi-Level\n  Hardest Domain Scheduler","summary":"  In Open-Set Domain Generalization (OSDG), the model is exposed to both new\nvariations of data appearance (domains) and open-set conditions, where both\nknown and novel categories are present at test time. The challenges of this\ntask arise from the dual need to generalize across diverse domains and\naccurately quantify category novelty, which is critical for applications in\ndynamic environments. Recently, meta-learning techniques have demonstrated\nsuperior results in OSDG, effectively orchestrating the meta-train and -test\ntasks by employing varied random categories and predefined domain partition\nstrategies. These approaches prioritize a well-designed training schedule over\ntraditional methods that focus primarily on data augmentation and the\nenhancement of discriminative feature learning. The prevailing meta-learning\nmodels in OSDG typically utilize a predefined sequential domain scheduler to\nstructure data partitions. However, a crucial aspect that remains inadequately\nexplored is the influence brought by strategies of domain schedulers during\ntraining. In this paper, we observe that an adaptive domain scheduler benefits\nmore in OSDG compared with prefixed sequential and random domain schedulers. We\npropose the Evidential Bi-Level Hardest Domain Scheduler (EBiL-HaDS) to achieve\nan adaptive domain scheduler. This method strategically sequences domains by\nassessing their reliabilities in utilizing a follower network, trained with\nconfidence scores learned in an evidential manner, regularized by max rebiasing\ndiscrepancy, and optimized in a bi-level manner. The results show that our\nmethod substantially improves OSDG performance and achieves more discriminative\nembeddings for both the seen and unseen categories. The source code is publicly\navailable at https://github.com/KPeng9510/EBiL-HaDS.\n","authors":["Kunyu Peng","Di Wen","Kailun Yang","Ao Luo","Yufan Chen","Jia Fu","M. Saquib Sarfraz","Alina Roitberg","Rainer Stiefelhagen"],"pdf_url":"https://arxiv.org/pdf/2409.17555v2.pdf","comment":"Accepted to NeurIPS 2024. The source code is publicly available at\n  https://github.com/KPeng9510/EBiL-HaDS"},{"id":"http://arxiv.org/abs/2407.15815v2","updated":"2024-10-23T05:32:34Z","published":"2024-07-22T17:29:02Z","title":"Learning to Manipulate Anywhere: A Visual Generalizable Framework For\n  Reinforcement Learning","summary":"  Can we endow visuomotor robots with generalization capabilities to operate in\ndiverse open-world scenarios? In this paper, we propose \\textbf{Maniwhere}, a\ngeneralizable framework tailored for visual reinforcement learning, enabling\nthe trained robot policies to generalize across a combination of multiple\nvisual disturbance types. Specifically, we introduce a multi-view\nrepresentation learning approach fused with Spatial Transformer Network (STN)\nmodule to capture shared semantic information and correspondences among\ndifferent viewpoints. In addition, we employ a curriculum-based randomization\nand augmentation approach to stabilize the RL training process and strengthen\nthe visual generalization ability. To exhibit the effectiveness of Maniwhere,\nwe meticulously design 8 tasks encompassing articulate objects, bi-manual, and\ndexterous hand manipulation tasks, demonstrating Maniwhere's strong visual\ngeneralization and sim2real transfer abilities across 3 hardware platforms. Our\nexperiments show that Maniwhere significantly outperforms existing\nstate-of-the-art methods. Videos are provided at\nhttps://gemcollector.github.io/maniwhere/.\n","authors":["Zhecheng Yuan","Tianming Wei","Shuiqi Cheng","Gu Zhang","Yuanpei Chen","Huazhe Xu"],"pdf_url":"https://arxiv.org/pdf/2407.15815v2.pdf","comment":"Webpage: https://gemcollector.github.io/maniwhere/"},{"id":"http://arxiv.org/abs/2312.11309v2","updated":"2024-10-23T05:30:24Z","published":"2023-12-18T16:02:43Z","title":"The Ultimate Combo: Boosting Adversarial Example Transferability by\n  Composing Data Augmentations","summary":"  To help adversarial examples generalize from surrogate machine-learning (ML)\nmodels to targets, certain transferability-based black-box evasion attacks\nincorporate data augmentations (e.g., random resizing). Yet, prior work has\nexplored limited augmentations and their composition. To fill the gap, we\nsystematically studied how data augmentation affects transferability.\nSpecifically, we explored 46 augmentation techniques originally proposed to\nhelp ML models generalize to unseen benign samples, and assessed how they\nimpact transferability, when applied individually or composed. Performing\nexhaustive search on a small subset of augmentation techniques and genetic\nsearch on all techniques, we identified augmentation combinations that help\npromote transferability. Extensive experiments with the ImageNet and CIFAR-10\ndatasets and 18 models showed that simple color-space augmentations (e.g.,\ncolor to greyscale) attain high transferability when combined with standard\naugmentations. Furthermore, we discovered that composing augmentations impacts\ntransferability mostly monotonically (i.e., more augmentations $\\rightarrow$\n$\\ge$transferability). We also found that the best composition significantly\noutperformed the state of the art (e.g., 91.8% vs. $\\le$82.5% average\ntransferability to adversarially trained targets on ImageNet). Lastly, our\ntheoretical analysis, backed by empirical evidence, intuitively explains why\ncertain augmentations promote transferability.\n","authors":["Zebin Yun","Achi-Or Weingarten","Eyal Ronen","Mahmood Sharif"],"pdf_url":"https://arxiv.org/pdf/2312.11309v2.pdf","comment":"Accepted by AISec'24"},{"id":"http://arxiv.org/abs/2402.02316v3","updated":"2024-10-23T05:26:10Z","published":"2024-02-04T02:09:18Z","title":"Diffusion Models are Certifiably Robust Classifiers","summary":"  Generative learning, recognized for its effective modeling of data\ndistributions, offers inherent advantages in handling out-of-distribution\ninstances, especially for enhancing robustness to adversarial attacks. Among\nthese, diffusion classifiers, utilizing powerful diffusion models, have\ndemonstrated superior empirical robustness. However, a comprehensive\ntheoretical understanding of their robustness is still lacking, raising\nconcerns about their vulnerability to stronger future attacks. In this study,\nwe prove that diffusion classifiers possess $O(1)$ Lipschitzness, and establish\ntheir certified robustness, demonstrating their inherent resilience. To achieve\nnon-constant Lipschitzness, thereby obtaining much tighter certified\nrobustness, we generalize diffusion classifiers to classify Gaussian-corrupted\ndata. This involves deriving the evidence lower bounds (ELBOs) for these\ndistributions, approximating the likelihood using the ELBO, and calculating\nclassification probabilities via Bayes' theorem. Experimental results show the\nsuperior certified robustness of these Noised Diffusion Classifiers (NDCs).\nNotably, we achieve over 80% and 70% certified robustness on CIFAR-10 under\nadversarial perturbations with \\(\\ell_2\\) norms less than 0.25 and 0.5,\nrespectively, using a single off-the-shelf diffusion model without any\nadditional data.\n","authors":["Huanran Chen","Yinpeng Dong","Shitong Shao","Zhongkai Hao","Xiao Yang","Hang Su","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2402.02316v3.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.17565v1","updated":"2024-10-23T05:19:20Z","published":"2024-10-23T05:19:20Z","title":"Double Banking on Knowledge: Customized Modulation and Prototypes for\n  Multi-Modality Semi-supervised Medical Image Segmentation","summary":"  Multi-modality (MM) semi-supervised learning (SSL) based medical image\nsegmentation has recently gained increasing attention for its ability to\nutilize MM data and reduce reliance on labeled images. However, current methods\nface several challenges: (1) Complex network designs hinder scalability to\nscenarios with more than two modalities. (2) Focusing solely on\nmodality-invariant representation while neglecting modality-specific features,\nleads to incomplete MM learning. (3) Leveraging unlabeled data with generative\nmethods can be unreliable for SSL. To address these problems, we propose Double\nBank Dual Consistency (DBDC), a novel MM-SSL approach for medical image\nsegmentation. To address challenge (1), we propose a modality all-in-one\nsegmentation network that accommodates data from any number of modalities,\nremoving the limitation on modality count. To address challenge (2), we design\ntwo learnable plug-in banks, Modality-Level Modulation bank (MLMB) and\nModality-Level Prototype (MLPB) bank, to capture both modality-invariant and\nmodality-specific knowledge. These banks are updated using our proposed\nModality Prototype Contrastive Learning (MPCL). Additionally, we design\nModality Adaptive Weighting (MAW) to dynamically adjust learning weights for\neach modality, ensuring balanced MM learning as different modalities learn at\ndifferent rates. Finally, to address challenge (3), we introduce a Dual\nConsistency (DC) strategy that enforces consistency at both the image and\nfeature levels without relying on generative methods. We evaluate our method on\na 2-to-4 modality segmentation task using three open-source datasets, and\nextensive experiments show that our method outperforms state-of-the-art\napproaches.\n","authors":["Yingyu Chen","Ziyuan Yang","Ming Yan","Zhongzhou Zhang","Hui Yu","Yan Liu","Yi Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.17565v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.06316v2","updated":"2024-10-23T05:14:19Z","published":"2023-12-11T12:03:30Z","title":"SemiSAM: Enhancing Semi-Supervised Medical Image Segmentation via\n  SAM-Assisted Consistency Regularization","summary":"  Semi-supervised learning has attracted much attention due to its less\ndependence on acquiring abundant annotations from experts compared to fully\nsupervised methods, which is especially important for medical image\nsegmentation which typically requires intensive pixel/voxel-wise labeling by\ndomain experts. Although semi-supervised methods can improve the performance by\nutilizing unlabeled data, there are still gaps between fully supervised methods\nunder extremely limited annotation scenarios. In this paper, we propose a\nsimple yet efficient strategy to explore the usage of the Segment Anything\nModel (SAM) for enhancing semi-supervised medical image segmentation.\nConcretely, the segmentation model trained with domain knowledge provides\ninformation for localization and generating input prompts to the SAM. Then the\ngenerated pseudo-labels of SAM are utilized as additional supervision to assist\nin the learning procedure of the semi-supervised framework. Extensive\nexperiments demonstrate that SemiSAM significantly improves the performance of\nexisting semi-supervised frameworks when only one or a few labeled images are\navailable and shows strong efficiency as a plug-and-play strategy for\nsemi-supervised medical image segmentation.\n","authors":["Yichi Zhang","Jin Yang","Yuchen Liu","Yuan Cheng","Yuan Qi"],"pdf_url":"https://arxiv.org/pdf/2312.06316v2.pdf","comment":"Accept for BIBM 2024"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2410.18077v1","updated":"2024-10-23T17:58:49Z","published":"2024-10-23T17:58:49Z","title":"ALTA: Compiler-Based Analysis of Transformers","summary":"  We propose a new programming language called ALTA and a compiler that can map\nALTA programs to Transformer weights. ALTA is inspired by RASP, a language\nproposed by Weiss et al. (2021), and Tracr (Lindner et al., 2023), a compiler\nfrom RASP programs to Transformer weights. ALTA complements and extends this\nprior work, offering the ability to express loops and to compile programs to\nUniversal Transformers, among other advantages. ALTA allows us to\nconstructively show how Transformers can represent length-invariant algorithms\nfor computing parity and addition, as well as a solution to the SCAN benchmark\nof compositional generalization tasks, without requiring intermediate\nscratchpad decoding steps. We also propose tools to analyze cases where the\nexpressibility of an algorithm is established, but end-to-end training on a\ngiven training set fails to induce behavior consistent with the desired\nalgorithm. To this end, we explore training from ALTA execution traces as a\nmore fine-grained supervision signal. This enables additional experiments and\ntheoretical analyses relating the learnability of various algorithms to data\navailability and modeling decisions, such as positional encodings. We make the\nALTA framework -- language specification, symbolic interpreter, and weight\ncompiler -- available to the community to enable further applications and\ninsights.\n","authors":["Peter Shaw","James Cohan","Jacob Eisenstein","Kenton Lee","Jonathan Berant","Kristina Toutanova"],"pdf_url":"https://arxiv.org/pdf/2410.18077v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18076v1","updated":"2024-10-23T17:58:45Z","published":"2024-10-23T17:58:45Z","title":"Leveraging Skills from Unlabeled Prior Data for Efficient Online\n  Exploration","summary":"  Unsupervised pretraining has been transformative in many supervised domains.\nHowever, applying such ideas to reinforcement learning (RL) presents a unique\nchallenge in that fine-tuning does not involve mimicking task-specific data,\nbut rather exploring and locating the solution through iterative\nself-improvement. In this work, we study how unlabeled prior trajectory data\ncan be leveraged to learn efficient exploration strategies. While prior data\ncan be used to pretrain a set of low-level skills, or as additional off-policy\ndata for online RL, it has been unclear how to combine these ideas effectively\nfor online exploration. Our method SUPE (Skills from Unlabeled Prior data for\nExploration) demonstrates that a careful combination of these ideas compounds\ntheir benefits. Our method first extracts low-level skills using a variational\nautoencoder (VAE), and then pseudo-relabels unlabeled trajectories using an\noptimistic reward model, transforming prior data into high-level, task-relevant\nexamples. Finally, SUPE uses these transformed examples as additional\noff-policy data for online RL to learn a high-level policy that composes\npretrained low-level skills to explore efficiently. We empirically show that\nSUPE reliably outperforms prior strategies, successfully solving a suite of\nlong-horizon, sparse-reward tasks. Code: https://github.com/rail-berkeley/supe.\n","authors":["Max Wilcoxson","Qiyang Li","Kevin Frans","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2410.18076v1.pdf","comment":"23 pages, 10 figures"},{"id":"http://arxiv.org/abs/2410.18071v1","updated":"2024-10-23T17:54:43Z","published":"2024-10-23T17:54:43Z","title":"TP-Eval: Tap Multimodal LLMs' Potential in Evaluation by Customizing\n  Prompts","summary":"  Recently, multimodal large language models (MLLMs) have received much\nattention for their impressive capabilities. The evaluation of MLLMs is\nbecoming critical to analyzing attributes of MLLMs and providing valuable\ninsights. However, current benchmarks overlook the problem of prompt\nsensitivity - minor prompt variations may lead to significant performance\nfluctuations. Thus, inappropriate prompts may obscure the models' capabilities,\nunderestimating the models' performance. Moreover, different models have\ndifferent preferences for different prompts, and thus, using the same prompt\nfor all models will cause evaluation bias. This paper analyzes this deficiency\nin existing benchmarks and further introduces a new evaluation framework named\nTP-Eval, which introduces a prompt customization method to reduce evaluation\nbiases and tap models' potential. TP-Eval will rewrite the original prompts to\ndifferent customized prompts for different models. In particular, we propose\nsome well-designed modules for prompt customization tailored to the scenario of\nMLLM evaluation. Extensive experiments demonstrate the effectiveness of our\napproach to uncovering models' capabilities, and TP-Eval should benefit the\ncommunity in developing more comprehensive and convincing MLLM evaluation\nbenchmarks.\n","authors":["Yuxuan Xie","Tianhua Li","Wenqi Shao","Kaipeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.18071v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.12568v2","updated":"2024-10-23T17:53:24Z","published":"2024-08-22T17:35:18Z","title":"Pruning By Explaining Revisited: Optimizing Attribution Methods to Prune\n  CNNs and Transformers","summary":"  To solve ever more complex problems, Deep Neural Networks are scaled to\nbillions of parameters, leading to huge computational costs. An effective\napproach to reduce computational requirements and increase efficiency is to\nprune unnecessary components of these often over-parameterized networks.\nPrevious work has shown that attribution methods from the field of eXplainable\nAI serve as effective means to extract and prune the least relevant network\ncomponents in a few-shot fashion. We extend the current state by proposing to\nexplicitly optimize hyperparameters of attribution methods for the task of\npruning, and further include transformer-based networks in our analysis. Our\napproach yields higher model compression rates of large transformer- and\nconvolutional architectures (VGG, ResNet, ViT) compared to previous works,\nwhile still attaining high performance on ImageNet classification tasks. Here,\nour experiments indicate that transformers have a higher degree of\nover-parameterization compared to convolutional neural networks. Code is\navailable at https://github.com/erfanhatefi/Pruning-by-eXplaining-in-PyTorch.\n","authors":["Sayed Mohammad Vakilzadeh Hatefi","Maximilian Dreyer","Reduan Achtibat","Thomas Wiegand","Wojciech Samek","Sebastian Lapuschkin"],"pdf_url":"https://arxiv.org/pdf/2408.12568v2.pdf","comment":"Accepted as a workshop paper at ECCV 2024, 26 pages (11 pages\n  manuscript, 3 pages references, 12 pages appendix)"},{"id":"http://arxiv.org/abs/2410.18070v1","updated":"2024-10-23T17:53:11Z","published":"2024-10-23T17:53:11Z","title":"Training Free Guided Flow Matching with Optimal Control","summary":"  Controlled generation with pre-trained Diffusion and Flow Matching models has\nvast applications. One strategy for guiding ODE-based generative models is\nthrough optimizing a target loss $R(x_1)$ while staying close to the prior\ndistribution. Along this line, some recent work showed the effectiveness of\nguiding flow model by differentiating through its ODE sampling process. Despite\nthe superior performance, the theoretical understanding of this line of methods\nis still preliminary, leaving space for algorithm improvement. Moreover,\nexisting methods predominately focus on Euclidean data manifold, and there is a\ncompelling need for guided flow methods on complex geometries such as SO(3),\nwhich prevails in high-stake scientific applications like protein design. We\npresent OC-Flow, a general and theoretically grounded training-free framework\nfor guided flow matching using optimal control. Building upon advances in\noptimal control theory, we develop effective and practical algorithms for\nsolving optimal control in guided ODE-based generation and provide a systematic\ntheoretical analysis of the convergence guarantee in both Euclidean and SO(3).\nWe show that existing backprop-through-ODE methods can be interpreted as\nspecial cases of Euclidean OC-Flow. OC-Flow achieved superior performance in\nextensive experiments on text-guided image manipulation, conditional molecule\ngeneration, and all-atom peptide design.\n","authors":["Luran Wang","Chaoran Cheng","Yizhen Liao","Yanru Qu","Ge Liu"],"pdf_url":"https://arxiv.org/pdf/2410.18070v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.03185v2","updated":"2024-10-23T17:52:57Z","published":"2024-03-05T18:22:15Z","title":"Correlated Proxies: A New Definition and Improved Mitigation for Reward\n  Hacking","summary":"  Because it is difficult to precisely specify complex objectives,\nreinforcement learning policies are often optimized using flawed proxy rewards\nthat seem to capture the true objective. However, optimizing proxy rewards\nfrequently leads to reward hacking: the optimized reward function ceases to be\na good proxy, and the resulting policy performs poorly with respect to the\nunspecified true reward. Principled solutions to reward hacking have been\nimpeded by the lack of a good definition for the problem. To address this, we\nintroduce a definition of reward hacking based on the correlation between proxy\nand true rewards for states and actions seen by a \"base policy\" that breaks\ndown under optimization. We show that this definition captures reward hacking\nbehavior across several realistic settings, including in reinforcement learning\nfrom human feedback (RLHF). We then show theoretically that regularization to\nthe base policy can effectively prevent reward hacking. While current RLHF\napproaches apply a KL penalty between the action distributions of policies, our\ntheory suggests that it is more effective to regularize using the $\\chi^2$\ndivergence between the policies' occupancy measures. We intuitively show why\nthis type of regularization is superior and demonstrate that it better\nmitigates reward hacking in practice across four realistic domains, including\nRLHF for LLMs. Our code is available at https://github.com/cassidylaidlaw/orpo.\n","authors":["Cassidy Laidlaw","Shivam Singhal","Anca Dragan"],"pdf_url":"https://arxiv.org/pdf/2403.03185v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13577v2","updated":"2024-10-23T17:50:54Z","published":"2023-11-22T18:32:03Z","title":"Physical Reasoning and Object Planning for Household Embodied Agents","summary":"  In this study, we explore the sophisticated domain of task planning for\nrobust household embodied agents, with a particular emphasis on the intricate\ntask of selecting substitute objects. We introduce the CommonSense Object\nAffordance Task (COAT), a novel framework designed to analyze reasoning\ncapabilities in commonsense scenarios. This approach is centered on\nunderstanding how these agents can effectively identify and utilize alternative\nobjects when executing household tasks, thereby offering insights into the\ncomplexities of practical decision-making in real-world environments. Drawing\ninspiration from factors affecting human decision-making, we explore how large\nlanguage models tackle this challenge through four meticulously crafted\ncommonsense question-and-answer datasets featuring refined rules and human\nannotations. Our evaluation of state-of-the-art language models on these\ndatasets sheds light on three pivotal considerations: 1) aligning an object's\ninherent utility with the task at hand, 2) navigating contextual dependencies\n(societal norms, safety, appropriateness, and efficiency), and 3) accounting\nfor the current physical state of the object. To maintain accessibility, we\nintroduce five abstract variables reflecting an object's physical condition,\nmodulated by human insights, to simulate diverse household scenarios. Our\ncontributions include insightful human preference mappings for all three\nfactors and four extensive QA datasets (2K, 15k, 60k, 70K questions) probing\nthe intricacies of utility dependencies, contextual dependencies and object\nphysical states. The datasets, along with our findings, are accessible at:\nhttps://github.com/Ayush8120/COAT. This research not only advances our\nunderstanding of physical commonsense reasoning in language models but also\npaves the way for future improvements in household agent intelligence.\n","authors":["Ayush Agrawal","Raghav Prabhakar","Anirudh Goyal","Dianbo Liu"],"pdf_url":"https://arxiv.org/pdf/2311.13577v2.pdf","comment":"Journal: TMLR(May/2024) Total: 39 pages (17 pages main content, 15\n  Figures)"},{"id":"http://arxiv.org/abs/2410.18067v1","updated":"2024-10-23T17:48:28Z","published":"2024-10-23T17:48:28Z","title":"Beyond position: how rotary embeddings shape representations and memory\n  in autoregressive transfomers","summary":"  Rotary Positional Embeddings (RoPE) enhance positional encoding in\nTransformer models, yet their full impact on model dynamics remains\nunderexplored. This paper studies how RoPE introduces position-dependent\nrotations, causing phase shifts in token embeddings that influence\nhigher-frequency components within the model's internal representations.\nThrough spectral analysis, we demonstrate that RoPE's rotation matrices induce\noscillatory behaviors in embeddings, affecting information retention across\nlayers and shaping temporal modeling capabilities. We show that activation\nfunctions in feed-forward networks interact with RoPE-modulated embeddings to\ngenerate harmonics, leading to constructive or destructive interference based\non phase alignment. Our findings reveal that phase alignment amplifies\nactivations and sharpens attention, while misalignment weakens activations and\ndisrupts focus on positional patterns. This study underscores the importance of\nfrequency components as intrinsic elements of model behavior, offering new\ninsights beyond traditional analyses.\n","authors":["Valeria Ruscio","Fabrizio Silvestri"],"pdf_url":"https://arxiv.org/pdf/2410.18067v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15240v2","updated":"2024-10-23T17:47:58Z","published":"2024-09-23T17:38:41Z","title":"MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue\n  Generation","summary":"  Long-term memory is important for chatbots and dialogue systems (DS) to\ncreate consistent and human-like conversations, evidenced by numerous developed\nmemory-augmented DS (MADS). To evaluate the effectiveness of such MADS,\nexisting commonly used evaluation metrics, like retrieval accuracy and\nperplexity (PPL), mainly focus on query-oriented factualness and language\nquality assessment. However, these metrics often lack practical value.\nMoreover, the evaluation dimensions are insufficient for human-like assessment\nin DS. Regarding memory-recalling paradigms, current evaluation schemes only\nconsider passive memory retrieval while ignoring diverse memory recall with\nrich triggering factors, e.g., emotions and surroundings, which can be\nessential in emotional support scenarios. To bridge the gap, we construct a\nnovel Memory-Augmented Dialogue Benchmark (MADail-Bench) covering various\nmemory-recalling paradigms based on cognitive science and psychology theories.\nThe benchmark assesses two tasks separately: memory retrieval and memory\nrecognition with the incorporation of both passive and proactive memory recall\ndata. We introduce new scoring criteria to the evaluation, including memory\ninjection, emotion support (ES) proficiency, and intimacy, to comprehensively\nassess generated responses. Results from cutting-edge embedding models and\nlarge language models on this benchmark indicate the potential for further\nadvancement. Extensive testing further reveals correlations between memory\ninjection, ES proficiency, and intimacy.\n","authors":["Junqing He","Liang Zhu","Rui Wang","Xi Wang","Reza Haffari","Jiaxing Zhang"],"pdf_url":"https://arxiv.org/pdf/2409.15240v2.pdf","comment":"Submitted to NAACL 2025"},{"id":"http://arxiv.org/abs/2407.15762v2","updated":"2024-10-23T17:42:39Z","published":"2024-07-22T16:13:38Z","title":"Conditional Language Policy: A General Framework for Steerable\n  Multi-Objective Finetuning","summary":"  Reward-based finetuning is crucial for aligning language policies with\nintended behaviors (e.g., creativity and safety). A key challenge is to develop\nsteerable language models that trade-off multiple (conflicting) objectives in a\nflexible and efficient manner. This paper presents Conditional Language Policy\n(CLP), a general framework for finetuning language models on multiple\nobjectives. Building on techniques from multi-task training and\nparameter-efficient finetuning, CLP learn steerable models that effectively\ntrade-off conflicting objectives at inference time. Notably, this does not\nrequire training or maintaining multiple models to achieve different trade-offs\nbetween the objectives. Through extensive experiments and ablations on two\nsummarization datasets, we show that CLP learns steerable language models that\noutperform and Pareto-dominate the existing approaches for multi-objective\nfinetuning.\n","authors":["Kaiwen Wang","Rahul Kidambi","Ryan Sullivan","Alekh Agarwal","Christoph Dann","Andrea Michi","Marco Gelmi","Yunxuan Li","Raghav Gupta","Avinava Dubey","Alexandre Ramé","Johan Ferret","Geoffrey Cideron","Le Hou","Hongkun Yu","Amr Ahmed","Aranyak Mehta","Léonard Hussenot","Olivier Bachem","Edouard Leurent"],"pdf_url":"https://arxiv.org/pdf/2407.15762v2.pdf","comment":"40 pages. Findings of EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.18065v1","updated":"2024-10-23T17:42:07Z","published":"2024-10-23T17:42:07Z","title":"SPIRE: Synergistic Planning, Imitation, and Reinforcement Learning for\n  Long-Horizon Manipulation","summary":"  Robot learning has proven to be a general and effective technique for\nprogramming manipulators. Imitation learning is able to teach robots solely\nfrom human demonstrations but is bottlenecked by the capabilities of the\ndemonstrations. Reinforcement learning uses exploration to discover better\nbehaviors; however, the space of possible improvements can be too large to\nstart from scratch. And for both techniques, the learning difficulty increases\nproportional to the length of the manipulation task. Accounting for this, we\npropose SPIRE, a system that first uses Task and Motion Planning (TAMP) to\ndecompose tasks into smaller learning subproblems and second combines imitation\nand reinforcement learning to maximize their strengths. We develop novel\nstrategies to train learning agents when deployed in the context of a planning\nsystem. We evaluate SPIRE on a suite of long-horizon and contact-rich robot\nmanipulation problems. We find that SPIRE outperforms prior approaches that\nintegrate imitation learning, reinforcement learning, and planning by 35% to\n50% in average task performance, is 6 times more data efficient in the number\nof human demonstrations needed to train proficient agents, and learns to\ncomplete tasks nearly twice as efficiently. View\nhttps://sites.google.com/view/spire-corl-2024 for more details.\n","authors":["Zihan Zhou","Animesh Garg","Dieter Fox","Caelan Garrett","Ajay Mandlekar"],"pdf_url":"https://arxiv.org/pdf/2410.18065v1.pdf","comment":"Conference on Robot Learning (CoRL) 2024"},{"id":"http://arxiv.org/abs/2405.18246v2","updated":"2024-10-23T17:33:57Z","published":"2024-05-28T14:58:07Z","title":"Utilitarian Algorithm Configuration for Infinite Parameter Spaces","summary":"  Utilitarian algorithm configuration is a general-purpose technique for\nautomatically searching the parameter space of a given algorithm to optimize\nits performance, as measured by a given utility function, on a given set of\ninputs. Recently introduced utilitarian configuration procedures offer\noptimality guarantees about the returned parameterization while provably\nadapting to the hardness of the underlying problem. However, the applicability\nof these approaches is severely limited by the fact that they only search a\nfinite, relatively small set of parameters. They cannot effectively search the\nconfiguration space of algorithms with continuous or uncountable parameters. In\nthis paper we introduce a new procedure, which we dub COUP (Continuous,\nOptimistic Utilitarian Procrastination). COUP is designed to search infinite\nparameter spaces efficiently to find good configurations quickly. Furthermore,\nCOUP maintains the theoretical benefits of previous utilitarian configuration\nprocedures when applied to finite parameter spaces but is significantly faster,\nboth provably and experimentally.\n","authors":["Devon Graham","Kevin Leyton-Brown"],"pdf_url":"https://arxiv.org/pdf/2405.18246v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18060v1","updated":"2024-10-23T17:33:27Z","published":"2024-10-23T17:33:27Z","title":"Explaining Bayesian Networks in Natural Language using Factor Arguments.\n  Evaluation in the medical domain","summary":"  In this paper, we propose a model for building natural language explanations\nfor Bayesian Network Reasoning in terms of factor arguments, which are\nargumentation graphs of flowing evidence, relating the observed evidence to a\ntarget variable we want to learn about. We introduce the notion of factor\nargument independence to address the outstanding question of defining when\narguments should be presented jointly or separately and present an algorithm\nthat, starting from the evidence nodes and a target node, produces a list of\nall independent factor arguments ordered by their strength. Finally, we\nimplemented a scheme to build natural language explanations of Bayesian\nReasoning using this approach. Our proposal has been validated in the medical\ndomain through a human-driven evaluation study where we compare the Bayesian\nNetwork Reasoning explanations obtained using factor arguments with an\nalternative explanation method. Evaluation results indicate that our proposed\nexplanation approach is deemed by users as significantly more useful for\nunderstanding Bayesian Network Reasoning than another existing explanation\nmethod it is compared to.\n","authors":["Jaime Sevilla","Nikolay Babakov","Ehud Reiter","Alberto Bugarin"],"pdf_url":"https://arxiv.org/pdf/2410.18060v1.pdf","comment":"First Workshop on Explainable Artificial Intelligence for the medical\n  domain - EXPLIMED. THE 27TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE"},{"id":"http://arxiv.org/abs/2410.02916v2","updated":"2024-10-23T17:26:06Z","published":"2024-10-03T19:07:53Z","title":"Safeguard is a Double-edged Sword: Denial-of-service Attack on Large\n  Language Models","summary":"  Safety is a paramount concern of large language models (LLMs) in their open\ndeployment. To this end, safeguard methods aim to enforce the ethical and\nresponsible use of LLMs through safety alignment or guardrail mechanisms.\nHowever, we found that the malicious attackers could exploit false positives of\nsafeguards, i.e., fooling the safeguard model to block safe content mistakenly,\nleading to a new denial-of-service (DoS) attack on LLMs. Specifically, by\nsoftware or phishing attacks on user client software, attackers insert a short,\nseemingly innocuous adversarial prompt into to user prompt templates in\nconfiguration files; thus, this prompt appears in final user requests without\nvisibility in the user interface and is not trivial to identify. By designing\nan optimization process that utilizes gradient and attention information, our\nattack can automatically generate seemingly safe adversarial prompts,\napproximately only 30 characters long, that universally block over 97\\% of user\nrequests on Llama Guard 3. The attack presents a new dimension of evaluating\nLLM safeguards focusing on false positives, fundamentally different from the\nclassic jailbreak.\n","authors":["Qingzhao Zhang","Ziyang Xiong","Z. Morley Mao"],"pdf_url":"https://arxiv.org/pdf/2410.02916v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18040v1","updated":"2024-10-23T17:07:32Z","published":"2024-10-23T17:07:32Z","title":"Key Algorithms for Keyphrase Generation: Instruction-Based LLMs for\n  Russian Scientific Keyphrases","summary":"  Keyphrase selection is a challenging task in natural language processing that\nhas a wide range of applications. Adapting existing supervised and unsupervised\nsolutions for the Russian language faces several limitations due to the rich\nmorphology of Russian and the limited number of training datasets available.\nRecent studies conducted on English texts show that large language models\n(LLMs) successfully address the task of generating keyphrases. LLMs allow\nachieving impressive results without task-specific fine-tuning, using text\nprompts instead. In this work, we access the performance of prompt-based\nmethods for generating keyphrases for Russian scientific abstracts. First, we\ncompare the performance of zero-shot and few-shot prompt-based methods,\nfine-tuned models, and unsupervised methods. Then we assess strategies for\nselecting keyphrase examples in a few-shot setting. We present the outcomes of\nhuman evaluation of the generated keyphrases and analyze the strengths and\nweaknesses of the models through expert assessment. Our results suggest that\nprompt-based methods can outperform common baselines even using simple text\nprompts.\n","authors":["Anna Glazkova","Dmitry Morozov","Timur Garipov"],"pdf_url":"https://arxiv.org/pdf/2410.18040v1.pdf","comment":"The 12th International Conference on Analysis of Images, Social\n  Networks and Texts (AIST'2024)"},{"id":"http://arxiv.org/abs/2410.18032v1","updated":"2024-10-23T17:02:59Z","published":"2024-10-23T17:02:59Z","title":"GraphTeam: Facilitating Large Language Model-based Graph Analysis via\n  Multi-Agent Collaboration","summary":"  Graphs are widely used for modeling relational data in real-world scenarios,\nsuch as social networks and urban computing. Existing LLM-based graph analysis\napproaches either integrate graph neural networks (GNNs) for specific machine\nlearning tasks, limiting their transferability, or rely solely on LLMs'\ninternal reasoning ability, resulting in suboptimal performance. To address\nthese limitations, we take advantage of recent advances in LLM-based agents,\nwhich have shown capabilities of utilizing external knowledge or tools for\nproblem solving. By simulating human problem-solving strategies such as analogy\nand collaboration, we propose a multi-agent system based on LLMs named\nGraphTeam, for graph analysis. GraphTeam consists of five LLM-based agents from\nthree modules, and the agents with different specialities can collaborate with\neach other to address complex problems. Specifically, (1) input-output\nnormalization module: the question agent extracts and refines four key\narguments from the original question, facilitating the problem understanding,\nand the answer agent organizes the results to meet the output requirement; (2)\nexternal knowledge retrieval module: we first build a knowledge base consisting\nof relevant documentation and experience information, and then the search agent\nretrieves the most relevant entries for each question. (3) problem-solving\nmodule: given the retrieved information from search agent, the coding agent\nuses established algorithms via programming to generate solutions, and in case\nthe coding agent does not work, the reasoning agent will directly compute the\nresults without programming. Extensive experiments on six graph analysis\nbenchmarks demonstrate that GraphTeam achieves state-of-the-art performance\nwith an average 25.85% improvement over the best baseline in terms of accuracy.\nThe code and data are available at https://github.com/BUPT-GAMMA/GraphTeam.\n","authors":["Xin Li","Qizhi Chu","Yubin Chen","Yang Liu","Yaoqi Liu","Zekai Yu","Weize Chen","Chen Qian","Chuan Shi","Cheng Yang"],"pdf_url":"https://arxiv.org/pdf/2410.18032v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.12025v2","updated":"2024-10-23T17:01:05Z","published":"2024-08-21T22:35:19Z","title":"Exploring Large Language Models for Feature Selection: A Data-centric\n  Perspective","summary":"  The rapid advancement of Large Language Models (LLMs) has significantly\ninfluenced various domains, leveraging their exceptional few-shot and zero-shot\nlearning capabilities. In this work, we aim to explore and understand the\nLLMs-based feature selection methods from a data-centric perspective. We begin\nby categorizing existing feature selection methods with LLMs into two groups:\ndata-driven feature selection which requires numerical values of samples to do\nstatistical inference and text-based feature selection which utilizes prior\nknowledge of LLMs to do semantical associations using descriptive context. We\nconduct experiments in both classification and regression tasks with LLMs in\nvarious sizes (e.g., GPT-4, ChatGPT and LLaMA-2). Our findings emphasize the\neffectiveness and robustness of text-based feature selection methods and\nshowcase their potentials using a real-world medical application. We also\ndiscuss the challenges and future opportunities in employing LLMs for feature\nselection, offering insights for further research and development in this\nemerging field.\n","authors":["Dawei Li","Zhen Tan","Huan Liu"],"pdf_url":"https://arxiv.org/pdf/2408.12025v2.pdf","comment":"Accepted by SIGKDD Explorations (December 2024)"},{"id":"http://arxiv.org/abs/2410.18027v1","updated":"2024-10-23T17:00:13Z","published":"2024-10-23T17:00:13Z","title":"Cross-lingual Transfer of Reward Models in Multilingual Alignment","summary":"  Reinforcement learning with human feedback (RLHF) is shown to largely benefit\nfrom precise reward models (RMs). However, recent studies in reward modeling\nschemes are skewed towards English, limiting the applicability of RLHF in\nmultilingual alignments. In this work, we investigate the cross-lingual\ntransfer of RMs trained in diverse languages, primarily from English. Our\nexperimental results demonstrate the strong cross-lingual transfer of English\nRMs, exceeding target language RMs by 3~4% average increase in Multilingual\nRewardBench. Furthermore, we analyze the cross-lingual transfer of RMs through\nthe representation shifts. Finally, we perform multilingual alignment to\nexemplify how cross-lingual transfer in RM propagates to enhanced multilingual\ninstruction-following capability, along with extensive analyses on\noff-the-shelf RMs. We release the code, model, and data.\n","authors":["Jiwoo Hong","Noah Lee","Rodrigo Martínez-Castaño","César Rodríguez","James Thorne"],"pdf_url":"https://arxiv.org/pdf/2410.18027v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.11757v4","updated":"2024-10-23T16:41:45Z","published":"2024-06-17T17:16:45Z","title":"STAR: SocioTechnical Approach to Red Teaming Language Models","summary":"  This research introduces STAR, a sociotechnical framework that improves on\ncurrent best practices for red teaming safety of large language models. STAR\nmakes two key contributions: it enhances steerability by generating\nparameterised instructions for human red teamers, leading to improved coverage\nof the risk surface. Parameterised instructions also provide more detailed\ninsights into model failures at no increased cost. Second, STAR improves signal\nquality by matching demographics to assess harms for specific groups, resulting\nin more sensitive annotations. STAR further employs a novel step of arbitration\nto leverage diverse viewpoints and improve label reliability, treating\ndisagreement not as noise but as a valuable contribution to signal quality.\n","authors":["Laura Weidinger","John Mellor","Bernat Guillen Pegueroles","Nahema Marchal","Ravin Kumar","Kristian Lum","Canfer Akbulut","Mark Diaz","Stevie Bergman","Mikel Rodriguez","Verena Rieser","William Isaac"],"pdf_url":"https://arxiv.org/pdf/2406.11757v4.pdf","comment":"8 pages, 5 figures, 5 pages appendix. * denotes equal contribution"},{"id":"http://arxiv.org/abs/2409.19841v2","updated":"2024-10-23T16:27:27Z","published":"2024-09-30T00:47:13Z","title":"Counter-Current Learning: A Biologically Plausible Dual Network Approach\n  for Deep Learning","summary":"  Despite its widespread use in neural networks, error backpropagation has\nfaced criticism for its lack of biological plausibility, suffering from issues\nsuch as the backward locking problem and the weight transport problem. These\nlimitations have motivated researchers to explore more biologically plausible\nlearning algorithms that could potentially shed light on how biological neural\nsystems adapt and learn. Inspired by the counter-current exchange mechanisms\nobserved in biological systems, we propose counter-current learning (CCL), a\nbiologically plausible framework for credit assignment in neural networks. This\nframework employs a feedforward network to process input data and a feedback\nnetwork to process targets, with each network enhancing the other through\nanti-parallel signal propagation. By leveraging the more informative signals\nfrom the bottom layer of the feedback network to guide the updates of the top\nlayer of the feedforward network and vice versa, CCL enables the simultaneous\ntransformation of source inputs to target outputs and the dynamic mutual\ninfluence of these transformations. Experimental results on MNIST,\nFashionMNIST, CIFAR10, and CIFAR100 datasets using multi-layer perceptrons and\nconvolutional neural networks demonstrate that CCL achieves comparable\nperformance to other biologically plausible algorithms while offering a more\nbiologically realistic learning mechanism. Furthermore, we showcase the\napplicability of our approach to an autoencoder task, underscoring its\npotential for unsupervised representation learning. Our work presents a\ndirection for biologically inspired and plausible learning algorithms, offering\nan alternative mechanism of learning and adaptation in neural networks.\n","authors":["Chia-Hsiang Kao","Bharath Hariharan"],"pdf_url":"https://arxiv.org/pdf/2409.19841v2.pdf","comment":"Accepted at NeurIPS 2024. Code available at\n  https://github.com/IandRover/CCL-NeurIPS24"},{"id":"http://arxiv.org/abs/2409.17270v2","updated":"2024-10-23T16:27:20Z","published":"2024-09-25T18:35:45Z","title":"Proof of Thought : Neurosymbolic Program Synthesis allows Robust and\n  Interpretable Reasoning","summary":"  Large Language Models (LLMs) have revolutionized natural language processing,\nyet they struggle with inconsistent reasoning, particularly in novel domains\nand complex logical sequences. This research introduces Proof of Thought, a\nframework that enhances the reliability and transparency of LLM outputs. Our\napproach bridges LLM-generated ideas with formal logic verification, employing\na custom interpreter to convert LLM outputs into First Order Logic constructs\nfor theorem prover scrutiny. Central to our method is an intermediary\nJSON-based Domain-Specific Language, which by design balances precise logical\nstructures with intuitive human concepts. This hybrid representation enables\nboth rigorous validation and accessible human comprehension of LLM reasoning\nprocesses. Key contributions include a robust type system with sort management\nfor enhanced logical integrity, explicit representation of rules for clear\ndistinction between factual and inferential knowledge, and a flexible\narchitecture that allows for easy extension to various domain-specific\napplications. We demonstrate Proof of Thought's effectiveness through\nbenchmarking on StrategyQA and a novel multimodal reasoning task, showing\nimproved performance in open-ended scenarios. By providing verifiable and\ninterpretable results, our technique addresses critical needs for AI system\naccountability and sets a foundation for human-in-the-loop oversight in\nhigh-stakes domains.\n","authors":["Debargha Ganguly","Srinivasan Iyengar","Vipin Chaudhary","Shivkumar Kalyanaraman"],"pdf_url":"https://arxiv.org/pdf/2409.17270v2.pdf","comment":"38th Conference on Neural Information Processing Systems (NeurIPS\n  2024) System 2 Reasoning At Scale Workshop"},{"id":"http://arxiv.org/abs/2410.18001v1","updated":"2024-10-23T16:24:23Z","published":"2024-10-23T16:24:23Z","title":"Benchmarking Foundation Models on Exceptional Cases: Dataset Creation\n  and Validation","summary":"  Foundation models (FMs) have achieved significant success across various\ntasks, leading to research on benchmarks for reasoning abilities. However,\nthere is a lack of studies on FMs performance in exceptional scenarios, which\nwe define as out-of-distribution (OOD) reasoning tasks. This paper is the first\nto address these cases, developing a novel dataset for evaluation of FMs across\nmultiple modalities, including graphic novels, calligraphy, news articles, and\nlyrics. It includes tasks for instance classification, character recognition,\ntoken prediction, and text generation. The paper also proposes prompt\nengineering techniques like Chain-of-Thought (CoT) and CoT+Few-Shot to enhance\nperformance. Validation of FMs using various methods revealed improvements. The\ncode repository is accessible at:\nhttps://github.com/MLAI-Yonsei/ExceptionalBenchmark\n","authors":["Suho Kang","Jungyang Park","Joonseo Ha","SoMin Kim","JinHyeong Kim","Subeen Park","Kyungwoo Song"],"pdf_url":"https://arxiv.org/pdf/2410.18001v1.pdf","comment":"EMNLP 2024 Workshop\n  Genbench(https://genbench.org/workshop_programme/)"},{"id":"http://arxiv.org/abs/2410.17991v1","updated":"2024-10-23T16:08:00Z","published":"2024-10-23T16:08:00Z","title":"AI driven health recommender","summary":"  As AI emerged as highest valued technology, We used that to create a web\napplication that makes a patient work easier .It detects the disease name based\non the symptoms given by the patient and recommends medication for respective\ndisease, precautions to take, diet to follow and workouts to do, so the disease\ncan be minimized. The web application is made with clean and Realtime data by\nusing Machine learning as root. We used flask to create a user-friendly\nplatform.\n","authors":["K. Vignesh","B. Pranavi","Ch. Sreenidhi"],"pdf_url":"https://arxiv.org/pdf/2410.17991v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.02131v4","updated":"2024-10-23T16:05:11Z","published":"2024-06-04T09:18:20Z","title":"CondTSF: One-line Plugin of Dataset Condensation for Time Series\n  Forecasting","summary":"  Dataset condensation is a newborn technique that generates a small dataset\nthat can be used in training deep neural networks to lower training costs. The\nobjective of dataset condensation is to ensure that the model trained with the\nsynthetic dataset can perform comparably to the model trained with full\ndatasets. However, existing methods predominantly concentrate on classification\ntasks, posing challenges in their adaptation to time series forecasting\n(TS-forecasting). This challenge arises from disparities in the evaluation of\nsynthetic data. In classification, the synthetic data is considered\nwell-distilled if the model trained with the full dataset and the model trained\nwith the synthetic dataset yield identical labels for the same input,\nregardless of variations in output logits distribution. Conversely, in\nTS-forecasting, the effectiveness of synthetic data distillation is determined\nby the distance between predictions of the two models. The synthetic data is\ndeemed well-distilled only when all data points within the predictions are\nsimilar. Consequently, TS-forecasting has a more rigorous evaluation\nmethodology compared to classification. To mitigate this gap, we theoretically\nanalyze the optimization objective of dataset condensation for TS-forecasting\nand propose a new one-line plugin of dataset condensation designated as Dataset\nCondensation for Time Series Forecasting (CondTSF) based on our analysis.\nPlugging CondTSF into previous dataset condensation methods facilitates a\nreduction in the distance between the predictions of the model trained with the\nfull dataset and the model trained with the synthetic dataset, thereby\nenhancing performance. We conduct extensive experiments on eight commonly used\ntime series datasets. CondTSF consistently improves the performance of all\nprevious dataset condensation methods across all datasets, particularly at low\ncondensing ratios.\n","authors":["Jianrong Ding","Zhanyu Liu","Guanjie Zheng","Haiming Jin","Linghe Kong"],"pdf_url":"https://arxiv.org/pdf/2406.02131v4.pdf","comment":"Accepted by NeurIPS 2024, the project can be found at\n  https://github.com/RafaDD/CondTSF"},{"id":"http://arxiv.org/abs/2410.17986v1","updated":"2024-10-23T16:00:14Z","published":"2024-10-23T16:00:14Z","title":"Federated Transformer: Multi-Party Vertical Federated Learning on\n  Practical Fuzzily Linked Data","summary":"  Federated Learning (FL) is an evolving paradigm that enables multiple parties\nto collaboratively train models without sharing raw data. Among its variants,\nVertical Federated Learning (VFL) is particularly relevant in real-world,\ncross-organizational collaborations, where distinct features of a shared\ninstance group are contributed by different parties. In these scenarios,\nparties are often linked using fuzzy identifiers, leading to a common practice\ntermed as multi-party fuzzy VFL. Existing models generally address either\nmulti-party VFL or fuzzy VFL between two parties. Extending these models to\npractical multi-party fuzzy VFL typically results in significant performance\ndegradation and increased costs for maintaining privacy. To overcome these\nlimitations, we introduce the Federated Transformer (FeT), a novel framework\nthat supports multi-party VFL with fuzzy identifiers. FeT innovatively encodes\nthese identifiers into data representations and employs a transformer\narchitecture distributed across different parties, incorporating three new\ntechniques to enhance performance. Furthermore, we have developed a multi-party\nprivacy framework for VFL that integrates differential privacy with secure\nmulti-party computation, effectively protecting local representations while\nminimizing associated utility costs. Our experiments demonstrate that the FeT\nsurpasses the baseline models by up to 46\\% in terms of accuracy when scaled to\n50 parties. Additionally, in two-party fuzzy VFL settings, FeT also shows\nimproved performance and privacy over cutting-edge VFL models.\n","authors":["Zhaomin Wu","Junyi Hou","Yiqun Diao","Bingsheng He"],"pdf_url":"https://arxiv.org/pdf/2410.17986v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14979v2","updated":"2024-10-23T15:43:28Z","published":"2024-10-19T05:01:56Z","title":"Do Large Language Models Truly Grasp Mathematics? An Empirical\n  Exploration","summary":"  Despite their proficiency in math tasks, the mechanisms underlying LLMs'\nmathematical reasoning abilities remain a subject of debate. Recent studies\nsuggest that chain-of-thought (CoT) prompts can bolster mathematical reasoning\nby encouraging LLMs to employ human-like logical reasoning (System 2), enabling\nthem to excel on the Cognitive Reflection Test (CRT). To assess whether LLMs\ngenuinely possess System 2-like logical reasoning, we introduced targeted\nmodifications to CRT problems. Our findings reveal that, despite the use of CoT\nprompts, mainstream LLMs, including the latest o1-preview model, continue to\nexhibit a significant error rate. Further analysis indicates that they\npredominantly rely on System 1-like intuitive reasoning and pattern matching\nderived from training data, rather than demonstrating mastery of mathematical\nthinking. This discovery challenges the prevailing notion that LLMs possess\ngenuine logical reasoning abilities and that CoT can enhance them.\nConsequently, this work may temper overly optimistic projections regarding\nLLMs' advancement toward artificial general intelligence.\n","authors":["Wei Xie","Shuoyoucheng Ma","Zhenhua Wang","Enze Wang","Baosheng Wang","Jinshu Su"],"pdf_url":"https://arxiv.org/pdf/2410.14979v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17971v1","updated":"2024-10-23T15:36:43Z","published":"2024-10-23T15:36:43Z","title":"Dynamic Spectrum Access for Ambient Backscatter Communication-assisted\n  D2D Systems with Quantum Reinforcement Learning","summary":"  Spectrum access is an essential problem in device-to-device (D2D)\ncommunications. However, with the recent growth in the number of mobile\ndevices, the wireless spectrum is becoming scarce, resulting in low spectral\nefficiency for D2D communications. To address this problem, this paper aims to\nintegrate the ambient backscatter communication technology into D2D devices to\nallow them to backscatter ambient RF signals to transmit their data when the\nshared spectrum is occupied by mobile users. To obtain the optimal spectrum\naccess policy, i.e., stay idle or access the shared spectrum and perform active\ntransmissions or backscattering ambient RF signals for transmissions, to\nmaximize the average throughput for D2D users, deep reinforcement learning\n(DRL) can be adopted. However, DRL-based solutions may require long training\ntime due to the curse of dimensionality issue as well as complex deep neural\nnetwork architectures. For that, we develop a novel quantum reinforcement\nlearning (RL) algorithm that can achieve a faster convergence rate with fewer\ntraining parameters compared to DRL thanks to the quantum superposition and\nquantum entanglement principles. Specifically, instead of using conventional\ndeep neural networks, the proposed quantum RL algorithm uses a parametrized\nquantum circuit to approximate an optimal policy. Extensive simulations then\ndemonstrate that the proposed solution not only can significantly improve the\naverage throughput of D2D devices when the shared spectrum is busy but also can\nachieve much better performance in terms of convergence rate and learning\ncomplexity compared to existing DRL-based methods.\n","authors":["Nguyen Van Huynh","Bolun Zhang","Dinh-Hieu Tran","Dinh Thai Hoang","Diep N. Nguyen","Gan Zheng","Dusit Niyato","Quoc-Viet Pham"],"pdf_url":"https://arxiv.org/pdf/2410.17971v1.pdf","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.17961v1","updated":"2024-10-23T15:30:13Z","published":"2024-10-23T15:30:13Z","title":"Closed-form merging of parameter-efficient modules for Federated\n  Continual Learning","summary":"  Model merging has emerged as a crucial technique in Deep Learning, enabling\nthe integration of multiple models into a unified system while preserving\nperformance and scalability. In this respect, the compositional properties of\nlow-rank adaptation techniques (e.g., LoRA) have proven beneficial, as simple\naveraging LoRA modules yields a single model that mostly integrates the\ncapabilities of all individual modules. Building on LoRA, we take a step\nfurther by imposing that the merged model matches the responses of all learned\nmodules. Solving this objective in closed form yields an indeterminate system\nwith A and B as unknown variables, indicating the existence of infinitely many\nclosed-form solutions. To address this challenge, we introduce LoRM, an\nalternating optimization strategy that trains one LoRA matrix at a time. This\nallows solving for each unknown variable individually, thus finding a unique\nsolution. We apply our proposed methodology to Federated Class-Incremental\nLearning (FCIL), ensuring alignment of model responses both between clients and\nacross tasks. Our method demonstrates state-of-the-art performance across a\nrange of FCIL scenarios.\n","authors":["Riccardo Salami","Pietro Buzzega","Matteo Mosconi","Jacopo Bonato","Luigi Sabetta","Simone Calderara"],"pdf_url":"https://arxiv.org/pdf/2410.17961v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.05101v3","updated":"2024-10-23T15:28:45Z","published":"2024-04-07T22:53:43Z","title":"StockGPT: A GenAI Model for Stock Prediction and Trading","summary":"  This paper introduces StockGPT, an autoregressive ``number'' model trained\nand tested on 70 million daily U.S.\\ stock returns over nearly 100 years.\nTreating each return series as a sequence of tokens, StockGPT automatically\nlearns the hidden patterns predictive of future returns via its attention\nmechanism. On a held-out test sample from 2001 to 2023, daily and monthly\nrebalanced long-short portfolios formed from StockGPT predictions yield strong\nperformance. The StockGPT-based portfolios span momentum and long-/short-term\nreversals, eliminating the need for manually crafted price-based strategies,\nand yield highly significant alphas against leading stock market factors,\nsuggesting a novel AI pricing effect. This highlights the immense promise of\ngenerative AI in surpassing human in making complex financial investment\ndecisions.\n","authors":["Dat Mai"],"pdf_url":"https://arxiv.org/pdf/2404.05101v3.pdf","comment":"26 pages, 3 figures, 8 tables"},{"id":"http://arxiv.org/abs/2410.17957v1","updated":"2024-10-23T15:27:37Z","published":"2024-10-23T15:27:37Z","title":"MCUBERT: Memory-Efficient BERT Inference on Commodity Microcontrollers","summary":"  In this paper, we propose MCUBERT to enable language models like BERT on tiny\nmicrocontroller units (MCUs) through network and scheduling co-optimization. We\nobserve the embedding table contributes to the major storage bottleneck for\ntiny BERT models. Hence, at the network level, we propose an MCU-aware\ntwo-stage neural architecture search algorithm based on clustered low-rank\napproximation for embedding compression. To reduce the inference memory\nrequirements, we further propose a novel fine-grained MCU-friendly scheduling\nstrategy. Through careful computation tiling and re-ordering as well as kernel\ndesign, we drastically increase the input sequence lengths supported on MCUs\nwithout any latency or accuracy penalty. MCUBERT reduces the parameter size of\nBERT-tiny and BERT-mini by 5.7$\\times$ and 3.0$\\times$ and the execution memory\nby 3.5$\\times$ and 4.3$\\times$, respectively. MCUBERT also achieves 1.5$\\times$\nlatency reduction. For the first time, MCUBERT enables lightweight BERT models\non commodity MCUs and processing more than 512 tokens with less than 256KB of\nmemory.\n","authors":["Zebin Yang","Renze Chen","Taiqiang Wu","Ngai Wong","Yun Liang","Runsheng Wang","Ru Huang","Meng Li"],"pdf_url":"https://arxiv.org/pdf/2410.17957v1.pdf","comment":"ICCAD 2024"},{"id":"http://arxiv.org/abs/2410.17954v1","updated":"2024-10-23T15:24:54Z","published":"2024-10-23T15:24:54Z","title":"ExpertFlow: Optimized Expert Activation and Token Allocation for\n  Efficient Mixture-of-Experts Inference","summary":"  Sparse Mixture of Experts (MoE) models, while outperforming dense Large\nLanguage Models (LLMs) in terms of performance, face significant deployment\nchallenges during inference due to their high memory demands. Existing\noffloading techniques, which involve swapping activated and idle experts\nbetween the GPU and CPU, often suffer from rigid expert caching mechanisms.\nThese mechanisms fail to adapt to dynamic routing, leading to inefficient cache\nutilization, or incur prohibitive costs for prediction training. To tackle\nthese inference-specific challenges, we introduce ExpertFlow, a comprehensive\nsystem specifically designed to enhance inference efficiency by accommodating\nflexible routing and enabling efficient expert scheduling between CPU and GPU.\nThis reduces overhead and boosts system performance. Central to our approach is\na predictive routing path-based offloading mechanism that utilizes a\nlightweight predictor to accurately forecast routing paths before computation\nbegins. This proactive strategy allows for real-time error correction in expert\ncaching, significantly increasing cache hit ratios and reducing the frequency\nof expert transfers, thereby minimizing I/O overhead. Additionally, we\nimplement a dynamic token scheduling strategy that optimizes MoE inference by\nrearranging input tokens across different batches. This method not only reduces\nthe number of activated experts per batch but also improves computational\nefficiency. Our extensive experiments demonstrate that ExpertFlow achieves up\nto 93.72\\% GPU memory savings and enhances inference speed by 2 to 10 times\ncompared to baseline methods, highlighting its effectiveness and utility as a\nrobust solution for resource-constrained inference scenarios.\n","authors":["Xin He","Shunkang Zhang","Yuxin Wang","Haiyan Yin","Zihao Zeng","Shaohuai Shi","Zhenheng Tang","Xiaowen Chu","Ivor Tsang","Ong Yew Soon"],"pdf_url":"https://arxiv.org/pdf/2410.17954v1.pdf","comment":"Mixture-of-Experts, Inference, Offloading"},{"id":"http://arxiv.org/abs/2410.17952v1","updated":"2024-10-23T15:24:16Z","published":"2024-10-23T15:24:16Z","title":"SimRAG: Self-Improving Retrieval-Augmented Generation for Adapting Large\n  Language Models to Specialized Domains","summary":"  Retrieval-augmented generation (RAG) enhances the question-answering (QA)\nabilities of large language models (LLMs) by integrating external knowledge.\nHowever, adapting general-purpose RAG systems to specialized fields such as\nscience and medicine poses unique challenges due to distribution shifts and\nlimited access to domain-specific data. To tackle this, we propose SimRAG, a\nself-training approach that equips the LLM with joint capabilities of question\nanswering and question generation for domain adaptation. Our method first\nfine-tunes the LLM on instruction-following, question-answering, and\nsearch-related data. Then, it prompts the same LLM to generate diverse\ndomain-relevant questions from unlabeled corpora, with an additional filtering\nstrategy to retain high-quality synthetic examples. By leveraging these\nsynthetic examples, the LLM can improve their performance on domain-specific\nRAG tasks. Experiments on 11 datasets, spanning two backbone sizes and three\ndomains, demonstrate that SimRAG outperforms baselines by 1.2\\%--8.6\\%.\n","authors":["Ran Xu","Hui Liu","Sreyashi Nag","Zhenwei Dai","Yaochen Xie","Xianfeng Tang","Chen Luo","Yang Li","Joyce C. Ho","Carl Yang","Qi He"],"pdf_url":"https://arxiv.org/pdf/2410.17952v1.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2410.17950v1","updated":"2024-10-23T15:23:23Z","published":"2024-10-23T15:23:23Z","title":"Benchmarking Floworks against OpenAI & Anthropic: A Novel Framework for\n  Enhanced LLM Function Calling","summary":"  Large Language Models (LLMs) have shown remarkable capabilities in various\ndomains, yet their economic impact has been limited by challenges in tool use\nand function calling. This paper introduces ThorV2, a novel architecture that\nsignificantly enhances LLMs' function calling abilities. We develop a\ncomprehensive benchmark focused on HubSpot CRM operations to evaluate ThorV2\nagainst leading models from OpenAI and Anthropic. Our results demonstrate that\nThorV2 outperforms existing models in accuracy, reliability, latency, and cost\nefficiency for both single and multi-API calling tasks. We also show that\nThorV2 is far more reliable and scales better to multistep tasks compared to\ntraditional models. Our work offers the tantalizing possibility of more\naccurate function-calling compared to today's best-performing models using\nsignificantly smaller LLMs. These advancements have significant implications\nfor the development of more capable AI assistants and the broader application\nof LLMs in real-world scenarios.\n","authors":["Nirav Bhan","Shival Gupta","Sai Manaswini","Ritik Baba","Narun Yadav","Hillori Desai","Yash Choudhary","Aman Pawar","Sarthak Shrivastava","Sudipta Biswas"],"pdf_url":"https://arxiv.org/pdf/2410.17950v1.pdf","comment":"15 pages for main paper, 21 pages in total including references and\n  appendix, 10 figures"},{"id":"http://arxiv.org/abs/2410.17943v1","updated":"2024-10-23T15:15:56Z","published":"2024-10-23T15:15:56Z","title":"Optimizing Travel Itineraries with AI Algorithms in a Microservices\n  Architecture: Balancing Cost, Time, Preferences, and Sustainability","summary":"  The objective of this research is how an implementation of AI algorithms in\nthe microservices architecture enhances travel itineraries by cost, time, user\npreferences, and environmental sustainability. It uses machine learning models\nfor both cost forecasting and personalization, genetic algorithm for\noptimization of the itinerary, and heuristics for sustainability checking.\nPrimary evaluated parameters consist of latency, ability to satisfy user\npreferences, cost and environmental concern. The experimental results\ndemonstrate an average of 4.5 seconds of response time on 1000 concurrent users\nand 92% of user preferences accuracy. The cost efficiency is proved, with 95%\nof provided trips being within the limits of the budget declared by the user.\nThe system also implements some measures to alleviate negative externalities\nrelated to travel and 60% of offered travel plans had green options\nincorporated, resulting in the average 15% lower carbon emissions than the\ntraditional travel plans offered. The genetic algorithm with time complexity\nO(g.p.f) provides the optimal solution in 100 generations. Every iteration\nimproves the quality of the solution by 5%, thus enabling its effective use in\noptimization problems where time is measured in seconds. Finally, the system is\ndesigned to be fault-tolerant with functional 99.9% availability which allows\nthe provision of services even when requirements are exceeded. Travel\noptimization platform is turned dynamic and efficient by this microservices\nbased architecture which provides enhanced scaling, allows asynchronous\ncommunication and real time changes. Because of the incorporation of Ai, cost\ncontrol and eco-friendliness approaches, the system addresses the different\nuser needs in the present days travel business.\n","authors":["Biman Barua","M. Shamim Kaiser"],"pdf_url":"https://arxiv.org/pdf/2410.17943v1.pdf","comment":"18 pages, 6 figures"},{"id":"http://arxiv.org/abs/2408.03093v2","updated":"2024-10-23T15:01:34Z","published":"2024-08-06T10:48:15Z","title":"Certifiably Robust Policies for Uncertain Parametric Environments","summary":"  We present a data-driven approach for producing policies that are provably\nrobust across unknown stochastic environments. Existing approaches can learn\nmodels of a single environment as an interval Markov decision processes (IMDP)\nand produce a robust policy with a probably approximately correct (PAC)\nguarantee on its performance. However these are unable to reason about the\nimpact of environmental parameters underlying the uncertainty. We propose a\nframework based on parametric Markov decision processes (MDPs) with unknown\ndistributions over parameters. We learn and analyse IMDPs for a set of unknown\nsample environments induced by parameters. The key challenge is then to produce\nmeaningful performance guarantees that combine the two layers of uncertainty:\n(1) multiple environments induced by parameters with an unknown distribution;\n(2) unknown induced environments which are approximated by IMDPs. We present a\nnovel approach based on scenario optimisation that yields a single PAC\nguarantee quantifying the risk level for which a specified performance level\ncan be assured in unseen environments, plus a means to trade-off risk and\nperformance. We implement and evaluate our framework using multiple robust\npolicy generation methods on a range of benchmarks. We show that our approach\nproduces tight bounds on a policy's performance with high confidence.\n","authors":["Yannik Schnitzer","Alessandro Abate","David Parker"],"pdf_url":"https://arxiv.org/pdf/2408.03093v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17933v1","updated":"2024-10-23T14:55:53Z","published":"2024-10-23T14:55:53Z","title":"Multi-Continental Healthcare Modelling Using Blockchain-Enabled\n  Federated Learning","summary":"  One of the biggest challenges of building artificial intelligence (AI) model\nin healthcare area is the data sharing. Since healthcare data is private,\nsensitive, and heterogeneous, collecting sufficient data for modelling is\nexhausted, costly, and sometimes impossible. In this paper, we propose a\nframework for global healthcare modelling using datasets from multi-continents\n(Europe, North America and Asia) while without sharing the local datasets, and\nchoose glucose management as a study model to verify its effectiveness.\nTechnically, blockchain-enabled federated learning is implemented with adaption\nto make it meet with the privacy and safety requirements of healthcare data,\nmeanwhile rewards honest participation and penalize malicious activities using\nits on-chain incentive mechanism. Experimental results show that the proposed\nframework is effective, efficient, and privacy preserved. Its prediction\naccuracy is much better than the models trained from limited personal data and\nis similar to, and even slightly better than, the results from a centralized\ndataset. This work paves the way for international collaborations on healthcare\nprojects, where additional data is crucial for reducing bias and providing\nbenefits to humanity.\n","authors":["Rui Sun","Zhipeng Wang","Hengrui Zhang","Ming Jiang","Yizhe Wen","Jiqun Zhang","Jiahao Sun","Shuoying Zhang","Erwu Liu","Kezhi Li"],"pdf_url":"https://arxiv.org/pdf/2410.17933v1.pdf","comment":"Accepted by IEEE Global Blockchain Conference"},{"id":"http://arxiv.org/abs/2410.02240v4","updated":"2024-10-23T14:53:38Z","published":"2024-10-03T06:25:53Z","title":"SCA: Highly Efficient Semantic-Consistent Unrestricted Adversarial\n  Attack","summary":"  Deep neural network based systems deployed in sensitive environments are\nvulnerable to adversarial attacks. Unrestricted adversarial attacks typically\nmanipulate the semantic content of an image (e.g., color or texture) to create\nadversarial examples that are both effective and photorealistic. Recent works\nhave utilized the diffusion inversion process to map images into a latent\nspace, where high-level semantics are manipulated by introducing perturbations.\nHowever, they often results in substantial semantic distortions in the denoised\noutput and suffers from low efficiency. In this study, we propose a novel\nframework called Semantic-Consistent Unrestricted Adversarial Attacks (SCA),\nwhich employs an inversion method to extract edit-friendly noise maps and\nutilizes Multimodal Large Language Model (MLLM) to provide semantic guidance\nthroughout the process. Under the condition of rich semantic information\nprovided by MLLM, we perform the DDPM denoising process of each step using a\nseries of edit-friendly noise maps, and leverage DPM Solver++ to accelerate\nthis process, enabling efficient sampling with semantic consistency. Compared\nto existing methods, our framework enables the efficient generation of\nadversarial examples that exhibit minimal discernible semantic changes.\nConsequently, we for the first time introduce Semantic-Consistent Adversarial\nExamples (SCAE). Extensive experiments and visualizations have demonstrated the\nhigh efficiency of SCA, particularly in being on average 12 times faster than\nthe state-of-the-art attacks. Our research can further draw attention to the\nsecurity of multimedia information.\n","authors":["Zihao Pan","Weibin Wu","Yuhang Cao","Zibin Zheng"],"pdf_url":"https://arxiv.org/pdf/2410.02240v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.08401v3","updated":"2024-10-23T14:48:44Z","published":"2024-04-12T11:15:15Z","title":"PnLCalib: Sports Field Registration via Points and Lines Optimization","summary":"  Camera calibration in broadcast sports videos presents numerous challenges\nfor accurate sports field registration due to multiple camera angles, varying\ncamera parameters, and frequent occlusions of the field. Traditional\nsearch-based methods depend on initial camera pose estimates, which can\nstruggle in non-standard positions and dynamic environments. In response, we\npropose an optimization-based calibration pipeline that leverages a 3D soccer\nfield model and a predefined set of keypoints to overcome these limitations.\nOur method also introduces a novel refinement module that improves initial\ncalibration by using detected field lines in a non-linear optimization process.\nThis approach outperforms existing techniques in both multi-view and\nsingle-view 3D camera calibration tasks, while maintaining competitive\nperformance in homography estimation. Extensive experimentation on real-world\nsoccer datasets, including SoccerNet-Calibration, WorldCup 2014, and\nTS-WorldCup, highlights the robustness and accuracy of our method across\ndiverse broadcast scenarios. Our approach offers significant improvements in\ncamera calibration precision and reliability.\n","authors":["Marc Gutiérrez-Pérez","Antonio Agudo"],"pdf_url":"https://arxiv.org/pdf/2404.08401v3.pdf","comment":"Extended version of \"No Bells, Just Whistles: Sports Field\n  Registration Leveraging Geometric Properties\""},{"id":"http://arxiv.org/abs/2310.10107v4","updated":"2024-10-23T14:47:42Z","published":"2023-10-16T06:41:13Z","title":"Posterior Sampling-based Online Learning for Episodic POMDPs","summary":"  Learning in POMDPs is known to be significantly harder than in MDPs. In this\npaper, we consider the online learning problem for episodic POMDPs with unknown\ntransition and observation models. We propose a Posterior Sampling-based\nreinforcement learning algorithm for POMDPs (PS4POMDPs), which is much simpler\nand more implementable compared to state-of-the-art optimism-based online\nlearning algorithms for POMDPs. We show that the Bayesian regret of the\nproposed algorithm scales as the square root of the number of episodes and is\npolynomial in the other parameters. In a general setting, the regret scales\nexponentially in the horizon length $H$, and we show that this is inevitable by\nproviding a lower bound. However, when the POMDP is undercomplete and weakly\nrevealing (a common assumption in the recent literature), we establish a\npolynomial Bayesian regret bound. We finally propose a posterior sampling\nalgorithm for multi-agent POMDPs, and show it too has sublinear regret.\n","authors":["Dengwang Tang","Dongze Ye","Rahul Jain","Ashutosh Nayyar","Pierluigi Nuzzo"],"pdf_url":"https://arxiv.org/pdf/2310.10107v4.pdf","comment":"41 pages, 9 figures"},{"id":"http://arxiv.org/abs/2312.05349v3","updated":"2024-10-23T14:47:10Z","published":"2023-12-08T20:12:26Z","title":"PixLore: A Dataset-driven Approach to Rich Image Captioning","summary":"  In the domain of vision-language integration, generating detailed image\ncaptions poses a significant challenge due to the lack of curated and rich\ndatasets. This study introduces PixLore, a novel method that leverages Querying\nTransformers through the fine-tuning of the BLIP-2 model using the LoRa method\non a standard commercial GPU. The followed approach, which involves training on\na carefully assembled dataset from state-of-the-art Computer Vision models\ncombined and augmented by ChatGPT, addresses the question of whether intricate\nimage understanding can be achieved with an ensemble of smaller-scale models,\nreferred to as Knowledge Stitching. Comparative evaluations against major\nmodels such as GPT-4 and Google Bard demonstrate that PixLore-2.7B, despite\nhaving considerably fewer parameters, is rated higher than the existing\nState-of-the-Art models in over half of the assessments. Precisely, PixLore\noutperform Bard and BLIP-2, which score approximately 35.18% and 27.98% lower\nthan PixLore in the task of image captioning. This research not only presents a\ngroundbreaking approach but also highlights the importance of well-curated\ndatasets in enhancing the performance of smaller models.\n","authors":["Diego Bonilla-Salvador","Marcelino Martínez-Sober","Joan Vila-Francés","Antonio José Serrano-López","Pablo Rodríguez-Belenguer","Fernando Mateo"],"pdf_url":"https://arxiv.org/pdf/2312.05349v3.pdf","comment":"Paper in preprint pending of publication"},{"id":"http://arxiv.org/abs/2410.17922v1","updated":"2024-10-23T14:40:37Z","published":"2024-10-23T14:40:37Z","title":"Guide for Defense (G4D): Dynamic Guidance for Robust and Balanced\n  Defense in Large Language Models","summary":"  With the extensive deployment of Large Language Models (LLMs), ensuring their\nsafety has become increasingly critical. However, existing defense methods\noften struggle with two key issues: (i) inadequate defense capabilities,\nparticularly in domain-specific scenarios like chemistry, where a lack of\nspecialized knowledge can lead to the generation of harmful responses to\nmalicious queries. (ii) over-defensiveness, which compromises the general\nutility and responsiveness of LLMs. To mitigate these issues, we introduce a\nmulti-agents-based defense framework, Guide for Defense (G4D), which leverages\naccurate external information to provide an unbiased summary of user intentions\nand analytically grounded safety response guidance. Extensive experiments on\npopular jailbreak attacks and benign datasets show that our G4D can enhance\nLLM's robustness against jailbreak attacks on general and domain-specific\nscenarios without compromising the model's general functionality.\n","authors":["He Cao","Weidi Luo","Yu Wang","Zijing Liu","Bing Feng","Yuan Yao","Yu Li"],"pdf_url":"https://arxiv.org/pdf/2410.17922v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17918v1","updated":"2024-10-23T14:34:39Z","published":"2024-10-23T14:34:39Z","title":"Addressing Asynchronicity in Clinical Multimodal Fusion via\n  Individualized Chest X-ray Generation","summary":"  Integrating multi-modal clinical data, such as electronic health records\n(EHR) and chest X-ray images (CXR), is particularly beneficial for clinical\nprediction tasks. However, in a temporal setting, multi-modal data are often\ninherently asynchronous. EHR can be continuously collected but CXR is generally\ntaken with a much longer interval due to its high cost and radiation dose. When\nclinical prediction is needed, the last available CXR image might have been\noutdated, leading to suboptimal predictions. To address this challenge, we\npropose DDL-CXR, a method that dynamically generates an up-to-date latent\nrepresentation of the individualized CXR images. Our approach leverages latent\ndiffusion models for patient-specific generation strategically conditioned on a\nprevious CXR image and EHR time series, providing information regarding\nanatomical structures and disease progressions, respectively. In this way, the\ninteraction across modalities could be better captured by the latent CXR\ngeneration process, ultimately improving the prediction performance.\nExperiments using MIMIC datasets show that the proposed model could effectively\naddress asynchronicity in multimodal fusion and consistently outperform\nexisting methods.\n","authors":["Wenfang Yao","Chen Liu","Kejing Yin","William K. Cheung","Jing Qin"],"pdf_url":"https://arxiv.org/pdf/2410.17918v1.pdf","comment":"Accepted by NeurIPS-24"},{"id":"http://arxiv.org/abs/2408.04377v3","updated":"2024-10-23T14:29:56Z","published":"2024-08-08T11:22:52Z","title":"Anomaly Prediction: A Novel Approach with Explicit Delay and Horizon","summary":"  Anomaly detection in time series data is a critical challenge across various\ndomains. Traditional methods typically focus on identifying anomalies in\nimmediate subsequent steps, often underestimating the significance of temporal\ndynamics such as delay time and horizons of anomalies, which generally require\nextensive post-analysis. This paper introduces a novel approach for time series\nanomaly prediction, incorporating temporal information directly into the\nprediction results. We propose a new dataset specifically designed to evaluate\nthis approach and conduct comprehensive experiments using several\nstate-of-the-art methods. Our results demonstrate the efficacy of our approach\nin providing timely and accurate anomaly predictions, setting a new benchmark\nfor future research in this field.\n","authors":["Jiang You","Arben Cela","René Natowicz","Jacob Ouanounou","Patrick Siarry"],"pdf_url":"https://arxiv.org/pdf/2408.04377v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17906v1","updated":"2024-10-23T14:26:35Z","published":"2024-10-23T14:26:35Z","title":"Leveraging Deep Learning for Time Series Extrinsic Regression in\n  predicting photometric metallicity of Fundamental-mode RR Lyrae Stars","summary":"  Astronomy is entering an unprecedented era of Big Data science, driven by\nmissions like the ESA's Gaia telescope, which aims to map the Milky Way in\nthree dimensions. Gaia's vast dataset presents a monumental challenge for\ntraditional analysis methods. The sheer scale of this data exceeds the\ncapabilities of manual exploration, necessitating the utilization of advanced\ncomputational techniques. In response to this challenge, we developed a novel\napproach leveraging deep learning to estimate the metallicity of fundamental\nmode (ab-type) RR Lyrae stars from their light curves in the Gaia optical\nG-band. Our study explores applying deep learning techniques, particularly\nadvanced neural network architectures, in predicting photometric metallicity\nfrom time-series data. Our deep learning models demonstrated notable predictive\nperformance, with a low mean absolute error (MAE) of 0.0565, the root mean\nsquare error (RMSE) achieved is 0.0765 and a high $R^2$ regression performance\nof 0.9401 measured by cross-validation. The weighted mean absolute error (wMAE)\nis 0.0563, while the weighted root mean square error (wRMSE) is 0.0763. These\nresults showcase the effectiveness of our approach in accurately estimating\nmetallicity values. Our work underscores the importance of deep learning in\nastronomical research, particularly with large datasets from missions like\nGaia. By harnessing the power of deep learning methods, we can provide\nprecision in analyzing vast datasets, contributing to more precise and\ncomprehensive insights into complex astronomical phenomena.\n","authors":["Lorenzo Monti","Tatiana Muraveva","Gisella Clementini","Alessia Garofalo"],"pdf_url":"https://arxiv.org/pdf/2410.17906v1.pdf","comment":"Sensors 2024, 24(16), 5203; (23 pages)"},{"id":"http://arxiv.org/abs/2405.16164v3","updated":"2024-10-23T14:24:50Z","published":"2024-05-25T10:15:51Z","title":"Acquiring Better Load Estimates by Combining Anomaly and Change Point\n  Detection in Power Grid Time-series Measurements","summary":"  In this paper we present novel methodology for automatic anomaly and switch\nevent filtering to improve load estimation in power grid systems. By leveraging\nunsupervised methods with supervised optimization, our approach prioritizes\ninterpretability while ensuring robust and generalizable performance on unseen\ndata. Through experimentation, a combination of binary segmentation for change\npoint detection and statistical process control for anomaly detection emerges\nas the most effective strategy, specifically when ensembled in a novel\nsequential manner. Results indicate the clear wasted potential when filtering\nis not applied. The automatic load estimation is also fairly accurate, with\napproximately 90% of estimates falling within a 10% error margin, with only a\nsingle significant failure in both the minimum and maximum load estimates\nacross 60 measurements in the test set. Our methodology's interpretability\nmakes it particularly suitable for critical infrastructure planning, thereby\nenhancing decision-making processes.\n","authors":["Roel Bouman","Linda Schmeitz","Luco Buise","Jacco Heres","Yuliya Shapovalova","Tom Heskes"],"pdf_url":"https://arxiv.org/pdf/2405.16164v3.pdf","comment":"All code can be found at: https://github.com/RoelBouman/StormPhase2"},{"id":"http://arxiv.org/abs/2410.17904v1","updated":"2024-10-23T14:22:49Z","published":"2024-10-23T14:22:49Z","title":"Reinforcement Learning under Latent Dynamics: Toward Statistical and\n  Algorithmic Modularity","summary":"  Real-world applications of reinforcement learning often involve environments\nwhere agents operate on complex, high-dimensional observations, but the\nunderlying (''latent'') dynamics are comparatively simple. However, outside of\nrestrictive settings such as small latent spaces, the fundamental statistical\nrequirements and algorithmic principles for reinforcement learning under latent\ndynamics are poorly understood.\n  This paper addresses the question of reinforcement learning under\n$\\textit{general}$ latent dynamics from a statistical and algorithmic\nperspective. On the statistical side, our main negative result shows that most\nwell-studied settings for reinforcement learning with function approximation\nbecome intractable when composed with rich observations; we complement this\nwith a positive result, identifying latent pushforward coverability as a\ngeneral condition that enables statistical tractability. Algorithmically, we\ndevelop provably efficient observable-to-latent reductions -- that is,\nreductions that transform an arbitrary algorithm for the latent MDP into an\nalgorithm that can operate on rich observations -- in two settings: one where\nthe agent has access to hindsight observations of the latent dynamics [LADZ23],\nand one where the agent can estimate self-predictive latent models [SAGHCB20].\nTogether, our results serve as a first step toward a unified statistical and\nalgorithmic theory for reinforcement learning under latent dynamics.\n","authors":["Philip Amortila","Dylan J. Foster","Nan Jiang","Akshay Krishnamurthy","Zakaria Mhammedi"],"pdf_url":"https://arxiv.org/pdf/2410.17904v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14703v2","updated":"2024-10-23T14:01:14Z","published":"2024-06-20T19:50:56Z","title":"Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality\n  Testset designed for LLMs with Psychometrics","summary":"  Recent advancements in Large Language Models (LLMs) have led to their\nadaptation in various domains as conversational agents. We wonder: can\npersonality tests be applied to these agents to analyze their behavior, similar\nto humans? We introduce TRAIT, a new benchmark consisting of 8K multi-choice\nquestions designed to assess the personality of LLMs. TRAIT is built on two\npsychometrically validated small human questionnaires, Big Five Inventory (BFI)\nand Short Dark Triad (SD-3), enhanced with the ATOMIC-10X knowledge graph to a\nvariety of real-world scenarios. TRAIT also outperforms existing personality\ntests for LLMs in terms of reliability and validity, achieving the highest\nscores across four key metrics: Content Validity, Internal Validity, Refusal\nRate, and Reliability. Using TRAIT, we reveal two notable insights into\npersonalities of LLMs: 1) LLMs exhibit distinct and consistent personality,\nwhich is highly influenced by their training data (e.g., data used for\nalignment tuning), and 2) current prompting techniques have limited\neffectiveness in eliciting certain traits, such as high psychopathy or low\nconscientiousness, suggesting the need for further research in this direction.\n","authors":["Seungbeen Lee","Seungwon Lim","Seungju Han","Giyeong Oh","Hyungjoo Chae","Jiwan Chung","Minju Kim","Beong-woo Kwak","Yeonsoo Lee","Dongha Lee","Jinyoung Yeo","Youngjae Yu"],"pdf_url":"https://arxiv.org/pdf/2406.14703v2.pdf","comment":"Preprint; Under review"},{"id":"http://arxiv.org/abs/2410.17885v1","updated":"2024-10-23T13:58:39Z","published":"2024-10-23T13:58:39Z","title":"R-CoT: Reverse Chain-of-Thought Problem Generation for Geometric\n  Reasoning in Large Multimodal Models","summary":"  Existing Large Multimodal Models (LMMs) struggle with mathematical geometric\nreasoning due to a lack of high-quality image-text paired data. Current\ngeometric data generation approaches, which apply preset templates to generate\ngeometric data or use Large Language Models (LLMs) to rephrase questions and\nanswers (Q&A), unavoidably limit data accuracy and diversity. To synthesize\nhigher-quality data, we propose a two-stage Reverse Chain-of-Thought (R-CoT)\ngeometry problem generation pipeline. First, we introduce GeoChain to produce\nhigh-fidelity geometric images and corresponding descriptions highlighting\nrelations among geometric elements. We then design a Reverse A&Q method that\nreasons step-by-step based on the descriptions and generates questions in\nreverse from the reasoning results. Experiments demonstrate that the proposed\nmethod brings significant and consistent improvements on multiple LMM\nbaselines, achieving new performance records in the 2B, 7B, and 8B settings.\nNotably, R-CoT-8B significantly outperforms previous state-of-the-art\nopen-source mathematical models by 16.6% on MathVista and 9.2% on GeoQA, while\nalso surpassing the closed-source model GPT-4o by an average of 13% across both\ndatasets. The code is available at https://github.com/dle666/R-CoT.\n","authors":["Linger Deng","Yuliang Liu","Bohan Li","Dongliang Luo","Liang Wu","Chengquan Zhang","Pengyuan Lyu","Ziyang Zhang","Gang Zhang","Errui Ding","Yingying Zhu","Xiang Bai"],"pdf_url":"https://arxiv.org/pdf/2410.17885v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17883v1","updated":"2024-10-23T13:57:00Z","published":"2024-10-23T13:57:00Z","title":"Lightweight Neural App Control","summary":"  This paper introduces a novel mobile phone control architecture, termed ``app\nagents\", for efficient interactions and controls across various Android apps.\nThe proposed Lightweight Multi-modal App Control (LiMAC) takes as input a\ntextual goal and a sequence of past mobile observations, such as screenshots\nand corresponding UI trees, to generate precise actions. To address the\ncomputational constraints inherent to smartphones, within LiMAC, we introduce a\nsmall Action Transformer (AcT) integrated with a fine-tuned vision-language\nmodel (VLM) for real-time decision-making and task execution. We evaluate LiMAC\non two open-source mobile control datasets, demonstrating the superior\nperformance of our small-form-factor approach against fine-tuned versions of\nopen-source VLMs, such as Florence2 and Qwen2-VL. It also significantly\noutperforms prompt engineering baselines utilising closed-source foundation\nmodels like GPT-4o. More specifically, LiMAC increases the overall action\naccuracy by up to 19% compared to fine-tuned VLMs, and up to 42% compared to\nprompt-engineering baselines.\n","authors":["Filippos Christianos","Georgios Papoudakis","Thomas Coste","Jianye Hao","Jun Wang","Kun Shao"],"pdf_url":"https://arxiv.org/pdf/2410.17883v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17031v2","updated":"2024-10-23T13:52:51Z","published":"2024-10-22T13:57:55Z","title":"GeoCode-GPT: A Large Language Model for Geospatial Code Generation Tasks","summary":"  The increasing demand for spatiotemporal data and modeling tasks in\ngeosciences has made geospatial code generation technology a critical factor in\nenhancing productivity. Although large language models (LLMs) have demonstrated\npotential in code generation tasks, they often encounter issues such as refusal\nto code or hallucination in geospatial code generation due to a lack of\ndomain-specific knowledge and code corpora. To address these challenges, this\npaper presents and open-sources the GeoCode-PT and GeoCode-SFT corpora, along\nwith the GeoCode-Eval evaluation dataset. Additionally, by leveraging QLoRA and\nLoRA for pretraining and fine-tuning, we introduce GeoCode-GPT-7B, the first\nLLM focused on geospatial code generation, fine-tuned from Code Llama-7B.\nFurthermore, we establish a comprehensive geospatial code evaluation framework,\nincorporating option matching, expert validation, and prompt engineering\nscoring for LLMs, and systematically evaluate GeoCode-GPT-7B using the\nGeoCode-Eval dataset. Experimental results show that GeoCode-GPT outperforms\nother models in multiple-choice accuracy by 9.1% to 32.1%, in code\nsummarization ability by 1.7% to 25.4%, and in code generation capability by\n1.2% to 25.1%. This paper provides a solution and empirical validation for\nenhancing LLMs' performance in geospatial code generation, extends the\nboundaries of domain-specific model applications, and offers valuable insights\ninto unlocking their potential in geospatial code generation.\n","authors":["Shuyang Hou","Zhangxiao Shen","Anqi Zhao","Jianyuan Liang","Zhipeng Gui","Xuefeng Guan","Rui Li","Huayi Wu"],"pdf_url":"https://arxiv.org/pdf/2410.17031v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17875v1","updated":"2024-10-23T13:47:05Z","published":"2024-10-23T13:47:05Z","title":"Understanding Layer Significance in LLM Alignment","summary":"  Aligning large language models (LLMs) through fine-tuning is essential for\ntailoring them to specific applications. Therefore, understanding what LLMs\nlearn during the alignment process is crucial. Recent studies suggest that\nalignment primarily adjusts a model's presentation style rather than its\nfoundational knowledge, indicating that only certain components of the model\nare significantly impacted. To delve deeper into LLM alignment, we propose to\nidentify which layers within LLMs are most critical to the alignment process,\nthereby uncovering how alignment influences model behavior at a granular level.\nWe propose a novel approach to identify the important layers for LLM alignment\n(ILA). It involves learning a binary mask for each incremental weight matrix in\nthe LoRA algorithm, indicating the significance of each layer. ILA consistently\nidentifies important layers across various alignment datasets, with nearly 90%\noverlap even with substantial dataset differences, highlighting fundamental\npatterns in LLM alignment. Experimental results indicate that freezing\nnon-essential layers improves overall model performance, while selectively\ntuning the most critical layers significantly enhances fine-tuning efficiency\nwith minimal performance loss.\n","authors":["Guangyuan Shi","Zexin Lu","Xiaoyu Dong","Wenlong Zhang","Xuanyu Zhang","Yujie Feng","Xiao-Ming Wu"],"pdf_url":"https://arxiv.org/pdf/2410.17875v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03489v2","updated":"2024-10-23T13:38:29Z","published":"2024-10-04T14:59:39Z","title":"Gradient-based Jailbreak Images for Multimodal Fusion Models","summary":"  Augmenting language models with image inputs may enable more effective\njailbreak attacks through continuous optimization, unlike text inputs that\nrequire discrete optimization. However, new multimodal fusion models tokenize\nall input modalities using non-differentiable functions, which hinders\nstraightforward attacks. In this work, we introduce the notion of a tokenizer\nshortcut that approximates tokenization with a continuous function and enables\ncontinuous optimization. We use tokenizer shortcuts to create the first\nend-to-end gradient image attacks against multimodal fusion models. We evaluate\nour attacks on Chameleon models and obtain jailbreak images that elicit harmful\ninformation for 72.5% of prompts. Jailbreak images outperform text jailbreaks\noptimized with the same objective and require 3x lower compute budget to\noptimize 50x more input tokens. Finally, we find that representation\nengineering defenses, like Circuit Breakers, trained only on text attacks can\neffectively transfer to adversarial image inputs.\n","authors":["Javier Rando","Hannah Korevaar","Erik Brinkman","Ivan Evtimov","Florian Tramèr"],"pdf_url":"https://arxiv.org/pdf/2410.03489v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.04953v3","updated":"2024-10-23T13:36:37Z","published":"2022-12-09T16:03:34Z","title":"TargetCall: Eliminating the Wasted Computation in Basecalling via\n  Pre-Basecalling Filtering","summary":"  Basecalling is an essential step in nanopore sequencing analysis where the\nraw signals of nanopore sequencers are converted into nucleotide sequences,\ni.e., reads. State-of-the-art basecallers employ complex deep learning models\nto achieve high basecalling accuracy. This makes basecalling computationally\ninefficient and memory-hungry, bottlenecking the entire genome analysis\npipeline. However, for many applications, the majority of reads do no match the\nreference genome of interest (i.e., target reference) and thus are discarded in\nlater steps in the genomics pipeline, wasting the basecalling computation. To\novercome this issue, we propose TargetCall, the first pre-basecalling filter to\neliminate the wasted computation in basecalling. TargetCall's key idea is to\ndiscard reads that will not match the target reference (i.e., off-target reads)\nprior to basecalling. TargetCall consists of two main components: (1)\nLightCall, a lightweight neural network basecaller that produces noisy reads;\nand (2) Similarity Check, which labels each of these noisy reads as on-target\nor off-target by matching them to the target reference. Our thorough\nexperimental evaluations show that TargetCall 1) improves the end-to-end\nbasecalling runtime performance of the state-of-the-art basecaller by 3.31x\nwhile maintaining high (98.88%) recall in keeping on-target reads, 2) maintains\nhigh accuracy in downstream analysis, and 3) achieves better runtime\nperformance, throughput, recall, precision, and generality compared to prior\nworks. TargetCall is available at https://github.com/CMU-SAFARI/TargetCall.\n","authors":["Meryem Banu Cavlak","Gagandeep Singh","Mohammed Alser","Can Firtina","Joël Lindegger","Mohammad Sadrosadati","Nika Mansouri Ghiasi","Can Alkan","Onur Mutlu"],"pdf_url":"https://arxiv.org/pdf/2212.04953v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17859v1","updated":"2024-10-23T13:30:02Z","published":"2024-10-23T13:30:02Z","title":"DataTales: A Benchmark for Real-World Intelligent Data Narration","summary":"  We introduce DataTales, a novel benchmark designed to assess the proficiency\nof language models in data narration, a task crucial for transforming complex\ntabular data into accessible narratives. Existing benchmarks often fall short\nin capturing the requisite analytical complexity for practical applications.\nDataTales addresses this gap by offering 4.9k financial reports paired with\ncorresponding market data, showcasing the demand for models to create clear\nnarratives and analyze large datasets while understanding specialized\nterminology in the field. Our findings highlights the significant challenge\nthat language models face in achieving the necessary precision and analytical\ndepth for proficient data narration, suggesting promising avenues for future\nmodel development and evaluation methodologies.\n","authors":["Yajing Yang","Qian Liu","Min-Yen Kan"],"pdf_url":"https://arxiv.org/pdf/2410.17859v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17856v1","updated":"2024-10-23T13:26:59Z","published":"2024-10-23T13:26:59Z","title":"ROCKET-1: Master Open-World Interaction with Visual-Temporal Context\n  Prompting","summary":"  Vision-language models (VLMs) have excelled in multimodal tasks, but adapting\nthem to embodied decision-making in open-world environments presents\nchallenges. A key issue is the difficulty in smoothly connecting individual\nentities in low-level observations with abstract concepts required for\nplanning. A common approach to address this problem is through the use of\nhierarchical agents, where VLMs serve as high-level reasoners that break down\ntasks into executable sub-tasks, typically specified using language and\nimagined observations. However, language often fails to effectively convey\nspatial information, while generating future images with sufficient accuracy\nremains challenging. To address these limitations, we propose visual-temporal\ncontext prompting, a novel communication protocol between VLMs and policy\nmodels. This protocol leverages object segmentation from both past and present\nobservations to guide policy-environment interactions. Using this approach, we\ntrain ROCKET-1, a low-level policy that predicts actions based on concatenated\nvisual observations and segmentation masks, with real-time object tracking\nprovided by SAM-2. Our method unlocks the full potential of VLMs\nvisual-language reasoning abilities, enabling them to solve complex creative\ntasks, especially those heavily reliant on spatial understanding. Experiments\nin Minecraft demonstrate that our approach allows agents to accomplish\npreviously unattainable tasks, highlighting the effectiveness of\nvisual-temporal context prompting in embodied decision-making. Codes and demos\nwill be available on the project page: https://craftjarvis.github.io/ROCKET-1.\n","authors":["Shaofei Cai","Zihao Wang","Kewei Lian","Zhancun Mu","Xiaojian Ma","Anji Liu","Yitao Liang"],"pdf_url":"https://arxiv.org/pdf/2410.17856v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17855v1","updated":"2024-10-23T13:26:19Z","published":"2024-10-23T13:26:19Z","title":"TAGE: Trustworthy Attribute Group Editing for Stable Few-shot Image\n  Generation","summary":"  Generative Adversarial Networks (GANs) have emerged as a prominent research\nfocus for image editing tasks, leveraging the powerful image generation\ncapabilities of the GAN framework to produce remarkable results.However,\nprevailing approaches are contingent upon extensive training datasets and\nexplicit supervision, presenting a significant challenge in manipulating the\ndiverse attributes of new image classes with limited sample availability. To\nsurmount this hurdle, we introduce TAGE, an innovative image generation network\ncomprising three integral modules: the Codebook Learning Module (CLM), the Code\nPrediction Module (CPM) and the Prompt-driven Semantic Module (PSM). The CPM\nmodule delves into the semantic dimensions of category-agnostic attributes,\nencapsulating them within a discrete codebook. This module is predicated on the\nconcept that images are assemblages of attributes, and thus, by editing these\ncategory-independent attributes, it is theoretically possible to generate\nimages from unseen categories. Subsequently, the CPM module facilitates\nnaturalistic image editing by predicting indices of category-independent\nattribute vectors within the codebook. Additionally, the PSM module generates\nsemantic cues that are seamlessly integrated into the Transformer architecture\nof the CPM, enhancing the model's comprehension of the targeted attributes for\nediting. With these semantic cues, the model can generate images that\naccentuate desired attributes more prominently while maintaining the integrity\nof the original category, even with a limited number of samples. We have\nconducted extensive experiments utilizing the Animal Faces, Flowers, and\nVGGFaces datasets. The results of these experiments demonstrate that our\nproposed method not only achieves superior performance but also exhibits a high\ndegree of stability when compared to other few-shot image generation\ntechniques.\n","authors":["Ruicheng Zhang","Guoheng Huang","Yejing Huo","Xiaochen Yuan","Zhizhen Zhou","Xuhang Chen","Guo Zhong"],"pdf_url":"https://arxiv.org/pdf/2410.17855v1.pdf","comment":"Accepted by International Conference on Signal Processing Systems\n  Conference"},{"id":"http://arxiv.org/abs/2410.17851v1","updated":"2024-10-23T13:20:42Z","published":"2024-10-23T13:20:42Z","title":"The Probabilistic Tsetlin Machine: A Novel Approach to Uncertainty\n  Quantification","summary":"  Tsetlin Machines (TMs) have emerged as a compelling alternative to\nconventional deep learning methods, offering notable advantages such as smaller\nmemory footprint, faster inference, fault-tolerant properties, and\ninterpretability. Although various adaptations of TMs have expanded their\napplicability across diverse domains, a fundamental gap remains in\nunderstanding how TMs quantify uncertainty in their predictions. In response,\nthis paper introduces the Probabilistic Tsetlin Machine (PTM) framework, aimed\nat providing a robust, reliable, and interpretable approach for uncertainty\nquantification. Unlike the original TM, the PTM learns the probability of\nstaying on each state of each Tsetlin Automaton (TA) across all clauses. These\nprobabilities are updated using the feedback tables that are part of the TM\nframework: Type I and Type II feedback. During inference, TAs decide their\nactions by sampling states based on learned probability distributions, akin to\nBayesian neural networks when generating weight values. In our experimental\nanalysis, we first illustrate the spread of the probabilities across TA states\nfor the noisy-XOR dataset. Then we evaluate the PTM alongside benchmark models\nusing both simulated and real-world datasets. The experiments on the simulated\ndataset reveal the PTM's effectiveness in uncertainty quantification,\nparticularly in delineating decision boundaries and identifying regions of high\nuncertainty. Moreover, when applied to multiclass classification tasks using\nthe Iris dataset, the PTM demonstrates competitive performance in terms of\npredictive entropy and expected calibration error, showcasing its potential as\na reliable tool for uncertainty estimation. Our findings underscore the\nimportance of selecting appropriate models for accurate uncertainty\nquantification in predictive tasks, with the PTM offering a particularly\ninterpretable and effective solution.\n","authors":["K. Darshana Abeyrathna","Sara El Mekkaoui","Andreas Hafver","Christian Agrell"],"pdf_url":"https://arxiv.org/pdf/2410.17851v1.pdf","comment":"12 pages, 5 figures, 6 tables, accepted and presented at ICAAI 2024,\n  London"},{"id":"http://arxiv.org/abs/2402.15055v2","updated":"2024-10-23T13:20:15Z","published":"2024-02-23T02:15:47Z","title":"Interpreting Context Look-ups in Transformers: Investigating\n  Attention-MLP Interactions","summary":"  Understanding the inner workings of large language models (LLMs) is crucial\nfor advancing their theoretical foundations and real-world applications. While\nthe attention mechanism and multi-layer perceptrons (MLPs) have been studied\nindependently, their interactions remain largely unexplored. This study\ninvestigates how attention heads and next-token neurons interact in LLMs to\npredict new words. We propose a methodology to identify next-token neurons,\nfind prompts that highly activate them, and determine the upstream attention\nheads responsible. We then generate and evaluate explanations for the activity\nof these attention heads in an automated manner. Our findings reveal that some\nattention heads recognize specific contexts relevant to predicting a token and\nactivate a downstream token-predicting neuron accordingly. This mechanism\nprovides a deeper understanding of how attention heads work with MLP neurons to\nperform next-token prediction. Our approach offers a foundation for further\nresearch into the intricate workings of LLMs and their impact on text\ngeneration and understanding.\n","authors":["Clement Neo","Shay B. Cohen","Fazl Barez"],"pdf_url":"https://arxiv.org/pdf/2402.15055v2.pdf","comment":"Accepted to EMNLP 2024 Main Conference"},{"id":"http://arxiv.org/abs/2410.15956v2","updated":"2024-10-23T13:00:27Z","published":"2024-10-21T12:34:17Z","title":"Do Large Language Models Have an English Accent? Evaluating and\n  Improving the Naturalness of Multilingual LLMs","summary":"  Current Large Language Models (LLMs) are predominantly designed with English\nas the primary language, and even the few that are multilingual tend to exhibit\nstrong English-centric biases. Much like speakers who might produce awkward\nexpressions when learning a second language, LLMs often generate unnatural\noutputs in non-English languages, reflecting English-centric patterns in both\nvocabulary and grammar. Despite the importance of this issue, the naturalness\nof multilingual LLM outputs has received limited attention. In this paper, we\naddress this gap by introducing novel automatic corpus-level metrics to assess\nthe lexical and syntactic naturalness of LLM outputs in a multilingual context.\nUsing our new metrics, we evaluate state-of-the-art LLMs on a curated benchmark\nin French and Chinese, revealing a tendency towards English-influenced\npatterns. To mitigate this issue, we also propose a simple and effective\nalignment method to improve the naturalness of an LLM in a target language and\ndomain, achieving consistent improvements in naturalness without compromising\nthe performance on general-purpose benchmarks. Our work highlights the\nimportance of developing multilingual metrics, resources and methods for the\nnew wave of multilingual LLMs.\n","authors":["Yanzhu Guo","Simone Conia","Zelin Zhou","Min Li","Saloni Potdar","Henry Xiao"],"pdf_url":"https://arxiv.org/pdf/2410.15956v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12376v2","updated":"2024-10-23T12:58:14Z","published":"2024-10-16T08:48:27Z","title":"ShapefileGPT: A Multi-Agent Large Language Model Framework for Automated\n  Shapefile Processing","summary":"  Vector data is one of the two core data structures in geographic information\nscience (GIS), essential for accurately storing and representing geospatial\ninformation. Shapefile, the most widely used vector data format, has become the\nindustry standard supported by all major geographic information systems.\nHowever, processing this data typically requires specialized GIS knowledge and\nskills, creating a barrier for researchers from other fields and impeding\ninterdisciplinary research in spatial data analysis. Moreover, while large\nlanguage models (LLMs) have made significant advancements in natural language\nprocessing and task automation, they still face challenges in handling the\ncomplex spatial and topological relationships inherent in GIS vector data. To\naddress these challenges, we propose ShapefileGPT, an innovative framework\npowered by LLMs, specifically designed to automate Shapefile tasks.\nShapefileGPT utilizes a multi-agent architecture, in which the planner agent is\nresponsible for task decomposition and supervision, while the worker agent\nexecutes the tasks. We developed a specialized function library for handling\nShapefiles and provided comprehensive API documentation, enabling the worker\nagent to operate Shapefiles efficiently through function calling. For\nevaluation, we developed a benchmark dataset based on authoritative textbooks,\nencompassing tasks in categories such as geometric operations and spatial\nqueries. ShapefileGPT achieved a task success rate of 95.24%, outperforming the\nGPT series models. In comparison to traditional LLMs, ShapefileGPT effectively\nhandles complex vector data analysis tasks, overcoming the limitations of\ntraditional LLMs in spatial analysis. This breakthrough opens new pathways for\nadvancing automation and intelligence in the GIS field, with significant\npotential in interdisciplinary data analysis and application contexts.\n","authors":["Qingming Lin","Rui Hu","Huaxia Li","Sensen Wu","Yadong Li","Kai Fang","Hailin Feng","Zhenhong Du","Liuchang Xu"],"pdf_url":"https://arxiv.org/pdf/2410.12376v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.13152v3","updated":"2024-10-23T12:56:05Z","published":"2024-05-21T18:45:18Z","title":"Enhancing Interaction Modeling with Agent Selection and Physical\n  Coefficient for Trajectory Prediction","summary":"  A thorough understanding of the interaction between the target agent and\nsurrounding agents is a prerequisite for accurate trajectory prediction.\nAlthough many methods have been explored, they all assign correlation\ncoefficients to surrounding agents in a purely learning-based manner. In this\nstudy, we present ASPILin, which manually selects interacting agents and\ncalculates their correlations instead of attention scores. Surprisingly, these\nsimple modifications can significantly improve prediction performance and\nsubstantially reduce computational costs. Additionally, ASPILin models the\ninteracting agents at each past time step separately, rather than only modeling\nthe interacting agents at the current time step. This clarifies the causal\nchain of the target agent's historical trajectory and helps the model better\nunderstand dynamic interactions. We intentionally simplified our model in other\naspects, such as map encoding. Remarkably, experiments conducted on the\nINTERACTION, highD, and CitySim datasets demonstrate that our method is\nefficient and straightforward, outperforming other state-of-the-art methods.\n","authors":["Shiji Huang","Lei Ye","Min Chen","Wenhai Luo","Dihong Wang","Chenqi Xu","Deyuan Liang"],"pdf_url":"https://arxiv.org/pdf/2405.13152v3.pdf","comment":"code:https://github.com/kkk00714/ASPILin"},{"id":"http://arxiv.org/abs/2410.17827v1","updated":"2024-10-23T12:40:33Z","published":"2024-10-23T12:40:33Z","title":"RE-tune: Incremental Fine Tuning of Biomedical Vision-Language Models\n  for Multi-label Chest X-ray Classification","summary":"  In this paper we introduce RE-tune, a novel approach for fine-tuning\npre-trained Multimodal Biomedical Vision-Language models (VLMs) in Incremental\nLearning scenarios for multi-label chest disease diagnosis. RE-tune freezes the\nbackbones and only trains simple adaptors on top of the Image and Text encoders\nof the VLM. By engineering positive and negative text prompts for diseases, we\nleverage the ability of Large Language Models to steer the training trajectory.\nWe evaluate RE-tune in three realistic incremental learning scenarios:\nclass-incremental, label-incremental, and data-incremental. Our results\ndemonstrate that Biomedical VLMs are natural continual learners and prevent\ncatastrophic forgetting. RE-tune not only achieves accurate multi-label\nclassification results, but also prioritizes patient privacy and it\ndistinguishes itself through exceptional computational efficiency, rendering it\nhighly suitable for broad adoption in real-world healthcare settings.\n","authors":["Marco Mistretta","Andrew D. Bagdanov"],"pdf_url":"https://arxiv.org/pdf/2410.17827v1.pdf","comment":"Accepted for publication at Medical Imaging meets NeurIPS (NeurIPS23)"},{"id":"http://arxiv.org/abs/2404.01335v2","updated":"2024-10-23T12:38:40Z","published":"2024-03-30T13:25:11Z","title":"Generative AI Models for Different Steps in Architectural Design: A\n  Literature Review","summary":"  Recent advances in generative artificial intelligence (AI) technologies have\nbeen significantly driven by models such as generative adversarial networks\n(GANs), variational autoencoders (VAEs), and denoising diffusion probabilistic\nmodels (DDPMs). Although architects recognize the potential of generative AI in\ndesign, personal barriers often restrict their access to the latest\ntechnological developments, thereby causing the application of generative AI in\narchitectural design to lag behind. Therefore, it is essential to comprehend\nthe principles and advancements of generative AI models and analyze their\nrelevance in architecture applications. This paper first provides an overview\nof generative AI technologies, with a focus on probabilistic diffusion models\n(DDPMs), 3D generative models, and foundation models, highlighting their recent\ndevelopments and main application scenarios. Then, the paper explains how the\nabovementioned models could be utilized in architecture. We subdivide the\narchitectural design process into six steps and review related research\nprojects in each step from 2020 to the present. Lastly, this paper discusses\npotential future directions for applying generative AI in the architectural\ndesign steps. This research can help architects quickly understand the\ndevelopment and latest progress of generative AI and contribute to the further\ndevelopment of intelligent architecture.\n","authors":["Chengyuan Li","Tianyu Zhang","Xusheng Du","Ye Zhang","Haoran Xie"],"pdf_url":"https://arxiv.org/pdf/2404.01335v2.pdf","comment":"34 pages, 14 figures, accepted by Frontiers of Architectural Research"},{"id":"http://arxiv.org/abs/2409.10568v2","updated":"2024-10-23T12:37:10Z","published":"2024-09-14T04:17:24Z","title":"On the limits of agency in agent-based models","summary":"  Agent-based modeling (ABM) seeks to understand the behavior of complex\nsystems by simulating a collection of agents that act and interact within an\nenvironment. Their practical utility requires capturing realistic environment\ndynamics and adaptive agent behavior while efficiently simulating million-size\npopulations. Recent advancements in large language models (LLMs) present an\nopportunity to enhance ABMs by using LLMs as agents with further potential to\ncapture adaptive behavior. However, the computational infeasibility of using\nLLMs for large populations has hindered their widespread adoption. In this\npaper, we introduce AgentTorch -- a framework that scales ABMs to millions of\nagents while capturing high-resolution agent behavior using LLMs. We benchmark\nthe utility of LLMs as ABM agents, exploring the trade-off between simulation\nscale and individual agency. Using the COVID-19 pandemic as a case study, we\ndemonstrate how AgentTorch can simulate 8.4 million agents representing New\nYork City, capturing the impact of isolation and employment behavior on health\nand economic outcomes. We compare the performance of different agent\narchitectures based on heuristic and LLM agents in predicting disease waves and\nunemployment rates. Furthermore, we showcase AgentTorch's capabilities for\nretrospective, counterfactual, and prospective analyses, highlighting how\nadaptive agent behavior can help overcome the limitations of historical data in\npolicy design. AgentTorch is an open-source project actively being used for\npolicy-making and scientific discovery around the world. The framework is\navailable here: github.com/AgentTorch/AgentTorch.\n","authors":["Ayush Chopra","Shashank Kumar","Nurullah Giray-Kuru","Ramesh Raskar","Arnau Quera-Bofarull"],"pdf_url":"https://arxiv.org/pdf/2409.10568v2.pdf","comment":"19 pages, 5 appendices, 5 figures"},{"id":"http://arxiv.org/abs/2410.17812v1","updated":"2024-10-23T12:17:03Z","published":"2024-10-23T12:17:03Z","title":"PGDiffSeg: Prior-Guided Denoising Diffusion Model with Parameter-Shared\n  Attention for Breast Cancer Segmentation","summary":"  Early detection through imaging and accurate diagnosis is crucial in\nmitigating the high mortality rate associated with breast cancer. However,\nlocating tumors from low-resolution and high-noise medical images is extremely\nchallenging. Therefore, this paper proposes a novel PGDiffSeg (Prior-Guided\nDiffusion Denoising Model with Parameter-Shared Attention) that applies\ndiffusion denoising methods to breast cancer medical image segmentation,\naccurately recovering the affected areas from Gaussian noise. Firstly, we\ndesign a parallel pipeline for noise processing and semantic information\nprocessing and propose a parameter-shared attention module (PSA) in multi-layer\nthat seamlessly integrates these two pipelines. This integration empowers\nPGDiffSeg to incorporate semantic details at multiple levels during the\ndenoising process, producing highly accurate segmentation maps. Secondly, we\nintroduce a guided strategy that leverages prior knowledge to simulate the\ndecision-making process of medical professionals, thereby enhancing the model's\nability to locate tumor positions precisely. Finally, we provide the first-ever\ndiscussion on the interpretability of the generative diffusion model in the\ncontext of breast cancer segmentation. Extensive experiments have demonstrated\nthe superiority of our model over the current state-of-the-art approaches,\nconfirming its effectiveness as a flexible diffusion denoising method suitable\nfor medical image research. Our code will be publicly available later.\n","authors":["Feiyan Feng","Tianyu Liu","Hong Wang","Jun Zhao","Wei Li","Yanshen Sun"],"pdf_url":"https://arxiv.org/pdf/2410.17812v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17799v1","updated":"2024-10-23T11:58:58Z","published":"2024-10-23T11:58:58Z","title":"OmniFlatten: An End-to-end GPT Model for Seamless Voice Conversation","summary":"  Full-duplex spoken dialogue systems significantly advance over traditional\nturn-based dialogue systems, as they allow simultaneous bidirectional\ncommunication, closely mirroring human-human interactions. However, achieving\nlow latency and natural interactions in full-duplex dialogue systems remains a\nsignificant challenge, especially considering human conversation dynamics such\nas interruptions, backchannels, and overlapping speech. In this paper, we\nintroduce a novel End-to-End GPT-based model OmniFlatten for full-duplex\nconversation, capable of effectively modeling the complex behaviors inherent to\nnatural conversations with low latency. To achieve full-duplex communication\ncapabilities, we propose a multi-stage post-training scheme that progressively\nadapts a text-based large language model (LLM) backbone into a speech-text\ndialogue LLM, capable of generating text and speech in real time, without\nmodifying the architecture of the backbone LLM. The training process comprises\nthree stages: modality alignment, half-duplex dialogue learning, and\nfull-duplex dialogue learning. Throughout all training stages, we standardize\nthe data using a flattening operation, which allows us to unify the training\nmethods and the model architecture across different modalities and tasks. Our\napproach offers a straightforward modeling technique and a promising research\ndirection for developing efficient and natural end-to-end full-duplex spoken\ndialogue systems. Audio samples of dialogues generated by OmniFlatten can be\nfound at this web site (https://omniflatten.github.io/).\n","authors":["Qinglin Zhang","Luyao Cheng","Chong Deng","Qian Chen","Wen Wang","Siqi Zheng","Jiaqing Liu","Hai Yu","Chaohong Tan"],"pdf_url":"https://arxiv.org/pdf/2410.17799v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2410.17792v1","updated":"2024-10-23T11:47:04Z","published":"2024-10-23T11:47:04Z","title":"Enhancing Federated Learning Convergence with Dynamic Data Queue and\n  Data Entropy-driven Participant Selection","summary":"  Federated Learning (FL) is a decentralized approach for collaborative model\ntraining on edge devices. This distributed method of model training offers\nadvantages in privacy, security, regulatory compliance, and cost-efficiency.\nOur emphasis in this research lies in addressing statistical complexity in FL,\nespecially when the data stored locally across devices is not identically and\nindependently distributed (non-IID). We have observed an accuracy reduction of\nup to approximately 10\\% to 30\\%, particularly in skewed scenarios where each\nedge device trains with only 1 class of data. This reduction is attributed to\nweight divergence, quantified using the Euclidean distance between device-level\nclass distributions and the population distribution, resulting in a bias term\n(\\(\\delta_k\\)). As a solution, we present a method to improve convergence in FL\nby creating a global subset of data on the server and dynamically distributing\nit across devices using a Dynamic Data queue-driven Federated Learning (DDFL).\nNext, we leverage Data Entropy metrics to observe the process during each\ntraining round and enable reasonable device selection for aggregation.\nFurthermore, we provide a convergence analysis of our proposed DDFL to justify\ntheir viability in practical FL scenarios, aiming for better device selection,\na non-sub-optimal global model, and faster convergence. We observe that our\napproach results in a substantial accuracy boost of approximately 5\\% for the\nMNIST dataset, around 18\\% for CIFAR-10, and 20\\% for CIFAR-100 with a 10\\%\nglobal subset of data, outperforming the state-of-the-art (SOTA) aggregation\nalgorithms.\n","authors":["Charuka Herath","Xiaolan Liu","Sangarapillai Lambotharan","Yogachandran Rahulamathavan"],"pdf_url":"https://arxiv.org/pdf/2410.17792v1.pdf","comment":"The Journal is submitted to IEEE Transactions in the Internet of\n  Things"},{"id":"http://arxiv.org/abs/2410.17787v1","updated":"2024-10-23T11:37:20Z","published":"2024-10-23T11:37:20Z","title":"Large Language Models Engineer Too Many Simple Features For Tabular Data","summary":"  Tabular machine learning problems often require time-consuming and\nlabor-intensive feature engineering. Recent efforts have focused on using large\nlanguage models (LLMs) to capitalize on their potential domain knowledge. At\nthe same time, researchers have observed ethically concerning negative biases\nin other LLM-related use cases, such as text generation. These developments\nmotivated us to investigate whether LLMs exhibit a bias that negatively impacts\nthe performance of feature engineering. While not ethically concerning, such a\nbias could hinder practitioners from fully utilizing LLMs for automated data\nscience. Therefore, we propose a method to detect potential biases by detecting\nanomalies in the frequency of operators (e.g., adding two features) suggested\nby LLMs when engineering new features. Our experiments evaluate the bias of\nfour LLMs, two big frontier and two small open-source models, across 27 tabular\ndatasets. Our results indicate that LLMs are biased toward simple operators,\nsuch as addition, and can fail to utilize more complex operators, such as\ngrouping followed by aggregations. Furthermore, the bias can negatively impact\nthe predictive performance when using LLM-generated features. Our results call\nfor mitigating bias when using LLMs for feature engineering.\n","authors":["Jaris Küken","Lennart Purucker","Frank Hutter"],"pdf_url":"https://arxiv.org/pdf/2410.17787v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2406.05804v4","updated":"2024-10-23T11:36:57Z","published":"2024-06-09T14:42:55Z","title":"A Review of Prominent Paradigms for LLM-Based Agents: Tool Use\n  (Including RAG), Planning, and Feedback Learning","summary":"  Tool use, planning, and feedback learning are currently three prominent\nparadigms for developing Large Language Model (LLM)-based agents across various\ntasks. Although numerous frameworks have been devised for each paradigm, their\nintricate workflows and inconsistent taxonomy create challenges in\nunderstanding and reviewing the frameworks across different paradigms. This\nsurvey introduces a unified taxonomy to systematically review and discuss these\nframeworks. Specifically, 1) the taxonomy defines environments/tasks, common\nLLM-profiled roles or LMPRs (policy models, evaluators, and dynamic models),\nand universally applicable workflows found in prior work, and 2) it enables a\ncomparison of key perspectives on the implementations of LMPRs and workflow\ndesigns across different agent paradigms and frameworks. 3) Finally, we\nidentify three limitations in existing workflow designs and systematically\ndiscuss the future work.\n","authors":["Xinzhe Li"],"pdf_url":"https://arxiv.org/pdf/2406.05804v4.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2410.17784v1","updated":"2024-10-23T11:34:29Z","published":"2024-10-23T11:34:29Z","title":"Holon Programming Model -- A Software-Defined Approach for System of\n  Systems","summary":"  As Systems of Systems evolve into increasingly complex networks, harnessing\ntheir collective potential becomes paramount. Traditional SoS engineering\napproaches lack the necessary programmability to develop third party SoS level\nbehaviors. To address this challenge, we propose a software defined approach to\nenable flexible and adaptive programming of SoS. We introduce the Holon\nProgramming Model, a software-defined framework designed to meet these needs.\nThe Holon Programming Model empowers developers to design and orchestrate\ncomplex system behaviors effectively, as illustrated in our disaster management\nscenario. This research outlines the Holon Programming Model theoretical\nunderpinnings and practical applications, with the aim of driving further\nexploration and advancement in the field of software defined SoS\n","authors":["Muhammad Ashfaq","Ahmed R. Sadik","Tommi Mikkonen","Muhammad Waseem","Niko Makitalo"],"pdf_url":"https://arxiv.org/pdf/2410.17784v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17781v1","updated":"2024-10-23T11:31:52Z","published":"2024-10-23T11:31:52Z","title":"Evaluating Explanations Through LLMs: Beyond Traditional User Studies","summary":"  As AI becomes fundamental in sectors like healthcare, explainable AI (XAI)\ntools are essential for trust and transparency. However, traditional user\nstudies used to evaluate these tools are often costly, time consuming, and\ndifficult to scale. In this paper, we explore the use of Large Language Models\n(LLMs) to replicate human participants to help streamline XAI evaluation. We\nreproduce a user study comparing counterfactual and causal explanations,\nreplicating human participants with seven LLMs under various settings. Our\nresults show that (i) LLMs can replicate most conclusions from the original\nstudy, (ii) different LLMs yield varying levels of alignment in the results,\nand (iii) experimental factors such as LLM memory and output variability affect\nalignment with human responses. These initial findings suggest that LLMs could\nprovide a scalable and cost-effective way to simplify qualitative XAI\nevaluation.\n","authors":["Francesco Bombassei De Bona","Gabriele Dominici","Tim Miller","Marc Langheinrich","Martin Gjoreski"],"pdf_url":"https://arxiv.org/pdf/2410.17781v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17772v1","updated":"2024-10-23T11:19:48Z","published":"2024-10-23T11:19:48Z","title":"Scaling Robot Policy Learning via Zero-Shot Labeling with Foundation\n  Models","summary":"  A central challenge towards developing robots that can relate human language\nto their perception and actions is the scarcity of natural language annotations\nin diverse robot datasets. Moreover, robot policies that follow natural\nlanguage instructions are typically trained on either templated language or\nexpensive human-labeled instructions, hindering their scalability. To this end,\nwe introduce NILS: Natural language Instruction Labeling for Scalability. NILS\nautomatically labels uncurated, long-horizon robot data at scale in a zero-shot\nmanner without any human intervention. NILS combines pretrained vision-language\nfoundation models in order to detect objects in a scene, detect object-centric\nchanges, segment tasks from large datasets of unlabelled interaction data and\nultimately label behavior datasets. Evaluations on BridgeV2, Fractal, and a\nkitchen play dataset show that NILS can autonomously annotate diverse robot\ndemonstrations of unlabeled and unstructured datasets while alleviating several\nshortcomings of crowdsourced human annotations, such as low data quality and\ndiversity. We use NILS to label over 115k trajectories obtained from over 430\nhours of robot data. We open-source our auto-labeling code and generated\nannotations on our website: http://robottasklabeling.github.io.\n","authors":["Nils Blank","Moritz Reuss","Marcel Rühle","Ömer Erdinç Yağmurlu","Fabian Wenzel","Oier Mees","Rudolf Lioutikov"],"pdf_url":"https://arxiv.org/pdf/2410.17772v1.pdf","comment":"Project Website at https://robottasklabeling.github.io/"},{"id":"http://arxiv.org/abs/2404.19232v7","updated":"2024-10-23T11:19:02Z","published":"2024-04-30T03:29:30Z","title":"GRAMMAR: Grounded and Modular Methodology for Assessment of\n  Closed-Domain Retrieval-Augmented Language Model","summary":"  Retrieval-Augmented Generation (RAG) systems are widely used across various\nindustries for querying closed-domain and in-house knowledge bases. However,\nevaluating these systems presents significant challenges due to the private\nnature of closed-domain data and a scarcity of queries with verifiable ground\ntruths. Moreover, there is a lack of analytical methods to diagnose problematic\nmodules and identify types of failure, such as those caused by knowledge\ndeficits or issues with robustness. To address these challenges, we introduce\nGRAMMAR (GRounded And Modular Methodology for Assessment of RAG), an evaluation\nframework comprising a grounded data generation process and an evaluation\nprotocol that effectively pinpoints defective modules. Our validation\nexperiments reveal that GRAMMAR provides a reliable approach for identifying\nvulnerable modules and supports hypothesis testing for textual form\nvulnerabilities. An open-source tool accompanying this framework is available\nin our GitHub repository (see https://github.com/xinzhel/grammar), allowing for\neasy reproduction of our results and enabling reliable and modular evaluation\nin closed-domain settings.\n","authors":["Xinzhe Li","Ming Liu","Shang Gao"],"pdf_url":"https://arxiv.org/pdf/2404.19232v7.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2410.13247v2","updated":"2024-10-23T11:09:57Z","published":"2024-10-17T06:14:34Z","title":"Collaborative AI in Sentiment Analysis: System Architecture, Data\n  Prediction and Deployment Strategies","summary":"  The advancement of large language model (LLM) based artificial intelligence\ntechnologies has been a game-changer, particularly in sentiment analysis. This\nprogress has enabled a shift from highly specialized research environments to\npractical, widespread applications within the industry. However, integrating\ndiverse AI models for processing complex multimodal data and the associated\nhigh costs of feature extraction presents significant challenges. Motivated by\nthe marketing oriented software development +needs, our study introduces a\ncollaborative AI framework designed to efficiently distribute and resolve tasks\nacross various AI systems to address these issues. Initially, we elucidate the\nkey solutions derived from our development process, highlighting the role of\ngenerative AI models like \\emph{chatgpt}, \\emph{google gemini} in simplifying\nintricate sentiment analysis tasks into manageable, phased objectives.\nFurthermore, we present a detailed case study utilizing our collaborative AI\nsystem in edge and cloud, showcasing its effectiveness in analyzing sentiments\nacross diverse online media channels.\n","authors":["Chaofeng Zhang","Jia Hou","Xueting Tan","Gaolei Li","Caijuan Chen"],"pdf_url":"https://arxiv.org/pdf/2410.13247v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17764v1","updated":"2024-10-23T11:02:59Z","published":"2024-10-23T11:02:59Z","title":"Beyond Backpropagation: Optimization with Multi-Tangent Forward\n  Gradients","summary":"  The gradients used to train neural networks are typically computed using\nbackpropagation. While an efficient way to obtain exact gradients,\nbackpropagation is computationally expensive, hinders parallelization, and is\nbiologically implausible. Forward gradients are an approach to approximate the\ngradients from directional derivatives along random tangents computed by\nforward-mode automatic differentiation. So far, research has focused on using a\nsingle tangent per step. This paper provides an in-depth analysis of\nmulti-tangent forward gradients and introduces an improved approach to\ncombining the forward gradients from multiple tangents based on orthogonal\nprojections. We demonstrate that increasing the number of tangents improves\nboth approximation quality and optimization performance across various tasks.\n","authors":["Katharina Flügel","Daniel Coquelin","Marie Weiel","Achim Streit","Markus Götz"],"pdf_url":"https://arxiv.org/pdf/2410.17764v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.12676v2","updated":"2024-10-23T11:01:45Z","published":"2023-12-20T00:31:43Z","title":"Bayesian Analysis of Combinatorial Gaussian Process Bandits","summary":"  We consider the combinatorial volatile Gaussian process (GP) semi-bandit\nproblem. Each round, an agent is provided a set of available base arms and must\nselect a subset of them to maximize the long-term cumulative reward. We study\nthe Bayesian setting and provide novel Bayesian cumulative regret bounds for\nthree GP-based algorithms: GP-UCB, GP-BayesUCB and GP-TS. Our bounds extend\nprevious results for GP-UCB and GP-TS to the infinite, volatile and\ncombinatorial setting, and to the best of our knowledge, we provide the first\nregret bound for GP-BayesUCB. Volatile arms encompass other widely considered\nbandit problems such as contextual bandits. Furthermore, we employ our\nframework to address the challenging real-world problem of online\nenergy-efficient navigation, where we demonstrate its effectiveness compared to\nthe alternatives.\n","authors":["Jack Sandberg","Niklas Åkerblom","Morteza Haghir Chehreghani"],"pdf_url":"https://arxiv.org/pdf/2312.12676v2.pdf","comment":"32 pages, 10 figures"},{"id":"http://arxiv.org/abs/2410.17758v1","updated":"2024-10-23T10:50:07Z","published":"2024-10-23T10:50:07Z","title":"Escaping the Forest: Sparse Interpretable Neural Networks for Tabular\n  Data","summary":"  Tabular datasets are widely used in scientific disciplines such as biology.\nWhile these disciplines have already adopted AI methods to enhance their\nfindings and analysis, they mainly use tree-based methods due to their\ninterpretability. At the same time, artificial neural networks have been shown\nto offer superior flexibility and depth for rich and complex non-tabular\nproblems, but they are falling behind tree-based models for tabular data in\nterms of performance and interpretability. Although sparsity has been shown to\nimprove the interpretability and performance of ANN models for complex\nnon-tabular datasets, enforcing sparsity structurally and formatively for\ntabular data before training the model, remains an open question. To address\nthis question, we establish a method that infuses sparsity in neural networks\nby utilising attention mechanisms to capture the features' importance in\ntabular datasets. We show that our models, Sparse TABular NET or sTAB-Net with\nattention mechanisms, are more effective than tree-based models, reaching the\nstate-of-the-art on biological datasets. They further permit the extraction of\ninsights from these datasets and achieve better performance than post-hoc\nmethods like SHAP.\n","authors":["Salvatore Raieli","Abdulrahman Altahhan","Nathalie Jeanray","Stéphane Gerart","Sebastien Vachenc"],"pdf_url":"https://arxiv.org/pdf/2410.17758v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17751v1","updated":"2024-10-23T10:28:17Z","published":"2024-10-23T10:28:17Z","title":"VISAGE: Video Synthesis using Action Graphs for Surgery","summary":"  Surgical data science (SDS) is a field that analyzes patient data before,\nduring, and after surgery to improve surgical outcomes and skills. However,\nsurgical data is scarce, heterogeneous, and complex, which limits the\napplicability of existing machine learning methods. In this work, we introduce\nthe novel task of future video generation in laparoscopic surgery. This task\ncan augment and enrich the existing surgical data and enable various\napplications, such as simulation, analysis, and robot-aided surgery.\nUltimately, it involves not only understanding the current state of the\noperation but also accurately predicting the dynamic and often unpredictable\nnature of surgical procedures. Our proposed method, VISAGE (VIdeo Synthesis\nusing Action Graphs for Surgery), leverages the power of action scene graphs to\ncapture the sequential nature of laparoscopic procedures and utilizes diffusion\nmodels to synthesize temporally coherent video sequences. VISAGE predicts the\nfuture frames given only a single initial frame, and the action graph triplets.\nBy incorporating domain-specific knowledge through the action graph, VISAGE\nensures the generated videos adhere to the expected visual and motion patterns\nobserved in real laparoscopic procedures. The results of our experiments\ndemonstrate high-fidelity video generation for laparoscopy procedures, which\nenables various applications in SDS.\n","authors":["Yousef Yeganeh","Rachmadio Lazuardi","Amir Shamseddin","Emine Dari","Yash Thirani","Nassir Navab Azade Farshad"],"pdf_url":"https://arxiv.org/pdf/2410.17751v1.pdf","comment":"Accepted at MICCAI 2024 Embodied AI and Robotics for HealTHcare\n  (EARTH) Workshop"},{"id":"http://arxiv.org/abs/2410.17744v1","updated":"2024-10-23T10:17:13Z","published":"2024-10-23T10:17:13Z","title":"Learning Versatile Skills with Curriculum Masking","summary":"  Masked prediction has emerged as a promising pretraining paradigm in offline\nreinforcement learning (RL) due to its versatile masking schemes, enabling\nflexible inference across various downstream tasks with a unified model.\nDespite the versatility of masked prediction, it remains unclear how to balance\nthe learning of skills at different levels of complexity. To address this, we\npropose CurrMask, a curriculum masking pretraining paradigm for sequential\ndecision making. Motivated by how humans learn by organizing knowledge in a\ncurriculum, CurrMask adjusts its masking scheme during pretraining for learning\nversatile skills. Through extensive experiments, we show that CurrMask exhibits\nsuperior zero-shot performance on skill prompting tasks, goal-conditioned\nplanning tasks, and competitive finetuning performance on offline RL tasks.\nAdditionally, our analysis of training dynamics reveals that CurrMask gradually\nacquires skills of varying complexity by dynamically adjusting its masking\nscheme.\n","authors":["Yao Tang","Zhihui Xie","Zichuan Lin","Deheng Ye","Shuai Li"],"pdf_url":"https://arxiv.org/pdf/2410.17744v1.pdf","comment":"NeurIPS 2024 poster, 21 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.17740v1","updated":"2024-10-23T10:14:37Z","published":"2024-10-23T10:14:37Z","title":"Emotion Recognition with Facial Attention and Objective Activation\n  Functions","summary":"  In this paper, we study the effect of introducing channel and spatial\nattention mechanisms, namely SEN-Net, ECA-Net, and CBAM, to existing CNN\nvision-based models such as VGGNet, ResNet, and ResNetV2 to perform the Facial\nEmotion Recognition task. We show that not only attention can significantly\nimprove the performance of these models but also that combining them with a\ndifferent activation function can further help increase the performance of\nthese models.\n","authors":["Andrzej Miskow","Abdulrahman Altahhan"],"pdf_url":"https://arxiv.org/pdf/2410.17740v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17735v1","updated":"2024-10-23T10:11:39Z","published":"2024-10-23T10:11:39Z","title":"New Insight in Cervical Cancer Diagnosis Using Convolution Neural\n  Network Architecture","summary":"  The Pap smear is a screening method for early cervical cancer diagnosis. The\nselection of the right optimizer in the convolutional neural network (CNN)\nmodel is key to the success of the CNN in image classification, including the\nclassification of cervical cancer Pap smear images. In this study, stochastic\ngradient descent (SGD), RMSprop, Adam, AdaGrad, AdaDelta, Adamax, and Nadam\noptimizers were used to classify cervical cancer Pap smear images from the\nSipakMed dataset. Resnet-18, Resnet-34, and VGG-16 are the CNN architectures\nused in this study, and each architecture uses a transfer-learning model. Based\non the test results, we conclude that the transfer learning model performs\nbetter on all CNNs and optimization techniques and that in the transfer\nlearning model, the optimization has little influence on the training of the\nmodel. Adamax, with accuracy values of 72.8% and 66.8%, had the best accuracy\nfor the VGG-16 and Resnet-18 architectures, respectively. Resnet-34 had 54.0%.\nThis is 0.034% lower than Nadam. Overall, Adamax is a suitable optimizer for\nCNN in cervical cancer classification on Resnet-18, Resnet-34, and VGG-16\narchitectures. This study provides new insights into the configuration of CNN\nmodels for Pap smear image analysis.\n","authors":["Ach. Khozaimi","Wayan Firdaus Mahmudy"],"pdf_url":"https://arxiv.org/pdf/2410.17735v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.03094v2","updated":"2024-10-23T10:09:10Z","published":"2024-07-03T13:34:33Z","title":"Conformal Prediction for Causal Effects of Continuous Treatments","summary":"  Uncertainty quantification of causal effects is crucial for safety-critical\napplications such as personalized medicine. A powerful approach for this is\nconformal prediction, which has several practical benefits due to\nmodel-agnostic finite-sample guarantees. Yet, existing methods for conformal\nprediction of causal effects are limited to binary/discrete treatments and make\nhighly restrictive assumptions such as known propensity scores. In this work,\nwe provide a novel conformal prediction method for potential outcomes of\ncontinuous treatments. We account for the additional uncertainty introduced\nthrough propensity estimation so that our conformal prediction intervals are\nvalid even if the propensity score is unknown. Our contributions are\nthree-fold: (1) We derive finite-sample prediction intervals for potential\noutcomes of continuous treatments. (2) We provide an algorithm for calculating\nthe derived intervals. (3) We demonstrate the effectiveness of the conformal\nprediction intervals in experiments on synthetic and real-world datasets. To\nthe best of our knowledge, we are the first to propose conformal prediction for\ncontinuous treatments when the propensity score is unknown and must be\nestimated from data.\n","authors":["Maresa Schröder","Dennis Frauen","Jonas Schweisthal","Konstantin Heß","Valentyn Melnychuk","Stefan Feuerriegel"],"pdf_url":"https://arxiv.org/pdf/2407.03094v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.14622v2","updated":"2024-10-23T10:06:10Z","published":"2024-02-22T15:10:45Z","title":"From Keywords to Structured Summaries: Streamlining Scholarly\n  Information Access","summary":"  This paper highlights the growing importance of information retrieval (IR)\nengines in the scientific community, addressing the inefficiency of traditional\nkeyword-based search engines due to the rising volume of publications. The\nproposed solution involves structured records, underpinning advanced\ninformation technology (IT) tools, including visualization dashboards, to\nrevolutionize how researchers access and filter articles, replacing the\ntraditional text-heavy approach. This vision is exemplified through a proof of\nconcept centered on the \"reproductive number estimate of infectious diseases\"\nresearch theme, using a fine-tuned large language model (LLM) to automate the\ncreation of structured records to populate a backend database that now goes\nbeyond keywords. The result is a next-generation information access system as\nan IR method accessible at https://orkg.org/usecases/r0-estimates.\n","authors":["Mahsa Shamsabadi","Jennifer D'Souza"],"pdf_url":"https://arxiv.org/pdf/2402.14622v2.pdf","comment":"8 pages, 3 figures | Accepted for publication as a poster paper at\n  the International Semantic Web Conference (ISWC 2024)"},{"id":"http://arxiv.org/abs/2410.17732v1","updated":"2024-10-23T10:06:08Z","published":"2024-10-23T10:06:08Z","title":"FuzzWiz -- Fuzzing Framework for Efficient Hardware Coverage","summary":"  Ever-increasing design complexity of System-on-Chips (SoCs) led to\nsignificant verification challenges. Unlike software, bugs in hardware design\nare vigorous and eternal i.e., once the hardware is fabricated, it cannot be\nrepaired with any patch. Despite being one of the powerful techniques used in\nverification, the dynamic random approach cannot give confidence to complex\nRegister Transfer Leve (RTL) designs during the pre-silicon design phase. In\nparticular, achieving coverage targets and exposing bugs is a complicated task\nwith random simulations. In this paper, we leverage an existing testing\nsolution available in the software world known as fuzzing and apply it to\nhardware verification in order to achieve coverage targets in quick time. We\ncreated an automated hardware fuzzing framework FuzzWiz using metamodeling and\nPython to achieve coverage goals faster. It includes parsing the RTL design\nmodule, converting it into C/C++ models, creating generic testbench with\nassertions, fuzzer-specific compilation, linking, and fuzzing. Furthermore, it\nis configurable and provides the debug flow if any crash is detected during the\nfuzzing process. The proposed framework is applied on four IP blocks from\nGoogle's OpenTitan chip with various fuzzing engines to show its scalability\nand compatibility. Our benchmarking results show that we could achieve around\n90% of the coverage 10 times faster than traditional simulation regression\nbased approach.\n","authors":["Deepak Narayan Gadde","Aman Kumar","Djones Lettnin","Sebastian Simon"],"pdf_url":"https://arxiv.org/pdf/2410.17732v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.06310v2","updated":"2024-10-23T09:59:15Z","published":"2024-08-12T17:24:19Z","title":"OWL2Vec4OA: Tailoring Knowledge Graph Embeddings for Ontology Alignment","summary":"  Ontology alignment is integral to achieving semantic interoperability as the\nnumber of available ontologies covering intersecting domains is increasing.\nThis paper proposes OWL2Vec4OA, an extension of the ontology embedding system\nOWL2Vec*. While OWL2Vec* has emerged as a powerful technique for ontology\nembedding, it currently lacks a mechanism to tailor the embedding to the\nontology alignment task. OWL2Vec4OA incorporates edge confidence values from\nseed mappings to guide the random walk strategy. We present the theoretical\nfoundations, implementation details, and experimental evaluation of our\nproposed extension, demonstrating its potential effectiveness for ontology\nalignment tasks.\n","authors":["Sevinj Teymurova","Ernesto Jiménez-Ruiz","Tillman Weyde","Jiaoyan Chen"],"pdf_url":"https://arxiv.org/pdf/2408.06310v2.pdf","comment":"Accepted to the 6th Knowledge Graph and Semantic Web Conference"},{"id":"http://arxiv.org/abs/2410.05354v3","updated":"2024-10-23T09:51:11Z","published":"2024-10-07T13:44:49Z","title":"Over-the-Air Federated Learning in Cell-Free MIMO with Long-term Power\n  Constraint","summary":"  Wireless networks supporting artificial intelligence have gained significant\nattention, with Over-the-Air Federated Learning emerging as a key application\ndue to its unique transmission and distributed computing characteristics. This\npaper derives error bounds for Over-the-Air Federated Learning in a Cell-free\nMIMO system and formulates an optimization problem to minimize optimality gap\nvia joint optimization of power control and beamforming. We introduce the\nMOP-LOFPC algorithm, which employs Lyapunov optimization to decouple long-term\nconstraints across rounds while requiring only causal channel state\ninformation. Experimental results demonstrate that MOP-LOFPC achieves a better\nand more flexible trade-off between the model's training loss and adherence to\nlong-term power constraints compared to existing baselines.\n","authors":["Yifan Wang","Cheng Zhang","Yuanndon Zhuang","Mingzeng Dai","Haiming Wang","Yongming Huang"],"pdf_url":"https://arxiv.org/pdf/2410.05354v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11642v2","updated":"2024-10-23T09:43:03Z","published":"2024-10-15T14:31:54Z","title":"Improve Value Estimation of Q Function and Reshape Reward with Monte\n  Carlo Tree Search","summary":"  Reinforcement learning has achieved remarkable success in perfect information\ngames such as Go and Atari, enabling agents to compete at the highest levels\nagainst human players. However, research in reinforcement learning for\nimperfect information games has been relatively limited due to the more complex\ngame structures and randomness. Traditional methods face challenges in training\nand improving performance in imperfect information games due to issues like\ninaccurate Q value estimation and reward sparsity. In this paper, we focus on\nUno, an imperfect information game, and aim to address these problems by\nreducing Q value overestimation and reshaping reward function. We propose a\nnovel algorithm that utilizes Monte Carlo Tree Search to average the value\nestimations in Q function. Even though we choose Double Deep Q Learning as the\nfoundational framework in this paper, our method can be generalized and used in\nany algorithm which needs Q value estimation, such as the Actor-Critic.\nAdditionally, we employ Monte Carlo Tree Search to reshape the reward structure\nin the game environment. We compare our algorithm with several traditional\nmethods applied to games such as Double Deep Q Learning, Deep Monte Carlo and\nNeural Fictitious Self Play, and the experiments demonstrate that our algorithm\nconsistently outperforms these approaches, especially as the number of players\nin Uno increases, indicating a higher level of difficulty.\n","authors":["Jiamian Li"],"pdf_url":"https://arxiv.org/pdf/2410.11642v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14282v3","updated":"2024-10-23T09:42:59Z","published":"2024-06-20T13:07:38Z","title":"Learning to Plan for Retrieval-Augmented Large Language Models from\n  Knowledge Graphs","summary":"  Improving the performance of large language models (LLMs) in complex\nquestion-answering (QA) scenarios has always been a research focal point.\nRecent studies have attempted to enhance LLMs' performance by combining\nstep-wise planning with external retrieval. While effective for advanced models\nlike GPT-3.5, smaller LLMs face challenges in decomposing complex questions,\nnecessitating supervised fine-tuning. Previous work has relied on manual\nannotation and knowledge distillation from teacher LLMs, which are\ntime-consuming and not accurate enough. In this paper, we introduce a novel\nframework for enhancing LLMs' planning capabilities by using planning data\nderived from knowledge graphs (KGs). LLMs fine-tuned with this data have\nimproved planning capabilities, better equipping them to handle complex QA\ntasks that involve retrieval. Evaluations on multiple datasets, including our\nnewly proposed benchmark, highlight the effectiveness of our framework and the\nbenefits of KG-derived planning data.\n","authors":["Junjie Wang","Mingyang Chen","Binbin Hu","Dan Yang","Ziqi Liu","Yue Shen","Peng Wei","Zhiqiang Zhang","Jinjie Gu","Jun Zhou","Jeff Z. Pan","Wen Zhang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2406.14282v3.pdf","comment":"EMNLP2024 Findings"},{"id":"http://arxiv.org/abs/2410.17714v1","updated":"2024-10-23T09:40:15Z","published":"2024-10-23T09:40:15Z","title":"CogSteer: Cognition-Inspired Selective Layer Intervention for Efficient\n  Semantic Steering in Large Language Models","summary":"  Despite their impressive capabilities, large language models (LLMs) often\nlack interpretability and can generate toxic content. While using LLMs as\nfoundation models and applying semantic steering methods are widely practiced,\nwe believe that efficient methods should be based on a thorough understanding\nof LLM behavior. To this end, we propose using eye movement measures to\ninterpret LLM behavior across layers. We find that LLMs exhibit patterns\nsimilar to human gaze across layers and different layers function differently.\nInspired by these findings, we introduce a heuristic steering layer selection\nand apply it to layer intervention methods via fine-tuning and inference. Using\nlanguage toxification and detoxification as test beds, we demonstrate that our\nproposed CogSteer methods achieve better results in terms of toxicity scores\nwhile efficiently saving 97% of the computational resources and 60% of the\ntraining time. Our model-agnostic approach can be adopted into various LLMs,\ncontributing to their interpretability and promoting trustworthiness for safe\ndeployment.\n","authors":["Xintong Wang","Jingheng Pan","Longqin Jiang","Liang Ding","Xingshan Li","Chris Biemann"],"pdf_url":"https://arxiv.org/pdf/2410.17714v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17712v1","updated":"2024-10-23T09:39:26Z","published":"2024-10-23T09:39:26Z","title":"A Data-Driven Odyssey in Solar Vehicles","summary":"  Solar vehicles, which simultaneously produce and consume energy, require\nmeticulous energy management. However, potential users often feel uncertain\nabout their operation compared to conventional vehicles. This study presents a\nsimulator designed to help users understand long-distance travel in solar\nvehicles and recognize the importance of proper energy management. By utilizing\nGoogle Maps data and weather information, the simulator replicates real-world\ndriving conditions and provides a dashboard displaying vehicle status, updated\nhourly based on user-inputted speed. Users can explore various speed policy\nscenarios and receive recommendations for optimal driving strategies. The\nsimulator's effectiveness was validated using the route of the World Solar\nChallenge (WSC). This research enables users to monitor energy dynamics before\na journey, enhancing their understanding of energy management and informing\nappropriate speed decisions.\n","authors":["Do Young Kim","Kyunghyun Kim","Gyeongseop Lee","Niloy Das","Seong-Woo Kim"],"pdf_url":"https://arxiv.org/pdf/2410.17712v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17711v1","updated":"2024-10-23T09:36:21Z","published":"2024-10-23T09:36:21Z","title":"Beware of Calibration Data for Pruning Large Language Models","summary":"  As large language models (LLMs) are widely applied across various fields,\nmodel compression has become increasingly crucial for reducing costs and\nimproving inference efficiency. Post-training pruning is a promising method\nthat does not require resource-intensive iterative training and only needs a\nsmall amount of calibration data to assess the importance of parameters.\nPrevious research has primarily focused on designing advanced pruning methods,\nwhile different calibration data's impact on pruning performance still lacks\nsystematical exploration. We fill this blank and surprisingly observe that the\neffects of calibration data even value more than designing advanced pruning\nstrategies, especially for high sparsity. Our preliminary exploration also\ndiscloses that using calibration data similar to the training data can yield\nbetter performance. As pre-training data is usually inaccessible for advanced\nLLMs, we further provide a self-generating calibration data synthesis strategy\nto construct feasible calibration data. We conduct experiments on the recent\nstrong open-source LLMs (e.g., DCLM, and LLaMA-3), and the results show that\nthe proposed method outperforms commonly used calibration data and can\neffectively enhance strong pruning methods (e.g., Wanda, OWL).\n","authors":["Yixin Ji","Yang Xiang","Juntao Li","Qingrong Xia","Ping Li","Xinyu Duan","Zhefeng Wang","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.17711v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2410.17700v1","updated":"2024-10-23T09:22:43Z","published":"2024-10-23T09:22:43Z","title":"Scalable Random Feature Latent Variable Models","summary":"  Random feature latent variable models (RFLVMs) represent the state-of-the-art\nin latent variable models, capable of handling non-Gaussian likelihoods and\neffectively uncovering patterns in high-dimensional data. However, their heavy\nreliance on Monte Carlo sampling results in scalability issues which makes it\ndifficult to use these models for datasets with a massive number of\nobservations. To scale up RFLVMs, we turn to the optimization-based variational\nBayesian inference (VBI) algorithm which is known for its scalability compared\nto sampling-based methods. However, implementing VBI for RFLVMs poses\nchallenges, such as the lack of explicit probability distribution functions\n(PDFs) for the Dirichlet process (DP) in the kernel learning component, and the\nincompatibility of existing VBI algorithms with RFLVMs. To address these\nissues, we introduce a stick-breaking construction for DP to obtain an explicit\nPDF and a novel VBI algorithm called ``block coordinate descent variational\ninference\" (BCD-VI). This enables the development of a scalable version of\nRFLVMs, or in short, SRFLVM. Our proposed method shows scalability,\ncomputational efficiency, superior performance in generating informative latent\nrepresentations and the ability of imputing missing data across various\nreal-world datasets, outperforming state-of-the-art competitors.\n","authors":["Ying Li","Zhidi Lin","Yuhao Liu","Michael Minyi Zhang","Pablo M. Olmos","Petar M. Djurić"],"pdf_url":"https://arxiv.org/pdf/2410.17700v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17694v1","updated":"2024-10-23T09:14:57Z","published":"2024-10-23T09:14:57Z","title":"An Adaptive Framework for Generating Systematic Explanatory Answer in\n  Online Q&A Platforms","summary":"  Question Answering (QA) systems face challenges in handling complex questions\nthat require multi-domain knowledge synthesis. The naive RAG models, although\neffective in information retrieval, struggle with complex questions that\nrequire comprehensive and in-depth answers. The pioneering task is defined as\nexplanatory answer generation, which entails handling identified challenges\nsuch as the requirement for comprehensive information and logical coherence\nwithin the generated context. To address these issues, we refer to systematic\nthinking theory and propose SynthRAG, an innovative framework designed to\nenhance QA performance. SynthRAG improves on conventional models by employing\nadaptive outlines for dynamic content structuring, generating systematic\ninformation to ensure detailed coverage, and producing customized answers\ntailored to specific user inquiries. This structured approach guarantees\nlogical coherence and thorough integration of information, yielding responses\nthat are both insightful and methodically organized. Empirical evaluations\nunderscore SynthRAG's effectiveness, demonstrating its superiority in handling\ncomplex questions, overcoming the limitations of naive RAG models, and\nsignificantly improving answer quality and depth. Furthermore, an online\ndeployment on the Zhihu platform revealed that SynthRAG's answers achieved\nnotable user engagement, with each response averaging 5.73 upvotes and\nsurpassing the performance of 79.8% of human contributors, highlighting the\npractical relevance and impact of the proposed framework. Our code is available\nat https://github.com/czy1999/SynthRAG .\n","authors":["Ziyang Chen","Xiaobin Wang","Yong Jiang","Jinzhi Liao","Pengjun Xie","Fei Huang","Xiang Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.17694v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2402.04892v2","updated":"2024-10-23T09:04:57Z","published":"2024-02-07T14:24:04Z","title":"Probabilistic ML Verification via Weighted Model Integration","summary":"  In machine learning (ML) verification, the majority of procedures are\nnon-quantitative and therefore cannot be used for verifying probabilistic\nmodels, or be applied in domains where hard guarantees are practically\nunachievable. The probabilistic formal verification (PFV) of ML models is in\nits infancy, with the existing approaches limited to specific ML models,\nproperties, or both. This contrasts with standard formal methods techniques,\nwhose successful adoption in real-world scenarios is also due to their support\nfor a wide range of properties and diverse systems. We propose a unifying\nframework for the PFV of ML systems based on Weighted Model Integration (WMI),\na relatively recent formalism for probabilistic inference with algebraic and\nlogical constraints. Crucially, reducing the PFV of ML models to WMI enables\nthe verification of many properties of interest over a wide range of systems,\naddressing multiple limitations of deterministic verification and ad-hoc\nalgorithms. We substantiate the generality of the approach on prototypical\ntasks involving the verification of group fairness, monotonicity, robustness to\nnoise, probabilistic local robustness and equivalence among predictors. We\ncharacterize the challenges related to the scalability of the approach and,\nthrough our WMI-based perspective, we show how successful scaling techniques in\nthe ML verification literature can be generalized beyond their original scope.\n","authors":["Paolo Morettin","Andrea Passerini","Roberto Sebastiani"],"pdf_url":"https://arxiv.org/pdf/2402.04892v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.10192v3","updated":"2024-10-23T08:39:00Z","published":"2024-02-15T18:48:32Z","title":"Multi-Excitation Projective Simulation with a Many-Body Physics Inspired\n  Inductive Bias","summary":"  With the impressive progress of deep learning, applications relying on\nmachine learning are increasingly being integrated into daily life. However,\nmost deep learning models have an opaque, oracle-like nature making it\ndifficult to interpret and understand their decisions. This problem led to the\ndevelopment of the field known as eXplainable Artificial Intelligence (XAI).\nOne method in this field known as Projective Simulation (PS) models a\nchain-of-thought as a random walk of a particle on a graph with vertices that\nhave concepts attached to them. While this description has various benefits,\nincluding the possibility of quantization, it cannot be naturally used to model\nthoughts that combine several concepts simultaneously. To overcome this\nlimitation, we introduce Multi-Excitation Projective Simulation (mePS), a\ngeneralization that considers a chain-of-thought to be a random walk of several\nparticles on a hypergraph. A definition for a dynamic hypergraph is put forward\nto describe the agent's training history along with applications to AI and\nhypergraph visualization. An inductive bias inspired by the remarkably\nsuccessful few-body interaction models used in quantum many-body physics is\nformalized for our classical mePS framework and employed to tackle the\nexponential complexity associated with naive implementations of hypergraphs. We\nprove that our inductive bias reduces the complexity from exponential to\npolynomial, with the exponent representing the cutoff on how many particles can\ninteract. We numerically apply our method to two toy environments and a more\ncomplex scenario modelling the diagnosis of a broken computer. These\nenvironments demonstrate the resource savings provided by an appropriate choice\nof inductive bias, as well as showcasing aspects of interpretability. A quantum\nmodel for mePS is also briefly outlined and some future directions for it are\ndiscussed.\n","authors":["Philip A. LeMaitre","Marius Krumm","Hans J. Briegel"],"pdf_url":"https://arxiv.org/pdf/2402.10192v3.pdf","comment":"26 pages, 8 figures; Code repository at\n  https://github.com/MariusKrumm/ManyBodyMEPS. Reorganized main text for better\n  readability"},{"id":"http://arxiv.org/abs/2410.17661v1","updated":"2024-10-23T08:24:47Z","published":"2024-10-23T08:24:47Z","title":"PETAH: Parameter Efficient Task Adaptation for Hybrid Transformers in a\n  resource-limited Context","summary":"  Following their success in natural language processing (NLP), there has been\na shift towards transformer models in computer vision. While transformers\nperform well and offer promising multi-tasking performance, due to their high\ncompute requirements, many resource-constrained applications still rely on\nconvolutional or hybrid models that combine the benefits of convolution and\nattention layers and achieve the best results in the sub 100M parameter range.\nSimultaneously, task adaptation techniques that allow for the use of one shared\ntransformer backbone for multiple downstream tasks, resulting in great storage\nsavings at negligible cost in performance, have not yet been adopted for hybrid\ntransformers. In this work, we investigate how to achieve the best\ntask-adaptation performance and introduce PETAH: Parameter Efficient Task\nAdaptation for Hybrid Transformers. We further combine PETAH adaptation with\npruning to achieve highly performant and storage friendly models for\nmulti-tasking. In our extensive evaluation on classification and other vision\ntasks, we demonstrate that our PETAH-adapted hybrid models outperform\nestablished task-adaptation techniques for ViTs while requiring fewer\nparameters and being more efficient on mobile hardware.\n","authors":["Maximilian Augustin","Syed Shakib Sarwar","Mostafa Elhoushi","Sai Qian Zhang","Yuecheng Li","Barbara De Salvo"],"pdf_url":"https://arxiv.org/pdf/2410.17661v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10216v2","updated":"2024-10-23T08:22:44Z","published":"2024-06-14T17:49:59Z","title":"Regularizing Hidden States Enables Learning Generalizable Reward Model\n  for LLMs","summary":"  Reward models trained on human preference data have been proven to\neffectively align Large Language Models (LLMs) with human intent within the\nframework of reinforcement learning from human feedback (RLHF). However,\ncurrent reward models have limited generalization capabilities to unseen\nprompts and responses, which can lead to an unexpected phenomenon known as\nreward over-optimization, resulting in a decline in actual performance due to\nexcessive optimization of rewards. While previous research has advocated for\nconstraining policy optimization, our study introduces a novel approach to\nenhance the reward model's generalization ability against distribution shifts\nby regularizing the hidden states. Specifically, we retain the base model's\nlanguage model head and incorporate a suite of text-generation losses to\npreserve the hidden states' text-generation capabilities, while concurrently\nlearning a reward head behind the same hidden states. Our experimental results\ndemonstrate that the introduced regularization technique markedly improves the\naccuracy of learned reward models across a variety of out-of-distribution (OOD)\ntasks and effectively alleviates the over-optimization issue in RLHF, offering\na more reliable and robust preference learning paradigm.\n","authors":["Rui Yang","Ruomeng Ding","Yong Lin","Huan Zhang","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.10216v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.17656v1","updated":"2024-10-23T08:18:38Z","published":"2024-10-23T08:18:38Z","title":"AutoRNet: Automatically Optimizing Heuristics for Robust Network Design\n  via Large Language Models","summary":"  Achieving robust networks is a challenging problem due to its NP-hard nature\nand complex solution space. Current methods, from handcrafted feature\nextraction to deep learning, have made progress but remain rigid, requiring\nmanual design and large labeled datasets. To address these issues, we propose\nAutoRNet, a framework that integrates large language models (LLMs) with\nevolutionary algorithms to generate heuristics for robust network design. We\ndesign network optimization strategies to provide domain-specific prompts for\nLLMs, utilizing domain knowledge to generate advanced heuristics. Additionally,\nwe introduce an adaptive fitness function to balance convergence and diversity\nwhile maintaining degree distributions. AutoRNet is evaluated on sparse and\ndense scale-free networks, outperforming current methods by reducing the need\nfor manual design and large datasets.\n","authors":["He Yu","Jing Liu"],"pdf_url":"https://arxiv.org/pdf/2410.17656v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17655v1","updated":"2024-10-23T08:18:26Z","published":"2024-10-23T08:18:26Z","title":"Mapping the Media Landscape: Predicting Factual Reporting and Political\n  Bias Through Web Interactions","summary":"  Bias assessment of news sources is paramount for professionals,\norganizations, and researchers who rely on truthful evidence for information\ngathering and reporting. While certain bias indicators are discernible from\ncontent analysis, descriptors like political bias and fake news pose greater\nchallenges. In this paper, we propose an extension to a recently presented news\nmedia reliability estimation method that focuses on modeling outlets and their\nlongitudinal web interactions. Concretely, we assess the classification\nperformance of four reinforcement learning strategies on a large news media\nhyperlink graph. Our experiments, targeting two challenging bias descriptors,\nfactual reporting and political bias, showed a significant performance\nimprovement at the source media level. Additionally, we validate our methods on\nthe CLEF 2023 CheckThat! Lab challenge, outperforming the reported results in\nboth, F1-score and the official MAE metric. Furthermore, we contribute by\nreleasing the largest annotated dataset of news source media, categorized with\nfactual reporting and political bias labels. Our findings suggest that\nprofiling news media sources based on their hyperlink interactions over time is\nfeasible, offering a bird's-eye view of evolving media landscapes.\n","authors":["Dairazalia Sánchez-Cortés","Sergio Burdisso","Esaú Villatoro-Tello","Petr Motlicek"],"pdf_url":"https://arxiv.org/pdf/2410.17655v1.pdf","comment":"Accepted to CLEF 2024"},{"id":"http://arxiv.org/abs/2410.17637v1","updated":"2024-10-23T07:56:48Z","published":"2024-10-23T07:56:48Z","title":"MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large\n  Vision-Language Models","summary":"  Visual preference alignment involves training Large Vision-Language Models\n(LVLMs) to predict human preferences between visual inputs. This is typically\nachieved by using labeled datasets of chosen/rejected pairs and employing\noptimization algorithms like direct preference optimization (DPO). Existing\nvisual alignment methods, primarily designed for single-image scenarios,\nstruggle to effectively handle the complexity of multi-image tasks due to the\nscarcity of diverse training data and the high cost of annotating\nchosen/rejected pairs. We present Multi-Image Augmented Direct Preference\nOptimization (MIA-DPO), a visual preference alignment approach that effectively\nhandles multi-image inputs. MIA-DPO mitigates the scarcity of diverse\nmulti-image training data by extending single-image data with unrelated images\narranged in grid collages or pic-in-pic formats, significantly reducing the\ncosts associated with multi-image data annotations. Our observation reveals\nthat attention values of LVLMs vary considerably across different images. We\nuse attention values to identify and filter out rejected responses the model\nmay have mistakenly focused on. Our attention-aware selection for constructing\nthe chosen/rejected pairs without relying on (i) human annotation, (ii) extra\ndata, and (iii) external models or APIs. MIA-DPO is compatible with various\narchitectures and outperforms existing methods on five multi-image benchmarks,\nachieving an average performance boost of 3.0% on LLaVA-v1.5 and 4.3% on the\nrecent InternLM-XC2.5. Moreover, MIA-DPO has a minimal effect on the model's\nability to understand single images.\n","authors":["Ziyu Liu","Yuhang Zang","Xiaoyi Dong","Pan Zhang","Yuhang Cao","Haodong Duan","Conghui He","Yuanjun Xiong","Dahua Lin","Jiaqi Wang"],"pdf_url":"https://arxiv.org/pdf/2410.17637v1.pdf","comment":"Project URL: https://github.com/Liuziyu77/MIA-DPO"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2410.18082v1","updated":"2024-10-23T17:59:52Z","published":"2024-10-23T17:59:52Z","title":"Prioritized Generative Replay","summary":"  Sample-efficient online reinforcement learning often uses replay buffers to\nstore experience for reuse when updating the value function. However, uniform\nreplay is inefficient, since certain classes of transitions can be more\nrelevant to learning. While prioritization of more useful samples is helpful,\nthis strategy can also lead to overfitting, as useful samples are likely to be\nmore rare. In this work, we instead propose a prioritized, parametric version\nof an agent's memory, using generative models to capture online experience.\nThis paradigm enables (1) densification of past experience, with new\ngenerations that benefit from the generative model's generalization capacity\nand (2) guidance via a family of \"relevance functions\" that push these\ngenerations towards more useful parts of an agent's acquired history. We show\nthis recipe can be instantiated using conditional diffusion models and simple\nrelevance functions such as curiosity- or value-based metrics. Our approach\nconsistently improves performance and sample efficiency in both state- and\npixel-based domains. We expose the mechanisms underlying these gains, showing\nhow guidance promotes diversity in our generated transitions and reduces\noverfitting. We also showcase how our approach can train policies with even\nhigher update-to-data ratios than before, opening up avenues to better scale\nonline RL agents.\n","authors":["Renhao Wang","Kevin Frans","Pieter Abbeel","Sergey Levine","Alexei A. Efros"],"pdf_url":"https://arxiv.org/pdf/2410.18082v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18077v1","updated":"2024-10-23T17:58:49Z","published":"2024-10-23T17:58:49Z","title":"ALTA: Compiler-Based Analysis of Transformers","summary":"  We propose a new programming language called ALTA and a compiler that can map\nALTA programs to Transformer weights. ALTA is inspired by RASP, a language\nproposed by Weiss et al. (2021), and Tracr (Lindner et al., 2023), a compiler\nfrom RASP programs to Transformer weights. ALTA complements and extends this\nprior work, offering the ability to express loops and to compile programs to\nUniversal Transformers, among other advantages. ALTA allows us to\nconstructively show how Transformers can represent length-invariant algorithms\nfor computing parity and addition, as well as a solution to the SCAN benchmark\nof compositional generalization tasks, without requiring intermediate\nscratchpad decoding steps. We also propose tools to analyze cases where the\nexpressibility of an algorithm is established, but end-to-end training on a\ngiven training set fails to induce behavior consistent with the desired\nalgorithm. To this end, we explore training from ALTA execution traces as a\nmore fine-grained supervision signal. This enables additional experiments and\ntheoretical analyses relating the learnability of various algorithms to data\navailability and modeling decisions, such as positional encodings. We make the\nALTA framework -- language specification, symbolic interpreter, and weight\ncompiler -- available to the community to enable further applications and\ninsights.\n","authors":["Peter Shaw","James Cohan","Jacob Eisenstein","Kenton Lee","Jonathan Berant","Kristina Toutanova"],"pdf_url":"https://arxiv.org/pdf/2410.18077v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18076v1","updated":"2024-10-23T17:58:45Z","published":"2024-10-23T17:58:45Z","title":"Leveraging Skills from Unlabeled Prior Data for Efficient Online\n  Exploration","summary":"  Unsupervised pretraining has been transformative in many supervised domains.\nHowever, applying such ideas to reinforcement learning (RL) presents a unique\nchallenge in that fine-tuning does not involve mimicking task-specific data,\nbut rather exploring and locating the solution through iterative\nself-improvement. In this work, we study how unlabeled prior trajectory data\ncan be leveraged to learn efficient exploration strategies. While prior data\ncan be used to pretrain a set of low-level skills, or as additional off-policy\ndata for online RL, it has been unclear how to combine these ideas effectively\nfor online exploration. Our method SUPE (Skills from Unlabeled Prior data for\nExploration) demonstrates that a careful combination of these ideas compounds\ntheir benefits. Our method first extracts low-level skills using a variational\nautoencoder (VAE), and then pseudo-relabels unlabeled trajectories using an\noptimistic reward model, transforming prior data into high-level, task-relevant\nexamples. Finally, SUPE uses these transformed examples as additional\noff-policy data for online RL to learn a high-level policy that composes\npretrained low-level skills to explore efficiently. We empirically show that\nSUPE reliably outperforms prior strategies, successfully solving a suite of\nlong-horizon, sparse-reward tasks. Code: https://github.com/rail-berkeley/supe.\n","authors":["Max Wilcoxson","Qiyang Li","Kevin Frans","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2410.18076v1.pdf","comment":"23 pages, 10 figures"},{"id":"http://arxiv.org/abs/2410.18075v1","updated":"2024-10-23T17:57:14Z","published":"2024-10-23T17:57:14Z","title":"ProFL: Performative Robust Optimal Federated Learning","summary":"  Performative prediction (PP) is a framework that captures distribution shifts\nthat occur during the training of machine learning models due to their\ndeployment. As the trained model is used, its generated data could cause the\nmodel to evolve, leading to deviations from the original data distribution. The\nimpact of such model-induced distribution shifts in the federated learning (FL)\nsetup remains unexplored despite being increasingly likely to transpire in\nreal-life use cases. Although Jin et al. (2024) recently extended PP to FL in a\nstraightforward manner, the resulting model only converges to a performative\nstable point, which may be far from optimal. The methods in Izzo et al. (2021);\nMiller et al. (2021) can find a performative optimal point in centralized\nsettings, but they require the performative risk to be convex and the training\ndata to be noiseless, assumptions often violated in realistic FL systems. This\npaper overcomes all of these shortcomings and proposes Performative robust\noptimal Federated Learning (ProFL), an algorithm that finds performative\noptimal points in FL from noisy and contaminated data. We present the\nconvergence analysis under the Polyak-Lojasiewicz condition, which applies to\nnon-convex objectives. Extensive experiments on multiple datasets validate our\nproposed algorithms' efficiency.\n","authors":["Xue Zheng","Tian Xie","Xuwei Tan","Aylin Yener","Xueru Zhang","Ali Payani","Myungjin Lee"],"pdf_url":"https://arxiv.org/pdf/2410.18075v1.pdf","comment":"27 pages with Appendix, 18 figures. The paper has been submitted and\n  is currently under review"},{"id":"http://arxiv.org/abs/2410.18074v1","updated":"2024-10-23T17:56:33Z","published":"2024-10-23T17:56:33Z","title":"UnCLe: Unsupervised Continual Learning of Depth Completion","summary":"  We propose UnCLe, a standardized benchmark for Unsupervised Continual\nLearning of a multimodal depth estimation task: Depth completion aims to infer\na dense depth map from a pair of synchronized RGB image and sparse depth map.\nWe benchmark depth completion models under the practical scenario of\nunsupervised learning over continuous streams of data. Existing methods are\ntypically trained on a static, or stationary, dataset. However, when adapting\nto novel non-stationary distributions, they \"catastrophically forget\"\npreviously learned information. UnCLe simulates these non-stationary\ndistributions by adapting depth completion models to sequences of datasets\ncontaining diverse scenes captured from distinct domains using different visual\nand range sensors. We adopt representative methods from continual learning\nparadigms and translate them to enable unsupervised continual learning of depth\ncompletion. We benchmark these models for indoor and outdoor and investigate\nthe degree of catastrophic forgetting through standard quantitative metrics.\nFurthermore, we introduce model inversion quality as an additional measure of\nforgetting. We find that unsupervised continual learning of depth completion is\nan open problem, and we invite researchers to leverage UnCLe as a development\nplatform.\n","authors":["Suchisrit Gangopadhyay","Xien Chen","Michael Chu","Patrick Rim","Hyoungseob Park","Alex Wong"],"pdf_url":"https://arxiv.org/pdf/2410.18074v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2408.12568v2","updated":"2024-10-23T17:53:24Z","published":"2024-08-22T17:35:18Z","title":"Pruning By Explaining Revisited: Optimizing Attribution Methods to Prune\n  CNNs and Transformers","summary":"  To solve ever more complex problems, Deep Neural Networks are scaled to\nbillions of parameters, leading to huge computational costs. An effective\napproach to reduce computational requirements and increase efficiency is to\nprune unnecessary components of these often over-parameterized networks.\nPrevious work has shown that attribution methods from the field of eXplainable\nAI serve as effective means to extract and prune the least relevant network\ncomponents in a few-shot fashion. We extend the current state by proposing to\nexplicitly optimize hyperparameters of attribution methods for the task of\npruning, and further include transformer-based networks in our analysis. Our\napproach yields higher model compression rates of large transformer- and\nconvolutional architectures (VGG, ResNet, ViT) compared to previous works,\nwhile still attaining high performance on ImageNet classification tasks. Here,\nour experiments indicate that transformers have a higher degree of\nover-parameterization compared to convolutional neural networks. Code is\navailable at https://github.com/erfanhatefi/Pruning-by-eXplaining-in-PyTorch.\n","authors":["Sayed Mohammad Vakilzadeh Hatefi","Maximilian Dreyer","Reduan Achtibat","Thomas Wiegand","Wojciech Samek","Sebastian Lapuschkin"],"pdf_url":"https://arxiv.org/pdf/2408.12568v2.pdf","comment":"Accepted as a workshop paper at ECCV 2024, 26 pages (11 pages\n  manuscript, 3 pages references, 12 pages appendix)"},{"id":"http://arxiv.org/abs/2410.18070v1","updated":"2024-10-23T17:53:11Z","published":"2024-10-23T17:53:11Z","title":"Training Free Guided Flow Matching with Optimal Control","summary":"  Controlled generation with pre-trained Diffusion and Flow Matching models has\nvast applications. One strategy for guiding ODE-based generative models is\nthrough optimizing a target loss $R(x_1)$ while staying close to the prior\ndistribution. Along this line, some recent work showed the effectiveness of\nguiding flow model by differentiating through its ODE sampling process. Despite\nthe superior performance, the theoretical understanding of this line of methods\nis still preliminary, leaving space for algorithm improvement. Moreover,\nexisting methods predominately focus on Euclidean data manifold, and there is a\ncompelling need for guided flow methods on complex geometries such as SO(3),\nwhich prevails in high-stake scientific applications like protein design. We\npresent OC-Flow, a general and theoretically grounded training-free framework\nfor guided flow matching using optimal control. Building upon advances in\noptimal control theory, we develop effective and practical algorithms for\nsolving optimal control in guided ODE-based generation and provide a systematic\ntheoretical analysis of the convergence guarantee in both Euclidean and SO(3).\nWe show that existing backprop-through-ODE methods can be interpreted as\nspecial cases of Euclidean OC-Flow. OC-Flow achieved superior performance in\nextensive experiments on text-guided image manipulation, conditional molecule\ngeneration, and all-atom peptide design.\n","authors":["Luran Wang","Chaoran Cheng","Yizhen Liao","Yanru Qu","Ge Liu"],"pdf_url":"https://arxiv.org/pdf/2410.18070v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.03185v2","updated":"2024-10-23T17:52:57Z","published":"2024-03-05T18:22:15Z","title":"Correlated Proxies: A New Definition and Improved Mitigation for Reward\n  Hacking","summary":"  Because it is difficult to precisely specify complex objectives,\nreinforcement learning policies are often optimized using flawed proxy rewards\nthat seem to capture the true objective. However, optimizing proxy rewards\nfrequently leads to reward hacking: the optimized reward function ceases to be\na good proxy, and the resulting policy performs poorly with respect to the\nunspecified true reward. Principled solutions to reward hacking have been\nimpeded by the lack of a good definition for the problem. To address this, we\nintroduce a definition of reward hacking based on the correlation between proxy\nand true rewards for states and actions seen by a \"base policy\" that breaks\ndown under optimization. We show that this definition captures reward hacking\nbehavior across several realistic settings, including in reinforcement learning\nfrom human feedback (RLHF). We then show theoretically that regularization to\nthe base policy can effectively prevent reward hacking. While current RLHF\napproaches apply a KL penalty between the action distributions of policies, our\ntheory suggests that it is more effective to regularize using the $\\chi^2$\ndivergence between the policies' occupancy measures. We intuitively show why\nthis type of regularization is superior and demonstrate that it better\nmitigates reward hacking in practice across four realistic domains, including\nRLHF for LLMs. Our code is available at https://github.com/cassidylaidlaw/orpo.\n","authors":["Cassidy Laidlaw","Shivam Singhal","Anca Dragan"],"pdf_url":"https://arxiv.org/pdf/2403.03185v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18067v1","updated":"2024-10-23T17:48:28Z","published":"2024-10-23T17:48:28Z","title":"Beyond position: how rotary embeddings shape representations and memory\n  in autoregressive transfomers","summary":"  Rotary Positional Embeddings (RoPE) enhance positional encoding in\nTransformer models, yet their full impact on model dynamics remains\nunderexplored. This paper studies how RoPE introduces position-dependent\nrotations, causing phase shifts in token embeddings that influence\nhigher-frequency components within the model's internal representations.\nThrough spectral analysis, we demonstrate that RoPE's rotation matrices induce\noscillatory behaviors in embeddings, affecting information retention across\nlayers and shaping temporal modeling capabilities. We show that activation\nfunctions in feed-forward networks interact with RoPE-modulated embeddings to\ngenerate harmonics, leading to constructive or destructive interference based\non phase alignment. Our findings reveal that phase alignment amplifies\nactivations and sharpens attention, while misalignment weakens activations and\ndisrupts focus on positional patterns. This study underscores the importance of\nfrequency components as intrinsic elements of model behavior, offering new\ninsights beyond traditional analyses.\n","authors":["Valeria Ruscio","Fabrizio Silvestri"],"pdf_url":"https://arxiv.org/pdf/2410.18067v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18066v1","updated":"2024-10-23T17:42:54Z","published":"2024-10-23T17:42:54Z","title":"The Double-Edged Sword of Behavioral Responses in Strategic\n  Classification: Theory and User Studies","summary":"  When humans are subject to an algorithmic decision system, they can\nstrategically adjust their behavior accordingly (``game'' the system). While a\ngrowing line of literature on strategic classification has used game-theoretic\nmodeling to understand and mitigate such gaming, these existing works consider\nstandard models of fully rational agents. In this paper, we propose a strategic\nclassification model that considers behavioral biases in human responses to\nalgorithms. We show how misperceptions of a classifier (specifically, of its\nfeature weights) can lead to different types of discrepancies between biased\nand rational agents' responses, and identify when behavioral agents over- or\nunder-invest in different features. We also show that strategic agents with\nbehavioral biases can benefit or (perhaps, unexpectedly) harm the firm compared\nto fully rational strategic agents. We complement our analytical results with\nuser studies, which support our hypothesis of behavioral biases in human\nresponses to the algorithm. Together, our findings highlight the need to\naccount for human (cognitive) biases when designing AI systems, and providing\nexplanations of them, to strategic human in the loop.\n","authors":["Raman Ebrahimi","Kristen Vaccaro","Parinaz Naghizadeh"],"pdf_url":"https://arxiv.org/pdf/2410.18066v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15762v2","updated":"2024-10-23T17:42:39Z","published":"2024-07-22T16:13:38Z","title":"Conditional Language Policy: A General Framework for Steerable\n  Multi-Objective Finetuning","summary":"  Reward-based finetuning is crucial for aligning language policies with\nintended behaviors (e.g., creativity and safety). A key challenge is to develop\nsteerable language models that trade-off multiple (conflicting) objectives in a\nflexible and efficient manner. This paper presents Conditional Language Policy\n(CLP), a general framework for finetuning language models on multiple\nobjectives. Building on techniques from multi-task training and\nparameter-efficient finetuning, CLP learn steerable models that effectively\ntrade-off conflicting objectives at inference time. Notably, this does not\nrequire training or maintaining multiple models to achieve different trade-offs\nbetween the objectives. Through extensive experiments and ablations on two\nsummarization datasets, we show that CLP learns steerable language models that\noutperform and Pareto-dominate the existing approaches for multi-objective\nfinetuning.\n","authors":["Kaiwen Wang","Rahul Kidambi","Ryan Sullivan","Alekh Agarwal","Christoph Dann","Andrea Michi","Marco Gelmi","Yunxuan Li","Raghav Gupta","Avinava Dubey","Alexandre Ramé","Johan Ferret","Geoffrey Cideron","Le Hou","Hongkun Yu","Amr Ahmed","Aranyak Mehta","Léonard Hussenot","Olivier Bachem","Edouard Leurent"],"pdf_url":"https://arxiv.org/pdf/2407.15762v2.pdf","comment":"40 pages. Findings of EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.18065v1","updated":"2024-10-23T17:42:07Z","published":"2024-10-23T17:42:07Z","title":"SPIRE: Synergistic Planning, Imitation, and Reinforcement Learning for\n  Long-Horizon Manipulation","summary":"  Robot learning has proven to be a general and effective technique for\nprogramming manipulators. Imitation learning is able to teach robots solely\nfrom human demonstrations but is bottlenecked by the capabilities of the\ndemonstrations. Reinforcement learning uses exploration to discover better\nbehaviors; however, the space of possible improvements can be too large to\nstart from scratch. And for both techniques, the learning difficulty increases\nproportional to the length of the manipulation task. Accounting for this, we\npropose SPIRE, a system that first uses Task and Motion Planning (TAMP) to\ndecompose tasks into smaller learning subproblems and second combines imitation\nand reinforcement learning to maximize their strengths. We develop novel\nstrategies to train learning agents when deployed in the context of a planning\nsystem. We evaluate SPIRE on a suite of long-horizon and contact-rich robot\nmanipulation problems. We find that SPIRE outperforms prior approaches that\nintegrate imitation learning, reinforcement learning, and planning by 35% to\n50% in average task performance, is 6 times more data efficient in the number\nof human demonstrations needed to train proficient agents, and learns to\ncomplete tasks nearly twice as efficiently. View\nhttps://sites.google.com/view/spire-corl-2024 for more details.\n","authors":["Zihan Zhou","Animesh Garg","Dieter Fox","Caelan Garrett","Ajay Mandlekar"],"pdf_url":"https://arxiv.org/pdf/2410.18065v1.pdf","comment":"Conference on Robot Learning (CoRL) 2024"},{"id":"http://arxiv.org/abs/2410.18038v1","updated":"2024-10-23T17:06:56Z","published":"2024-10-23T17:06:56Z","title":"POD-Attention: Unlocking Full Prefill-Decode Overlap for Faster LLM\n  Inference","summary":"  Each request in LLM inference goes through two phases: compute-bound prefill\nand memory-bandwidth-bound decode. To improve GPU utilization, recent systems\nuse hybrid batching that combines the prefill and decode phases of different\nrequests into the same batch. Hybrid batching works well for linear operations\nas it amortizes the cost of loading model weights from HBM. However, attention\ncomputation in hybrid batches remains inefficient because existing attention\nkernels are optimized for either prefill or decode.\n  In this paper, we present POD-Attention -- the first GPU kernel that\nefficiently computes attention for hybrid batches. POD-Attention aims to\nmaximize the utilization of both compute and memory bandwidth by carefully\nallocating the GPU's resources such that prefill and decode operations happen\nconcurrently on the same multiprocessor. We integrate POD-Attention in a\nstate-of-the-art LLM inference scheduler Sarathi-Serve. POD-Attention speeds up\nattention computation by up to 75% (mean 28%) and increases LLM serving\nthroughput by up to 22% in offline inference. In online inference,\nPOD-Attention enables lower time-to-first-token (TTFT), time-between-tokens\n(TBT), and request execution latency versus Sarathi-Serve.\n","authors":["Aditya K Kamath","Ramya Prabhu","Jayashree Mohan","Simon Peter","Ramachandran Ramjee","Ashish Panwar"],"pdf_url":"https://arxiv.org/pdf/2410.18038v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.04429v2","updated":"2024-10-23T16:42:06Z","published":"2024-09-06T17:49:56Z","title":"VILA-U: a Unified Foundation Model Integrating Visual Understanding and\n  Generation","summary":"  VILA-U is a Unified foundation model that integrates Video, Image, Language\nunderstanding and generation. Traditional visual language models (VLMs) use\nseparate modules for understanding and generating visual content, which can\nlead to misalignment and increased complexity. In contrast, VILA-U employs a\nsingle autoregressive next-token prediction framework for both tasks,\neliminating the need for additional components like diffusion models. This\napproach not only simplifies the model but also achieves near state-of-the-art\nperformance in visual language understanding and generation. The success of\nVILA-U is attributed to two main factors: the unified vision tower that aligns\ndiscrete visual tokens with textual inputs during pretraining, which enhances\nvisual perception, and autoregressive image generation can achieve similar\nquality as diffusion models with high-quality dataset. This allows VILA-U to\nperform comparably to more complex models using a fully token-based\nautoregressive framework.\n","authors":["Yecheng Wu","Zhuoyang Zhang","Junyu Chen","Haotian Tang","Dacheng Li","Yunhao Fang","Ligeng Zhu","Enze Xie","Hongxu Yin","Li Yi","Song Han","Yao Lu"],"pdf_url":"https://arxiv.org/pdf/2409.04429v2.pdf","comment":"Code: https://github.com/mit-han-lab/vila-u. The first two authors\n  contributed equally to this work"},{"id":"http://arxiv.org/abs/2409.19841v2","updated":"2024-10-23T16:27:27Z","published":"2024-09-30T00:47:13Z","title":"Counter-Current Learning: A Biologically Plausible Dual Network Approach\n  for Deep Learning","summary":"  Despite its widespread use in neural networks, error backpropagation has\nfaced criticism for its lack of biological plausibility, suffering from issues\nsuch as the backward locking problem and the weight transport problem. These\nlimitations have motivated researchers to explore more biologically plausible\nlearning algorithms that could potentially shed light on how biological neural\nsystems adapt and learn. Inspired by the counter-current exchange mechanisms\nobserved in biological systems, we propose counter-current learning (CCL), a\nbiologically plausible framework for credit assignment in neural networks. This\nframework employs a feedforward network to process input data and a feedback\nnetwork to process targets, with each network enhancing the other through\nanti-parallel signal propagation. By leveraging the more informative signals\nfrom the bottom layer of the feedback network to guide the updates of the top\nlayer of the feedforward network and vice versa, CCL enables the simultaneous\ntransformation of source inputs to target outputs and the dynamic mutual\ninfluence of these transformations. Experimental results on MNIST,\nFashionMNIST, CIFAR10, and CIFAR100 datasets using multi-layer perceptrons and\nconvolutional neural networks demonstrate that CCL achieves comparable\nperformance to other biologically plausible algorithms while offering a more\nbiologically realistic learning mechanism. Furthermore, we showcase the\napplicability of our approach to an autoencoder task, underscoring its\npotential for unsupervised representation learning. Our work presents a\ndirection for biologically inspired and plausible learning algorithms, offering\nan alternative mechanism of learning and adaptation in neural networks.\n","authors":["Chia-Hsiang Kao","Bharath Hariharan"],"pdf_url":"https://arxiv.org/pdf/2409.19841v2.pdf","comment":"Accepted at NeurIPS 2024. Code available at\n  https://github.com/IandRover/CCL-NeurIPS24"},{"id":"http://arxiv.org/abs/2409.17270v2","updated":"2024-10-23T16:27:20Z","published":"2024-09-25T18:35:45Z","title":"Proof of Thought : Neurosymbolic Program Synthesis allows Robust and\n  Interpretable Reasoning","summary":"  Large Language Models (LLMs) have revolutionized natural language processing,\nyet they struggle with inconsistent reasoning, particularly in novel domains\nand complex logical sequences. This research introduces Proof of Thought, a\nframework that enhances the reliability and transparency of LLM outputs. Our\napproach bridges LLM-generated ideas with formal logic verification, employing\na custom interpreter to convert LLM outputs into First Order Logic constructs\nfor theorem prover scrutiny. Central to our method is an intermediary\nJSON-based Domain-Specific Language, which by design balances precise logical\nstructures with intuitive human concepts. This hybrid representation enables\nboth rigorous validation and accessible human comprehension of LLM reasoning\nprocesses. Key contributions include a robust type system with sort management\nfor enhanced logical integrity, explicit representation of rules for clear\ndistinction between factual and inferential knowledge, and a flexible\narchitecture that allows for easy extension to various domain-specific\napplications. We demonstrate Proof of Thought's effectiveness through\nbenchmarking on StrategyQA and a novel multimodal reasoning task, showing\nimproved performance in open-ended scenarios. By providing verifiable and\ninterpretable results, our technique addresses critical needs for AI system\naccountability and sets a foundation for human-in-the-loop oversight in\nhigh-stakes domains.\n","authors":["Debargha Ganguly","Srinivasan Iyengar","Vipin Chaudhary","Shivkumar Kalyanaraman"],"pdf_url":"https://arxiv.org/pdf/2409.17270v2.pdf","comment":"38th Conference on Neural Information Processing Systems (NeurIPS\n  2024) System 2 Reasoning At Scale Workshop"},{"id":"http://arxiv.org/abs/2410.18003v1","updated":"2024-10-23T16:25:36Z","published":"2024-10-23T16:25:36Z","title":"Inferring stability properties of chaotic systems on autoencoders'\n  latent spaces","summary":"  The data-driven learning of solutions of partial differential equations can\nbe based on a divide-and-conquer strategy. First, the high dimensional data is\ncompressed to a latent space with an autoencoder; and, second, the temporal\ndynamics are inferred on the latent space with a form of recurrent neural\nnetwork. In chaotic systems and turbulence, convolutional autoencoders and echo\nstate networks (CAE-ESN) successfully forecast the dynamics, but little is\nknown about whether the stability properties can also be inferred. We show that\nthe CAE-ESN model infers the invariant stability properties and the geometry of\nthe tangent space in the low-dimensional manifold (i.e. the latent space)\nthrough Lyapunov exponents and covariant Lyapunov vectors. This work opens up\nnew opportunities for inferring the stability of high-dimensional chaotic\nsystems in latent spaces.\n","authors":["Elise Özalp","Luca Magri"],"pdf_url":"https://arxiv.org/pdf/2410.18003v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.10992v2","updated":"2024-10-23T16:19:06Z","published":"2024-06-24T09:29:14Z","title":"AlleNoise: large-scale text classification benchmark dataset with\n  real-world label noise","summary":"  Label noise remains a challenge for training robust classification models.\nMost methods for mitigating label noise have been benchmarked using primarily\ndatasets with synthetic noise. While the need for datasets with realistic noise\ndistribution has partially been addressed by web-scraped benchmarks such as\nWebVision and Clothing1M, those benchmarks are restricted to the computer\nvision domain. With the growing importance of Transformer-based models, it is\ncrucial to establish text classification benchmarks for learning with noisy\nlabels. In this paper, we present AlleNoise, a new curated text classification\nbenchmark dataset with real-world instance-dependent label noise, containing\nover 500,000 examples across approximately 5,600 classes, complemented with a\nmeaningful, hierarchical taxonomy of categories. The noise distribution comes\nfrom actual users of a major e-commerce marketplace, so it realistically\nreflects the semantics of human mistakes. In addition to the noisy labels, we\nprovide human-verified clean labels, which help to get a deeper insight into\nthe noise distribution, unlike web-scraped datasets typically used in the\nfield. We demonstrate that a representative selection of established methods\nfor learning with noisy labels is inadequate to handle such real-world noise.\nIn addition, we show evidence that these algorithms do not alleviate excessive\nmemorization. As such, with AlleNoise, we set the bar high for the development\nof label noise methods that can handle real-world label noise in text\nclassification tasks. The code and dataset are available for download at\nhttps://github.com/allegro/AlleNoise.\n","authors":["Alicja Rączkowska","Aleksandra Osowska-Kurczab","Jacek Szczerbiński","Kalina Jasinska-Kobus","Klaudia Nazarko"],"pdf_url":"https://arxiv.org/pdf/2407.10992v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17998v1","updated":"2024-10-23T16:12:59Z","published":"2024-10-23T16:12:59Z","title":"Estimating the Spectral Moments of the Kernel Integral Operator from\n  Finite Sample Matrices","summary":"  Analyzing the structure of sampled features from an input data distribution\nis challenging when constrained by limited measurements in both the number of\ninputs and features. Traditional approaches often rely on the eigenvalue\nspectrum of the sample covariance matrix derived from finite measurement\nmatrices; however, these spectra are sensitive to the size of the measurement\nmatrix, leading to biased insights. In this paper, we introduce a novel\nalgorithm that provides unbiased estimates of the spectral moments of the\nkernel integral operator in the limit of infinite inputs and features from\nfinitely sampled measurement matrices. Our method, based upon dynamic\nprogramming, is efficient and capable of estimating the moments of the operator\nspectrum. We demonstrate the accuracy of our estimator on radial basis function\n(RBF) kernels, highlighting its consistency with the theoretical spectra.\nFurthermore, we showcase the practical utility and robustness of our method in\nunderstanding the geometry of learned representations in neural networks.\n","authors":["Chanwoo Chun","SueYeon Chung","Daniel D. Lee"],"pdf_url":"https://arxiv.org/pdf/2410.17998v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.02131v4","updated":"2024-10-23T16:05:11Z","published":"2024-06-04T09:18:20Z","title":"CondTSF: One-line Plugin of Dataset Condensation for Time Series\n  Forecasting","summary":"  Dataset condensation is a newborn technique that generates a small dataset\nthat can be used in training deep neural networks to lower training costs. The\nobjective of dataset condensation is to ensure that the model trained with the\nsynthetic dataset can perform comparably to the model trained with full\ndatasets. However, existing methods predominantly concentrate on classification\ntasks, posing challenges in their adaptation to time series forecasting\n(TS-forecasting). This challenge arises from disparities in the evaluation of\nsynthetic data. In classification, the synthetic data is considered\nwell-distilled if the model trained with the full dataset and the model trained\nwith the synthetic dataset yield identical labels for the same input,\nregardless of variations in output logits distribution. Conversely, in\nTS-forecasting, the effectiveness of synthetic data distillation is determined\nby the distance between predictions of the two models. The synthetic data is\ndeemed well-distilled only when all data points within the predictions are\nsimilar. Consequently, TS-forecasting has a more rigorous evaluation\nmethodology compared to classification. To mitigate this gap, we theoretically\nanalyze the optimization objective of dataset condensation for TS-forecasting\nand propose a new one-line plugin of dataset condensation designated as Dataset\nCondensation for Time Series Forecasting (CondTSF) based on our analysis.\nPlugging CondTSF into previous dataset condensation methods facilitates a\nreduction in the distance between the predictions of the model trained with the\nfull dataset and the model trained with the synthetic dataset, thereby\nenhancing performance. We conduct extensive experiments on eight commonly used\ntime series datasets. CondTSF consistently improves the performance of all\nprevious dataset condensation methods across all datasets, particularly at low\ncondensing ratios.\n","authors":["Jianrong Ding","Zhanyu Liu","Guanjie Zheng","Haiming Jin","Linghe Kong"],"pdf_url":"https://arxiv.org/pdf/2406.02131v4.pdf","comment":"Accepted by NeurIPS 2024, the project can be found at\n  https://github.com/RafaDD/CondTSF"},{"id":"http://arxiv.org/abs/2304.10650v2","updated":"2024-10-23T16:03:19Z","published":"2023-04-20T21:25:33Z","title":"Learning a quantum computer's capability","summary":"  Accurately predicting a quantum computer's capability -- which circuits it\ncan run and how well it can run them -- is a foundational goal of quantum\ncharacterization and benchmarking. As modern quantum computers become\nincreasingly hard to simulate, we must develop accurate and scalable predictive\ncapability models to help researchers and stakeholders decide which quantum\ncomputers to build and use. In this work, we propose a hardware-agnostic method\nto efficiently construct scalable predictive models of a quantum computer's\ncapability for almost any class of circuits, and demonstrate our method using\nconvolutional neural networks (CNNs). Our CNN-based approach works by\nefficiently representing a circuit as a three-dimensional tensor and then using\na CNN to predict its success rate. Our CNN capability models obtain\napproximately a $1\\%$ average absolute prediction error when modeling\nprocessors experiencing both Markovian and non-Markovian stochastic Pauli\nerrors. We also apply our CNNs to model the capabilities of cloud-access\nquantum computing systems, obtaining moderate prediction accuracy (average\nabsolute error around $2-5\\%$), and we highlight the challenges to building\nbetter neural network capability models.\n","authors":["Daniel Hothem","Kevin Young","Tommie Catanach","Timothy Proctor"],"pdf_url":"https://arxiv.org/pdf/2304.10650v2.pdf","comment":"20 pages, 11 figures, plus appendices"},{"id":"http://arxiv.org/abs/2410.17986v1","updated":"2024-10-23T16:00:14Z","published":"2024-10-23T16:00:14Z","title":"Federated Transformer: Multi-Party Vertical Federated Learning on\n  Practical Fuzzily Linked Data","summary":"  Federated Learning (FL) is an evolving paradigm that enables multiple parties\nto collaboratively train models without sharing raw data. Among its variants,\nVertical Federated Learning (VFL) is particularly relevant in real-world,\ncross-organizational collaborations, where distinct features of a shared\ninstance group are contributed by different parties. In these scenarios,\nparties are often linked using fuzzy identifiers, leading to a common practice\ntermed as multi-party fuzzy VFL. Existing models generally address either\nmulti-party VFL or fuzzy VFL between two parties. Extending these models to\npractical multi-party fuzzy VFL typically results in significant performance\ndegradation and increased costs for maintaining privacy. To overcome these\nlimitations, we introduce the Federated Transformer (FeT), a novel framework\nthat supports multi-party VFL with fuzzy identifiers. FeT innovatively encodes\nthese identifiers into data representations and employs a transformer\narchitecture distributed across different parties, incorporating three new\ntechniques to enhance performance. Furthermore, we have developed a multi-party\nprivacy framework for VFL that integrates differential privacy with secure\nmulti-party computation, effectively protecting local representations while\nminimizing associated utility costs. Our experiments demonstrate that the FeT\nsurpasses the baseline models by up to 46\\% in terms of accuracy when scaled to\n50 parties. Additionally, in two-party fuzzy VFL settings, FeT also shows\nimproved performance and privacy over cutting-edge VFL models.\n","authors":["Zhaomin Wu","Junyi Hou","Yiqun Diao","Bingsheng He"],"pdf_url":"https://arxiv.org/pdf/2410.17986v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17980v1","updated":"2024-10-23T15:51:13Z","published":"2024-10-23T15:51:13Z","title":"Stick-breaking Attention","summary":"  The self-attention mechanism traditionally relies on the softmax operator,\nnecessitating positional embeddings like RoPE, or position biases to account\nfor token order. But current methods using still face length generalisation\nchallenges. We propose an alternative attention mechanism based on the\nstick-breaking process: For each token before the current, we determine a break\npoint $\\beta_{i,j}$, which represents the proportion of the remaining stick to\nallocate to the current token. We repeat the process until the stick is fully\nallocated, resulting in a sequence of attention weights. This process naturally\nincorporates recency bias, which has linguistic motivations for grammar parsing\n(Shen et. al., 2017). We study the implications of replacing the conventional\nsoftmax-based attention mechanism with stick-breaking attention. We then\ndiscuss implementation of numerically stable stick-breaking attention and adapt\nFlash Attention to accommodate this mechanism. When used as a drop-in\nreplacement for current softmax+RoPE attention systems, we find that\nstick-breaking attention performs competitively with current methods on length\ngeneralisation and downstream tasks. Stick-breaking also performs well at\nlength generalisation, allowing a model trained with $2^{11}$ context window to\nperform well at $2^{14}$ with perplexity improvements.\n","authors":["Shawn Tan","Yikang Shen","Songlin Yang","Aaron Courville","Rameswar Panda"],"pdf_url":"https://arxiv.org/pdf/2410.17980v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.02447v3","updated":"2024-10-23T15:48:45Z","published":"2024-06-04T16:12:27Z","title":"Federated Class-Incremental Learning with Hierarchical Generative\n  Prototypes","summary":"  Federated Learning (FL) aims at unburdening the training of deep models by\ndistributing computation across multiple devices (clients) while safeguarding\ndata privacy. On top of that, Federated Continual Learning (FCL) also accounts\nfor data distribution evolving over time, mirroring the dynamic nature of\nreal-world environments. While previous studies have identified Catastrophic\nForgetting and Client Drift as primary causes of performance degradation in\nFCL, we shed light on the importance of Incremental Bias and Federated Bias,\nwhich cause models to prioritize classes that are recently introduced or\nlocally predominant, respectively. Our proposal constrains both biases in the\nlast layer by efficiently finetuning a pre-trained backbone using learnable\nprompts, resulting in clients that produce less biased representations and more\nbiased classifiers. Therefore, instead of solely relying on parameter\naggregation, we leverage generative prototypes to effectively balance the\npredictions of the global model. Our method significantly improves the current\nState Of The Art, providing an average increase of +7.8% in accuracy. Code to\nreproduce the results is provided in the suppl. material.\n","authors":["Riccardo Salami","Pietro Buzzega","Matteo Mosconi","Mattia Verasani","Simone Calderara"],"pdf_url":"https://arxiv.org/pdf/2406.02447v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14979v2","updated":"2024-10-23T15:43:28Z","published":"2024-10-19T05:01:56Z","title":"Do Large Language Models Truly Grasp Mathematics? An Empirical\n  Exploration","summary":"  Despite their proficiency in math tasks, the mechanisms underlying LLMs'\nmathematical reasoning abilities remain a subject of debate. Recent studies\nsuggest that chain-of-thought (CoT) prompts can bolster mathematical reasoning\nby encouraging LLMs to employ human-like logical reasoning (System 2), enabling\nthem to excel on the Cognitive Reflection Test (CRT). To assess whether LLMs\ngenuinely possess System 2-like logical reasoning, we introduced targeted\nmodifications to CRT problems. Our findings reveal that, despite the use of CoT\nprompts, mainstream LLMs, including the latest o1-preview model, continue to\nexhibit a significant error rate. Further analysis indicates that they\npredominantly rely on System 1-like intuitive reasoning and pattern matching\nderived from training data, rather than demonstrating mastery of mathematical\nthinking. This discovery challenges the prevailing notion that LLMs possess\ngenuine logical reasoning abilities and that CoT can enhance them.\nConsequently, this work may temper overly optimistic projections regarding\nLLMs' advancement toward artificial general intelligence.\n","authors":["Wei Xie","Shuoyoucheng Ma","Zhenhua Wang","Enze Wang","Baosheng Wang","Jinshu Su"],"pdf_url":"https://arxiv.org/pdf/2410.14979v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17976v1","updated":"2024-10-23T15:39:08Z","published":"2024-10-23T15:39:08Z","title":"metasnf: Meta Clustering with Similarity Network Fusion in R","summary":"  metasnf is an R package that enables users to apply meta clustering, a method\nfor efficiently searching a broad space of cluster solutions by clustering the\nsolutions themselves, to clustering workflows based on similarity network\nfusion (SNF). SNF is a multi-modal data integration algorithm commonly used for\nbiomedical subtype discovery. The package also contains functions to assist\nwith cluster visualization, characterization, and validation. This package can\nhelp researchers identify SNF-derived cluster solutions that are guided by\ncontext-specific utility over context-agnostic measures of quality.\n","authors":["Prashanth S Velayudhan","Xiaoqiao Xu","Prajkta Kallurkar","Ana Patricia Balbon","Maria T Secara","Adam Taback","Denise Sabac","Nicholas Chan","Shihao Ma","Bo Wang","Daniel Felsky","Stephanie H Ameis","Brian Cox","Colin Hawco","Lauren Erdman","Anne L Wheeler"],"pdf_url":"https://arxiv.org/pdf/2410.17976v1.pdf","comment":"72 pages, 22 figures, submitted to Journal of Statistical Software"},{"id":"http://arxiv.org/abs/2410.17970v1","updated":"2024-10-23T15:36:08Z","published":"2024-10-23T15:36:08Z","title":"Optical Generative Models","summary":"  Generative models cover various application areas, including image, video and\nmusic synthesis, natural language processing, and molecular design, among many\nothers. As digital generative models become larger, scalable inference in a\nfast and energy-efficient manner becomes a challenge. Here, we present optical\ngenerative models inspired by diffusion models, where a shallow and fast\ndigital encoder first maps random noise into phase patterns that serve as\noptical generative seeds for a desired data distribution; a jointly-trained\nfree-space-based reconfigurable decoder all-optically processes these\ngenerative seeds to create novel images (never seen before) following the\ntarget data distribution. Except for the illumination power and the random seed\ngeneration through a shallow encoder, these optical generative models do not\nconsume computing power during the synthesis of novel images. We report the\noptical generation of monochrome and multi-color novel images of handwritten\ndigits, fashion products, butterflies, and human faces, following the data\ndistributions of MNIST, Fashion MNIST, Butterflies-100, and Celeb-A datasets,\nrespectively, achieving an overall performance comparable to digital neural\nnetwork-based generative models. To experimentally demonstrate optical\ngenerative models, we used visible light to generate, in a snapshot, novel\nimages of handwritten digits and fashion products. These optical generative\nmodels might pave the way for energy-efficient, scalable and rapid inference\ntasks, further exploiting the potentials of optics and photonics for artificial\nintelligence-generated content.\n","authors":["Shiqi Chen","Yuhang Li","Hanlong Chen","Aydogan Ozcan"],"pdf_url":"https://arxiv.org/pdf/2410.17970v1.pdf","comment":"24 Pages, 9 Figures"},{"id":"http://arxiv.org/abs/2410.11709v2","updated":"2024-10-23T15:35:57Z","published":"2024-10-15T15:46:03Z","title":"On the potential of Optimal Transport in Geospatial Data Science","summary":"  Prediction problems in geographic information science and transportation are\noften motivated by the possibility to enhance operational efficiency and\nthereby reduce emissions. Examples range from predicting car sharing demand for\nrelocation planning to forecasting traffic congestion for navigation purposes.\nHowever, conventional accuracy metrics ignore the spatial distribution of the\nerrors, despite its relevance for operations. Here, we put forward a spatially\naware evaluation metric and loss function based on Optimal Transport (OT). Our\nframework leverages partial OT and can minimize relocation costs in any spatial\nprediction problem. We showcase the advantages of OT-based evaluation over\nconventional metrics and further demonstrate the application of an OT loss\nfunction for improving forecasts of bike sharing demand and charging station\noccupancy. Thus, our framework not only aligns with operational considerations,\nbut also signifies a step forward in refining predictions within geospatial\napplications. All code is available at https://github.com/mie-lab/geospatialOT.\n","authors":["Nina Wiedemann","Théo Uscidda","Martin Raubal"],"pdf_url":"https://arxiv.org/pdf/2410.11709v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17967v1","updated":"2024-10-23T15:34:11Z","published":"2024-10-23T15:34:11Z","title":"POMDP-Driven Cognitive Massive MIMO Radar: Joint Target\n  Detection-Tracking In Unknown Disturbances","summary":"  The joint detection and tracking of a moving target embedded in an unknown\ndisturbance represents a key feature that motivates the development of the\ncognitive radar paradigm. Building upon recent advancements in robust target\ndetection with multiple-input multiple-output (MIMO) radars, this work explores\nthe application of a Partially Observable Markov Decision Process (POMDP)\nframework to enhance the tracking and detection tasks in a statistically\nunknown environment. In the POMDP setup, the radar system is considered as an\nintelligent agent that continuously senses the surrounding environment,\noptimizing its actions to maximize the probability of detection $(P_D)$ and\nimprove the target position and velocity estimation, all this while keeping a\nconstant probability of false alarm $(P_{FA})$. The proposed approach employs\nan online algorithm that does not require any apriori knowledge of the noise\nstatistics, and it relies on a much more general observation model than the\ntraditional range-azimuth-elevation model employed by conventional tracking\nalgorithms. Simulation results clearly show substantial performance improvement\nof the POMDP-based algorithm compared to the State-Action-Reward-State-Action\n(SARSA)-based one that has been recently investigated in the context of massive\nMIMO (MMIMO) radar systems.\n","authors":["Imad Bouhou","Stefano Fortunati","Leila Gharsalli","Alexandre Renaux"],"pdf_url":"https://arxiv.org/pdf/2410.17967v1.pdf","comment":"The paper has been submitted to ieee Transactions on radar systems"},{"id":"http://arxiv.org/abs/2401.11576v3","updated":"2024-10-23T15:30:50Z","published":"2024-01-21T19:53:17Z","title":"Quantum Architecture Search with Unsupervised Representation Learning","summary":"  Unsupervised representation learning presents new opportunities for advancing\nQuantum Architecture Search (QAS) on Noisy Intermediate-Scale Quantum (NISQ)\ndevices. QAS is designed to optimize quantum circuits for Variational Quantum\nAlgorithms (VQAs). Most QAS algorithms tightly couple the search space and\nsearch algorithm, typically requiring the evaluation of numerous quantum\ncircuits, resulting in high computational costs and limiting scalability to\nlarger quantum circuits. Predictor-based QAS algorithms mitigate this issue by\nestimating circuit performance based on structure or embedding. However, these\nmethods often demand time-intensive labeling to optimize gate parameters across\nmany circuits, which is crucial for training accurate predictors. Inspired by\nthe classical neural architecture search algorithm Arch2vec, we investigate the\npotential of unsupervised representation learning for QAS without relying on\npredictors. Our framework decouples unsupervised architecture representation\nlearning from the search process, enabling the learned representations to be\napplied across various downstream tasks. Additionally, it integrates an\nimproved quantum circuit graph encoding scheme, addressing the limitations of\nexisting representations and enhancing search efficiency. This predictor-free\napproach removes the need for large labeled datasets. During the search, we\nemploy REINFORCE and Bayesian Optimization to explore the latent representation\nspace and compare their performance against baseline methods. Our results\ndemonstrate that the framework efficiently identifies high-performing quantum\ncircuits with fewer search iterations.\n","authors":["Yize Sun","Zixin Wu","Yunpu Ma","Volker Tresp"],"pdf_url":"https://arxiv.org/pdf/2401.11576v3.pdf","comment":"9 Pages, quantum architecture search, unsupervised representation\n  learning"},{"id":"http://arxiv.org/abs/2410.17963v1","updated":"2024-10-23T15:30:37Z","published":"2024-10-23T15:30:37Z","title":"A Time-Aware Approach to Early Detection of Anorexia: UNSL at eRisk 2024","summary":"  The eRisk laboratory aims to address issues related to early risk detection\non the Web. In this year's edition, three tasks were proposed, where Task 2 was\nabout early detection of signs of anorexia. Early risk detection is a problem\nwhere precision and speed are two crucial objectives. Our research group solved\nTask 2 by defining a CPI+DMC approach, addressing both objectives\nindependently, and a time-aware approach, where precision and speed are\nconsidered a combined single-objective. We implemented the last approach by\nexplicitly integrating time during the learning process, considering the\nERDE{\\theta} metric as the training objective. It also allowed us to\nincorporate temporal metrics to validate and select the optimal models. We\nachieved outstanding results for the ERDE50 metric and ranking-based metrics,\ndemonstrating consistency in solving ERD problems.\n","authors":["Horacio Thompson","Marcelo Errecalde"],"pdf_url":"https://arxiv.org/pdf/2410.17963v1.pdf","comment":"In Conference and Labs of the Evaluation Forum (CLEF 2024), Grenoble,\n  France"},{"id":"http://arxiv.org/abs/2410.17961v1","updated":"2024-10-23T15:30:13Z","published":"2024-10-23T15:30:13Z","title":"Closed-form merging of parameter-efficient modules for Federated\n  Continual Learning","summary":"  Model merging has emerged as a crucial technique in Deep Learning, enabling\nthe integration of multiple models into a unified system while preserving\nperformance and scalability. In this respect, the compositional properties of\nlow-rank adaptation techniques (e.g., LoRA) have proven beneficial, as simple\naveraging LoRA modules yields a single model that mostly integrates the\ncapabilities of all individual modules. Building on LoRA, we take a step\nfurther by imposing that the merged model matches the responses of all learned\nmodules. Solving this objective in closed form yields an indeterminate system\nwith A and B as unknown variables, indicating the existence of infinitely many\nclosed-form solutions. To address this challenge, we introduce LoRM, an\nalternating optimization strategy that trains one LoRA matrix at a time. This\nallows solving for each unknown variable individually, thus finding a unique\nsolution. We apply our proposed methodology to Federated Class-Incremental\nLearning (FCIL), ensuring alignment of model responses both between clients and\nacross tasks. Our method demonstrates state-of-the-art performance across a\nrange of FCIL scenarios.\n","authors":["Riccardo Salami","Pietro Buzzega","Matteo Mosconi","Jacopo Bonato","Luigi Sabetta","Simone Calderara"],"pdf_url":"https://arxiv.org/pdf/2410.17961v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.08649v2","updated":"2024-10-23T15:29:28Z","published":"2024-06-12T21:18:14Z","title":"MOTIVE: A Drug-Target Interaction Graph For Inductive Link Prediction","summary":"  Drug-target interaction (DTI) prediction is crucial for identifying new\ntherapeutics and detecting mechanisms of action. While structure-based methods\naccurately model physical interactions between a drug and its protein target,\ncell-based assays such as Cell Painting can better capture complex DTI\ninteractions. This paper introduces MOTIVE, a Morphological cOmpound Target\nInteraction Graph dataset comprising Cell Painting features for 11,000 genes\nand 3,600 compounds, along with their relationships extracted from seven\npublicly available databases. We provide random, cold-source (new drugs), and\ncold-target (new genes) data splits to enable rigorous evaluation under\nrealistic use cases. Our benchmark results show that graph neural networks that\nuse Cell Painting features consistently outperform those that learn from graph\nstructure alone, feature-based models, and topological heuristics. MOTIVE\naccelerates both graph ML research and drug discovery by promoting the\ndevelopment of more reliable DTI prediction models. MOTIVE resources are\navailable at https://github.com/carpenter-singh-lab/motive.\n","authors":["John Arevalo","Ellen Su","Anne E Carpenter","Shantanu Singh"],"pdf_url":"https://arxiv.org/pdf/2406.08649v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.09063v3","updated":"2024-10-23T15:28:59Z","published":"2023-05-15T23:12:15Z","title":"Bounded KRnet and its applications to density estimation and\n  approximation","summary":"  In this paper, we develop an invertible mapping, called B-KRnet, on a bounded\ndomain and apply it to density estimation/approximation for data or the\nsolutions of PDEs such as the Fokker-Planck equation and the Keller-Segel\nequation. Similar to KRnet, the structure of B-KRnet adapts the\npseudo-triangular structure into a normalizing flow model. The main difference\nbetween B-KRnet and KRnet is that B-KRnet is defined on a hypercube while KRnet\nis defined on the whole space, in other words, a new mechanism is introduced in\nB-KRnet to maintain the exact invertibility. Using B-KRnet as a transport map,\nwe obtain an explicit probability density function (PDF) model that corresponds\nto the pushforward of a prior (uniform) distribution on the hypercube. It can\nbe directly applied to density estimation when only data are available. By\ncoupling KRnet and B-KRnet, we define a deep generative model on a\nhigh-dimensional domain where some dimensions are bounded and other dimensions\nare unbounded. A typical case is the solution of the stationary kinetic\nFokker-Planck equation, which is a PDF of position and momentum. Based on\nB-KRnet, we develop an adaptive learning approach to approximate partial\ndifferential equations whose solutions are PDFs or can be treated as PDFs. A\nvariety of numerical experiments is presented to demonstrate the effectiveness\nof B-KRnet.\n","authors":["Li Zeng","Xiaoliang Wan","Tao Zhou"],"pdf_url":"https://arxiv.org/pdf/2305.09063v3.pdf","comment":"26 pages, 13 figures"},{"id":"http://arxiv.org/abs/2201.12091v5","updated":"2024-10-23T15:28:38Z","published":"2022-01-28T13:00:17Z","title":"Linear Adversarial Concept Erasure","summary":"  Modern neural models trained on textual data rely on pre-trained\nrepresentations that emerge without direct supervision. As these\nrepresentations are increasingly being used in real-world applications, the\ninability to \\emph{control} their content becomes an increasingly important\nproblem. We formulate the problem of identifying and erasing a linear subspace\nthat corresponds to a given concept, in order to prevent linear predictors from\nrecovering the concept. We model this problem as a constrained, linear maximin\ngame, and show that existing solutions are generally not optimal for this task.\nWe derive a closed-form solution for certain objectives, and propose a convex\nrelaxation, \\method, that works well for others. When evaluated in the context\nof binary gender removal, the method recovers a low-dimensional subspace whose\nremoval mitigates bias by intrinsic and extrinsic evaluation. We show that the\nmethod is highly expressive, effectively mitigating bias in deep nonlinear\nclassifiers while maintaining tractability and interpretability.\n","authors":["Shauli Ravfogel","Michael Twiton","Yoav Goldberg","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2201.12091v5.pdf","comment":"Accepted in ICML 2022; a revised version"},{"id":"http://arxiv.org/abs/2410.17959v1","updated":"2024-10-23T15:28:25Z","published":"2024-10-23T15:28:25Z","title":"Medical Imaging Complexity and its Effects on GAN Performance","summary":"  The proliferation of machine learning models in diverse clinical applications\nhas led to a growing need for high-fidelity, medical image training data. Such\ndata is often scarce due to cost constraints and privacy concerns. Alleviating\nthis burden, medical image synthesis via generative adversarial networks (GANs)\nemerged as a powerful method for synthetically generating photo-realistic\nimages based on existing sets of real medical images. However, the exact image\nset size required to efficiently train such a GAN is unclear. In this work, we\nexperimentally establish benchmarks that measure the relationship between a\nsample dataset size and the fidelity of the generated images, given the\ndataset's distribution of image complexities. We analyze statistical metrics\nbased on delentropy, an image complexity measure rooted in Shannon's entropy in\ninformation theory. For our pipeline, we conduct experiments with two\nstate-of-the-art GANs, StyleGAN 3 and SPADE-GAN, trained on multiple medical\nimaging datasets with variable sample sizes. Across both GANs, general\nperformance improved with increasing training set size but suffered with\nincreasing complexity.\n","authors":["William Cagas","Chan Ko","Blake Hsiao","Shryuk Grandhi","Rishi Bhattacharya","Kevin Zhu","Michael Lam"],"pdf_url":"https://arxiv.org/pdf/2410.17959v1.pdf","comment":"Accepted to ACCV, Workshop on Generative AI for Synthetic Medical\n  Data"},{"id":"http://arxiv.org/abs/2410.17957v1","updated":"2024-10-23T15:27:37Z","published":"2024-10-23T15:27:37Z","title":"MCUBERT: Memory-Efficient BERT Inference on Commodity Microcontrollers","summary":"  In this paper, we propose MCUBERT to enable language models like BERT on tiny\nmicrocontroller units (MCUs) through network and scheduling co-optimization. We\nobserve the embedding table contributes to the major storage bottleneck for\ntiny BERT models. Hence, at the network level, we propose an MCU-aware\ntwo-stage neural architecture search algorithm based on clustered low-rank\napproximation for embedding compression. To reduce the inference memory\nrequirements, we further propose a novel fine-grained MCU-friendly scheduling\nstrategy. Through careful computation tiling and re-ordering as well as kernel\ndesign, we drastically increase the input sequence lengths supported on MCUs\nwithout any latency or accuracy penalty. MCUBERT reduces the parameter size of\nBERT-tiny and BERT-mini by 5.7$\\times$ and 3.0$\\times$ and the execution memory\nby 3.5$\\times$ and 4.3$\\times$, respectively. MCUBERT also achieves 1.5$\\times$\nlatency reduction. For the first time, MCUBERT enables lightweight BERT models\non commodity MCUs and processing more than 512 tokens with less than 256KB of\nmemory.\n","authors":["Zebin Yang","Renze Chen","Taiqiang Wu","Ngai Wong","Yun Liang","Runsheng Wang","Ru Huang","Meng Li"],"pdf_url":"https://arxiv.org/pdf/2410.17957v1.pdf","comment":"ICCAD 2024"},{"id":"http://arxiv.org/abs/2410.17952v1","updated":"2024-10-23T15:24:16Z","published":"2024-10-23T15:24:16Z","title":"SimRAG: Self-Improving Retrieval-Augmented Generation for Adapting Large\n  Language Models to Specialized Domains","summary":"  Retrieval-augmented generation (RAG) enhances the question-answering (QA)\nabilities of large language models (LLMs) by integrating external knowledge.\nHowever, adapting general-purpose RAG systems to specialized fields such as\nscience and medicine poses unique challenges due to distribution shifts and\nlimited access to domain-specific data. To tackle this, we propose SimRAG, a\nself-training approach that equips the LLM with joint capabilities of question\nanswering and question generation for domain adaptation. Our method first\nfine-tunes the LLM on instruction-following, question-answering, and\nsearch-related data. Then, it prompts the same LLM to generate diverse\ndomain-relevant questions from unlabeled corpora, with an additional filtering\nstrategy to retain high-quality synthetic examples. By leveraging these\nsynthetic examples, the LLM can improve their performance on domain-specific\nRAG tasks. Experiments on 11 datasets, spanning two backbone sizes and three\ndomains, demonstrate that SimRAG outperforms baselines by 1.2\\%--8.6\\%.\n","authors":["Ran Xu","Hui Liu","Sreyashi Nag","Zhenwei Dai","Yaochen Xie","Xianfeng Tang","Chen Luo","Yang Li","Joyce C. Ho","Carl Yang","Qi He"],"pdf_url":"https://arxiv.org/pdf/2410.17952v1.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2410.17948v1","updated":"2024-10-23T15:22:21Z","published":"2024-10-23T15:22:21Z","title":"Generalized Resubstitution for Regression Error Estimation","summary":"  We propose generalized resubstitution error estimators for regression, a\nbroad family of estimators, each corresponding to a choice of empirical\nprobability measures and loss function. The usual sum of squares criterion is a\nspecial case corresponding to the standard empirical probability measure and\nthe quadratic loss. Other choices of empirical probability measure lead to more\ngeneral estimators with superior bias and variance properties. We prove that\nthese error estimators are consistent under broad assumptions. In addition,\nprocedures for choosing the empirical measure based on the method of moments\nand maximum pseudo-likelihood are proposed and investigated. Detailed\nexperimental results using polynomial regression demonstrate empirically the\nsuperior finite-sample bias and variance properties of the proposed estimators.\nThe R code for the experiments is provided.\n","authors":["Diego Marcondes","Ulisses Braga-Neto"],"pdf_url":"https://arxiv.org/pdf/2410.17948v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17945v1","updated":"2024-10-23T15:18:07Z","published":"2024-10-23T15:18:07Z","title":"Theoretically Grounded Pruning of Large Ground Sets for Constrained,\n  Discrete Optimization","summary":"  Modern instances of combinatorial optimization problems often exhibit\nbillion-scale ground sets, which have many uninformative or redundant elements.\nIn this work, we develop light-weight pruning algorithms to quickly discard\nelements that are unlikely to be part of an optimal solution. Under mild\nassumptions on the instance, we prove theoretical guarantees on the fraction of\nthe optimal value retained and the size of the resulting pruned ground set.\nThrough extensive experiments on real-world datasets for various applications,\nwe demonstrate that our algorithm, QuickPrune, efficiently prunes over 90% of\nthe ground set and outperforms state-of-the-art classical and machine learning\nheuristics for pruning.\n","authors":["Ankur Nath","Alan Kuhnle"],"pdf_url":"https://arxiv.org/pdf/2410.17945v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17943v1","updated":"2024-10-23T15:15:56Z","published":"2024-10-23T15:15:56Z","title":"Optimizing Travel Itineraries with AI Algorithms in a Microservices\n  Architecture: Balancing Cost, Time, Preferences, and Sustainability","summary":"  The objective of this research is how an implementation of AI algorithms in\nthe microservices architecture enhances travel itineraries by cost, time, user\npreferences, and environmental sustainability. It uses machine learning models\nfor both cost forecasting and personalization, genetic algorithm for\noptimization of the itinerary, and heuristics for sustainability checking.\nPrimary evaluated parameters consist of latency, ability to satisfy user\npreferences, cost and environmental concern. The experimental results\ndemonstrate an average of 4.5 seconds of response time on 1000 concurrent users\nand 92% of user preferences accuracy. The cost efficiency is proved, with 95%\nof provided trips being within the limits of the budget declared by the user.\nThe system also implements some measures to alleviate negative externalities\nrelated to travel and 60% of offered travel plans had green options\nincorporated, resulting in the average 15% lower carbon emissions than the\ntraditional travel plans offered. The genetic algorithm with time complexity\nO(g.p.f) provides the optimal solution in 100 generations. Every iteration\nimproves the quality of the solution by 5%, thus enabling its effective use in\noptimization problems where time is measured in seconds. Finally, the system is\ndesigned to be fault-tolerant with functional 99.9% availability which allows\nthe provision of services even when requirements are exceeded. Travel\noptimization platform is turned dynamic and efficient by this microservices\nbased architecture which provides enhanced scaling, allows asynchronous\ncommunication and real time changes. Because of the incorporation of Ai, cost\ncontrol and eco-friendliness approaches, the system addresses the different\nuser needs in the present days travel business.\n","authors":["Biman Barua","M. Shamim Kaiser"],"pdf_url":"https://arxiv.org/pdf/2410.17943v1.pdf","comment":"18 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.17941v1","updated":"2024-10-23T15:09:02Z","published":"2024-10-23T15:09:02Z","title":"Spiking Graph Neural Network on Riemannian Manifolds","summary":"  Graph neural networks (GNNs) have become the dominant solution for learning\non graphs, the typical non-Euclidean structures. Conventional GNNs, constructed\nwith the Artificial Neuron Network (ANN), have achieved impressive performance\nat the cost of high computation and energy consumption. In parallel, spiking\nGNNs with brain-like spiking neurons are drawing increasing research attention\nowing to the energy efficiency. So far, existing spiking GNNs consider graphs\nin Euclidean space, ignoring the structural geometry, and suffer from the high\nlatency issue due to Back-Propagation-Through-Time (BPTT) with the surrogate\ngradient. In light of the aforementioned issues, we are devoted to exploring\nspiking GNN on Riemannian manifolds, and present a Manifold-valued Spiking GNN\n(MSG). In particular, we design a new spiking neuron on geodesically complete\nmanifolds with the diffeomorphism, so that BPTT regarding the spikes is\nreplaced by the proposed differentiation via manifold. Theoretically, we show\nthat MSG approximates a solver of the manifold ordinary differential equation.\nExtensive experiments on common graphs show the proposed MSG achieves superior\nperformance to previous spiking GNNs and energy efficiency to conventional\nGNNs.\n","authors":["Li Sun","Zhenhao Huang","Qiqi Wan","Hao Peng","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2410.17941v1.pdf","comment":"Accepted by NeurIPS 2024, 30 pages"},{"id":"http://arxiv.org/abs/2406.14856v2","updated":"2024-10-23T15:08:59Z","published":"2024-06-21T04:02:19Z","title":"Accessible, At-Home Detection of Parkinson's Disease via Multi-task\n  Video Analysis","summary":"  Limited accessibility to neurological care leads to underdiagnosed\nParkinson's Disease (PD), preventing early intervention. Existing AI-based PD\ndetection methods primarily focus on unimodal analysis of motor or speech\ntasks, overlooking the multifaceted nature of the disease. To address this, we\nintroduce a large-scale, multi-task video dataset consisting of 1102 sessions\n(each containing videos of finger tapping, facial expression, and speech tasks\ncaptured via webcam) from 845 participants (272 with PD). We propose a novel\nUncertainty-calibrated Fusion Network (UFNet) that leverages this multimodal\ndata to enhance diagnostic accuracy. UFNet employs independent task-specific\nnetworks, trained with Monte Carlo Dropout for uncertainty quantification,\nfollowed by self-attended fusion of features, with attention weights\ndynamically adjusted based on task-specific uncertainties. To ensure\npatient-centered evaluation, the participants were randomly split into three\nsets: 60% for training, 20% for model selection, and 20% for final performance\nevaluation. UFNet significantly outperformed single-task models in terms of\naccuracy, area under the ROC curve (AUROC), and sensitivity while maintaining\nnon-inferior specificity. Withholding uncertain predictions further boosted the\nperformance, achieving 88.0+-0.3%$ accuracy, 93.0+-0.2% AUROC, 79.3+-0.9%\nsensitivity, and 92.6+-0.3% specificity, at the expense of not being able to\npredict for 2.3+-0.3% data (+- denotes 95% confidence interval). Further\nanalysis suggests that the trained model does not exhibit any detectable bias\nacross sex and ethnic subgroups and is most effective for individuals aged\nbetween 50 and 80. Requiring only a webcam and microphone, our approach\nfacilitates accessible home-based PD screening, especially in regions with\nlimited healthcare resources.\n","authors":["Md Saiful Islam","Tariq Adnan","Jan Freyberg","Sangwu Lee","Abdelrahman Abdelkader","Meghan Pawlik","Cathe Schwartz","Karen Jaffe","Ruth B. Schneider","E Ray Dorsey","Ehsan Hoque"],"pdf_url":"https://arxiv.org/pdf/2406.14856v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03093v2","updated":"2024-10-23T15:01:34Z","published":"2024-08-06T10:48:15Z","title":"Certifiably Robust Policies for Uncertain Parametric Environments","summary":"  We present a data-driven approach for producing policies that are provably\nrobust across unknown stochastic environments. Existing approaches can learn\nmodels of a single environment as an interval Markov decision processes (IMDP)\nand produce a robust policy with a probably approximately correct (PAC)\nguarantee on its performance. However these are unable to reason about the\nimpact of environmental parameters underlying the uncertainty. We propose a\nframework based on parametric Markov decision processes (MDPs) with unknown\ndistributions over parameters. We learn and analyse IMDPs for a set of unknown\nsample environments induced by parameters. The key challenge is then to produce\nmeaningful performance guarantees that combine the two layers of uncertainty:\n(1) multiple environments induced by parameters with an unknown distribution;\n(2) unknown induced environments which are approximated by IMDPs. We present a\nnovel approach based on scenario optimisation that yields a single PAC\nguarantee quantifying the risk level for which a specified performance level\ncan be assured in unseen environments, plus a means to trade-off risk and\nperformance. We implement and evaluate our framework using multiple robust\npolicy generation methods on a range of benchmarks. We show that our approach\nproduces tight bounds on a policy's performance with high confidence.\n","authors":["Yannik Schnitzer","Alessandro Abate","David Parker"],"pdf_url":"https://arxiv.org/pdf/2408.03093v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17935v1","updated":"2024-10-23T15:00:30Z","published":"2024-10-23T15:00:30Z","title":"Semi-Implicit Functional Gradient Flow","summary":"  Particle-based variational inference methods (ParVIs) use non-parametric\nvariational families represented by particles to approximate the target\ndistribution according to the kernelized Wasserstein gradient flow for the\nKullback-Leibler (KL) divergence. Recent works introduce functional gradient\nflows to substitute the kernel for better flexibility. However, the\ndeterministic updating mechanism may suffer from limited exploration and\nrequire expensive repetitive runs for new samples. In this paper, we propose\nSemi-Implicit Functional Gradient flow (SIFG), a functional gradient ParVI\nmethod that uses perturbed particles as the approximation family. The\ncorresponding functional gradient flow, which can be estimated via denoising\nscore matching, exhibits strong theoretical convergence guarantee. We also\npresent an adaptive version of our method to automatically choose the suitable\nnoise magnitude. Extensive experiments demonstrate the effectiveness and\nefficiency of the proposed framework on both simulated and real data problems.\n","authors":["Shiyue Zhang","Ziheng Cheng","Cheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.17935v1.pdf","comment":"31 pages, 12 figures"},{"id":"http://arxiv.org/abs/2410.17934v1","updated":"2024-10-23T14:59:06Z","published":"2024-10-23T14:59:06Z","title":"Retrieving snow depth distribution by downscaling ERA5 Reanalysis with\n  ICESat-2 laser altimetry","summary":"  Estimating the variability of seasonal snow cover, in particular snow depth\nin remote areas, poses significant challenges due to limited spatial and\ntemporal data availability. This study uses snow depth measurements from the\nICESat-2 satellite laser altimeter, which are sparse in both space and time,\nand incorporates them with climate reanalysis data into a\ndownscaling-calibration scheme to produce monthly gridded snow depth maps at\nmicroscale (10 m). Snow surface elevation measurements from ICESat-2 along\nprofiles are compared to a digital elevation model to determine snow depth at\neach point. To efficiently turn sparse measurements into snow depth maps, a\nregression model is fitted to establish a relationship between the retrieved\nsnow depth and the corresponding ERA5 Land snow depth. This relationship,\nreferred to as subgrid variability, is then applied to downscale the monthly\nERA5 Land snow depth data. The method can provide timeseries of monthly snow\ndepth maps for the entire ERA5 time range (since 1950). The validation of\ndownscaled snow depth data was performed at an intermediate scale (100 m x 500\nm) using datasets from airborne laser scanning (ALS) in the Hardangervidda\nregion of southern Norway. Results show that snow depth prediction achieved R2\nvalues ranging from 0.74 to 0.88 (post-calibration). The method relies on\nglobally available data and is applicable to other snow regions above the\ntreeline. Though requiring area-specific calibration, our approach has the\npotential to provide snow depth maps in areas where no such data exist and can\nbe used to extrapolate existing snow surveys in time and over larger areas.\nWith this, it can offer valuable input data for hydrological, ecological or\npermafrost modeling tasks.\n","authors":["Zhihao Liu","Simon Filhol","Désirée Treichler"],"pdf_url":"https://arxiv.org/pdf/2410.17934v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17933v1","updated":"2024-10-23T14:55:53Z","published":"2024-10-23T14:55:53Z","title":"Multi-Continental Healthcare Modelling Using Blockchain-Enabled\n  Federated Learning","summary":"  One of the biggest challenges of building artificial intelligence (AI) model\nin healthcare area is the data sharing. Since healthcare data is private,\nsensitive, and heterogeneous, collecting sufficient data for modelling is\nexhausted, costly, and sometimes impossible. In this paper, we propose a\nframework for global healthcare modelling using datasets from multi-continents\n(Europe, North America and Asia) while without sharing the local datasets, and\nchoose glucose management as a study model to verify its effectiveness.\nTechnically, blockchain-enabled federated learning is implemented with adaption\nto make it meet with the privacy and safety requirements of healthcare data,\nmeanwhile rewards honest participation and penalize malicious activities using\nits on-chain incentive mechanism. Experimental results show that the proposed\nframework is effective, efficient, and privacy preserved. Its prediction\naccuracy is much better than the models trained from limited personal data and\nis similar to, and even slightly better than, the results from a centralized\ndataset. This work paves the way for international collaborations on healthcare\nprojects, where additional data is crucial for reducing bias and providing\nbenefits to humanity.\n","authors":["Rui Sun","Zhipeng Wang","Hengrui Zhang","Ming Jiang","Yizhe Wen","Jiqun Zhang","Jiahao Sun","Shuoying Zhang","Erwu Liu","Kezhi Li"],"pdf_url":"https://arxiv.org/pdf/2410.17933v1.pdf","comment":"Accepted by IEEE Global Blockchain Conference"},{"id":"http://arxiv.org/abs/2402.04033v3","updated":"2024-10-23T14:50:51Z","published":"2024-02-06T14:26:22Z","title":"On provable privacy vulnerabilities of graph representations","summary":"  Graph representation learning (GRL) is critical for extracting insights from\ncomplex network structures, but it also raises security concerns due to\npotential privacy vulnerabilities in these representations. This paper\ninvestigates the structural vulnerabilities in graph neural models where\nsensitive topological information can be inferred through edge reconstruction\nattacks. Our research primarily addresses the theoretical underpinnings of\nsimilarity-based edge reconstruction attacks (SERA), furnishing a\nnon-asymptotic analysis of their reconstruction capacities. Moreover, we\npresent empirical corroboration indicating that such attacks can perfectly\nreconstruct sparse graphs as graph size increases. Conversely, we establish\nthat sparsity is a critical factor for SERA's effectiveness, as demonstrated\nthrough analysis and experiments on (dense) stochastic block models. Finally,\nwe explore the resilience of private graph representations produced via noisy\naggregation (NAG) mechanism against SERA. Through theoretical analysis and\nempirical assessments, we affirm the mitigation of SERA using NAG . In\nparallel, we also empirically delineate instances wherein SERA demonstrates\nboth efficacy and deficiency in its capacity to function as an instrument for\nelucidating the trade-off between privacy and utility.\n","authors":["Ruofan Wu","Guanhua Fang","Qiying Pan","Mingyang Zhang","Tengfei Liu","Weiqiang Wang"],"pdf_url":"https://arxiv.org/pdf/2402.04033v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.01959v2","updated":"2024-10-23T14:49:39Z","published":"2024-06-04T04:39:51Z","title":"Adaptive Variance Reduction for Stochastic Optimization under Weaker\n  Assumptions","summary":"  This paper explores adaptive variance reduction methods for stochastic\noptimization based on the STORM technique. Existing adaptive extensions of\nSTORM rely on strong assumptions like bounded gradients and bounded function\nvalues, or suffer an additional $\\mathcal{O}(\\log T)$ term in the convergence\nrate. To address these limitations, we introduce a novel adaptive STORM method\nthat achieves an optimal convergence rate of $\\mathcal{O}(T^{-1/3})$ for\nnon-convex functions with our newly designed learning rate strategy. Compared\nwith existing approaches, our method requires weaker assumptions and attains\nthe optimal convergence rate without the additional $\\mathcal{O}(\\log T)$ term.\nWe also extend the proposed technique to stochastic compositional optimization,\nobtaining the same optimal rate of $\\mathcal{O}(T^{-1/3})$. Furthermore, we\ninvestigate the non-convex finite-sum problem and develop another innovative\nadaptive variance reduction method that achieves an optimal convergence rate of\n$\\mathcal{O}(n^{1/4} T^{-1/2} )$, where $n$ represents the number of component\nfunctions. Numerical experiments across various tasks validate the\neffectiveness of our method.\n","authors":["Wei Jiang","Sifan Yang","Yibo Wang","Lijun Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.01959v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2406.00489"},{"id":"http://arxiv.org/abs/2310.10107v4","updated":"2024-10-23T14:47:42Z","published":"2023-10-16T06:41:13Z","title":"Posterior Sampling-based Online Learning for Episodic POMDPs","summary":"  Learning in POMDPs is known to be significantly harder than in MDPs. In this\npaper, we consider the online learning problem for episodic POMDPs with unknown\ntransition and observation models. We propose a Posterior Sampling-based\nreinforcement learning algorithm for POMDPs (PS4POMDPs), which is much simpler\nand more implementable compared to state-of-the-art optimism-based online\nlearning algorithms for POMDPs. We show that the Bayesian regret of the\nproposed algorithm scales as the square root of the number of episodes and is\npolynomial in the other parameters. In a general setting, the regret scales\nexponentially in the horizon length $H$, and we show that this is inevitable by\nproviding a lower bound. However, when the POMDP is undercomplete and weakly\nrevealing (a common assumption in the recent literature), we establish a\npolynomial Bayesian regret bound. We finally propose a posterior sampling\nalgorithm for multi-agent POMDPs, and show it too has sublinear regret.\n","authors":["Dengwang Tang","Dongze Ye","Rahul Jain","Ashutosh Nayyar","Pierluigi Nuzzo"],"pdf_url":"https://arxiv.org/pdf/2310.10107v4.pdf","comment":"41 pages, 9 figures"},{"id":"http://arxiv.org/abs/2406.00489v2","updated":"2024-10-23T14:42:35Z","published":"2024-06-01T16:38:43Z","title":"Efficient Sign-Based Optimization: Accelerating Convergence via Variance\n  Reduction","summary":"  Sign stochastic gradient descent (signSGD) is a communication-efficient\nmethod that transmits only the sign of stochastic gradients for parameter\nupdating. Existing literature has demonstrated that signSGD can achieve a\nconvergence rate of $\\mathcal{O}(d^{1/2}T^{-1/4})$, where $d$ represents the\ndimension and $T$ is the iteration number. In this paper, we improve this\nconvergence rate to $\\mathcal{O}(d^{1/2}T^{-1/3})$ by introducing the\nSign-based Stochastic Variance Reduction (SSVR) method, which employs variance\nreduction estimators to track gradients and leverages their signs to update.\nFor finite-sum problems, our method can be further enhanced to achieve a\nconvergence rate of $\\mathcal{O}(m^{1/4}d^{1/2}T^{-1/2})$, where $m$ denotes\nthe number of component functions. Furthermore, we investigate the\nheterogeneous majority vote in distributed settings and introduce two novel\nalgorithms that attain improved convergence rates of\n$\\mathcal{O}(d^{1/2}T^{-1/2} + dn^{-1/2})$ and $\\mathcal{O}(d^{1/4}T^{-1/4})$\nrespectively, outperforming the previous results of $\\mathcal{O}(dT^{-1/4} +\ndn^{-1/2})$ and $\\mathcal{O}(d^{3/8}T^{-1/8})$, where $n$ represents the number\nof nodes. Numerical experiments across different tasks validate the\neffectiveness of our proposed methods.\n","authors":["Wei Jiang","Sifan Yang","Wenhao Yang","Lijun Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.00489v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17918v1","updated":"2024-10-23T14:34:39Z","published":"2024-10-23T14:34:39Z","title":"Addressing Asynchronicity in Clinical Multimodal Fusion via\n  Individualized Chest X-ray Generation","summary":"  Integrating multi-modal clinical data, such as electronic health records\n(EHR) and chest X-ray images (CXR), is particularly beneficial for clinical\nprediction tasks. However, in a temporal setting, multi-modal data are often\ninherently asynchronous. EHR can be continuously collected but CXR is generally\ntaken with a much longer interval due to its high cost and radiation dose. When\nclinical prediction is needed, the last available CXR image might have been\noutdated, leading to suboptimal predictions. To address this challenge, we\npropose DDL-CXR, a method that dynamically generates an up-to-date latent\nrepresentation of the individualized CXR images. Our approach leverages latent\ndiffusion models for patient-specific generation strategically conditioned on a\nprevious CXR image and EHR time series, providing information regarding\nanatomical structures and disease progressions, respectively. In this way, the\ninteraction across modalities could be better captured by the latent CXR\ngeneration process, ultimately improving the prediction performance.\nExperiments using MIMIC datasets show that the proposed model could effectively\naddress asynchronicity in multimodal fusion and consistently outperform\nexisting methods.\n","authors":["Wenfang Yao","Chen Liu","Kejing Yin","William K. Cheung","Jing Qin"],"pdf_url":"https://arxiv.org/pdf/2410.17918v1.pdf","comment":"Accepted by NeurIPS-24"},{"id":"http://arxiv.org/abs/2410.17917v1","updated":"2024-10-23T14:34:36Z","published":"2024-10-23T14:34:36Z","title":"regAL: Python Package for Active Learning of Regression Problems","summary":"  Increasingly more research areas rely on machine learning methods to\naccelerate discovery while saving resources. Machine learning models, however,\nusually require large datasets of experimental or computational results, which\nin certain fields, such as (bio)chemistry, materials science, or medicine, are\nrarely given and often prohibitively expensive to obtain. To bypass that\nobstacle, active learning methods are employed to develop machine learning\nmodels with a desired performance while requiring the least possible number of\ncomputational or experimental results from the domain of application. For this\npurpose, the model's knowledge about certain regions of the application domain\nis estimated to guide the choice of the model's training set. Although active\nlearning is widely studied for classification problems (discrete outcomes),\ncomparatively few works handle this method for regression problems (continuous\noutcomes). In this work, we present our Python package regAL, which allows\nusers to evaluate different active learning strategies for regression problems.\nWith a minimal input of just the dataset in question, but many additional\ncustomization and insight options, this package is intended for anyone who aims\nto perform and understand active learning in their problem-specific scope.\n","authors":["Elizaveta Surzhikova","Jonny Proppe"],"pdf_url":"https://arxiv.org/pdf/2410.17917v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17913v1","updated":"2024-10-23T14:33:11Z","published":"2024-10-23T14:33:11Z","title":"Deep learning for model correction of dynamical systems with data\n  scarcity","summary":"  We present a deep learning framework for correcting existing dynamical system\nmodels utilizing only a scarce high-fidelity data set. In many practical\nsituations, one has a low-fidelity model that can capture the dynamics\nreasonably well but lacks high resolution, due to the inherent limitation of\nthe model and the complexity of the underlying physics. When high resolution\ndata become available, it is natural to seek model correction to improve the\nresolution of the model predictions. We focus on the case when the amount of\nhigh-fidelity data is so small that most of the existing data driven modeling\nmethods cannot be applied. In this paper, we address these challenges with a\nmodel-correction method which only requires a scarce high-fidelity data set.\nOur method first seeks a deep neural network (DNN) model to approximate the\nexisting low-fidelity model. By using the scarce high-fidelity data, the method\nthen corrects the DNN model via transfer learning (TL). After TL, an improved\nDNN model with high prediction accuracy to the underlying dynamics is obtained.\nOne distinct feature of the propose method is that it does not assume a\nspecific form of the model correction terms. Instead, it offers an inherent\ncorrection to the low-fidelity model via TL. A set of numerical examples are\npresented to demonstrate the effectiveness of the proposed method.\n","authors":["Caroline Tatsuoka","Dongbin Xiu"],"pdf_url":"https://arxiv.org/pdf/2410.17913v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04377v3","updated":"2024-10-23T14:29:56Z","published":"2024-08-08T11:22:52Z","title":"Anomaly Prediction: A Novel Approach with Explicit Delay and Horizon","summary":"  Anomaly detection in time series data is a critical challenge across various\ndomains. Traditional methods typically focus on identifying anomalies in\nimmediate subsequent steps, often underestimating the significance of temporal\ndynamics such as delay time and horizons of anomalies, which generally require\nextensive post-analysis. This paper introduces a novel approach for time series\nanomaly prediction, incorporating temporal information directly into the\nprediction results. We propose a new dataset specifically designed to evaluate\nthis approach and conduct comprehensive experiments using several\nstate-of-the-art methods. Our results demonstrate the efficacy of our approach\nin providing timely and accurate anomaly predictions, setting a new benchmark\nfor future research in this field.\n","authors":["Jiang You","Arben Cela","René Natowicz","Jacob Ouanounou","Patrick Siarry"],"pdf_url":"https://arxiv.org/pdf/2408.04377v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16164v3","updated":"2024-10-23T14:24:50Z","published":"2024-05-25T10:15:51Z","title":"Acquiring Better Load Estimates by Combining Anomaly and Change Point\n  Detection in Power Grid Time-series Measurements","summary":"  In this paper we present novel methodology for automatic anomaly and switch\nevent filtering to improve load estimation in power grid systems. By leveraging\nunsupervised methods with supervised optimization, our approach prioritizes\ninterpretability while ensuring robust and generalizable performance on unseen\ndata. Through experimentation, a combination of binary segmentation for change\npoint detection and statistical process control for anomaly detection emerges\nas the most effective strategy, specifically when ensembled in a novel\nsequential manner. Results indicate the clear wasted potential when filtering\nis not applied. The automatic load estimation is also fairly accurate, with\napproximately 90% of estimates falling within a 10% error margin, with only a\nsingle significant failure in both the minimum and maximum load estimates\nacross 60 measurements in the test set. Our methodology's interpretability\nmakes it particularly suitable for critical infrastructure planning, thereby\nenhancing decision-making processes.\n","authors":["Roel Bouman","Linda Schmeitz","Luco Buise","Jacco Heres","Yuliya Shapovalova","Tom Heskes"],"pdf_url":"https://arxiv.org/pdf/2405.16164v3.pdf","comment":"All code can be found at: https://github.com/RoelBouman/StormPhase2"},{"id":"http://arxiv.org/abs/2410.17904v1","updated":"2024-10-23T14:22:49Z","published":"2024-10-23T14:22:49Z","title":"Reinforcement Learning under Latent Dynamics: Toward Statistical and\n  Algorithmic Modularity","summary":"  Real-world applications of reinforcement learning often involve environments\nwhere agents operate on complex, high-dimensional observations, but the\nunderlying (''latent'') dynamics are comparatively simple. However, outside of\nrestrictive settings such as small latent spaces, the fundamental statistical\nrequirements and algorithmic principles for reinforcement learning under latent\ndynamics are poorly understood.\n  This paper addresses the question of reinforcement learning under\n$\\textit{general}$ latent dynamics from a statistical and algorithmic\nperspective. On the statistical side, our main negative result shows that most\nwell-studied settings for reinforcement learning with function approximation\nbecome intractable when composed with rich observations; we complement this\nwith a positive result, identifying latent pushforward coverability as a\ngeneral condition that enables statistical tractability. Algorithmically, we\ndevelop provably efficient observable-to-latent reductions -- that is,\nreductions that transform an arbitrary algorithm for the latent MDP into an\nalgorithm that can operate on rich observations -- in two settings: one where\nthe agent has access to hindsight observations of the latent dynamics [LADZ23],\nand one where the agent can estimate self-predictive latent models [SAGHCB20].\nTogether, our results serve as a first step toward a unified statistical and\nalgorithmic theory for reinforcement learning under latent dynamics.\n","authors":["Philip Amortila","Dylan J. Foster","Nan Jiang","Akshay Krishnamurthy","Zakaria Mhammedi"],"pdf_url":"https://arxiv.org/pdf/2410.17904v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17898v1","updated":"2024-10-23T14:16:34Z","published":"2024-10-23T14:16:34Z","title":"Scalable Offline Reinforcement Learning for Mean Field Games","summary":"  Reinforcement learning algorithms for mean-field games offer a scalable\nframework for optimizing policies in large populations of interacting agents.\nExisting methods often depend on online interactions or access to system\ndynamics, limiting their practicality in real-world scenarios where such\ninteractions are infeasible or difficult to model. In this paper, we present\nOffline Munchausen Mirror Descent (Off-MMD), a novel mean-field RL algorithm\nthat approximates equilibrium policies in mean-field games using purely offline\ndata. By leveraging iterative mirror descent and importance sampling\ntechniques, Off-MMD estimates the mean-field distribution from static datasets\nwithout relying on simulation or environment dynamics. Additionally, we\nincorporate techniques from offline reinforcement learning to address common\nissues like Q-value overestimation, ensuring robust policy learning even with\nlimited data coverage. Our algorithm scales to complex environments and\ndemonstrates strong performance on benchmark tasks like crowd exploration or\nnavigation, highlighting its applicability to real-world multi-agent systems\nwhere online experimentation is infeasible. We empirically demonstrate the\nrobustness of Off-MMD to low-quality datasets and conduct experiments to\ninvestigate its sensitivity to hyperparameter choices.\n","authors":["Axel Brunnbauer","Julian Lemmel","Zahra Babaiee","Sophie Neubauer","Radu Grosu"],"pdf_url":"https://arxiv.org/pdf/2410.17898v1.pdf","comment":"Submitted to AAMAS"},{"id":"http://arxiv.org/abs/2407.19353v2","updated":"2024-10-23T14:11:34Z","published":"2024-07-28T00:07:20Z","title":"A spring-block theory of feature learning in deep neural networks","summary":"  Feature-learning deep nets progressively collapse data to a regular\nlow-dimensional geometry. How this phenomenon emerges from collective action of\nnonlinearity, noise, learning rate, and other choices that shape the dynamics,\nhas eluded first-principles theories built from microscopic neuronal dynamics.\nWe exhibit a noise-nonlinearity phase diagram that identifies regimes where\nshallow or deep layers learn more effectively. We then propose a macroscopic\nmechanical theory that reproduces the diagram, explaining why some DNNs are\nlazy and some active, and linking feature learning across layers to\ngeneralization.\n","authors":["Cheng Shi","Liming Pan","Ivan Dokmanić"],"pdf_url":"https://arxiv.org/pdf/2407.19353v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15592v2","updated":"2024-10-23T14:08:10Z","published":"2024-10-21T02:21:56Z","title":"CPE-Pro: A Structure-Sensitive Deep Learning Method for Protein\n  Representation and Origin Evaluation","summary":"  Protein structures are important for understanding their functions and\ninteractions. Currently, many protein structure prediction methods are\nenriching the structure database. Discriminating the origin of structures is\ncrucial for distinguishing between experimentally resolved and computationally\npredicted structures, evaluating the reliability of prediction methods, and\nguiding downstream biological studies. Building on works in structure\nprediction, We developed a structure-sensitive supervised deep learning model,\nCrystal vs Predicted Evaluator for Protein Structure (CPE-Pro), to represent\nand discriminate the origin of protein structures. CPE-Pro learns the\nstructural information of proteins and captures inter-structural differences to\nachieve accurate traceability on four data classes, and is expected to be\nextended to more. Simultaneously, we utilized Foldseek to encode protein\nstructures into \"structure-sequences\" and trained a protein Structural Sequence\nLanguage Model, SSLM. Preliminary experiments demonstrated that, compared to\nlarge-scale protein language models pre-trained on vast amounts of amino acid\nsequences, the \"structure-sequence\" enables the language model to learn more\ninformative protein features, enhancing and optimizing structural\nrepresentations. We have provided the code, model weights, and all related\nmaterials on https://github.com/GouWenrui/CPE-Pro-main.git.\n","authors":["Wenrui Gou","Wenhui Ge","Yang Tan","Mingchen Li","Guisheng Fan","Huiqun Yu"],"pdf_url":"https://arxiv.org/pdf/2410.15592v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19472v2","updated":"2024-10-23T14:02:12Z","published":"2024-09-28T22:41:49Z","title":"Towards Croppable Implicit Neural Representations","summary":"  Implicit Neural Representations (INRs) have peaked interest in recent years\ndue to their ability to encode natural signals using neural networks. While\nINRs allow for useful applications such as interpolating new coordinates and\nsignal compression, their black-box nature makes it difficult to modify them\npost-training. In this paper we explore the idea of editable INRs, and\nspecifically focus on the widely used cropping operation. To this end, we\npresent Local-Global SIRENs -- a novel INR architecture that supports cropping\nby design. Local-Global SIRENs are based on combining local and global feature\nextraction for signal encoding. What makes their design unique is the ability\nto effortlessly remove specific portions of an encoded signal, with a\nproportional weight decrease. This is achieved by eliminating the corresponding\nweights from the network, without the need for retraining. We further show how\nthis architecture can be used to support the straightforward extension of\npreviously encoded signals. Beyond signal editing, we examine how the\nLocal-Global approach can accelerate training, enhance encoding of various\nsignals, improve downstream performance, and be applied to modern INRs such as\nINCODE, highlighting its potential and flexibility. Code is available at\nhttps://github.com/maorash/Local-Global-INRs.\n","authors":["Maor Ashkenazi","Eran Treister"],"pdf_url":"https://arxiv.org/pdf/2409.19472v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2408.06927v2","updated":"2024-10-23T14:01:27Z","published":"2024-08-13T14:29:00Z","title":"Breaking Class Barriers: Efficient Dataset Distillation via Inter-Class\n  Feature Compensator","summary":"  Dataset distillation has emerged as a technique aiming to condense\ninformative features from large, natural datasets into a compact and synthetic\nform. While recent advancements have refined this technique, its performance is\nbottlenecked by the prevailing class-specific synthesis paradigm. Under this\nparadigm, synthetic data is optimized exclusively for a pre-assigned one-hot\nlabel, creating an implicit class barrier in feature condensation. This leads\nto inefficient utilization of the distillation budget and oversight of\ninter-class feature distributions, which ultimately limits the effectiveness\nand efficiency, as demonstrated in our analysis. To overcome these constraints,\nthis paper presents the Inter-class Feature Compensator (INFER), an innovative\ndistillation approach that transcends the class-specific data-label framework\nwidely utilized in current dataset distillation methods. Specifically, INFER\nleverages a Universal Feature Compensator (UFC) to enhance feature integration\nacross classes, enabling the generation of multiple additional synthetic\ninstances from a single UFC input. This significantly improves the efficiency\nof the distillation budget. Moreover, INFER enriches inter-class interactions\nduring the distillation, thereby enhancing the effectiveness and\ngeneralizability of the distilled data. By allowing for the linear\ninterpolation of labels similar to those in the original dataset, INFER\nmeticulously optimizes the synthetic data and dramatically reduces the size of\nsoft labels in the synthetic dataset to almost zero, establishing a new\nbenchmark for efficiency and effectiveness in dataset distillation.\n","authors":["Xin Zhang","Jiawei Du","Ping Liu","Joey Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.06927v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12819v2","updated":"2024-10-23T14:00:36Z","published":"2024-07-01T10:33:46Z","title":"I've Got 99 Problems But FLOPS Ain't One","summary":"  Hyperscalers dominate the landscape of large network deployments, yet they\nrarely share data or insights about the challenges they face. In light of this\nsupremacy, what problems can we find to solve in this space? We take an\nunconventional approach to find relevant research directions, starting from\npublic plans to build a $100 billion datacenter for machine learning\napplications. Leveraging the language models scaling laws, we discover what\nworkloads such a datacenter might carry and explore the challenges one may\nencounter in doing so, with a focus on networking research. We conclude that\nbuilding the datacenter and training such models is technically possible, but\nthis requires novel wide-area transports for inter-DC communication, a\nmultipath transport and novel datacenter topologies for intra-datacenter\ncommunication, high speed scale-up networks and transports, outlining a rich\nresearch agenda for the networking community.\n","authors":["Alexandru M. Gherghescu","Vlad-Andrei Bădoiu","Alexandru Agache","Mihai-Valentin Dumitru","Iuliu Vasilescu","Radu Mantu","Costin Raiciu"],"pdf_url":"https://arxiv.org/pdf/2407.12819v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17882v1","updated":"2024-10-23T13:55:42Z","published":"2024-10-23T13:55:42Z","title":"Identifiable Representation and Model Learning for Latent Dynamic\n  Systems","summary":"  Learning identifiable representations and models from low-level observations\nis useful for an intelligent spacecraft to reliability finish downstream tasks.\nFor temporal observations, to ensure that the data generating process is\nprovably inverted, most existing works either assume the noise variables in the\ndynamic mechanisms are (conditionally) independent, or require interventions\nwhich can directly affect each latent variable. However, in practice, the\nrelationship between the exogenous inputs/interventions and the latent\nvariables may follow some complex deterministic mechanisms. In this work, we\nstudy the problem of identifiable representation and model learning for latent\ndynamic systems. The key idea is that we use an inductive bias inspired by\ncontrollable canonical forms, which is invariant, sparse, and input dependent\nby definition. We prove that, for linear or affine nonlinear latent dynamic\nsystems, it is possible to identify the representations up to scaling and\ndetermine the models up to some simple transformations. The results have\npotential to provide some theoretical guarantees for developing more\ntrustworthy decision-making and control methods for intelligent spacecrafts.\n","authors":["Congxi Zhang","Yongchun Xie"],"pdf_url":"https://arxiv.org/pdf/2410.17882v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17881v1","updated":"2024-10-23T13:53:26Z","published":"2024-10-23T13:53:26Z","title":"AdaRankGrad: Adaptive Gradient-Rank and Moments for Memory-Efficient\n  LLMs Training and Fine-Tuning","summary":"  Training and fine-tuning large language models (LLMs) come with challenges\nrelated to memory and computational requirements due to the increasing size of\nthe model weights and the optimizer states. Various techniques have been\ndeveloped to tackle these challenges, such as low-rank adaptation (LoRA), which\ninvolves introducing a parallel trainable low-rank matrix to the fixed\npre-trained weights at each layer. However, these methods often fall short\ncompared to the full-rank weight training approach, as they restrict the\nparameter search to a low-rank subspace. This limitation can disrupt training\ndynamics and require a full-rank warm start to mitigate the impact. In this\npaper, we introduce a new method inspired by a phenomenon we formally prove: as\ntraining progresses, the rank of the estimated layer gradients gradually\ndecreases, and asymptotically approaches rank one. Leveraging this, our\napproach involves adaptively reducing the rank of the gradients during Adam\noptimization steps, using an efficient online-updating low-rank projections\nrule. We further present a randomized SVD scheme for efficiently finding the\nprojection matrix. Our technique enables full-parameter fine-tuning with\nadaptive low-rank gradient updates, significantly reducing overall memory\nrequirements during training compared to state-of-the-art methods while\nimproving model performance in both pretraining and fine-tuning. Finally, we\nprovide a convergence analysis of our method and demonstrate its merits for\ntraining and fine-tuning language and biological foundation models.\n","authors":["Yehonathan Refael","Jonathan Svirsky","Boris Shustin","Wasim Huleihel","Ofir Lindenbaum"],"pdf_url":"https://arxiv.org/pdf/2410.17881v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17878v1","updated":"2024-10-23T13:50:27Z","published":"2024-10-23T13:50:27Z","title":"Relaxed Equivariance via Multitask Learning","summary":"  Incorporating equivariance as an inductive bias into deep learning\narchitectures to take advantage of the data symmetry has been successful in\nmultiple applications, such as chemistry and dynamical systems. In particular,\nroto-translations are crucial for effectively modeling geometric graphs and\nmolecules, where understanding the 3D structures enhances generalization.\nHowever, equivariant models often pose challenges due to their high\ncomputational complexity. In this paper, we introduce REMUL, a training\nprocedure for approximating equivariance with multitask learning. We show that\nunconstrained models (which do not build equivariance into the architecture)\ncan learn approximate symmetries by minimizing an additional simple\nequivariance loss. By formulating equivariance as a new learning objective, we\ncan control the level of approximate equivariance in the model. Our method\nachieves competitive performance compared to equivariant baselines while being\n$10 \\times$ faster at inference and $2.5 \\times$ at training.\n","authors":["Ahmed A. Elhag","T. Konstantin Rusch","Francesco Di Giovanni","Michael Bronstein"],"pdf_url":"https://arxiv.org/pdf/2410.17878v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.04953v3","updated":"2024-10-23T13:36:37Z","published":"2022-12-09T16:03:34Z","title":"TargetCall: Eliminating the Wasted Computation in Basecalling via\n  Pre-Basecalling Filtering","summary":"  Basecalling is an essential step in nanopore sequencing analysis where the\nraw signals of nanopore sequencers are converted into nucleotide sequences,\ni.e., reads. State-of-the-art basecallers employ complex deep learning models\nto achieve high basecalling accuracy. This makes basecalling computationally\ninefficient and memory-hungry, bottlenecking the entire genome analysis\npipeline. However, for many applications, the majority of reads do no match the\nreference genome of interest (i.e., target reference) and thus are discarded in\nlater steps in the genomics pipeline, wasting the basecalling computation. To\novercome this issue, we propose TargetCall, the first pre-basecalling filter to\neliminate the wasted computation in basecalling. TargetCall's key idea is to\ndiscard reads that will not match the target reference (i.e., off-target reads)\nprior to basecalling. TargetCall consists of two main components: (1)\nLightCall, a lightweight neural network basecaller that produces noisy reads;\nand (2) Similarity Check, which labels each of these noisy reads as on-target\nor off-target by matching them to the target reference. Our thorough\nexperimental evaluations show that TargetCall 1) improves the end-to-end\nbasecalling runtime performance of the state-of-the-art basecaller by 3.31x\nwhile maintaining high (98.88%) recall in keeping on-target reads, 2) maintains\nhigh accuracy in downstream analysis, and 3) achieves better runtime\nperformance, throughput, recall, precision, and generality compared to prior\nworks. TargetCall is available at https://github.com/CMU-SAFARI/TargetCall.\n","authors":["Meryem Banu Cavlak","Gagandeep Singh","Mohammed Alser","Can Firtina","Joël Lindegger","Mohammad Sadrosadati","Nika Mansouri Ghiasi","Can Alkan","Onur Mutlu"],"pdf_url":"https://arxiv.org/pdf/2212.04953v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17865v1","updated":"2024-10-23T13:36:23Z","published":"2024-10-23T13:36:23Z","title":"Population stratification for prediction of mortality in post-AKI\n  patients","summary":"  Acute kidney injury (AKI) is a serious clinical condition that affects up to\n20% of hospitalised patients. AKI is associated with short term unplanned\nhospital readmission and post-discharge mortality risk. Patient risk and\nhealthcare expenditures can be minimised by followup planning grounded on\npredictive models and machine learning. Since AKI is multi-factorial,\npredictive models specialised in different categories of patients can increase\naccuracy of predictions. In the present article we present some results\nfollowing this approach.\n","authors":["Flavio S. Correa da Silva","Simon Sawhney"],"pdf_url":"https://arxiv.org/pdf/2410.17865v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17863v1","updated":"2024-10-23T13:35:18Z","published":"2024-10-23T13:35:18Z","title":"CASCRNet: An Atrous Spatial Pyramid Pooling and Shared Channel Residual\n  based Network for Capsule Endoscopy","summary":"  This manuscript summarizes work on the Capsule Vision Challenge 2024 by\nMISAHUB. To address the multi-class disease classification task, which is\nchallenging due to the complexity and imbalance in the Capsule Vision challenge\ndataset, this paper proposes CASCRNet (Capsule endoscopy-Aspp-SCR-Network), a\nparameter-efficient and novel model that uses Shared Channel Residual (SCR)\nblocks and Atrous Spatial Pyramid Pooling (ASPP) blocks. Further, the\nperformance of the proposed model is compared with other well-known approaches.\nThe experimental results yield that proposed model provides better disease\nclassification results. The proposed model was successful in classifying\ndiseases with an F1 Score of 78.5% and a Mean AUC of 98.3%, which is promising\ngiven its compact architecture.\n","authors":["K V Srinanda","M Manvith Prabhu","Shyam Lal"],"pdf_url":"https://arxiv.org/pdf/2410.17863v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.17851v1","updated":"2024-10-23T13:20:42Z","published":"2024-10-23T13:20:42Z","title":"The Probabilistic Tsetlin Machine: A Novel Approach to Uncertainty\n  Quantification","summary":"  Tsetlin Machines (TMs) have emerged as a compelling alternative to\nconventional deep learning methods, offering notable advantages such as smaller\nmemory footprint, faster inference, fault-tolerant properties, and\ninterpretability. Although various adaptations of TMs have expanded their\napplicability across diverse domains, a fundamental gap remains in\nunderstanding how TMs quantify uncertainty in their predictions. In response,\nthis paper introduces the Probabilistic Tsetlin Machine (PTM) framework, aimed\nat providing a robust, reliable, and interpretable approach for uncertainty\nquantification. Unlike the original TM, the PTM learns the probability of\nstaying on each state of each Tsetlin Automaton (TA) across all clauses. These\nprobabilities are updated using the feedback tables that are part of the TM\nframework: Type I and Type II feedback. During inference, TAs decide their\nactions by sampling states based on learned probability distributions, akin to\nBayesian neural networks when generating weight values. In our experimental\nanalysis, we first illustrate the spread of the probabilities across TA states\nfor the noisy-XOR dataset. Then we evaluate the PTM alongside benchmark models\nusing both simulated and real-world datasets. The experiments on the simulated\ndataset reveal the PTM's effectiveness in uncertainty quantification,\nparticularly in delineating decision boundaries and identifying regions of high\nuncertainty. Moreover, when applied to multiclass classification tasks using\nthe Iris dataset, the PTM demonstrates competitive performance in terms of\npredictive entropy and expected calibration error, showcasing its potential as\na reliable tool for uncertainty estimation. Our findings underscore the\nimportance of selecting appropriate models for accurate uncertainty\nquantification in predictive tasks, with the PTM offering a particularly\ninterpretable and effective solution.\n","authors":["K. Darshana Abeyrathna","Sara El Mekkaoui","Andreas Hafver","Christian Agrell"],"pdf_url":"https://arxiv.org/pdf/2410.17851v1.pdf","comment":"12 pages, 5 figures, 6 tables, accepted and presented at ICAAI 2024,\n  London"},{"id":"http://arxiv.org/abs/2402.15055v2","updated":"2024-10-23T13:20:15Z","published":"2024-02-23T02:15:47Z","title":"Interpreting Context Look-ups in Transformers: Investigating\n  Attention-MLP Interactions","summary":"  Understanding the inner workings of large language models (LLMs) is crucial\nfor advancing their theoretical foundations and real-world applications. While\nthe attention mechanism and multi-layer perceptrons (MLPs) have been studied\nindependently, their interactions remain largely unexplored. This study\ninvestigates how attention heads and next-token neurons interact in LLMs to\npredict new words. We propose a methodology to identify next-token neurons,\nfind prompts that highly activate them, and determine the upstream attention\nheads responsible. We then generate and evaluate explanations for the activity\nof these attention heads in an automated manner. Our findings reveal that some\nattention heads recognize specific contexts relevant to predicting a token and\nactivate a downstream token-predicting neuron accordingly. This mechanism\nprovides a deeper understanding of how attention heads work with MLP neurons to\nperform next-token prediction. Our approach offers a foundation for further\nresearch into the intricate workings of LLMs and their impact on text\ngeneration and understanding.\n","authors":["Clement Neo","Shay B. Cohen","Fazl Barez"],"pdf_url":"https://arxiv.org/pdf/2402.15055v2.pdf","comment":"Accepted to EMNLP 2024 Main Conference"},{"id":"http://arxiv.org/abs/2410.13563v2","updated":"2024-10-23T13:19:26Z","published":"2024-10-17T14:00:18Z","title":"Ornstein-Uhlenbeck Adaptation as a Mechanism for Learning in Brains and\n  Machines","summary":"  Learning is a fundamental property of intelligent systems, observed across\nbiological organisms and engineered systems. While modern intelligent systems\ntypically rely on gradient descent for learning, the need for exact gradients\nand complex information flow makes its implementation in biological and\nneuromorphic systems challenging. This has motivated the exploration of\nalternative learning mechanisms that can operate locally and do not rely on\nexact gradients. In this work, we introduce a novel approach that leverages\nnoise in the parameters of the system and global reinforcement signals. Using\nan Ornstein-Uhlenbeck process with adaptive dynamics, our method balances\nexploration and exploitation during learning, driven by deviations from error\npredictions, akin to reward prediction error. Operating in continuous time,\nOrstein-Uhlenbeck adaptation (OUA) is proposed as a general mechanism for\nlearning dynamic, time-evolving environments. We validate our approach across\ndiverse tasks, including supervised learning and reinforcement learning in\nfeedforward and recurrent systems. Additionally, we demonstrate that it can\nperform meta-learning, adjusting hyper-parameters autonomously. Our results\nindicate that OUA provides a viable alternative to traditional gradient-based\nmethods, with potential applications in neuromorphic computing. It also hints\nat a possible mechanism for noise-driven learning in the brain, where\nstochastic neurotransmitter release may guide synaptic adjustments.\n","authors":["Jesus Garcia Fernandez","Nasir Ahmad","Marcel van Gerven"],"pdf_url":"https://arxiv.org/pdf/2410.13563v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11397v2","updated":"2024-10-23T13:14:21Z","published":"2024-10-15T08:39:31Z","title":"FOOGD: Federated Collaboration for Both Out-of-distribution\n  Generalization and Detection","summary":"  Federated learning (FL) is a promising machine learning paradigm that\ncollaborates with client models to capture global knowledge. However, deploying\nFL models in real-world scenarios remains unreliable due to the coexistence of\nin-distribution data and unexpected out-of-distribution (OOD) data, such as\ncovariate-shift and semantic-shift data. Current FL researches typically\naddress either covariate-shift data through OOD generalization or\nsemantic-shift data via OOD detection, overlooking the simultaneous occurrence\nof various OOD shifts. In this work, we propose FOOGD, a method that estimates\nthe probability density of each client and obtains reliable global distribution\nas guidance for the subsequent FL process. Firstly, SM3D in FOOGD estimates\nscore model for arbitrary distributions without prior constraints, and detects\nsemantic-shift data powerfully. Then SAG in FOOGD provides invariant yet\ndiverse knowledge for both local covariate-shift generalization and client\nperformance generalization. In empirical validations, FOOGD significantly\nenjoys three main advantages: (1) reliably estimating non-normalized\ndecentralized distributions, (2) detecting semantic shift data via score\nvalues, and (3) generalizing to covariate-shift data by regularizing feature\nextractor. The prejoct is open in https://github.com/XeniaLLL/FOOGD-main.git.\n","authors":["Xinting Liao","Weiming Liu","Pengyang Zhou","Fengyuan Yu","Jiahe Xu","Jun Wang","Wenjie Wang","Chaochao Chen","Xiaolin Zheng"],"pdf_url":"https://arxiv.org/pdf/2410.11397v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.17840v1","updated":"2024-10-23T13:05:46Z","published":"2024-10-23T13:05:46Z","title":"Is the GPU Half-Empty or Half-Full? Practical Scheduling Techniques for\n  LLMs","summary":"  Serving systems for Large Language Models (LLMs) improve throughput by\nprocessing several requests concurrently. However, multiplexing hardware\nresources between concurrent requests involves non-trivial scheduling\ndecisions. Practical serving systems typically implement these decisions at two\nlevels: First, a load balancer routes requests to different servers which each\nhold a replica of the LLM. Then, on each server, an engine-level scheduler\ndecides when to run a request, or when to queue or preempt it. Improved\nscheduling policies may benefit a wide range of LLM deployments and can often\nbe implemented as \"drop-in replacements\" to a system's current policy. In this\nwork, we survey scheduling techniques from the literature and from practical\nserving systems. We find that schedulers from the literature often achieve good\nperformance but introduce significant complexity. In contrast, schedulers in\npractical deployments often leave easy performance gains on the table but are\neasy to implement, deploy and configure. This finding motivates us to introduce\ntwo new scheduling techniques, which are both easy to implement, and outperform\ncurrent techniques on production workload traces.\n","authors":["Ferdi Kossmann","Bruce Fontaine","Daya Khudia","Michael Cafarella","Samuel Madden"],"pdf_url":"https://arxiv.org/pdf/2410.17840v1.pdf","comment":"12 pages, 11 figures"},{"id":"http://arxiv.org/abs/2403.14774v2","updated":"2024-10-23T13:01:14Z","published":"2024-03-21T18:28:43Z","title":"Few-Shot Adversarial Prompt Learning on Vision-Language Models","summary":"  The vulnerability of deep neural networks to imperceptible adversarial\nperturbations has attracted widespread attention. Inspired by the success of\nvision-language foundation models, previous efforts achieved zero-shot\nadversarial robustness by aligning adversarial visual features with text\nsupervision. However, in practice, they are still unsatisfactory due to several\nissues, including heavy adaptation cost, suboptimal text supervision, and\nuncontrolled natural generalization capacity. In this paper, to address these\nissues, we propose a few-shot adversarial prompt framework where adapting input\nsequences with limited data makes significant adversarial robustness\nimprovement. Specifically, we achieve this by providing adversarially\ncorrelated text supervision that is end-to-end learned from adversarial\nexamples. We also propose a novel training objective that enhances the\nconsistency of multi-modal features while encourages differentiated uni-modal\nfeatures between natural and adversarial examples. The proposed framework gives\naccess to learn adversarial text supervision, which provides superior\ncross-modal adversarial alignment and matches state-of-the-art zero-shot\nadversarial robustness with only 1% training data. Code is available at:\nhttps://github.com/lionel-w2/FAP.\n","authors":["Yiwei Zhou","Xiaobo Xia","Zhiwei Lin","Bo Han","Tongliang Liu"],"pdf_url":"https://arxiv.org/pdf/2403.14774v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.17055v2","updated":"2024-10-23T12:55:39Z","published":"2024-10-22T14:36:44Z","title":"Optimal Design for Reward Modeling in RLHF","summary":"  Reinforcement Learning from Human Feedback (RLHF) has become a popular\napproach to align language models (LMs) with human preferences. This method\ninvolves collecting a large dataset of human pairwise preferences across\nvarious text generations and using it to infer (implicitly or explicitly) a\nreward model. Numerous methods have been proposed to learn the reward model and\nalign a LM with it. However, the costly process of collecting human preferences\nhas received little attention and could benefit from theoretical insights. This\npaper addresses this issue and aims to formalize the reward training model in\nRLHF. We frame the selection of an effective dataset as a simple regret\nminimization task, using a linear contextual dueling bandit method. Given the\npotentially large number of arms, this approach is more coherent than the\nbest-arm identification setting. We then propose an offline framework for\nsolving this problem. Under appropriate assumptions - linearity of the reward\nmodel in the embedding space, and boundedness of the reward parameter - we\nderive bounds on the simple regret. Finally, we provide a lower bound that\nmatches our upper bound up to constant and logarithmic terms. To our knowledge,\nthis is the first theoretical contribution in this area to provide an offline\napproach as well as worst-case guarantees.\n","authors":["Antoine Scheid","Etienne Boursier","Alain Durmus","Michael I. Jordan","Pierre Ménard","Eric Moulines","Michal Valko"],"pdf_url":"https://arxiv.org/pdf/2410.17055v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17835v1","updated":"2024-10-23T12:54:04Z","published":"2024-10-23T12:54:04Z","title":"Optimal Streaming Algorithms for Multi-Armed Bandits","summary":"  This paper studies two variants of the best arm identification (BAI) problem\nunder the streaming model, where we have a stream of $n$ arms with reward\ndistributions supported on $[0,1]$ with unknown means. The arms in the stream\nare arriving one by one, and the algorithm cannot access an arm unless it is\nstored in a limited size memory.\n  We first study the streaming \\eps-$top$-$k$ arms identification problem,\nwhich asks for $k$ arms whose reward means are lower than that of the $k$-th\nbest arm by at most $\\eps$ with probability at least $1-\\delta$. For general\n$\\eps \\in (0,1)$, the existing solution for this problem assumes $k = 1$ and\nachieves the optimal sample complexity $O(\\frac{n}{\\eps^2} \\log\n\\frac{1}{\\delta})$ using $O(\\log^*(n))$ ($\\log^*(n)$ equals the number of times\nthat we need to apply the logarithm function on $n$ before the results is no\nmore than 1.) memory and a single pass of the stream. We propose an algorithm\nthat works for any $k$ and achieves the optimal sample complexity\n$O(\\frac{n}{\\eps^2} \\log\\frac{k}{\\delta})$ using a single-arm memory and a\nsingle pass of the stream.\n  Second, we study the streaming BAI problem, where the objective is to\nidentify the arm with the maximum reward mean with at least $1-\\delta$\nprobability, using a single-arm memory and as few passes of the input stream as\npossible. We present a single-arm-memory algorithm that achieves a near\ninstance-dependent optimal sample complexity within $O(\\log \\Delta_2^{-1})$\npasses, where $\\Delta_2$ is the gap between the mean of the best arm and that\nof the second best arm.\n","authors":["Tianyuan Jin","Keke Huang","Jing Tang","Xiaokui Xiao"],"pdf_url":"https://arxiv.org/pdf/2410.17835v1.pdf","comment":"24pages"},{"id":"http://arxiv.org/abs/2410.17834v1","updated":"2024-10-23T12:53:58Z","published":"2024-10-23T12:53:58Z","title":"Non-intrusive Speech Quality Assessment with Diffusion Models Trained on\n  Clean Speech","summary":"  Diffusion models have found great success in generating high quality, natural\nsamples of speech, but their potential for density estimation for speech has so\nfar remained largely unexplored. In this work, we leverage an unconditional\ndiffusion model trained only on clean speech for the assessment of speech\nquality. We show that the quality of a speech utterance can be assessed by\nestimating the likelihood of a corresponding sample in the terminating Gaussian\ndistribution, obtained via a deterministic noising process. The resulting\nmethod is purely unsupervised, trained only on clean speech, and therefore does\nnot rely on annotations. Our diffusion-based approach leverages clean speech\npriors to assess quality based on how the input relates to the learned\ndistribution of clean data. Our proposed log-likelihoods show promising\nresults, correlating well with intrusive speech quality metrics such as POLQA\nand SI-SDR.\n","authors":["Danilo de Oliveira","Julius Richter","Jean-Marie Lemercier","Simon Welker","Timo Gerkmann"],"pdf_url":"https://arxiv.org/pdf/2410.17834v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01476v2","updated":"2024-10-23T12:53:49Z","published":"2024-10-02T12:30:05Z","title":"Reducing Variance in Meta-Learning via Laplace Approximation for\n  Regression Tasks","summary":"  Given a finite set of sample points, meta-learning algorithms aim to learn an\noptimal adaptation strategy for new, unseen tasks. Often, this data can be\nambiguous as it might belong to different tasks concurrently. This is\nparticularly the case in meta-regression tasks. In such cases, the estimated\nadaptation strategy is subject to high variance due to the limited amount of\nsupport data for each task, which often leads to sub-optimal generalization\nperformance. In this work, we address the problem of variance reduction in\ngradient-based meta-learning and formalize the class of problems prone to this,\na condition we refer to as \\emph{task overlap}. Specifically, we propose a\nnovel approach that reduces the variance of the gradient estimate by weighing\neach support point individually by the variance of its posterior over the\nparameters. To estimate the posterior, we utilize the Laplace approximation,\nwhich allows us to express the variance in terms of the curvature of the loss\nlandscape of our meta-learner. Experimental results demonstrate the\neffectiveness of the proposed method and highlight the importance of variance\nreduction in meta-learning.\n","authors":["Alfredo Reichlin","Gustaf Tegnér","Miguel Vasco","Hang Yin","Mårten Björkman","Danica Kragic"],"pdf_url":"https://arxiv.org/pdf/2410.01476v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.01708v4","updated":"2024-10-23T12:50:18Z","published":"2022-10-04T16:08:54Z","title":"Conquering the Communication Constraints to Enable Large Pre-Trained\n  Models in Federated Learning","summary":"  Federated learning (FL) has emerged as a promising paradigm for enabling the\ncollaborative training of models without centralized access to the raw data on\nlocal devices. In the typical FL paradigm (e.g., FedAvg), model weights are\nsent to and from the server each round to participating clients. Recently, the\nuse of small pre-trained models has been shown effective in federated learning\noptimization and improving convergence. However, recent state-of-the-art\npre-trained models are getting more capable but also have more parameters. In\nconventional FL, sharing the enormous model weights can quickly put a massive\ncommunication burden on the system, especially if more capable models are\nemployed. Can we find a solution to enable those strong and readily-available\npre-trained models in FL to achieve excellent performance while simultaneously\nreducing the communication burden? To this end, we investigate the use of\nparameter-efficient fine-tuning in federated learning and thus introduce a new\nframework: FedPEFT. Specifically, we systemically evaluate the performance of\nFedPEFT across a variety of client stability, data distribution, and\ndifferential privacy settings. By only locally tuning and globally sharing a\nsmall portion of the model weights, significant reductions in the total\ncommunication overhead can be achieved while maintaining competitive or even\nbetter performance in a wide range of federated learning scenarios, providing\ninsight into a new paradigm for practical and effective federated systems.\n","authors":["Guangyu Sun","Umar Khalid","Matias Mendieta","Taojiannan Yang","Pu Wang","Minwoo Lee","Chen Chen"],"pdf_url":"https://arxiv.org/pdf/2210.01708v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.01335v2","updated":"2024-10-23T12:38:40Z","published":"2024-03-30T13:25:11Z","title":"Generative AI Models for Different Steps in Architectural Design: A\n  Literature Review","summary":"  Recent advances in generative artificial intelligence (AI) technologies have\nbeen significantly driven by models such as generative adversarial networks\n(GANs), variational autoencoders (VAEs), and denoising diffusion probabilistic\nmodels (DDPMs). Although architects recognize the potential of generative AI in\ndesign, personal barriers often restrict their access to the latest\ntechnological developments, thereby causing the application of generative AI in\narchitectural design to lag behind. Therefore, it is essential to comprehend\nthe principles and advancements of generative AI models and analyze their\nrelevance in architecture applications. This paper first provides an overview\nof generative AI technologies, with a focus on probabilistic diffusion models\n(DDPMs), 3D generative models, and foundation models, highlighting their recent\ndevelopments and main application scenarios. Then, the paper explains how the\nabovementioned models could be utilized in architecture. We subdivide the\narchitectural design process into six steps and review related research\nprojects in each step from 2020 to the present. Lastly, this paper discusses\npotential future directions for applying generative AI in the architectural\ndesign steps. This research can help architects quickly understand the\ndevelopment and latest progress of generative AI and contribute to the further\ndevelopment of intelligent architecture.\n","authors":["Chengyuan Li","Tianyu Zhang","Xusheng Du","Ye Zhang","Haoran Xie"],"pdf_url":"https://arxiv.org/pdf/2404.01335v2.pdf","comment":"34 pages, 14 figures, accepted by Frontiers of Architectural Research"},{"id":"http://arxiv.org/abs/2410.17823v1","updated":"2024-10-23T12:32:21Z","published":"2024-10-23T12:32:21Z","title":"Att2CPC: Attention-Guided Lossy Attribute Compression of Point Clouds","summary":"  With the great progress of 3D sensing and acquisition technology, the volume\nof point cloud data has grown dramatically, which urges the development of\nefficient point cloud compression methods. In this paper, we focus on the task\nof learned lossy point cloud attribute compression (PCAC). We propose an\nefficient attention-based method for lossy compression of point cloud\nattributes leveraging on an autoencoder architecture. Specifically, at the\nencoding side, we conduct multiple downsampling to best exploit the local\nattribute patterns, in which effective External Cross Attention (ECA) is\ndevised to hierarchically aggregate features by intergrating attributes and\ngeometry contexts. At the decoding side, the attributes of the point cloud are\nprogressively reconstructed based on the multi-scale representation and the\nzero-padding upsampling tactic. To the best of our knowledge, this is the first\napproach to introduce attention mechanism to point-based lossy PCAC task. We\nverify the compression efficiency of our model on various sequences, including\nhuman body frames, sparse objects, and large-scale point cloud scenes.\nExperiments show that our method achieves an average improvement of 1.15 dB and\n2.13 dB in BD-PSNR of Y channel and YUV channel, respectively, when comparing\nwith the state-of-the-art point-based method Deep-PCAC. Codes of this paper are\navailable at https://github.com/I2-Multimedia-Lab/Att2CPC.\n","authors":["Kai Liu","Kang You","Pan Gao","Manoranjan Paul"],"pdf_url":"https://arxiv.org/pdf/2410.17823v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.04811v2","updated":"2024-10-23T12:27:12Z","published":"2024-07-05T18:49:07Z","title":"Simplifying Deep Temporal Difference Learning","summary":"  Q-learning played a foundational role in the field reinforcement learning\n(RL). However, TD algorithms with off-policy data, such as Q-learning, or\nnonlinear function approximation like deep neural networks require several\nadditional tricks to stabilise training, primarily a replay buffer and target\nnetworks. Unfortunately, the delayed updating of frozen network parameters in\nthe target network harms the sample efficiency and, similarly, the replay\nbuffer introduces memory and implementation overheads. In this paper, we\ninvestigate whether it is possible to accelerate and simplify TD training while\nmaintaining its stability. Our key theoretical result demonstrates for the\nfirst time that regularisation techniques such as LayerNorm can yield provably\nconvergent TD algorithms without the need for a target network, even with\noff-policy data. Empirically, we find that online, parallelised sampling\nenabled by vectorised environments stabilises training without the need of a\nreplay buffer. Motivated by these findings, we propose PQN, our simplified deep\nonline Q-Learning algorithm. Surprisingly, this simple algorithm is competitive\nwith more complex methods like: Rainbow in Atari, R2D2 in Hanabi, QMix in Smax,\nPPO-RNN in Craftax, and can be up to 50x faster than traditional DQN without\nsacrificing sample efficiency. In an era where PPO has become the go-to RL\nalgorithm, PQN reestablishes Q-learning as a viable alternative.\n","authors":["Matteo Gallici","Mattie Fellows","Benjamin Ellis","Bartomeu Pou","Ivan Masmitja","Jakob Nicolaus Foerster","Mario Martin"],"pdf_url":"https://arxiv.org/pdf/2407.04811v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.04372v3","updated":"2024-10-23T12:19:16Z","published":"2024-01-09T06:15:45Z","title":"Stable generative modeling using Schrödinger bridges","summary":"  We consider the problem of sampling from an unknown distribution for which\nonly a sufficiently large number of training samples are available. Such\nsettings have recently drawn considerable interest in the context of generative\nmodelling and Bayesian inference. In this paper, we propose a generative model\ncombining Schr\\\"odinger bridges and Langevin dynamics. Schr\\\"odinger bridges\nover an appropriate reversible reference process are used to approximate the\nconditional transition probability from the available training samples, which\nis then implemented in a discrete-time reversible Langevin sampler to generate\nnew samples. By setting the kernel bandwidth in the reference process to match\nthe time step size used in the unadjusted Langevin algorithm, our method\neffectively circumvents any stability issues typically associated with the\ntime-stepping of stiff stochastic differential equations. Moreover, we\nintroduce a novel split-step scheme, ensuring that the generated samples remain\nwithin the convex hull of the training samples. Our framework can be naturally\nextended to generate conditional samples and to Bayesian inference problems. We\ndemonstrate the performance of our proposed scheme through experiments on\nsynthetic datasets with increasing dimensions and on a stochastic subgrid-scale\nparametrization conditional sampling problem as well as generating sample\ntrajectories of a dynamical system using conditional sampling.\n","authors":["Georg A. Gottwald","Fengyi Li","Youssef Marzouk","Sebastian Reich"],"pdf_url":"https://arxiv.org/pdf/2401.04372v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11960v4","updated":"2024-10-23T12:18:49Z","published":"2024-03-18T16:57:16Z","title":"Causality-Aware Spatiotemporal Graph Neural Networks for Spatiotemporal\n  Time Series Imputation","summary":"  Spatiotemporal time series are usually collected via monitoring sensors\nplaced at different locations, which usually contain missing values due to\nvarious failures, such as mechanical damages and Internet outages. Imputing the\nmissing values is crucial for analyzing time series. When recovering a specific\ndata point, most existing methods consider all the information relevant to that\npoint regardless of the cause-and-effect relationship. During data collection,\nit is inevitable that some unknown confounders are included, e.g., background\nnoise in time series and non-causal shortcut edges in the constructed sensor\nnetwork. These confounders could open backdoor paths and establish non-causal\ncorrelations between the input and output. Over-exploiting these non-causal\ncorrelations could cause overfitting. In this paper, we first revisit\nspatiotemporal time series imputation from a causal perspective and show how to\nblock the confounders via the frontdoor adjustment. Based on the results of\nfrontdoor adjustment, we introduce a novel Causality-Aware Spatiotemporal Graph\nNeural Network (Casper), which contains a novel Prompt Based Decoder (PBD) and\na Spatiotemporal Causal Attention (SCA). PBD could reduce the impact of\nconfounders and SCA could discover the sparse causal relationships among\nembeddings. Theoretical analysis reveals that SCA discovers causal\nrelationships based on the values of gradients. We evaluate Casper on three\nreal-world datasets, and the experimental results show that Casper could\noutperform the baselines and could effectively discover causal relationships.\n","authors":["Baoyu Jing","Dawei Zhou","Kan Ren","Carl Yang"],"pdf_url":"https://arxiv.org/pdf/2403.11960v4.pdf","comment":"Accepted by CIKM'2024. Fixed typos"},{"id":"http://arxiv.org/abs/2410.17814v1","updated":"2024-10-23T12:18:36Z","published":"2024-10-23T12:18:36Z","title":"Learning Lossless Compression for High Bit-Depth Volumetric Medical\n  Image","summary":"  Recent advances in learning-based methods have markedly enhanced the\ncapabilities of image compression. However, these methods struggle with high\nbit-depth volumetric medical images, facing issues such as degraded\nperformance, increased memory demand, and reduced processing speed. To address\nthese challenges, this paper presents the Bit-Division based Lossless\nVolumetric Image Compression (BD-LVIC) framework, which is tailored for high\nbit-depth medical volume compression. The BD-LVIC framework skillfully divides\nthe high bit-depth volume into two lower bit-depth segments: the Most\nSignificant Bit-Volume (MSBV) and the Least Significant Bit-Volume (LSBV). The\nMSBV concentrates on the most significant bits of the volumetric medical image,\ncapturing vital structural details in a compact manner. This reduction in\ncomplexity greatly improves compression efficiency using traditional codecs.\nConversely, the LSBV deals with the least significant bits, which encapsulate\nintricate texture details. To compress this detailed information effectively,\nwe introduce an effective learning-based compression model equipped with a\nTransformer-Based Feature Alignment Module, which exploits both intra-slice and\ninter-slice redundancies to accurately align features. Subsequently, a Parallel\nAutoregressive Coding Module merges these features to precisely estimate the\nprobability distribution of the least significant bit-planes. Our extensive\ntesting demonstrates that the BD-LVIC framework not only sets new performance\nbenchmarks across various datasets but also maintains a competitive coding\nspeed, highlighting its significant potential and practical utility in the\nrealm of volumetric medical image compression.\n","authors":["Kai Wang","Yuanchao Bai","Daxin Li","Deming Zhai","Junjun Jiang","Xianming Liu"],"pdf_url":"https://arxiv.org/pdf/2410.17814v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2408.04307v2","updated":"2024-10-23T12:08:33Z","published":"2024-08-08T08:40:15Z","title":"MoC-System: Efficient Fault Tolerance for Sparse Mixture-of-Experts\n  Model Training","summary":"  As large language models continue to scale up, distributed training systems\nhave expanded beyond 10k nodes, intensifying the importance of fault tolerance.\nCheckpoint has emerged as the predominant fault tolerance strategy, with\nextensive studies dedicated to optimizing its efficiency. However, the advent\nof the sparse Mixture-of-Experts (MoE) model presents new challenges due to the\nsubstantial increase in model size, despite comparable computational demands to\ndense models.\n  In this work, we propose the Mixture-of-Checkpoint System (MoC-System) to\norchestrate the vast array of checkpoint shards produced in distributed\ntraining systems. MoC-System features a novel Partial Experts Checkpointing\n(PEC) mechanism, an algorithm-system co-design that strategically saves a\nselected subset of experts, effectively reducing the MoE checkpoint size to\nlevels comparable with dense models. Incorporating hybrid parallel strategies,\nMoC-System involves fully sharded checkpointing strategies to evenly distribute\nthe workload across distributed ranks. Furthermore, MoC-System introduces a\ntwo-level checkpointing management method that asynchronously handles in-memory\nsnapshots and persistence processes.\n  We build MoC-System upon the Megatron-DeepSpeed framework, achieving up to a\n98.9% reduction in overhead for each checkpointing process compared to the\noriginal method, during MoE model training with ZeRO-2 data parallelism and\nexpert parallelism. Additionally, extensive empirical analyses substantiate\nthat our methods enhance efficiency while maintaining comparable model\naccuracy, even achieving an average accuracy increase of 1.08% on downstream\ntasks.\n","authors":["Weilin Cai","Le Qin","Jiayi Huang"],"pdf_url":"https://arxiv.org/pdf/2408.04307v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12641v3","updated":"2024-10-23T11:54:42Z","published":"2024-03-19T11:24:14Z","title":"Automated Contrastive Learning Strategy Search for Time Series","summary":"  In recent years, Contrastive Learning (CL) has become a predominant\nrepresentation learning paradigm for time series. Most existing methods\nmanually build specific CL Strategies (CLS) by human heuristics for certain\ndatasets and tasks. However, manually developing CLS usually requires excessive\nprior knowledge about the data, and massive experiments to determine the\ndetailed CL configurations. In this paper, we present an Automated Machine\nLearning (AutoML) practice at Microsoft, which automatically learns CLS for\ntime series datasets and tasks, namely Automated Contrastive Learning (AutoCL).\nWe first construct a principled search space of size over $3\\times10^{12}$,\ncovering data augmentation, embedding transformation, contrastive pair\nconstruction, and contrastive losses. Further, we introduce an efficient\nreinforcement learning algorithm, which optimizes CLS from the performance on\nthe validation tasks, to obtain effective CLS within the space. Experimental\nresults on various real-world datasets demonstrate that AutoCL could\nautomatically find the suitable CLS for the given dataset and task. From the\ncandidate CLS found by AutoCL on several public datasets/tasks, we compose a\ntransferable Generally Good Strategy (GGS), which has a strong performance for\nother datasets. We also provide empirical analysis as a guide for the future\ndesign of CLS.\n","authors":["Baoyu Jing","Yansen Wang","Guoxin Sui","Jing Hong","Jingrui He","Yuqing Yang","Dongsheng Li","Kan Ren"],"pdf_url":"https://arxiv.org/pdf/2403.12641v3.pdf","comment":"Accepted by CIKM'2024. Fixed typos"},{"id":"http://arxiv.org/abs/2410.17796v1","updated":"2024-10-23T11:52:52Z","published":"2024-10-23T11:52:52Z","title":"A Comprehensive Analysis on the Learning Curve in Kernel Ridge\n  Regression","summary":"  This paper conducts a comprehensive study of the learning curves of kernel\nridge regression (KRR) under minimal assumptions. Our contributions are\nthree-fold: 1) we analyze the role of key properties of the kernel, such as its\nspectral eigen-decay, the characteristics of the eigenfunctions, and the\nsmoothness of the kernel; 2) we demonstrate the validity of the Gaussian\nEquivalent Property (GEP), which states that the generalization performance of\nKRR remains the same when the whitened features are replaced by standard\nGaussian vectors, thereby shedding light on the success of previous analyzes\nunder the Gaussian Design Assumption; 3) we derive novel bounds that improve\nover existing bounds across a broad range of setting such as (in)dependent\nfeature vectors and various combinations of eigen-decay rates in the\nover/underparameterized regimes.\n","authors":["Tin Sum Cheng","Aurelien Lucchi","Anastasis Kratsios","David Belius"],"pdf_url":"https://arxiv.org/pdf/2410.17796v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17792v1","updated":"2024-10-23T11:47:04Z","published":"2024-10-23T11:47:04Z","title":"Enhancing Federated Learning Convergence with Dynamic Data Queue and\n  Data Entropy-driven Participant Selection","summary":"  Federated Learning (FL) is a decentralized approach for collaborative model\ntraining on edge devices. This distributed method of model training offers\nadvantages in privacy, security, regulatory compliance, and cost-efficiency.\nOur emphasis in this research lies in addressing statistical complexity in FL,\nespecially when the data stored locally across devices is not identically and\nindependently distributed (non-IID). We have observed an accuracy reduction of\nup to approximately 10\\% to 30\\%, particularly in skewed scenarios where each\nedge device trains with only 1 class of data. This reduction is attributed to\nweight divergence, quantified using the Euclidean distance between device-level\nclass distributions and the population distribution, resulting in a bias term\n(\\(\\delta_k\\)). As a solution, we present a method to improve convergence in FL\nby creating a global subset of data on the server and dynamically distributing\nit across devices using a Dynamic Data queue-driven Federated Learning (DDFL).\nNext, we leverage Data Entropy metrics to observe the process during each\ntraining round and enable reasonable device selection for aggregation.\nFurthermore, we provide a convergence analysis of our proposed DDFL to justify\ntheir viability in practical FL scenarios, aiming for better device selection,\na non-sub-optimal global model, and faster convergence. We observe that our\napproach results in a substantial accuracy boost of approximately 5\\% for the\nMNIST dataset, around 18\\% for CIFAR-10, and 20\\% for CIFAR-100 with a 10\\%\nglobal subset of data, outperforming the state-of-the-art (SOTA) aggregation\nalgorithms.\n","authors":["Charuka Herath","Xiaolan Liu","Sangarapillai Lambotharan","Yogachandran Rahulamathavan"],"pdf_url":"https://arxiv.org/pdf/2410.17792v1.pdf","comment":"The Journal is submitted to IEEE Transactions in the Internet of\n  Things"},{"id":"http://arxiv.org/abs/2410.17787v1","updated":"2024-10-23T11:37:20Z","published":"2024-10-23T11:37:20Z","title":"Large Language Models Engineer Too Many Simple Features For Tabular Data","summary":"  Tabular machine learning problems often require time-consuming and\nlabor-intensive feature engineering. Recent efforts have focused on using large\nlanguage models (LLMs) to capitalize on their potential domain knowledge. At\nthe same time, researchers have observed ethically concerning negative biases\nin other LLM-related use cases, such as text generation. These developments\nmotivated us to investigate whether LLMs exhibit a bias that negatively impacts\nthe performance of feature engineering. While not ethically concerning, such a\nbias could hinder practitioners from fully utilizing LLMs for automated data\nscience. Therefore, we propose a method to detect potential biases by detecting\nanomalies in the frequency of operators (e.g., adding two features) suggested\nby LLMs when engineering new features. Our experiments evaluate the bias of\nfour LLMs, two big frontier and two small open-source models, across 27 tabular\ndatasets. Our results indicate that LLMs are biased toward simple operators,\nsuch as addition, and can fail to utilize more complex operators, such as\ngrouping followed by aggregations. Furthermore, the bias can negatively impact\nthe predictive performance when using LLM-generated features. Our results call\nfor mitigating bias when using LLMs for feature engineering.\n","authors":["Jaris Küken","Lennart Purucker","Frank Hutter"],"pdf_url":"https://arxiv.org/pdf/2410.17787v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.17772v1","updated":"2024-10-23T11:19:48Z","published":"2024-10-23T11:19:48Z","title":"Scaling Robot Policy Learning via Zero-Shot Labeling with Foundation\n  Models","summary":"  A central challenge towards developing robots that can relate human language\nto their perception and actions is the scarcity of natural language annotations\nin diverse robot datasets. Moreover, robot policies that follow natural\nlanguage instructions are typically trained on either templated language or\nexpensive human-labeled instructions, hindering their scalability. To this end,\nwe introduce NILS: Natural language Instruction Labeling for Scalability. NILS\nautomatically labels uncurated, long-horizon robot data at scale in a zero-shot\nmanner without any human intervention. NILS combines pretrained vision-language\nfoundation models in order to detect objects in a scene, detect object-centric\nchanges, segment tasks from large datasets of unlabelled interaction data and\nultimately label behavior datasets. Evaluations on BridgeV2, Fractal, and a\nkitchen play dataset show that NILS can autonomously annotate diverse robot\ndemonstrations of unlabeled and unstructured datasets while alleviating several\nshortcomings of crowdsourced human annotations, such as low data quality and\ndiversity. We use NILS to label over 115k trajectories obtained from over 430\nhours of robot data. We open-source our auto-labeling code and generated\nannotations on our website: http://robottasklabeling.github.io.\n","authors":["Nils Blank","Moritz Reuss","Marcel Rühle","Ömer Erdinç Yağmurlu","Fabian Wenzel","Oier Mees","Rudolf Lioutikov"],"pdf_url":"https://arxiv.org/pdf/2410.17772v1.pdf","comment":"Project Website at https://robottasklabeling.github.io/"},{"id":"http://arxiv.org/abs/2410.17770v1","updated":"2024-10-23T11:19:08Z","published":"2024-10-23T11:19:08Z","title":"Locating Information in Large Language Models via Random Matrix Theory","summary":"  As large language models (LLMs) become central to AI applications, gaining a\ndeeper understanding of their inner workings is increasingly important. In this\nwork, we analyze the weight matrices of pretrained transformer models --\nspecifically BERT and Llama -- using random matrix theory (RMT) as a\nzero-information hypothesis. While randomly initialized weights perfectly agree\nwith RMT predictions, deviations emerge after training, allowing us to locate\nlearned structures within the models. We identify layer-type specific behaviors\nthat are consistent across all blocks and architectures considered. By\npinpointing regions that deviate from RMT predictions, we highlight areas of\nfeature learning and confirm this through comparisons with the activation\ncovariance matrices of the corresponding layers. Our method provides a\ndiagnostic tool for identifying relevant regions in transformer weights using\nonly the trained matrices. Additionally, we address the ongoing debate\nregarding the significance of small singular values in the context of\nfine-tuning and alignment in LLMs. Our findings reveal that, after fine-tuning,\nsmall singular values play a crucial role in the models' capabilities,\nsuggesting that removing them in an already aligned transformer can be\ndetrimental, as it may compromise model alignment.\n","authors":["Max Staats","Matthias Thamm","Bernd Rosenow"],"pdf_url":"https://arxiv.org/pdf/2410.17770v1.pdf","comment":"17 pages, 14 figures"},{"id":"http://arxiv.org/abs/2410.17765v1","updated":"2024-10-23T11:06:36Z","published":"2024-10-23T11:06:36Z","title":"Faster Language Models with Better Multi-Token Prediction Using Tensor\n  Decomposition","summary":"  We propose a new model for multi-token prediction in transformers, aiming to\nenhance sampling efficiency without compromising accuracy. Motivated by recent\nwork that predicts the probabilities of subsequent tokens using multiple heads,\nwe connect this approach to rank-$1$ canonical tensor decomposition. By\ngeneralizing it to a rank-$r$ canonical probability decomposition, we develop\nan improved model that predicts multiple tokens simultaneously. This model can\nalso be interpreted as a mixture of experts, allowing us to leverage successful\ntechniques from that domain for efficient and robust training. Importantly, the\noverall overhead for training and sampling remains low. Our method demonstrates\nsignificant improvements in inference speed for both text and code generation\ntasks, proving particularly beneficial within the self-speculative decoding\nparadigm. It maintains its effectiveness across various model sizes and\ntraining epochs, highlighting its robustness and scalability.\n","authors":["Artem Basharin","Andrei Chertkov","Ivan Oseledets"],"pdf_url":"https://arxiv.org/pdf/2410.17765v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17764v1","updated":"2024-10-23T11:02:59Z","published":"2024-10-23T11:02:59Z","title":"Beyond Backpropagation: Optimization with Multi-Tangent Forward\n  Gradients","summary":"  The gradients used to train neural networks are typically computed using\nbackpropagation. While an efficient way to obtain exact gradients,\nbackpropagation is computationally expensive, hinders parallelization, and is\nbiologically implausible. Forward gradients are an approach to approximate the\ngradients from directional derivatives along random tangents computed by\nforward-mode automatic differentiation. So far, research has focused on using a\nsingle tangent per step. This paper provides an in-depth analysis of\nmulti-tangent forward gradients and introduces an improved approach to\ncombining the forward gradients from multiple tangents based on orthogonal\nprojections. We demonstrate that increasing the number of tangents improves\nboth approximation quality and optimization performance across various tasks.\n","authors":["Katharina Flügel","Daniel Coquelin","Marie Weiel","Achim Streit","Markus Götz"],"pdf_url":"https://arxiv.org/pdf/2410.17764v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.12676v2","updated":"2024-10-23T11:01:45Z","published":"2023-12-20T00:31:43Z","title":"Bayesian Analysis of Combinatorial Gaussian Process Bandits","summary":"  We consider the combinatorial volatile Gaussian process (GP) semi-bandit\nproblem. Each round, an agent is provided a set of available base arms and must\nselect a subset of them to maximize the long-term cumulative reward. We study\nthe Bayesian setting and provide novel Bayesian cumulative regret bounds for\nthree GP-based algorithms: GP-UCB, GP-BayesUCB and GP-TS. Our bounds extend\nprevious results for GP-UCB and GP-TS to the infinite, volatile and\ncombinatorial setting, and to the best of our knowledge, we provide the first\nregret bound for GP-BayesUCB. Volatile arms encompass other widely considered\nbandit problems such as contextual bandits. Furthermore, we employ our\nframework to address the challenging real-world problem of online\nenergy-efficient navigation, where we demonstrate its effectiveness compared to\nthe alternatives.\n","authors":["Jack Sandberg","Niklas Åkerblom","Morteza Haghir Chehreghani"],"pdf_url":"https://arxiv.org/pdf/2312.12676v2.pdf","comment":"32 pages, 10 figures"},{"id":"http://arxiv.org/abs/2410.17762v1","updated":"2024-10-23T11:01:39Z","published":"2024-10-23T11:01:39Z","title":"Anomaly Resilient Temporal QoS Prediction using Hypergraph Convoluted\n  Transformer Network","summary":"  Quality-of-Service (QoS) prediction is a critical task in the service\nlifecycle, enabling precise and adaptive service recommendations by\nanticipating performance variations over time in response to evolving network\nuncertainties and user preferences. However, contemporary QoS prediction\nmethods frequently encounter data sparsity and cold-start issues, which hinder\naccurate QoS predictions and limit the ability to capture diverse user\npreferences. Additionally, these methods often assume QoS data reliability,\nneglecting potential credibility issues such as outliers and the presence of\ngreysheep users and services with atypical invocation patterns. Furthermore,\ntraditional approaches fail to leverage diverse features, including\ndomain-specific knowledge and complex higher-order patterns, essential for\naccurate QoS predictions. In this paper, we introduce a real-time, trust-aware\nframework for temporal QoS prediction to address the aforementioned challenges,\nfeaturing an end-to-end deep architecture called the Hypergraph Convoluted\nTransformer Network (HCTN). HCTN combines a hypergraph structure with graph\nconvolution over hyper-edges to effectively address high-sparsity issues by\ncapturing complex, high-order correlations. Complementing this, the transformer\nnetwork utilizes multi-head attention along with parallel 1D convolutional\nlayers and fully connected dense blocks to capture both fine-grained and\ncoarse-grained dynamic patterns. Additionally, our approach includes a\nsparsity-resilient solution for detecting greysheep users and services,\nincorporating their unique characteristics to improve prediction accuracy.\nTrained with a robust loss function resistant to outliers, HCTN demonstrated\nstate-of-the-art performance on the large-scale WSDREAM-2 datasets for response\ntime and throughput.\n","authors":["Suraj Kumar","Soumi Chattopadhyay","Chandranath Adak"],"pdf_url":"https://arxiv.org/pdf/2410.17762v1.pdf","comment":"16 pages, 12 figures"},{"id":"http://arxiv.org/abs/2410.17760v1","updated":"2024-10-23T10:56:05Z","published":"2024-10-23T10:56:05Z","title":"Topology meets Machine Learning: An Introduction using the Euler\n  Characteristic Transform","summary":"  This overview article makes the case for how topological concepts can enrich\nresearch in machine learning. Using the Euler Characteristic Transform (ECT), a\ngeometrical-topological invariant, as a running example, I present different\nuse cases that result in more efficient models for analyzing point clouds,\ngraphs, and meshes. Moreover, I outline a vision for how topological concepts\ncould be used in the future, comprising (1) the learning of functions on\ntopological spaces, (2) the building of hybrid models that imbue neural\nnetworks with knowledge about the topological information in data, and (3) the\nanalysis of qualitative properties of neural networks. With current research\nalready addressing some of these aspects, this article thus serves as an\nintroduction and invitation to this nascent area of research.\n","authors":["Bastian Rieck"],"pdf_url":"https://arxiv.org/pdf/2410.17760v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17758v1","updated":"2024-10-23T10:50:07Z","published":"2024-10-23T10:50:07Z","title":"Escaping the Forest: Sparse Interpretable Neural Networks for Tabular\n  Data","summary":"  Tabular datasets are widely used in scientific disciplines such as biology.\nWhile these disciplines have already adopted AI methods to enhance their\nfindings and analysis, they mainly use tree-based methods due to their\ninterpretability. At the same time, artificial neural networks have been shown\nto offer superior flexibility and depth for rich and complex non-tabular\nproblems, but they are falling behind tree-based models for tabular data in\nterms of performance and interpretability. Although sparsity has been shown to\nimprove the interpretability and performance of ANN models for complex\nnon-tabular datasets, enforcing sparsity structurally and formatively for\ntabular data before training the model, remains an open question. To address\nthis question, we establish a method that infuses sparsity in neural networks\nby utilising attention mechanisms to capture the features' importance in\ntabular datasets. We show that our models, Sparse TABular NET or sTAB-Net with\nattention mechanisms, are more effective than tree-based models, reaching the\nstate-of-the-art on biological datasets. They further permit the extraction of\ninsights from these datasets and achieve better performance than post-hoc\nmethods like SHAP.\n","authors":["Salvatore Raieli","Abdulrahman Altahhan","Nathalie Jeanray","Stéphane Gerart","Sebastien Vachenc"],"pdf_url":"https://arxiv.org/pdf/2410.17758v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.05549v3","updated":"2024-10-23T10:31:03Z","published":"2023-01-12T18:46:28Z","title":"On the explainability of quantum neural networks based on variational\n  quantum circuits","summary":"  Ridge functions are used to describe and study the lower bound of the\napproximation done by the neural networks which can be written as a linear\ncombination of activation functions. If the activation functions are also ridge\nfunctions, these networks are called explainable neural networks.\n  In this brief paper, we first show that quantum neural networks which are\nbased on variational quantum circuits can be written as a linear combination of\nridge functions by following matrix notations. Consequently, we show that the\ninterpretability and explainability of such quantum neural networks can be\ndirectly considered and studied as an approximation with the linear combination\nof ridge functions.\n","authors":["Ammar Daskin"],"pdf_url":"https://arxiv.org/pdf/2301.05549v3.pdf","comment":"a brief paper,a few missing references have been added"}]},"2024-10-24T00:00:00Z":{"Robotics":[{"id":"http://arxiv.org/abs/2405.08310v4","updated":"2024-10-24T01:38:42Z","published":"2024-05-14T04:23:44Z","title":"Cross-Category Functional Grasp Transfer","summary":"  Generating grasps for a dexterous hand often requires numerous grasping\nannotations. However, annotating high DoF dexterous hand poses is quite\nchallenging. Especially for functional grasps, requiring the hand to grasp the\nobject in a specific pose to facilitate subsequent manipulations. This prompts\nus to explore how people achieve manipulations on new objects based on past\ngrasp experiences. We find that when grasping new items, people are adept at\ndiscovering and leveraging various similarities between objects, including\nshape, layout, and grasp type. Considering this, we analyze and collect\ngrasp-related similarity relationships among 51 common tool-like object\ncategories and annotate semantic grasp representation for 1768 objects. These\nobjects are connected through similarities to form a knowledge graph, which\nhelps infer our proposed cross-category functional grasp synthesis. Through\nextensive experiments, we demonstrate that the grasp-related knowledge indeed\ncontributed to achieving functional grasp transfer across unknown or entirely\nnew categories of objects.\n","authors":["Rina Wu","Tianqiang Zhu","Xiangbo Lin","Yi Sun"],"pdf_url":"https://arxiv.org/pdf/2405.08310v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16821v2","updated":"2024-10-24T00:55:09Z","published":"2024-10-22T08:48:48Z","title":"Guiding Reinforcement Learning with Incomplete System Dynamics","summary":"  Model-free reinforcement learning (RL) is inherently a reactive method,\noperating under the assumption that it starts with no prior knowledge of the\nsystem and entirely depends on trial-and-error for learning. This approach\nfaces several challenges, such as poor sample efficiency, generalization, and\nthe need for well-designed reward functions to guide learning effectively. On\nthe other hand, controllers based on complete system dynamics do not require\ndata. This paper addresses the intermediate situation where there is not enough\nmodel information for complete controller design, but there is enough to\nsuggest that a model-free approach is not the best approach either. By\ncarefully decoupling known and unknown information about the system dynamics,\nwe obtain an embedded controller guided by our partial model and thus improve\nthe learning efficiency of an RL-enhanced approach. A modular design allows us\nto deploy mainstream RL algorithms to refine the policy. Simulation results\nshow that our method significantly improves sample efficiency compared with\nstandard RL methods on continuous control tasks, and also offers enhanced\nperformance over traditional control approaches. Experiments on a real ground\nvehicle also validate the performance of our method, including generalization\nand robustness.\n","authors":["Shuyuan Wang","Jingliang Duan","Nathan P. Lawrence","Philip D. Loewen","Michael G. Forbes","R. Bhushan Gopaluni","Lixian Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.16821v2.pdf","comment":"Accepted to IROS 2024"}]}}